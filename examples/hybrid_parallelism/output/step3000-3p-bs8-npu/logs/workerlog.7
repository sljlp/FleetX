/home/gongwb/.local/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0712 16:56:03.228435 48466 init.cc:88] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=check_nan_inf,benchmark,eager_delete_scope,fraction_of_cpu_memory_to_use,initial_cpu_memory_in_mb,init_allocated_mem,paddle_num_threads,dist_threadpool_size,eager_delete_tensor_gb,fast_eager_deletion_mode,memory_fraction_of_eager_deletion,allocator_strategy,reader_queue_speed_test_mode,print_sub_graph_dir,pe_profile_fname,inner_op_parallelism,enable_parallel_graph,fuse_parameter_groups_size,multiple_of_cupti_buffer_size,fuse_parameter_memory_size,tracer_profile_fname,dygraph_debug,use_system_allocator,enable_unused_var_check,free_idle_chunk,free_when_no_cache_hit,call_stack_level,sort_sum_gradient,max_inplace_grad_add,use_pinned_memory,cpu_deterministic,selected_npus,fraction_of_gpu_memory_to_use,initial_gpu_memory_in_mb,reallocate_gpu_memory_in_mb,gpu_memory_limit_mb 
I0712 16:56:03.228633 48466 init.cc:95] After Parse: argc is 1
-----------  Configuration Arguments -----------
data_dir: ./data
debug: False
do_eval: True
epoch: 100
ernie_config_file: config/ernie_base_config.json
eval_batch_size: 35
eval_data_path: ./data
eval_steps: -1
global_bsz: 8
global_steps: 0
grad_merge: 0
init_checkpoint: 
learning_rate: 0.0001
log_steps: 1
max_seq_len: 512
micro_bsz: 1
num_dp: 2
num_mp: 2
num_pp: 2
num_sharding: 1
num_train_steps: 3000
output_dir: output/step3000-3p-bs8-npu
preln: False
save_steps: 4000
seed: 2021
use_amp: True
use_hybrid_dp: True
use_lamb: False
use_offload: False
use_recompute: True
use_sharding: True
vocab_file: ./config/30k-clean.vocab.albert
warmup_steps: 10000
weight_decay: 0.01
------------------------------------------------
to run startup
[INFO] 2021-07-12 16:56:03,959 [run_pretraining.py:  216]:	pretraining start
[INFO] 2021-07-12 16:56:03,960 [run_pretraining.py:  234]:	using recompute.
[INFO] 2021-07-12 16:56:03,960 [run_pretraining.py:  279]:	using globa_bsz: 8 micro_bsz: 1, acc_steps: 4
[DEBUG] 2021-07-12 16:56:04,024 [run_pretraining.py:  118]:	========= dp_sharding worker: 1 of 2 ==========
[INFO] 2021-07-12 16:56:04,024 [pretraining_ds_mlm.py:  289]:	Apply sharding in distribution env 1/2
[INFO] 2021-07-12 16:56:04,024 [pretraining_ds_mlm.py:  291]:	read from ./data/part-00000.100,./data/part-00000.103,./data/part-00000.105,./data/part-00000.102,./data/part-00000.109
I0712 16:56:04.025218 48466 reader_py.cc:387] init_lod_tensor_blocking_queue
INFO:root:places would be ommited when DataLoader is not iterable
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:158
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/ernie.py:159
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:170
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:280
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:43
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/fluid/layers/math_op_patch.py:320: UserWarning: /home/liupeng51/github/FleetX/examples/hybrid_parallelism/model/transformer_encoder.py:44
The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
[DEBUG] 2021-07-12 16:56:04,831 [run_pretraining.py:  315]:	base lr: 0.0001
/home/liupeng51/github/Paddle/build/build_ubuntu_develop_release_ascend_y_none_3.7.5/python/paddle/distributed/fleet/base/fleet_base.py:818: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
2021-07-12 16:56:04 INFO     Gradient merge in [pp_gm], acc step = [4]
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Gradient merge in [pp_gm], acc step = [4]
Mon Jul 12 16:56:05-INFO: recompute segment[0]
Mon Jul 12 16:56:05-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Mon Jul 12 16:56:05-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Mon Jul 12 16:56:05-INFO: recompute segment[0]
Mon Jul 12 16:56:05-INFO: segment start op: [squeeze2]: [['shard_index_0.tmp_0']]
Mon Jul 12 16:56:05-INFO: segment end op: [layer_norm]: [['encoder_layer_0_post_ffn_layer_norm_bias', 'encoder_layer_0_post_ffn_layer_norm_scale', 'tmp_10']]
Mon Jul 12 16:56:05-INFO: found [0] vars which cross recompute segment: [set()], better checkpoints might be set to reduce those vars
pp_rank: 1
2021-07-12 16:56:10 INFO     Hybrid DP mode turn on !
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:Hybrid DP mode turn on !
2021-07-12 16:56:10 INFO     global word size: 8
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global word size: 8
2021-07-12 16:56:10 INFO     global rank: 7
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global rank: 7
2021-07-12 16:56:10 INFO     global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global endpoints: ['192.168.206.27:6170', '192.168.206.27:6171', '192.168.206.27:6172', '192.168.206.27:6173', '192.168.206.27:6174', '192.168.206.27:6175', '192.168.206.27:6176', '192.168.206.27:6177']
2021-07-12 16:56:10 INFO     global ring id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:global ring id: 3
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     mp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group size: 2
2021-07-12 16:56:10 INFO     mp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp rank: 1
2021-07-12 16:56:10 INFO     mp group id: 3
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group id: 3
2021-07-12 16:56:10 INFO     mp group endpoints: ['192.168.206.27:6176', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp group endpoints: ['192.168.206.27:6176', '192.168.206.27:6177']
2021-07-12 16:56:10 INFO     mp ring id: 0
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:mp ring id: 0
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     sharding group size: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group size: 1
2021-07-12 16:56:10 INFO     sharding rank: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding rank: -1
2021-07-12 16:56:10 INFO     sharding group id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group id: -1
2021-07-12 16:56:10 INFO     sharding group endpoints: []
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding group endpoints: []
2021-07-12 16:56:10 INFO     sharding ring id: -1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:sharding ring id: -1
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     pp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group size: 2
2021-07-12 16:56:10 INFO     pp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp rank: 1
2021-07-12 16:56:10 INFO     pp group id: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group id: 1
2021-07-12 16:56:10 INFO     pp group endpoints: ['192.168.206.27:6175', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp group endpoints: ['192.168.206.27:6175', '192.168.206.27:6177']
2021-07-12 16:56:10 INFO     pp ring id: 20
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pp ring id: 20
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
2021-07-12 16:56:10 INFO     pure dp group size: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group size: 2
2021-07-12 16:56:10 INFO     pure dp rank: 1
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp rank: 1
2021-07-12 16:56:10 INFO     pure dp group endpoints: ['192.168.206.27:6173', '192.168.206.27:6177']
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp group endpoints: ['192.168.206.27:6173', '192.168.206.27:6177']
2021-07-12 16:56:10 INFO     pure dp ring id: 2
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:pure dp ring id: 2
2021-07-12 16:56:10 INFO     ##############################
INFO:paddle.distributed.fleet.meta_optimizers.sharding_optimizer:##############################
pp pair:(0, 1), ring_id: 20
pp pair:(1, 0), ring_id: 21
I0712 16:56:31.029923 48466 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6177 successful.
I0712 16:56:31.352085 48466 collective_helper_npu.cc:83] initialized comm: 0xffffee3ee990, nranks: 8, hccl_id: 0xea8b084, rank: 7
I0712 16:56:34.793270 48466 collective_helper_npu.cc:88] initialized comm: 0xffffee3ee990, nranks: 8, hccl_id: 0xea8b084, rank: 7
I0712 16:56:34.793458 48466 collective_helper_npu.cc:93] hccl communicator of rank 7 in ring 3 has been created on device 7, with comm: 0xea50df0
I0712 16:56:36.120052 48466 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6177 successful.
I0712 16:56:36.121060 48466 collective_helper_npu.cc:83] initialized comm: 0xffffee3ee990, nranks: 2, hccl_id: 0xea99344, rank: 1
I0712 16:56:37.347558 48466 collective_helper_npu.cc:88] initialized comm: 0xffffee3ee990, nranks: 2, hccl_id: 0xea99344, rank: 1
I0712 16:56:37.350750 48466 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 0 has been created on device 7, with comm: 0xe8c0190
I0712 16:56:37.670311 48466 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6177 successful.
I0712 16:56:37.671195 48466 collective_helper_npu.cc:83] initialized comm: 0xffffee3ee990, nranks: 2, hccl_id: 0xeaa3d34, rank: 1
I0712 16:56:38.886246 48466 collective_helper_npu.cc:88] initialized comm: 0xffffee3ee990, nranks: 2, hccl_id: 0xeaa3d34, rank: 1
I0712 16:56:38.886430 48466 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 20 has been created on device 7, with comm: 0xea37bc0
I0712 16:56:39.222151 48466 collective_helper_npu.cc:83] initialized comm: 0xffffee3ee990, nranks: 2, hccl_id: 0xeaa6054, rank: 0
I0712 16:56:40.438089 48466 collective_helper_npu.cc:88] initialized comm: 0xffffee3ee990, nranks: 2, hccl_id: 0xeaa6054, rank: 0
I0712 16:56:40.438295 48466 collective_helper_npu.cc:93] hccl communicator of rank 0 in ring 21 has been created on device 7, with comm: 0xe8bb7b0
I0712 16:56:40.788249 48466 gen_hccl_id_op_helper.cc:181] Server listening on: 192.168.206.27:6177 successful.
I0712 16:56:41.193684 48466 collective_helper_npu.cc:83] initialized comm: 0xffffee3ee990, nranks: 2, hccl_id: 0xe9afb24, rank: 1
I0712 16:56:42.608085 48466 collective_helper_npu.cc:88] initialized comm: 0xffffee3ee990, nranks: 2, hccl_id: 0xe9afb24, rank: 1
I0712 16:56:42.608280 48466 collective_helper_npu.cc:93] hccl communicator of rank 1 in ring 2 has been created on device 7, with comm: 0xea89560
Done broadcast
[INFO] 2021-07-12 16:56:43,035 [run_pretraining.py:  512]:	********exe.run_0******* 
I0712 16:56:45.852128 51985 lod_tensor_blocking_queue.h:104] Init queue with size 1
I0712 16:56:45.852330 51985 buffered_reader.cc:41] BufferedReader
[INFO] 2021-07-12 17:00:09,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:00:09,936 [run_pretraining.py:  534]:	loss/total_loss, 10.445125579833984, 1
[INFO] 2021-07-12 17:00:09,936 [run_pretraining.py:  535]:	loss/mlm_loss, 10.445125579833984, 1
[INFO] 2021-07-12 17:00:09,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 0.0, 1
[INFO] 2021-07-12 17:00:09,936 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 1
[INFO] 2021-07-12 17:00:09,936 [run_pretraining.py:  558]:	worker_index: 7, step: 1, cost: 10.445126, mlm loss: 10.445126, speed: 0.004833 steps/s, speed: 0.038666 samples/s, speed: 19.796849 tokens/s, learning rate: 0.000e+00, loss_scalings: 32768.000000, pp_loss: 10.438354
[INFO] 2021-07-12 17:00:09,936 [run_pretraining.py:  512]:	********exe.run_1******* 
[INFO] 2021-07-12 17:01:50,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:01:50,858 [run_pretraining.py:  534]:	loss/total_loss, 10.517101287841797, 2
[INFO] 2021-07-12 17:01:50,859 [run_pretraining.py:  535]:	loss/mlm_loss, 10.517101287841797, 2
[INFO] 2021-07-12 17:01:50,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.99999905104687e-09, 2
[INFO] 2021-07-12 17:01:50,859 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 2
[INFO] 2021-07-12 17:01:50,859 [run_pretraining.py:  558]:	worker_index: 7, step: 2, cost: 10.517101, mlm loss: 10.517101, speed: 0.009909 steps/s, speed: 0.079269 samples/s, speed: 40.585870 tokens/s, learning rate: 1.000e-08, loss_scalings: 32768.000000, pp_loss: 9.328709
[INFO] 2021-07-12 17:01:50,859 [run_pretraining.py:  512]:	********exe.run_2******* 
[INFO] 2021-07-12 17:03:30,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:03:30,519 [run_pretraining.py:  534]:	loss/total_loss, 10.267779350280762, 3
[INFO] 2021-07-12 17:03:30,519 [run_pretraining.py:  535]:	loss/mlm_loss, 10.267779350280762, 3
[INFO] 2021-07-12 17:03:30,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.999999810209374e-08, 3
[INFO] 2021-07-12 17:03:30,519 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 3
[INFO] 2021-07-12 17:03:30,520 [run_pretraining.py:  558]:	worker_index: 7, step: 3, cost: 10.267779, mlm loss: 10.267779, speed: 0.010034 steps/s, speed: 0.080273 samples/s, speed: 41.099760 tokens/s, learning rate: 2.000e-08, loss_scalings: 32768.000000, pp_loss: 10.433286
[INFO] 2021-07-12 17:03:30,520 [run_pretraining.py:  512]:	********exe.run_3******* 
[INFO] 2021-07-12 17:05:10,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:05:10,865 [run_pretraining.py:  534]:	loss/total_loss, 10.529485702514648, 4
[INFO] 2021-07-12 17:05:10,866 [run_pretraining.py:  535]:	loss/mlm_loss, 10.529485702514648, 4
[INFO] 2021-07-12 17:05:10,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.999999892949745e-08, 4
[INFO] 2021-07-12 17:05:10,866 [run_pretraining.py:  539]:	lr/loss_scaling, 32768.0, 4
[INFO] 2021-07-12 17:05:10,866 [run_pretraining.py:  558]:	worker_index: 7, step: 4, cost: 10.529486, mlm loss: 10.529486, speed: 0.009966 steps/s, speed: 0.079724 samples/s, speed: 40.818921 tokens/s, learning rate: 3.000e-08, loss_scalings: 32768.000000, pp_loss: 10.479538
[INFO] 2021-07-12 17:05:10,866 [run_pretraining.py:  512]:	********exe.run_4******* 
[INFO] 2021-07-12 17:06:52,489 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  534]:	loss/total_loss, 10.47780704498291, 5
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  535]:	loss/mlm_loss, 10.47780704498291, 5
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999620418748e-08, 5
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 5
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  558]:	worker_index: 7, step: 5, cost: 10.477807, mlm loss: 10.477807, speed: 0.009840 steps/s, speed: 0.078722 samples/s, speed: 40.305518 tokens/s, learning rate: 4.000e-08, loss_scalings: 26214.400391, pp_loss: 10.483012
[INFO] 2021-07-12 17:06:52,490 [run_pretraining.py:  512]:	********exe.run_5******* 
[INFO] 2021-07-12 17:08:33,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:08:33,482 [run_pretraining.py:  534]:	loss/total_loss, 10.376049995422363, 6
[INFO] 2021-07-12 17:08:33,483 [run_pretraining.py:  535]:	loss/mlm_loss, 10.376049995422363, 6
[INFO] 2021-07-12 17:08:33,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.000000058430487e-08, 6
[INFO] 2021-07-12 17:08:33,483 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 6
[INFO] 2021-07-12 17:08:33,483 [run_pretraining.py:  558]:	worker_index: 7, step: 6, cost: 10.376050, mlm loss: 10.376050, speed: 0.009902 steps/s, speed: 0.079214 samples/s, speed: 40.557768 tokens/s, learning rate: 5.000e-08, loss_scalings: 26214.400391, pp_loss: 10.427780
[INFO] 2021-07-12 17:08:33,483 [run_pretraining.py:  512]:	********exe.run_6******* 
[INFO] 2021-07-12 17:10:13,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:10:13,737 [run_pretraining.py:  534]:	loss/total_loss, 10.34471321105957, 7
[INFO] 2021-07-12 17:10:13,737 [run_pretraining.py:  535]:	loss/mlm_loss, 10.34471321105957, 7
[INFO] 2021-07-12 17:10:13,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.99999978589949e-08, 7
[INFO] 2021-07-12 17:10:13,738 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 7
[INFO] 2021-07-12 17:10:13,738 [run_pretraining.py:  558]:	worker_index: 7, step: 7, cost: 10.344713, mlm loss: 10.344713, speed: 0.009975 steps/s, speed: 0.079797 samples/s, speed: 40.856171 tokens/s, learning rate: 6.000e-08, loss_scalings: 26214.400391, pp_loss: 10.324240
[INFO] 2021-07-12 17:10:13,738 [run_pretraining.py:  512]:	********exe.run_7******* 
[INFO] 2021-07-12 17:11:53,681 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:11:53,682 [run_pretraining.py:  534]:	loss/total_loss, 10.368057250976562, 8
[INFO] 2021-07-12 17:11:53,682 [run_pretraining.py:  535]:	loss/mlm_loss, 10.368057250976562, 8
[INFO] 2021-07-12 17:11:53,682 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-08, 8
[INFO] 2021-07-12 17:11:53,682 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 8
[INFO] 2021-07-12 17:11:53,682 [run_pretraining.py:  558]:	worker_index: 7, step: 8, cost: 10.368057, mlm loss: 10.368057, speed: 0.010006 steps/s, speed: 0.080045 samples/s, speed: 40.983060 tokens/s, learning rate: 7.000e-08, loss_scalings: 26214.400391, pp_loss: 10.440754
[INFO] 2021-07-12 17:11:53,682 [run_pretraining.py:  512]:	********exe.run_8******* 
[INFO] 2021-07-12 17:13:32,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:13:32,354 [run_pretraining.py:  534]:	loss/total_loss, 10.41706657409668, 9
[INFO] 2021-07-12 17:13:32,354 [run_pretraining.py:  535]:	loss/mlm_loss, 10.41706657409668, 9
[INFO] 2021-07-12 17:13:32,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999240837496e-08, 9
[INFO] 2021-07-12 17:13:32,354 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 9
[INFO] 2021-07-12 17:13:32,354 [run_pretraining.py:  558]:	worker_index: 7, step: 9, cost: 10.417067, mlm loss: 10.417067, speed: 0.010135 steps/s, speed: 0.081077 samples/s, speed: 41.511493 tokens/s, learning rate: 8.000e-08, loss_scalings: 26214.400391, pp_loss: 10.434383
[INFO] 2021-07-12 17:13:32,355 [run_pretraining.py:  512]:	********exe.run_9******* 
[INFO] 2021-07-12 17:15:11,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:15:11,283 [run_pretraining.py:  534]:	loss/total_loss, 10.396039962768555, 10
[INFO] 2021-07-12 17:15:11,284 [run_pretraining.py:  535]:	loss/mlm_loss, 10.396039962768555, 10
[INFO] 2021-07-12 17:15:11,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.999999323577867e-08, 10
[INFO] 2021-07-12 17:15:11,284 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 10
[INFO] 2021-07-12 17:15:11,284 [run_pretraining.py:  558]:	worker_index: 7, step: 10, cost: 10.396040, mlm loss: 10.396040, speed: 0.010108 steps/s, speed: 0.080866 samples/s, speed: 41.403585 tokens/s, learning rate: 9.000e-08, loss_scalings: 26214.400391, pp_loss: 10.413338
[INFO] 2021-07-12 17:15:11,284 [run_pretraining.py:  512]:	********exe.run_10******* 
[INFO] 2021-07-12 17:16:00,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:16:00,915 [run_pretraining.py:  534]:	loss/total_loss, 10.375444412231445, 11
[INFO] 2021-07-12 17:16:00,915 [run_pretraining.py:  535]:	loss/mlm_loss, 10.375444412231445, 11
[INFO] 2021-07-12 17:16:00,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0000000116860974e-07, 11
[INFO] 2021-07-12 17:16:00,916 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 11
[INFO] 2021-07-12 17:16:00,916 [run_pretraining.py:  558]:	worker_index: 7, step: 11, cost: 10.375444, mlm loss: 10.375444, speed: 0.020149 steps/s, speed: 0.161189 samples/s, speed: 82.528717 tokens/s, learning rate: 1.000e-07, loss_scalings: 26214.400391, pp_loss: 10.406864
[INFO] 2021-07-12 17:16:00,916 [run_pretraining.py:  512]:	********exe.run_11******* 
[INFO] 2021-07-12 17:17:35,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:17:35,444 [run_pretraining.py:  534]:	loss/total_loss, 10.476089477539062, 12
[INFO] 2021-07-12 17:17:35,444 [run_pretraining.py:  535]:	loss/mlm_loss, 10.476089477539062, 12
[INFO] 2021-07-12 17:17:35,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.099999948905861e-07, 12
[INFO] 2021-07-12 17:17:35,444 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 12
[INFO] 2021-07-12 17:17:35,444 [run_pretraining.py:  558]:	worker_index: 7, step: 12, cost: 10.476089, mlm loss: 10.476089, speed: 0.010579 steps/s, speed: 0.084632 samples/s, speed: 43.331333 tokens/s, learning rate: 1.100e-07, loss_scalings: 26214.400391, pp_loss: 10.422281
[INFO] 2021-07-12 17:17:35,444 [run_pretraining.py:  512]:	********exe.run_12******* 
[INFO] 2021-07-12 17:18:51,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:18:51,094 [run_pretraining.py:  534]:	loss/total_loss, 10.391823768615723, 13
[INFO] 2021-07-12 17:18:51,094 [run_pretraining.py:  535]:	loss/mlm_loss, 10.391823768615723, 13
[INFO] 2021-07-12 17:18:51,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.199999957179898e-07, 13
[INFO] 2021-07-12 17:18:51,095 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 13
[INFO] 2021-07-12 17:18:51,095 [run_pretraining.py:  558]:	worker_index: 7, step: 13, cost: 10.391824, mlm loss: 10.391824, speed: 0.013219 steps/s, speed: 0.105750 samples/s, speed: 54.144077 tokens/s, learning rate: 1.200e-07, loss_scalings: 26214.400391, pp_loss: 10.382896
[INFO] 2021-07-12 17:18:51,095 [run_pretraining.py:  512]:	********exe.run_13******* 
[INFO] 2021-07-12 17:20:05,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:20:05,876 [run_pretraining.py:  534]:	loss/total_loss, 10.418133735656738, 14
[INFO] 2021-07-12 17:20:05,876 [run_pretraining.py:  535]:	loss/mlm_loss, 10.418133735656738, 14
[INFO] 2021-07-12 17:20:05,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000365082087e-07, 14
[INFO] 2021-07-12 17:20:05,876 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 14
[INFO] 2021-07-12 17:20:05,876 [run_pretraining.py:  558]:	worker_index: 7, step: 14, cost: 10.418134, mlm loss: 10.418134, speed: 0.013372 steps/s, speed: 0.106979 samples/s, speed: 54.773427 tokens/s, learning rate: 1.300e-07, loss_scalings: 26214.400391, pp_loss: 10.406833
[INFO] 2021-07-12 17:20:05,876 [run_pretraining.py:  512]:	********exe.run_14******* 
[INFO] 2021-07-12 17:21:43,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:21:43,848 [run_pretraining.py:  534]:	loss/total_loss, 10.433586120605469, 15
[INFO] 2021-07-12 17:21:43,848 [run_pretraining.py:  535]:	loss/mlm_loss, 10.433586120605469, 15
[INFO] 2021-07-12 17:21:43,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-07, 15
[INFO] 2021-07-12 17:21:43,848 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 15
[INFO] 2021-07-12 17:21:43,848 [run_pretraining.py:  558]:	worker_index: 7, step: 15, cost: 10.433586, mlm loss: 10.433586, speed: 0.010207 steps/s, speed: 0.081657 samples/s, speed: 41.808330 tokens/s, learning rate: 1.400e-07, loss_scalings: 26214.400391, pp_loss: 10.424534
[INFO] 2021-07-12 17:21:43,848 [run_pretraining.py:  512]:	********exe.run_15******* 
[INFO] 2021-07-12 17:22:59,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:22:59,156 [run_pretraining.py:  534]:	loss/total_loss, 10.308748245239258, 16
[INFO] 2021-07-12 17:22:59,156 [run_pretraining.py:  535]:	loss/mlm_loss, 10.308748245239258, 16
[INFO] 2021-07-12 17:22:59,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999109477358e-07, 16
[INFO] 2021-07-12 17:22:59,157 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 16
[INFO] 2021-07-12 17:22:59,157 [run_pretraining.py:  558]:	worker_index: 7, step: 16, cost: 10.308748, mlm loss: 10.308748, speed: 0.013279 steps/s, speed: 0.106230 samples/s, speed: 54.389927 tokens/s, learning rate: 1.500e-07, loss_scalings: 26214.400391, pp_loss: 10.378241
[INFO] 2021-07-12 17:22:59,157 [run_pretraining.py:  512]:	********exe.run_16******* 
[INFO] 2021-07-12 17:23:49,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:23:49,314 [run_pretraining.py:  534]:	loss/total_loss, 10.408365249633789, 17
[INFO] 2021-07-12 17:23:49,314 [run_pretraining.py:  535]:	loss/mlm_loss, 10.408365249633789, 17
[INFO] 2021-07-12 17:23:49,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999998481674993e-07, 17
[INFO] 2021-07-12 17:23:49,315 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 17
[INFO] 2021-07-12 17:23:49,315 [run_pretraining.py:  558]:	worker_index: 7, step: 17, cost: 10.408365, mlm loss: 10.408365, speed: 0.019937 steps/s, speed: 0.159498 samples/s, speed: 81.663037 tokens/s, learning rate: 1.600e-07, loss_scalings: 26214.400391, pp_loss: 10.433668
[INFO] 2021-07-12 17:23:49,315 [run_pretraining.py:  512]:	********exe.run_17******* 
[INFO] 2021-07-12 17:25:28,105 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:25:28,105 [run_pretraining.py:  534]:	loss/total_loss, 10.362347602844238, 18
[INFO] 2021-07-12 17:25:28,105 [run_pretraining.py:  535]:	loss/mlm_loss, 10.362347602844238, 18
[INFO] 2021-07-12 17:25:28,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.69999992749581e-07, 18
[INFO] 2021-07-12 17:25:28,106 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 18
[INFO] 2021-07-12 17:25:28,106 [run_pretraining.py:  558]:	worker_index: 7, step: 18, cost: 10.362348, mlm loss: 10.362348, speed: 0.010122 steps/s, speed: 0.080980 samples/s, speed: 41.461591 tokens/s, learning rate: 1.700e-07, loss_scalings: 26214.400391, pp_loss: 10.399511
[INFO] 2021-07-12 17:25:28,106 [run_pretraining.py:  512]:	********exe.run_18******* 
[INFO] 2021-07-12 17:27:03,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:27:03,453 [run_pretraining.py:  534]:	loss/total_loss, 10.456608772277832, 19
[INFO] 2021-07-12 17:27:03,453 [run_pretraining.py:  535]:	loss/mlm_loss, 10.456608772277832, 19
[INFO] 2021-07-12 17:27:03,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7999998647155735e-07, 19
[INFO] 2021-07-12 17:27:03,453 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 19
[INFO] 2021-07-12 17:27:03,454 [run_pretraining.py:  558]:	worker_index: 7, step: 19, cost: 10.456609, mlm loss: 10.456609, speed: 0.010488 steps/s, speed: 0.083904 samples/s, speed: 42.958775 tokens/s, learning rate: 1.800e-07, loss_scalings: 26214.400391, pp_loss: 10.361478
[INFO] 2021-07-12 17:27:03,454 [run_pretraining.py:  512]:	********exe.run_19******* 
[INFO] 2021-07-12 17:28:18,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:28:18,388 [run_pretraining.py:  534]:	loss/total_loss, 10.404756546020508, 20
[INFO] 2021-07-12 17:28:18,389 [run_pretraining.py:  535]:	loss/mlm_loss, 10.404756546020508, 20
[INFO] 2021-07-12 17:28:18,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999440438842e-07, 20
[INFO] 2021-07-12 17:28:18,389 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 20
[INFO] 2021-07-12 17:28:18,389 [run_pretraining.py:  558]:	worker_index: 7, step: 20, cost: 10.404757, mlm loss: 10.404757, speed: 0.013345 steps/s, speed: 0.106760 samples/s, speed: 54.661064 tokens/s, learning rate: 1.900e-07, loss_scalings: 26214.400391, pp_loss: 10.414680
[INFO] 2021-07-12 17:28:18,389 [run_pretraining.py:  512]:	********exe.run_20******* 
[INFO] 2021-07-12 17:29:07,966 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:29:07,967 [run_pretraining.py:  534]:	loss/total_loss, 10.403264999389648, 21
[INFO] 2021-07-12 17:29:07,967 [run_pretraining.py:  535]:	loss/mlm_loss, 10.403264999389648, 21
[INFO] 2021-07-12 17:29:07,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0000000233721948e-07, 21
[INFO] 2021-07-12 17:29:07,967 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 21
[INFO] 2021-07-12 17:29:07,967 [run_pretraining.py:  558]:	worker_index: 7, step: 21, cost: 10.403265, mlm loss: 10.403265, speed: 0.020170 steps/s, speed: 0.161364 samples/s, speed: 82.618237 tokens/s, learning rate: 2.000e-07, loss_scalings: 26214.400391, pp_loss: 10.419712
[INFO] 2021-07-12 17:29:07,967 [run_pretraining.py:  512]:	********exe.run_21******* 
[INFO] 2021-07-12 17:30:23,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:30:23,141 [run_pretraining.py:  534]:	loss/total_loss, 7.545193195343018, 22
[INFO] 2021-07-12 17:30:23,141 [run_pretraining.py:  535]:	loss/mlm_loss, 7.545193195343018, 22
[INFO] 2021-07-12 17:30:23,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998184834112e-07, 22
[INFO] 2021-07-12 17:30:23,141 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 22
[INFO] 2021-07-12 17:30:23,141 [run_pretraining.py:  558]:	worker_index: 7, step: 22, cost: 7.545193, mlm loss: 7.545193, speed: 0.013303 steps/s, speed: 0.106421 samples/s, speed: 54.487420 tokens/s, learning rate: 2.100e-07, loss_scalings: 26214.400391, pp_loss: 9.685627
[INFO] 2021-07-12 17:30:23,141 [run_pretraining.py:  512]:	********exe.run_22******* 
[INFO] 2021-07-12 17:32:00,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:32:00,396 [run_pretraining.py:  534]:	loss/total_loss, 10.357638359069824, 23
[INFO] 2021-07-12 17:32:00,396 [run_pretraining.py:  535]:	loss/mlm_loss, 10.357638359069824, 23
[INFO] 2021-07-12 17:32:00,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.199999897811722e-07, 23
[INFO] 2021-07-12 17:32:00,397 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 23
[INFO] 2021-07-12 17:32:00,397 [run_pretraining.py:  558]:	worker_index: 7, step: 23, cost: 10.357638, mlm loss: 10.357638, speed: 0.010282 steps/s, speed: 0.082258 samples/s, speed: 42.116088 tokens/s, learning rate: 2.200e-07, loss_scalings: 26214.400391, pp_loss: 10.395157
[INFO] 2021-07-12 17:32:00,397 [run_pretraining.py:  512]:	********exe.run_23******* 
[INFO] 2021-07-12 17:33:12,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:33:12,826 [run_pretraining.py:  534]:	loss/total_loss, 10.396308898925781, 24
[INFO] 2021-07-12 17:33:12,827 [run_pretraining.py:  535]:	loss/mlm_loss, 10.396308898925781, 24
[INFO] 2021-07-12 17:33:12,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2999999771400326e-07, 24
[INFO] 2021-07-12 17:33:12,827 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 24
[INFO] 2021-07-12 17:33:12,827 [run_pretraining.py:  558]:	worker_index: 7, step: 24, cost: 10.396309, mlm loss: 10.396309, speed: 0.013807 steps/s, speed: 0.110452 samples/s, speed: 56.551634 tokens/s, learning rate: 2.300e-07, loss_scalings: 26214.400391, pp_loss: 10.348850
[INFO] 2021-07-12 17:33:12,827 [run_pretraining.py:  512]:	********exe.run_24******* 
[INFO] 2021-07-12 17:34:27,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:34:27,411 [run_pretraining.py:  534]:	loss/total_loss, 6.1993088722229, 25
[INFO] 2021-07-12 17:34:27,411 [run_pretraining.py:  535]:	loss/mlm_loss, 6.1993088722229, 25
[INFO] 2021-07-12 17:34:27,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.399999914359796e-07, 25
[INFO] 2021-07-12 17:34:27,411 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 25
[INFO] 2021-07-12 17:34:27,412 [run_pretraining.py:  558]:	worker_index: 7, step: 25, cost: 6.199309, mlm loss: 6.199309, speed: 0.013408 steps/s, speed: 0.107262 samples/s, speed: 54.917892 tokens/s, learning rate: 2.400e-07, loss_scalings: 26214.400391, pp_loss: 9.342001
[INFO] 2021-07-12 17:34:27,412 [run_pretraining.py:  512]:	********exe.run_25******* 
[INFO] 2021-07-12 17:36:04,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:36:04,248 [run_pretraining.py:  534]:	loss/total_loss, 10.304071426391602, 26
[INFO] 2021-07-12 17:36:04,248 [run_pretraining.py:  535]:	loss/mlm_loss, 10.304071426391602, 26
[INFO] 2021-07-12 17:36:04,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999993688107e-07, 26
[INFO] 2021-07-12 17:36:04,248 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 26
[INFO] 2021-07-12 17:36:04,248 [run_pretraining.py:  558]:	worker_index: 7, step: 26, cost: 10.304071, mlm loss: 10.304071, speed: 0.010327 steps/s, speed: 0.082614 samples/s, speed: 42.298383 tokens/s, learning rate: 2.500e-07, loss_scalings: 26214.400391, pp_loss: 10.397598
[INFO] 2021-07-12 17:36:04,248 [run_pretraining.py:  512]:	********exe.run_26******* 
[INFO] 2021-07-12 17:37:41,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:37:41,328 [run_pretraining.py:  534]:	loss/total_loss, 10.55246353149414, 27
[INFO] 2021-07-12 17:37:41,328 [run_pretraining.py:  535]:	loss/mlm_loss, 10.55246353149414, 27
[INFO] 2021-07-12 17:37:41,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000730164174e-07, 27
[INFO] 2021-07-12 17:37:41,328 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 27
[INFO] 2021-07-12 17:37:41,328 [run_pretraining.py:  558]:	worker_index: 7, step: 27, cost: 10.552464, mlm loss: 10.552464, speed: 0.010301 steps/s, speed: 0.082407 samples/s, speed: 42.192351 tokens/s, learning rate: 2.600e-07, loss_scalings: 26214.400391, pp_loss: 10.447516
[INFO] 2021-07-12 17:37:41,328 [run_pretraining.py:  512]:	********exe.run_27******* 
[INFO] 2021-07-12 17:38:32,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:38:32,271 [run_pretraining.py:  534]:	loss/total_loss, 10.398557662963867, 28
[INFO] 2021-07-12 17:38:32,271 [run_pretraining.py:  535]:	loss/mlm_loss, 10.398557662963867, 28
[INFO] 2021-07-12 17:38:32,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.699999868127634e-07, 28
[INFO] 2021-07-12 17:38:32,271 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 28
[INFO] 2021-07-12 17:38:32,271 [run_pretraining.py:  558]:	worker_index: 7, step: 28, cost: 10.398558, mlm loss: 10.398558, speed: 0.019630 steps/s, speed: 0.157040 samples/s, speed: 80.404490 tokens/s, learning rate: 2.700e-07, loss_scalings: 26214.400391, pp_loss: 10.380404
[INFO] 2021-07-12 17:38:32,272 [run_pretraining.py:  512]:	********exe.run_28******* 
[INFO] 2021-07-12 17:39:43,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:39:43,339 [run_pretraining.py:  534]:	loss/total_loss, 10.319509506225586, 29
[INFO] 2021-07-12 17:39:43,339 [run_pretraining.py:  535]:	loss/mlm_loss, 10.319509506225586, 29
[INFO] 2021-07-12 17:39:43,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-07, 29
[INFO] 2021-07-12 17:39:43,339 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 29
[INFO] 2021-07-12 17:39:43,339 [run_pretraining.py:  558]:	worker_index: 7, step: 29, cost: 10.319510, mlm loss: 10.319510, speed: 0.014071 steps/s, speed: 0.112570 samples/s, speed: 57.635712 tokens/s, learning rate: 2.800e-07, loss_scalings: 26214.400391, pp_loss: 10.362778
[INFO] 2021-07-12 17:39:43,339 [run_pretraining.py:  512]:	********exe.run_29******* 
[INFO] 2021-07-12 17:40:32,223 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:40:32,223 [run_pretraining.py:  534]:	loss/total_loss, 10.386037826538086, 30
[INFO] 2021-07-12 17:40:32,223 [run_pretraining.py:  535]:	loss/mlm_loss, 10.386037826538086, 30
[INFO] 2021-07-12 17:40:32,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.900000026784255e-07, 30
[INFO] 2021-07-12 17:40:32,224 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 30
[INFO] 2021-07-12 17:40:32,224 [run_pretraining.py:  558]:	worker_index: 7, step: 30, cost: 10.386038, mlm loss: 10.386038, speed: 0.020457 steps/s, speed: 0.163654 samples/s, speed: 83.790778 tokens/s, learning rate: 2.900e-07, loss_scalings: 26214.400391, pp_loss: 9.660351
[INFO] 2021-07-12 17:40:32,224 [run_pretraining.py:  512]:	********exe.run_30******* 
[INFO] 2021-07-12 17:41:23,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:41:23,372 [run_pretraining.py:  534]:	loss/total_loss, 10.395002365112305, 31
[INFO] 2021-07-12 17:41:23,372 [run_pretraining.py:  535]:	loss/mlm_loss, 10.395002365112305, 31
[INFO] 2021-07-12 17:41:23,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998218954715e-07, 31
[INFO] 2021-07-12 17:41:23,372 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 31
[INFO] 2021-07-12 17:41:23,372 [run_pretraining.py:  558]:	worker_index: 7, step: 31, cost: 10.395002, mlm loss: 10.395002, speed: 0.019551 steps/s, speed: 0.156409 samples/s, speed: 80.081564 tokens/s, learning rate: 3.000e-07, loss_scalings: 26214.400391, pp_loss: 9.378296
[INFO] 2021-07-12 17:41:23,372 [run_pretraining.py:  512]:	********exe.run_31******* 
[INFO] 2021-07-12 17:42:13,622 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  534]:	loss/total_loss, 10.490288734436035, 32
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  535]:	loss/mlm_loss, 10.490288734436035, 32
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999901223782e-07, 32
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 32
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  558]:	worker_index: 7, step: 32, cost: 10.490289, mlm loss: 10.490289, speed: 0.019901 steps/s, speed: 0.159204 samples/s, speed: 81.512497 tokens/s, learning rate: 3.100e-07, loss_scalings: 26214.400391, pp_loss: 10.472807
[INFO] 2021-07-12 17:42:13,623 [run_pretraining.py:  512]:	********exe.run_32******* 
[INFO] 2021-07-12 17:43:03,059 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:43:03,059 [run_pretraining.py:  534]:	loss/total_loss, 10.298696517944336, 33
[INFO] 2021-07-12 17:43:03,060 [run_pretraining.py:  535]:	loss/mlm_loss, 10.298696517944336, 33
[INFO] 2021-07-12 17:43:03,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1999996963349986e-07, 33
[INFO] 2021-07-12 17:43:03,060 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 33
[INFO] 2021-07-12 17:43:03,060 [run_pretraining.py:  558]:	worker_index: 7, step: 33, cost: 10.298697, mlm loss: 10.298697, speed: 0.020228 steps/s, speed: 0.161825 samples/s, speed: 82.854581 tokens/s, learning rate: 3.200e-07, loss_scalings: 26214.400391, pp_loss: 10.352451
[INFO] 2021-07-12 17:43:03,060 [run_pretraining.py:  512]:	********exe.run_33******* 
[INFO] 2021-07-12 17:43:29,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:43:29,446 [run_pretraining.py:  534]:	loss/total_loss, 10.540481567382812, 34
[INFO] 2021-07-12 17:43:29,446 [run_pretraining.py:  535]:	loss/mlm_loss, 10.540481567382812, 34
[INFO] 2021-07-12 17:43:29,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2999997756633093e-07, 34
[INFO] 2021-07-12 17:43:29,446 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 34
[INFO] 2021-07-12 17:43:29,446 [run_pretraining.py:  558]:	worker_index: 7, step: 34, cost: 10.540482, mlm loss: 10.540482, speed: 0.037899 steps/s, speed: 0.303195 samples/s, speed: 155.235957 tokens/s, learning rate: 3.300e-07, loss_scalings: 26214.400391, pp_loss: 10.468230
[INFO] 2021-07-12 17:43:29,446 [run_pretraining.py:  512]:	********exe.run_34******* 
[INFO] 2021-07-12 17:44:17,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  534]:	loss/total_loss, 10.352157592773438, 35
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  535]:	loss/mlm_loss, 10.352157592773438, 35
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.39999985499162e-07, 35
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 35
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  558]:	worker_index: 7, step: 35, cost: 10.352158, mlm loss: 10.352158, speed: 0.020841 steps/s, speed: 0.166725 samples/s, speed: 85.363026 tokens/s, learning rate: 3.400e-07, loss_scalings: 26214.400391, pp_loss: 10.408596
[INFO] 2021-07-12 17:44:17,430 [run_pretraining.py:  512]:	********exe.run_35******* 
[INFO] 2021-07-12 17:44:42,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:44:42,793 [run_pretraining.py:  534]:	loss/total_loss, 10.36866569519043, 36
[INFO] 2021-07-12 17:44:42,793 [run_pretraining.py:  535]:	loss/mlm_loss, 10.36866569519043, 36
[INFO] 2021-07-12 17:44:42,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4999999343199306e-07, 36
[INFO] 2021-07-12 17:44:42,794 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 36
[INFO] 2021-07-12 17:44:42,794 [run_pretraining.py:  558]:	worker_index: 7, step: 36, cost: 10.368666, mlm loss: 10.368666, speed: 0.039428 steps/s, speed: 0.315423 samples/s, speed: 161.496561 tokens/s, learning rate: 3.500e-07, loss_scalings: 26214.400391, pp_loss: 10.445641
[INFO] 2021-07-12 17:44:42,794 [run_pretraining.py:  512]:	********exe.run_36******* 
[INFO] 2021-07-12 17:45:32,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:45:32,302 [run_pretraining.py:  534]:	loss/total_loss, 10.410269737243652, 37
[INFO] 2021-07-12 17:45:32,302 [run_pretraining.py:  535]:	loss/mlm_loss, 10.410269737243652, 37
[INFO] 2021-07-12 17:45:32,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999729431147e-07, 37
[INFO] 2021-07-12 17:45:32,302 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 37
[INFO] 2021-07-12 17:45:32,302 [run_pretraining.py:  558]:	worker_index: 7, step: 37, cost: 10.410270, mlm loss: 10.410270, speed: 0.020199 steps/s, speed: 0.161591 samples/s, speed: 82.734584 tokens/s, learning rate: 3.600e-07, loss_scalings: 26214.400391, pp_loss: 10.414081
[INFO] 2021-07-12 17:45:32,302 [run_pretraining.py:  512]:	********exe.run_37******* 
[INFO] 2021-07-12 17:45:33,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:45:33,256 [run_pretraining.py:  534]:	loss/total_loss, 10.423382759094238, 38
[INFO] 2021-07-12 17:45:33,256 [run_pretraining.py:  535]:	loss/mlm_loss, 10.423382759094238, 38
[INFO] 2021-07-12 17:45:33,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999998087594577e-07, 38
[INFO] 2021-07-12 17:45:33,256 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 38
[INFO] 2021-07-12 17:45:33,256 [run_pretraining.py:  558]:	worker_index: 7, step: 38, cost: 10.423383, mlm loss: 10.423383, speed: 1.048792 steps/s, speed: 8.390334 samples/s, speed: 4295.851167 tokens/s, learning rate: 3.700e-07, loss_scalings: 26214.400391, pp_loss: 10.426041
[INFO] 2021-07-12 17:45:33,256 [run_pretraining.py:  512]:	********exe.run_38******* 
[INFO] 2021-07-12 17:46:46,200 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:46:46,201 [run_pretraining.py:  534]:	loss/total_loss, 10.412676811218262, 39
[INFO] 2021-07-12 17:46:46,201 [run_pretraining.py:  535]:	loss/mlm_loss, 10.412676811218262, 39
[INFO] 2021-07-12 17:46:46,201 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998880877683e-07, 39
[INFO] 2021-07-12 17:46:46,201 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 39
[INFO] 2021-07-12 17:46:46,201 [run_pretraining.py:  558]:	worker_index: 7, step: 39, cost: 10.412677, mlm loss: 10.412677, speed: 0.013709 steps/s, speed: 0.109673 samples/s, speed: 56.152386 tokens/s, learning rate: 3.800e-07, loss_scalings: 26214.400391, pp_loss: 10.382687
[INFO] 2021-07-12 17:46:46,201 [run_pretraining.py:  512]:	********exe.run_39******* 
[INFO] 2021-07-12 17:47:10,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:47:10,263 [run_pretraining.py:  534]:	loss/total_loss, 10.446718215942383, 40
[INFO] 2021-07-12 17:47:10,264 [run_pretraining.py:  535]:	loss/mlm_loss, 10.446718215942383, 40
[INFO] 2021-07-12 17:47:10,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8999996831989847e-07, 40
[INFO] 2021-07-12 17:47:10,264 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 40
[INFO] 2021-07-12 17:47:10,264 [run_pretraining.py:  558]:	worker_index: 7, step: 40, cost: 10.446718, mlm loss: 10.446718, speed: 0.041560 steps/s, speed: 0.332477 samples/s, speed: 170.228055 tokens/s, learning rate: 3.900e-07, loss_scalings: 26214.400391, pp_loss: 9.793818
[INFO] 2021-07-12 17:47:10,264 [run_pretraining.py:  512]:	********exe.run_40******* 
[INFO] 2021-07-12 17:48:26,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:48:26,859 [run_pretraining.py:  534]:	loss/total_loss, 10.360222816467285, 41
[INFO] 2021-07-12 17:48:26,859 [run_pretraining.py:  535]:	loss/mlm_loss, 10.360222816467285, 41
[INFO] 2021-07-12 17:48:26,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0000000467443897e-07, 41
[INFO] 2021-07-12 17:48:26,860 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 41
[INFO] 2021-07-12 17:48:26,860 [run_pretraining.py:  558]:	worker_index: 7, step: 41, cost: 10.360223, mlm loss: 10.360223, speed: 0.013056 steps/s, speed: 0.104445 samples/s, speed: 53.475968 tokens/s, learning rate: 4.000e-07, loss_scalings: 26214.400391, pp_loss: 9.289505
[INFO] 2021-07-12 17:48:26,860 [run_pretraining.py:  512]:	********exe.run_41******* 
[INFO] 2021-07-12 17:49:41,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:49:42,000 [run_pretraining.py:  534]:	loss/total_loss, 10.304762840270996, 42
[INFO] 2021-07-12 17:49:42,000 [run_pretraining.py:  535]:	loss/mlm_loss, 10.304762840270996, 42
[INFO] 2021-07-12 17:49:42,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-07, 42
[INFO] 2021-07-12 17:49:42,000 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 42
[INFO] 2021-07-12 17:49:42,000 [run_pretraining.py:  558]:	worker_index: 7, step: 42, cost: 10.304763, mlm loss: 10.304763, speed: 0.013309 steps/s, speed: 0.106469 samples/s, speed: 54.511992 tokens/s, learning rate: 4.100e-07, loss_scalings: 26214.400391, pp_loss: 10.336824
[INFO] 2021-07-12 17:49:42,000 [run_pretraining.py:  512]:	********exe.run_42******* 
[INFO] 2021-07-12 17:50:07,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:50:07,127 [run_pretraining.py:  534]:	loss/total_loss, 10.330808639526367, 43
[INFO] 2021-07-12 17:50:07,127 [run_pretraining.py:  535]:	loss/mlm_loss, 10.330808639526367, 43
[INFO] 2021-07-12 17:50:07,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.1999996369668224e-07, 43
[INFO] 2021-07-12 17:50:07,127 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 43
[INFO] 2021-07-12 17:50:07,127 [run_pretraining.py:  558]:	worker_index: 7, step: 43, cost: 10.330809, mlm loss: 10.330809, speed: 0.039798 steps/s, speed: 0.318384 samples/s, speed: 163.012468 tokens/s, learning rate: 4.200e-07, loss_scalings: 26214.400391, pp_loss: 10.352401
[INFO] 2021-07-12 17:50:07,128 [run_pretraining.py:  512]:	********exe.run_43******* 
[INFO] 2021-07-12 17:50:31,961 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:50:31,962 [run_pretraining.py:  534]:	loss/total_loss, 10.386178970336914, 44
[INFO] 2021-07-12 17:50:31,962 [run_pretraining.py:  535]:	loss/mlm_loss, 10.386178970336914, 44
[INFO] 2021-07-12 17:50:31,962 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3000000005122274e-07, 44
[INFO] 2021-07-12 17:50:31,962 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 44
[INFO] 2021-07-12 17:50:31,962 [run_pretraining.py:  558]:	worker_index: 7, step: 44, cost: 10.386179, mlm loss: 10.386179, speed: 0.040267 steps/s, speed: 0.322137 samples/s, speed: 164.934062 tokens/s, learning rate: 4.300e-07, loss_scalings: 26214.400391, pp_loss: 10.391459
[INFO] 2021-07-12 17:50:31,962 [run_pretraining.py:  512]:	********exe.run_44******* 
[INFO] 2021-07-12 17:51:21,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:51:21,612 [run_pretraining.py:  534]:	loss/total_loss, 10.440710067749023, 45
[INFO] 2021-07-12 17:51:21,612 [run_pretraining.py:  535]:	loss/mlm_loss, 10.440710067749023, 45
[INFO] 2021-07-12 17:51:21,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999795623444e-07, 45
[INFO] 2021-07-12 17:51:21,612 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 45
[INFO] 2021-07-12 17:51:21,612 [run_pretraining.py:  558]:	worker_index: 7, step: 45, cost: 10.440710, mlm loss: 10.440710, speed: 0.020141 steps/s, speed: 0.161130 samples/s, speed: 82.498662 tokens/s, learning rate: 4.400e-07, loss_scalings: 26214.400391, pp_loss: 10.424158
[INFO] 2021-07-12 17:51:21,612 [run_pretraining.py:  512]:	********exe.run_45******* 
[INFO] 2021-07-12 17:51:48,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  534]:	loss/total_loss, 10.334491729736328, 46
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  535]:	loss/mlm_loss, 10.334491729736328, 46
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.49999959073466e-07, 46
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 46
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  558]:	worker_index: 7, step: 46, cost: 10.334492, mlm loss: 10.334492, speed: 0.037137 steps/s, speed: 0.297099 samples/s, speed: 152.114736 tokens/s, learning rate: 4.500e-07, loss_scalings: 26214.400391, pp_loss: 10.421806
[INFO] 2021-07-12 17:51:48,540 [run_pretraining.py:  512]:	********exe.run_46******* 
[INFO] 2021-07-12 17:52:37,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:52:37,780 [run_pretraining.py:  534]:	loss/total_loss, 10.395575523376465, 47
[INFO] 2021-07-12 17:52:37,780 [run_pretraining.py:  535]:	loss/mlm_loss, 10.395575523376465, 47
[INFO] 2021-07-12 17:52:37,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.599999954280065e-07, 47
[INFO] 2021-07-12 17:52:37,780 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 47
[INFO] 2021-07-12 17:52:37,780 [run_pretraining.py:  558]:	worker_index: 7, step: 47, cost: 10.395576, mlm loss: 10.395576, speed: 0.020309 steps/s, speed: 0.162471 samples/s, speed: 83.185055 tokens/s, learning rate: 4.600e-07, loss_scalings: 26214.400391, pp_loss: 10.371349
[INFO] 2021-07-12 17:52:37,780 [run_pretraining.py:  512]:	********exe.run_47******* 
[INFO] 2021-07-12 17:53:02,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:53:02,011 [run_pretraining.py:  534]:	loss/total_loss, 10.139674186706543, 48
[INFO] 2021-07-12 17:53:02,011 [run_pretraining.py:  535]:	loss/mlm_loss, 10.139674186706543, 48
[INFO] 2021-07-12 17:53:02,011 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.6999997493912815e-07, 48
[INFO] 2021-07-12 17:53:02,012 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 48
[INFO] 2021-07-12 17:53:02,012 [run_pretraining.py:  558]:	worker_index: 7, step: 48, cost: 10.139674, mlm loss: 10.139674, speed: 0.041270 steps/s, speed: 0.330162 samples/s, speed: 169.042787 tokens/s, learning rate: 4.700e-07, loss_scalings: 26214.400391, pp_loss: 10.370579
[INFO] 2021-07-12 17:53:02,012 [run_pretraining.py:  512]:	********exe.run_48******* 
[INFO] 2021-07-12 17:54:14,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:54:14,164 [run_pretraining.py:  534]:	loss/total_loss, 9.206905364990234, 49
[INFO] 2021-07-12 17:54:14,165 [run_pretraining.py:  535]:	loss/mlm_loss, 9.206905364990234, 49
[INFO] 2021-07-12 17:54:14,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.799999828719592e-07, 49
[INFO] 2021-07-12 17:54:14,165 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 49
[INFO] 2021-07-12 17:54:14,165 [run_pretraining.py:  558]:	worker_index: 7, step: 49, cost: 9.206905, mlm loss: 9.206905, speed: 0.013860 steps/s, speed: 0.110876 samples/s, speed: 56.768630 tokens/s, learning rate: 4.800e-07, loss_scalings: 26214.400391, pp_loss: 10.113831
[INFO] 2021-07-12 17:54:14,165 [run_pretraining.py:  512]:	********exe.run_49******* 
[INFO] 2021-07-12 17:54:39,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:54:39,253 [run_pretraining.py:  534]:	loss/total_loss, 10.416088104248047, 50
[INFO] 2021-07-12 17:54:39,253 [run_pretraining.py:  535]:	loss/mlm_loss, 10.416088104248047, 50
[INFO] 2021-07-12 17:54:39,253 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.899999908047903e-07, 50
[INFO] 2021-07-12 17:54:39,253 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 50
[INFO] 2021-07-12 17:54:39,253 [run_pretraining.py:  558]:	worker_index: 7, step: 50, cost: 10.416088, mlm loss: 10.416088, speed: 0.039860 steps/s, speed: 0.318878 samples/s, speed: 163.265576 tokens/s, learning rate: 4.900e-07, loss_scalings: 26214.400391, pp_loss: 10.423394
[INFO] 2021-07-12 17:54:39,254 [run_pretraining.py:  512]:	********exe.run_50******* 
[INFO] 2021-07-12 17:55:04,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:55:04,400 [run_pretraining.py:  534]:	loss/total_loss, 10.181148529052734, 51
[INFO] 2021-07-12 17:55:04,400 [run_pretraining.py:  535]:	loss/mlm_loss, 10.181148529052734, 51
[INFO] 2021-07-12 17:55:04,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999987376214e-07, 51
[INFO] 2021-07-12 17:55:04,400 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 51
[INFO] 2021-07-12 17:55:04,400 [run_pretraining.py:  558]:	worker_index: 7, step: 51, cost: 10.181149, mlm loss: 10.181149, speed: 0.039767 steps/s, speed: 0.318139 samples/s, speed: 162.887147 tokens/s, learning rate: 5.000e-07, loss_scalings: 26214.400391, pp_loss: 10.209280
[INFO] 2021-07-12 17:55:04,401 [run_pretraining.py:  512]:	********exe.run_51******* 
[INFO] 2021-07-12 17:56:38,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:56:38,518 [run_pretraining.py:  534]:	loss/total_loss, 10.358838081359863, 52
[INFO] 2021-07-12 17:56:38,518 [run_pretraining.py:  535]:	loss/mlm_loss, 10.358838081359863, 52
[INFO] 2021-07-12 17:56:38,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.100000066704524e-07, 52
[INFO] 2021-07-12 17:56:38,518 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 52
[INFO] 2021-07-12 17:56:38,518 [run_pretraining.py:  558]:	worker_index: 7, step: 52, cost: 10.358838, mlm loss: 10.358838, speed: 0.010625 steps/s, speed: 0.085001 samples/s, speed: 43.520311 tokens/s, learning rate: 5.100e-07, loss_scalings: 26214.400391, pp_loss: 10.375241
[INFO] 2021-07-12 17:56:38,518 [run_pretraining.py:  512]:	********exe.run_52******* 
[INFO] 2021-07-12 17:57:01,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:01,488 [run_pretraining.py:  534]:	loss/total_loss, 10.301262855529785, 53
[INFO] 2021-07-12 17:57:01,488 [run_pretraining.py:  535]:	loss/mlm_loss, 10.301262855529785, 53
[INFO] 2021-07-12 17:57:01,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000146032835e-07, 53
[INFO] 2021-07-12 17:57:01,488 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 53
[INFO] 2021-07-12 17:57:01,488 [run_pretraining.py:  558]:	worker_index: 7, step: 53, cost: 10.301263, mlm loss: 10.301263, speed: 0.043536 steps/s, speed: 0.348292 samples/s, speed: 178.325346 tokens/s, learning rate: 5.200e-07, loss_scalings: 26214.400391, pp_loss: 10.356220
[INFO] 2021-07-12 17:57:01,488 [run_pretraining.py:  512]:	********exe.run_53******* 
[INFO] 2021-07-12 17:57:26,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:26,479 [run_pretraining.py:  534]:	loss/total_loss, 10.356303215026855, 54
[INFO] 2021-07-12 17:57:26,479 [run_pretraining.py:  535]:	loss/mlm_loss, 10.356303215026855, 54
[INFO] 2021-07-12 17:57:26,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999656926957e-07, 54
[INFO] 2021-07-12 17:57:26,479 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 54
[INFO] 2021-07-12 17:57:26,479 [run_pretraining.py:  558]:	worker_index: 7, step: 54, cost: 10.356303, mlm loss: 10.356303, speed: 0.040015 steps/s, speed: 0.320120 samples/s, speed: 163.901328 tokens/s, learning rate: 5.300e-07, loss_scalings: 26214.400391, pp_loss: 10.324286
[INFO] 2021-07-12 17:57:26,479 [run_pretraining.py:  512]:	********exe.run_54******* 
[INFO] 2021-07-12 17:57:51,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:51,321 [run_pretraining.py:  534]:	loss/total_loss, 10.413901329040527, 55
[INFO] 2021-07-12 17:57:51,321 [run_pretraining.py:  535]:	loss/mlm_loss, 10.413901329040527, 55
[INFO] 2021-07-12 17:57:51,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.399999736255268e-07, 55
[INFO] 2021-07-12 17:57:51,321 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 55
[INFO] 2021-07-12 17:57:51,321 [run_pretraining.py:  558]:	worker_index: 7, step: 55, cost: 10.413901, mlm loss: 10.413901, speed: 0.040256 steps/s, speed: 0.322050 samples/s, speed: 164.889704 tokens/s, learning rate: 5.400e-07, loss_scalings: 26214.400391, pp_loss: 10.352819
[INFO] 2021-07-12 17:57:51,321 [run_pretraining.py:  512]:	********exe.run_55******* 
[INFO] 2021-07-12 17:57:52,309 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:57:52,309 [run_pretraining.py:  534]:	loss/total_loss, 10.408546447753906, 56
[INFO] 2021-07-12 17:57:52,309 [run_pretraining.py:  535]:	loss/mlm_loss, 10.408546447753906, 56
[INFO] 2021-07-12 17:57:52,309 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.499999815583578e-07, 56
[INFO] 2021-07-12 17:57:52,309 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 56
[INFO] 2021-07-12 17:57:52,309 [run_pretraining.py:  558]:	worker_index: 7, step: 56, cost: 10.408546, mlm loss: 10.408546, speed: 1.012278 steps/s, speed: 8.098224 samples/s, speed: 4146.290643 tokens/s, learning rate: 5.500e-07, loss_scalings: 26214.400391, pp_loss: 10.039245
[INFO] 2021-07-12 17:57:52,310 [run_pretraining.py:  512]:	********exe.run_56******* 
[INFO] 2021-07-12 17:58:15,802 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:58:15,803 [run_pretraining.py:  534]:	loss/total_loss, 10.192152976989746, 57
[INFO] 2021-07-12 17:58:15,803 [run_pretraining.py:  535]:	loss/mlm_loss, 10.192152976989746, 57
[INFO] 2021-07-12 17:58:15,803 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-07, 57
[INFO] 2021-07-12 17:58:15,803 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 57
[INFO] 2021-07-12 17:58:15,803 [run_pretraining.py:  558]:	worker_index: 7, step: 57, cost: 10.192153, mlm loss: 10.192153, speed: 0.042566 steps/s, speed: 0.340526 samples/s, speed: 174.349403 tokens/s, learning rate: 5.600e-07, loss_scalings: 26214.400391, pp_loss: 10.273182
[INFO] 2021-07-12 17:58:15,803 [run_pretraining.py:  512]:	********exe.run_57******* 
[INFO] 2021-07-12 17:58:42,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:58:42,081 [run_pretraining.py:  534]:	loss/total_loss, 10.350852966308594, 58
[INFO] 2021-07-12 17:58:42,081 [run_pretraining.py:  535]:	loss/mlm_loss, 10.350852966308594, 58
[INFO] 2021-07-12 17:58:42,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6999999742402e-07, 58
[INFO] 2021-07-12 17:58:42,081 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 58
[INFO] 2021-07-12 17:58:42,081 [run_pretraining.py:  558]:	worker_index: 7, step: 58, cost: 10.350853, mlm loss: 10.350853, speed: 0.038055 steps/s, speed: 0.304443 samples/s, speed: 155.874774 tokens/s, learning rate: 5.700e-07, loss_scalings: 26214.400391, pp_loss: 10.385928
[INFO] 2021-07-12 17:58:42,081 [run_pretraining.py:  512]:	********exe.run_58******* 
[INFO] 2021-07-12 17:59:06,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  534]:	loss/total_loss, 10.31093978881836, 59
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  535]:	loss/mlm_loss, 10.31093978881836, 59
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.80000005356851e-07, 59
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 59
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  558]:	worker_index: 7, step: 59, cost: 10.310940, mlm loss: 10.310940, speed: 0.040164 steps/s, speed: 0.321313 samples/s, speed: 164.512085 tokens/s, learning rate: 5.800e-07, loss_scalings: 26214.400391, pp_loss: 10.338635
[INFO] 2021-07-12 17:59:06,980 [run_pretraining.py:  512]:	********exe.run_59******* 
[INFO] 2021-07-12 17:59:07,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  534]:	loss/total_loss, 10.372377395629883, 60
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  535]:	loss/mlm_loss, 10.372377395629883, 60
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.900000132896821e-07, 60
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 60
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  558]:	worker_index: 7, step: 60, cost: 10.372377, mlm loss: 10.372377, speed: 1.045478 steps/s, speed: 8.363826 samples/s, speed: 4282.278904 tokens/s, learning rate: 5.900e-07, loss_scalings: 26214.400391, pp_loss: 10.339716
[INFO] 2021-07-12 17:59:07,937 [run_pretraining.py:  512]:	********exe.run_60******* 
[INFO] 2021-07-12 17:59:34,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:34,492 [run_pretraining.py:  534]:	loss/total_loss, 10.250242233276367, 61
[INFO] 2021-07-12 17:59:34,492 [run_pretraining.py:  535]:	loss/mlm_loss, 10.250242233276367, 61
[INFO] 2021-07-12 17:59:34,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999643790943e-07, 61
[INFO] 2021-07-12 17:59:34,492 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 61
[INFO] 2021-07-12 17:59:34,492 [run_pretraining.py:  558]:	worker_index: 7, step: 61, cost: 10.250242, mlm loss: 10.250242, speed: 0.037659 steps/s, speed: 0.301270 samples/s, speed: 154.250484 tokens/s, learning rate: 6.000e-07, loss_scalings: 26214.400391, pp_loss: 10.347910
[INFO] 2021-07-12 17:59:34,492 [run_pretraining.py:  512]:	********exe.run_61******* 
[INFO] 2021-07-12 17:59:57,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 17:59:57,534 [run_pretraining.py:  534]:	loss/total_loss, 10.299509048461914, 62
[INFO] 2021-07-12 17:59:57,535 [run_pretraining.py:  535]:	loss/mlm_loss, 10.299509048461914, 62
[INFO] 2021-07-12 17:59:57,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.099999723119254e-07, 62
[INFO] 2021-07-12 17:59:57,535 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 62
[INFO] 2021-07-12 17:59:57,535 [run_pretraining.py:  558]:	worker_index: 7, step: 62, cost: 10.299509, mlm loss: 10.299509, speed: 0.043399 steps/s, speed: 0.347189 samples/s, speed: 177.760752 tokens/s, learning rate: 6.100e-07, loss_scalings: 26214.400391, pp_loss: 10.306835
[INFO] 2021-07-12 17:59:57,535 [run_pretraining.py:  512]:	********exe.run_62******* 
[INFO] 2021-07-12 18:00:22,668 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:00:22,668 [run_pretraining.py:  534]:	loss/total_loss, 10.381903648376465, 63
[INFO] 2021-07-12 18:00:22,668 [run_pretraining.py:  535]:	loss/mlm_loss, 10.381903648376465, 63
[INFO] 2021-07-12 18:00:22,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999802447564e-07, 63
[INFO] 2021-07-12 18:00:22,668 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 63
[INFO] 2021-07-12 18:00:22,669 [run_pretraining.py:  558]:	worker_index: 7, step: 63, cost: 10.381904, mlm loss: 10.381904, speed: 0.039788 steps/s, speed: 0.318306 samples/s, speed: 162.972804 tokens/s, learning rate: 6.200e-07, loss_scalings: 26214.400391, pp_loss: 10.329862
[INFO] 2021-07-12 18:00:22,669 [run_pretraining.py:  512]:	********exe.run_63******* 
[INFO] 2021-07-12 18:00:47,670 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:00:47,670 [run_pretraining.py:  534]:	loss/total_loss, 10.332651138305664, 64
[INFO] 2021-07-12 18:00:47,671 [run_pretraining.py:  535]:	loss/mlm_loss, 10.332651138305664, 64
[INFO] 2021-07-12 18:00:47,671 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999881775875e-07, 64
[INFO] 2021-07-12 18:00:47,671 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 64
[INFO] 2021-07-12 18:00:47,671 [run_pretraining.py:  558]:	worker_index: 7, step: 64, cost: 10.332651, mlm loss: 10.332651, speed: 0.039998 steps/s, speed: 0.319980 samples/s, speed: 163.829885 tokens/s, learning rate: 6.300e-07, loss_scalings: 26214.400391, pp_loss: 10.312142
[INFO] 2021-07-12 18:00:47,671 [run_pretraining.py:  512]:	********exe.run_64******* 
[INFO] 2021-07-12 18:01:34,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:01:34,940 [run_pretraining.py:  534]:	loss/total_loss, 10.267027854919434, 65
[INFO] 2021-07-12 18:01:34,940 [run_pretraining.py:  535]:	loss/mlm_loss, 10.267027854919434, 65
[INFO] 2021-07-12 18:01:34,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.399999392669997e-07, 65
[INFO] 2021-07-12 18:01:34,940 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 65
[INFO] 2021-07-12 18:01:34,940 [run_pretraining.py:  558]:	worker_index: 7, step: 65, cost: 10.267028, mlm loss: 10.267028, speed: 0.021156 steps/s, speed: 0.169246 samples/s, speed: 86.654121 tokens/s, learning rate: 6.400e-07, loss_scalings: 26214.400391, pp_loss: 10.357232
[INFO] 2021-07-12 18:01:34,940 [run_pretraining.py:  512]:	********exe.run_65******* 
[INFO] 2021-07-12 18:01:58,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:01:58,672 [run_pretraining.py:  534]:	loss/total_loss, 10.351457595825195, 66
[INFO] 2021-07-12 18:01:58,672 [run_pretraining.py:  535]:	loss/mlm_loss, 10.351457595825195, 66
[INFO] 2021-07-12 18:01:58,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.500000040432496e-07, 66
[INFO] 2021-07-12 18:01:58,672 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 66
[INFO] 2021-07-12 18:01:58,672 [run_pretraining.py:  558]:	worker_index: 7, step: 66, cost: 10.351458, mlm loss: 10.351458, speed: 0.042138 steps/s, speed: 0.337102 samples/s, speed: 172.596044 tokens/s, learning rate: 6.500e-07, loss_scalings: 26214.400391, pp_loss: 10.322080
[INFO] 2021-07-12 18:01:58,672 [run_pretraining.py:  512]:	********exe.run_66******* 
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  534]:	loss/total_loss, 10.169800758361816, 67
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  535]:	loss/mlm_loss, 10.169800758361816, 67
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999551326619e-07, 67
[INFO] 2021-07-12 18:02:24,262 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 67
[INFO] 2021-07-12 18:02:24,263 [run_pretraining.py:  558]:	worker_index: 7, step: 67, cost: 10.169801, mlm loss: 10.169801, speed: 0.039078 steps/s, speed: 0.312627 samples/s, speed: 160.065151 tokens/s, learning rate: 6.600e-07, loss_scalings: 26214.400391, pp_loss: 10.312764
[INFO] 2021-07-12 18:02:24,263 [run_pretraining.py:  512]:	********exe.run_67******* 
[INFO] 2021-07-12 18:03:12,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:03:12,745 [run_pretraining.py:  534]:	loss/total_loss, 6.061476707458496, 68
[INFO] 2021-07-12 18:03:12,745 [run_pretraining.py:  535]:	loss/mlm_loss, 6.061476707458496, 68
[INFO] 2021-07-12 18:03:12,745 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.699999630654929e-07, 68
[INFO] 2021-07-12 18:03:12,745 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 68
[INFO] 2021-07-12 18:03:12,745 [run_pretraining.py:  558]:	worker_index: 7, step: 68, cost: 6.061477, mlm loss: 6.061477, speed: 0.020626 steps/s, speed: 0.165009 samples/s, speed: 84.484589 tokens/s, learning rate: 6.700e-07, loss_scalings: 26214.400391, pp_loss: 9.221996
[INFO] 2021-07-12 18:03:12,746 [run_pretraining.py:  512]:	********exe.run_68******* 
[INFO] 2021-07-12 18:03:37,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:03:37,909 [run_pretraining.py:  534]:	loss/total_loss, 10.273798942565918, 69
[INFO] 2021-07-12 18:03:37,909 [run_pretraining.py:  535]:	loss/mlm_loss, 10.273798942565918, 69
[INFO] 2021-07-12 18:03:37,909 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.79999970998324e-07, 69
[INFO] 2021-07-12 18:03:37,909 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 69
[INFO] 2021-07-12 18:03:37,909 [run_pretraining.py:  558]:	worker_index: 7, step: 69, cost: 10.273799, mlm loss: 10.273799, speed: 0.039740 steps/s, speed: 0.317924 samples/s, speed: 162.776858 tokens/s, learning rate: 6.800e-07, loss_scalings: 26214.400391, pp_loss: 10.267651
[INFO] 2021-07-12 18:03:37,909 [run_pretraining.py:  512]:	********exe.run_69******* 
[INFO] 2021-07-12 18:04:03,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:03,911 [run_pretraining.py:  534]:	loss/total_loss, 10.30667495727539, 70
[INFO] 2021-07-12 18:04:03,911 [run_pretraining.py:  535]:	loss/mlm_loss, 10.30667495727539, 70
[INFO] 2021-07-12 18:04:03,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.899999789311551e-07, 70
[INFO] 2021-07-12 18:04:03,911 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 70
[INFO] 2021-07-12 18:04:03,911 [run_pretraining.py:  558]:	worker_index: 7, step: 70, cost: 10.306675, mlm loss: 10.306675, speed: 0.038460 steps/s, speed: 0.307679 samples/s, speed: 157.531519 tokens/s, learning rate: 6.900e-07, loss_scalings: 26214.400391, pp_loss: 10.315434
[INFO] 2021-07-12 18:04:03,911 [run_pretraining.py:  512]:	********exe.run_70******* 
[INFO] 2021-07-12 18:04:28,989 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:28,990 [run_pretraining.py:  534]:	loss/total_loss, 10.441292762756348, 71
[INFO] 2021-07-12 18:04:28,990 [run_pretraining.py:  535]:	loss/mlm_loss, 10.441292762756348, 71
[INFO] 2021-07-12 18:04:28,990 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999868639861e-07, 71
[INFO] 2021-07-12 18:04:28,990 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 71
[INFO] 2021-07-12 18:04:28,990 [run_pretraining.py:  558]:	worker_index: 7, step: 71, cost: 10.441293, mlm loss: 10.441293, speed: 0.039875 steps/s, speed: 0.319004 samples/s, speed: 163.329977 tokens/s, learning rate: 7.000e-07, loss_scalings: 26214.400391, pp_loss: 10.342715
[INFO] 2021-07-12 18:04:28,990 [run_pretraining.py:  512]:	********exe.run_71******* 
[INFO] 2021-07-12 18:04:54,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:04:54,347 [run_pretraining.py:  534]:	loss/total_loss, 10.331863403320312, 72
[INFO] 2021-07-12 18:04:54,347 [run_pretraining.py:  535]:	loss/mlm_loss, 10.331863403320312, 72
[INFO] 2021-07-12 18:04:54,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-07, 72
[INFO] 2021-07-12 18:04:54,347 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 72
[INFO] 2021-07-12 18:04:54,347 [run_pretraining.py:  558]:	worker_index: 7, step: 72, cost: 10.331863, mlm loss: 10.331863, speed: 0.039438 steps/s, speed: 0.315504 samples/s, speed: 161.537904 tokens/s, learning rate: 7.100e-07, loss_scalings: 26214.400391, pp_loss: 10.407063
[INFO] 2021-07-12 18:04:54,347 [run_pretraining.py:  512]:	********exe.run_72******* 
[INFO] 2021-07-12 18:06:07,144 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  534]:	loss/total_loss, 10.306451797485352, 73
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  535]:	loss/mlm_loss, 10.306451797485352, 73
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999458862294e-07, 73
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 73
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  558]:	worker_index: 7, step: 73, cost: 10.306452, mlm loss: 10.306452, speed: 0.013737 steps/s, speed: 0.109894 samples/s, speed: 56.265501 tokens/s, learning rate: 7.200e-07, loss_scalings: 26214.400391, pp_loss: 10.259329
[INFO] 2021-07-12 18:06:07,145 [run_pretraining.py:  512]:	********exe.run_73******* 
[INFO] 2021-07-12 18:06:30,309 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:06:30,310 [run_pretraining.py:  534]:	loss/total_loss, 10.286260604858398, 74
[INFO] 2021-07-12 18:06:30,310 [run_pretraining.py:  535]:	loss/mlm_loss, 10.286260604858398, 74
[INFO] 2021-07-12 18:06:30,310 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.300000106624793e-07, 74
[INFO] 2021-07-12 18:06:30,310 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 74
[INFO] 2021-07-12 18:06:30,310 [run_pretraining.py:  558]:	worker_index: 7, step: 74, cost: 10.286261, mlm loss: 10.286261, speed: 0.043170 steps/s, speed: 0.345363 samples/s, speed: 176.825631 tokens/s, learning rate: 7.300e-07, loss_scalings: 26214.400391, pp_loss: 10.349230
[INFO] 2021-07-12 18:06:30,310 [run_pretraining.py:  512]:	********exe.run_74******* 
[INFO] 2021-07-12 18:07:18,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:18,880 [run_pretraining.py:  534]:	loss/total_loss, 10.293088912963867, 75
[INFO] 2021-07-12 18:07:18,880 [run_pretraining.py:  535]:	loss/mlm_loss, 10.293088912963867, 75
[INFO] 2021-07-12 18:07:18,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.399999617518915e-07, 75
[INFO] 2021-07-12 18:07:18,880 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 75
[INFO] 2021-07-12 18:07:18,880 [run_pretraining.py:  558]:	worker_index: 7, step: 75, cost: 10.293089, mlm loss: 10.293089, speed: 0.020589 steps/s, speed: 0.164713 samples/s, speed: 84.333236 tokens/s, learning rate: 7.400e-07, loss_scalings: 26214.400391, pp_loss: 10.287367
[INFO] 2021-07-12 18:07:18,880 [run_pretraining.py:  512]:	********exe.run_75******* 
[INFO] 2021-07-12 18:07:19,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:19,859 [run_pretraining.py:  534]:	loss/total_loss, 10.276949882507324, 76
[INFO] 2021-07-12 18:07:19,859 [run_pretraining.py:  535]:	loss/mlm_loss, 10.276949882507324, 76
[INFO] 2021-07-12 18:07:19,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.499999696847226e-07, 76
[INFO] 2021-07-12 18:07:19,859 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 76
[INFO] 2021-07-12 18:07:19,859 [run_pretraining.py:  558]:	worker_index: 7, step: 76, cost: 10.276950, mlm loss: 10.276950, speed: 1.022219 steps/s, speed: 8.177753 samples/s, speed: 4187.009444 tokens/s, learning rate: 7.500e-07, loss_scalings: 26214.400391, pp_loss: 10.327798
[INFO] 2021-07-12 18:07:19,859 [run_pretraining.py:  512]:	********exe.run_76******* 
[INFO] 2021-07-12 18:07:20,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  534]:	loss/total_loss, 10.347142219543457, 77
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  535]:	loss/mlm_loss, 10.347142219543457, 77
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999776175537e-07, 77
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 77
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  558]:	worker_index: 7, step: 77, cost: 10.347142, mlm loss: 10.347142, speed: 1.025051 steps/s, speed: 8.200407 samples/s, speed: 4198.608188 tokens/s, learning rate: 7.600e-07, loss_scalings: 26214.400391, pp_loss: 10.272371
[INFO] 2021-07-12 18:07:20,835 [run_pretraining.py:  512]:	********exe.run_77******* 
[INFO] 2021-07-12 18:08:10,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:10,248 [run_pretraining.py:  534]:	loss/total_loss, 10.206883430480957, 78
[INFO] 2021-07-12 18:08:10,248 [run_pretraining.py:  535]:	loss/mlm_loss, 10.206883430480957, 78
[INFO] 2021-07-12 18:08:10,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999855503847e-07, 78
[INFO] 2021-07-12 18:08:10,248 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 78
[INFO] 2021-07-12 18:08:10,248 [run_pretraining.py:  558]:	worker_index: 7, step: 78, cost: 10.206883, mlm loss: 10.206883, speed: 0.020238 steps/s, speed: 0.161903 samples/s, speed: 82.894290 tokens/s, learning rate: 7.700e-07, loss_scalings: 26214.400391, pp_loss: 10.298221
[INFO] 2021-07-12 18:08:10,248 [run_pretraining.py:  512]:	********exe.run_78******* 
[INFO] 2021-07-12 18:08:34,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:34,213 [run_pretraining.py:  534]:	loss/total_loss, 10.255459785461426, 79
[INFO] 2021-07-12 18:08:34,213 [run_pretraining.py:  535]:	loss/mlm_loss, 10.255459785461426, 79
[INFO] 2021-07-12 18:08:34,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.799999366397969e-07, 79
[INFO] 2021-07-12 18:08:34,213 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 79
[INFO] 2021-07-12 18:08:34,213 [run_pretraining.py:  558]:	worker_index: 7, step: 79, cost: 10.255460, mlm loss: 10.255460, speed: 0.041729 steps/s, speed: 0.333831 samples/s, speed: 170.921353 tokens/s, learning rate: 7.800e-07, loss_scalings: 26214.400391, pp_loss: 10.257747
[INFO] 2021-07-12 18:08:34,213 [run_pretraining.py:  512]:	********exe.run_79******* 
[INFO] 2021-07-12 18:08:35,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:08:35,173 [run_pretraining.py:  534]:	loss/total_loss, 10.166330337524414, 80
[INFO] 2021-07-12 18:08:35,173 [run_pretraining.py:  535]:	loss/mlm_loss, 10.166330337524414, 80
[INFO] 2021-07-12 18:08:35,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.89999944572628e-07, 80
[INFO] 2021-07-12 18:08:35,173 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 80
[INFO] 2021-07-12 18:08:35,173 [run_pretraining.py:  558]:	worker_index: 7, step: 80, cost: 10.166330, mlm loss: 10.166330, speed: 1.042084 steps/s, speed: 8.336673 samples/s, speed: 4268.376378 tokens/s, learning rate: 7.900e-07, loss_scalings: 26214.400391, pp_loss: 9.990374
[INFO] 2021-07-12 18:08:35,174 [run_pretraining.py:  512]:	********exe.run_80******* 
[INFO] 2021-07-12 18:09:23,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:23,454 [run_pretraining.py:  534]:	loss/total_loss, 10.37299633026123, 81
[INFO] 2021-07-12 18:09:23,454 [run_pretraining.py:  535]:	loss/mlm_loss, 10.37299633026123, 81
[INFO] 2021-07-12 18:09:23,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.000000093488779e-07, 81
[INFO] 2021-07-12 18:09:23,454 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 81
[INFO] 2021-07-12 18:09:23,454 [run_pretraining.py:  558]:	worker_index: 7, step: 81, cost: 10.372996, mlm loss: 10.372996, speed: 0.020713 steps/s, speed: 0.165700 samples/s, speed: 84.838425 tokens/s, learning rate: 8.000e-07, loss_scalings: 26214.400391, pp_loss: 10.348948
[INFO] 2021-07-12 18:09:23,454 [run_pretraining.py:  512]:	********exe.run_81******* 
[INFO] 2021-07-12 18:09:24,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:24,417 [run_pretraining.py:  534]:	loss/total_loss, 10.19382095336914, 82
[INFO] 2021-07-12 18:09:24,418 [run_pretraining.py:  535]:	loss/mlm_loss, 10.19382095336914, 82
[INFO] 2021-07-12 18:09:24,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10000017281709e-07, 82
[INFO] 2021-07-12 18:09:24,418 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 82
[INFO] 2021-07-12 18:09:24,418 [run_pretraining.py:  558]:	worker_index: 7, step: 82, cost: 10.193821, mlm loss: 10.193821, speed: 1.038499 steps/s, speed: 8.307993 samples/s, speed: 4253.692653 tokens/s, learning rate: 8.100e-07, loss_scalings: 26214.400391, pp_loss: 10.313285
[INFO] 2021-07-12 18:09:24,418 [run_pretraining.py:  512]:	********exe.run_82******* 
[INFO] 2021-07-12 18:09:25,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:25,357 [run_pretraining.py:  534]:	loss/total_loss, 10.23080825805664, 83
[INFO] 2021-07-12 18:09:25,357 [run_pretraining.py:  535]:	loss/mlm_loss, 10.23080825805664, 83
[INFO] 2021-07-12 18:09:25,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-07, 83
[INFO] 2021-07-12 18:09:25,358 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 83
[INFO] 2021-07-12 18:09:25,358 [run_pretraining.py:  558]:	worker_index: 7, step: 83, cost: 10.230808, mlm loss: 10.230808, speed: 1.064618 steps/s, speed: 8.516941 samples/s, speed: 4360.673931 tokens/s, learning rate: 8.200e-07, loss_scalings: 26214.400391, pp_loss: 10.243374
[INFO] 2021-07-12 18:09:25,358 [run_pretraining.py:  512]:	********exe.run_83******* 
[INFO] 2021-07-12 18:09:26,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:26,296 [run_pretraining.py:  534]:	loss/total_loss, 10.292776107788086, 84
[INFO] 2021-07-12 18:09:26,296 [run_pretraining.py:  535]:	loss/mlm_loss, 10.292776107788086, 84
[INFO] 2021-07-12 18:09:26,296 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999763039523e-07, 84
[INFO] 2021-07-12 18:09:26,296 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 84
[INFO] 2021-07-12 18:09:26,296 [run_pretraining.py:  558]:	worker_index: 7, step: 84, cost: 10.292776, mlm loss: 10.292776, speed: 1.066046 steps/s, speed: 8.528369 samples/s, speed: 4366.524813 tokens/s, learning rate: 8.300e-07, loss_scalings: 26214.400391, pp_loss: 10.283358
[INFO] 2021-07-12 18:09:26,296 [run_pretraining.py:  512]:	********exe.run_84******* 
[INFO] 2021-07-12 18:09:27,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  534]:	loss/total_loss, 10.196115493774414, 85
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  535]:	loss/mlm_loss, 10.196115493774414, 85
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999273933645e-07, 85
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 85
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  558]:	worker_index: 7, step: 85, cost: 10.196115, mlm loss: 10.196115, speed: 1.067434 steps/s, speed: 8.539471 samples/s, speed: 4372.208925 tokens/s, learning rate: 8.400e-07, loss_scalings: 26214.400391, pp_loss: 10.274700
[INFO] 2021-07-12 18:09:27,234 [run_pretraining.py:  512]:	********exe.run_85******* 
[INFO] 2021-07-12 18:09:51,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:09:51,417 [run_pretraining.py:  534]:	loss/total_loss, 10.260025978088379, 86
[INFO] 2021-07-12 18:09:51,417 [run_pretraining.py:  535]:	loss/mlm_loss, 10.260025978088379, 86
[INFO] 2021-07-12 18:09:51,417 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.500000490130333e-07, 86
[INFO] 2021-07-12 18:09:51,417 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 86
[INFO] 2021-07-12 18:09:51,417 [run_pretraining.py:  558]:	worker_index: 7, step: 86, cost: 10.260026, mlm loss: 10.260026, speed: 0.041352 steps/s, speed: 0.330813 samples/s, speed: 169.376286 tokens/s, learning rate: 8.500e-07, loss_scalings: 26214.400391, pp_loss: 10.284963
[INFO] 2021-07-12 18:09:51,417 [run_pretraining.py:  512]:	********exe.run_86******* 
[INFO] 2021-07-12 18:10:17,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:10:17,858 [run_pretraining.py:  534]:	loss/total_loss, 10.297883033752441, 87
[INFO] 2021-07-12 18:10:17,859 [run_pretraining.py:  535]:	loss/mlm_loss, 10.297883033752441, 87
[INFO] 2021-07-12 18:10:17,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-07, 87
[INFO] 2021-07-12 18:10:17,859 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 87
[INFO] 2021-07-12 18:10:17,859 [run_pretraining.py:  558]:	worker_index: 7, step: 87, cost: 10.297883, mlm loss: 10.297883, speed: 0.037820 steps/s, speed: 0.302563 samples/s, speed: 154.912430 tokens/s, learning rate: 8.600e-07, loss_scalings: 26214.400391, pp_loss: 10.339764
[INFO] 2021-07-12 18:10:17,859 [run_pretraining.py:  512]:	********exe.run_87******* 
[INFO] 2021-07-12 18:10:43,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:10:43,553 [run_pretraining.py:  534]:	loss/total_loss, 10.375574111938477, 88
[INFO] 2021-07-12 18:10:43,553 [run_pretraining.py:  535]:	loss/mlm_loss, 10.375574111938477, 88
[INFO] 2021-07-12 18:10:43,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.700000080352766e-07, 88
[INFO] 2021-07-12 18:10:43,553 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 88
[INFO] 2021-07-12 18:10:43,553 [run_pretraining.py:  558]:	worker_index: 7, step: 88, cost: 10.375574, mlm loss: 10.375574, speed: 0.038920 steps/s, speed: 0.311362 samples/s, speed: 159.417146 tokens/s, learning rate: 8.700e-07, loss_scalings: 26214.400391, pp_loss: 10.352224
[INFO] 2021-07-12 18:10:43,553 [run_pretraining.py:  512]:	********exe.run_88******* 
[INFO] 2021-07-12 18:11:07,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:07,458 [run_pretraining.py:  534]:	loss/total_loss, 10.32655143737793, 89
[INFO] 2021-07-12 18:11:07,458 [run_pretraining.py:  535]:	loss/mlm_loss, 10.32655143737793, 89
[INFO] 2021-07-12 18:11:07,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999591246888e-07, 89
[INFO] 2021-07-12 18:11:07,459 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 89
[INFO] 2021-07-12 18:11:07,459 [run_pretraining.py:  558]:	worker_index: 7, step: 89, cost: 10.326551, mlm loss: 10.326551, speed: 0.041832 steps/s, speed: 0.334659 samples/s, speed: 171.345362 tokens/s, learning rate: 8.800e-07, loss_scalings: 26214.400391, pp_loss: 10.321741
[INFO] 2021-07-12 18:11:07,459 [run_pretraining.py:  512]:	********exe.run_89******* 
[INFO] 2021-07-12 18:11:57,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:57,434 [run_pretraining.py:  534]:	loss/total_loss, 10.278838157653809, 90
[INFO] 2021-07-12 18:11:57,434 [run_pretraining.py:  535]:	loss/mlm_loss, 10.278838157653809, 90
[INFO] 2021-07-12 18:11:57,434 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.899999670575198e-07, 90
[INFO] 2021-07-12 18:11:57,435 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 90
[INFO] 2021-07-12 18:11:57,435 [run_pretraining.py:  558]:	worker_index: 7, step: 90, cost: 10.278838, mlm loss: 10.278838, speed: 0.020010 steps/s, speed: 0.160079 samples/s, speed: 81.960530 tokens/s, learning rate: 8.900e-07, loss_scalings: 26214.400391, pp_loss: 10.271581
[INFO] 2021-07-12 18:11:57,435 [run_pretraining.py:  512]:	********exe.run_90******* 
[INFO] 2021-07-12 18:11:58,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  534]:	loss/total_loss, 10.258624076843262, 91
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  535]:	loss/mlm_loss, 10.258624076843262, 91
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.99999918146932e-07, 91
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 91
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  558]:	worker_index: 7, step: 91, cost: 10.258624, mlm loss: 10.258624, speed: 1.067734 steps/s, speed: 8.541868 samples/s, speed: 4373.436589 tokens/s, learning rate: 9.000e-07, loss_scalings: 26214.400391, pp_loss: 10.231561
[INFO] 2021-07-12 18:11:58,372 [run_pretraining.py:  512]:	********exe.run_91******* 
[INFO] 2021-07-12 18:11:59,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:11:59,311 [run_pretraining.py:  534]:	loss/total_loss, 10.270209312438965, 92
[INFO] 2021-07-12 18:11:59,311 [run_pretraining.py:  535]:	loss/mlm_loss, 10.270209312438965, 92
[INFO] 2021-07-12 18:11:59,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.100000397666008e-07, 92
[INFO] 2021-07-12 18:11:59,311 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 92
[INFO] 2021-07-12 18:11:59,312 [run_pretraining.py:  558]:	worker_index: 7, step: 92, cost: 10.270209, mlm loss: 10.270209, speed: 1.064979 steps/s, speed: 8.519835 samples/s, speed: 4362.155394 tokens/s, learning rate: 9.100e-07, loss_scalings: 26214.400391, pp_loss: 10.280787
[INFO] 2021-07-12 18:11:59,312 [run_pretraining.py:  512]:	********exe.run_92******* 
[INFO] 2021-07-12 18:12:00,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  534]:	loss/total_loss, 10.300923347473145, 93
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  535]:	loss/mlm_loss, 10.300923347473145, 93
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.19999990856013e-07, 93
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 93
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  558]:	worker_index: 7, step: 93, cost: 10.300923, mlm loss: 10.300923, speed: 1.068406 steps/s, speed: 8.547251 samples/s, speed: 4376.192715 tokens/s, learning rate: 9.200e-07, loss_scalings: 26214.400391, pp_loss: 10.278910
[INFO] 2021-07-12 18:12:00,248 [run_pretraining.py:  512]:	********exe.run_93******* 
[INFO] 2021-07-12 18:12:01,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:01,188 [run_pretraining.py:  534]:	loss/total_loss, 10.279757499694824, 94
[INFO] 2021-07-12 18:12:01,188 [run_pretraining.py:  535]:	loss/mlm_loss, 10.279757499694824, 94
[INFO] 2021-07-12 18:12:01,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999987888441e-07, 94
[INFO] 2021-07-12 18:12:01,188 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 94
[INFO] 2021-07-12 18:12:01,188 [run_pretraining.py:  558]:	worker_index: 7, step: 94, cost: 10.279757, mlm loss: 10.279757, speed: 1.064740 steps/s, speed: 8.517916 samples/s, speed: 4361.173176 tokens/s, learning rate: 9.300e-07, loss_scalings: 26214.400391, pp_loss: 10.234072
[INFO] 2021-07-12 18:12:01,188 [run_pretraining.py:  512]:	********exe.run_94******* 
[INFO] 2021-07-12 18:12:26,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:26,871 [run_pretraining.py:  534]:	loss/total_loss, 5.401887893676758, 95
[INFO] 2021-07-12 18:12:26,871 [run_pretraining.py:  535]:	loss/mlm_loss, 5.401887893676758, 95
[INFO] 2021-07-12 18:12:26,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999498782563e-07, 95
[INFO] 2021-07-12 18:12:26,871 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 95
[INFO] 2021-07-12 18:12:26,871 [run_pretraining.py:  558]:	worker_index: 7, step: 95, cost: 5.401888, mlm loss: 5.401888, speed: 0.038937 steps/s, speed: 0.311493 samples/s, speed: 159.484439 tokens/s, learning rate: 9.400e-07, loss_scalings: 26214.400391, pp_loss: 9.092726
[INFO] 2021-07-12 18:12:26,871 [run_pretraining.py:  512]:	********exe.run_95******* 
[INFO] 2021-07-12 18:12:27,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:27,827 [run_pretraining.py:  534]:	loss/total_loss, 10.30689525604248, 96
[INFO] 2021-07-12 18:12:27,827 [run_pretraining.py:  535]:	loss/mlm_loss, 10.30689525604248, 96
[INFO] 2021-07-12 18:12:27,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-07, 96
[INFO] 2021-07-12 18:12:27,827 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 96
[INFO] 2021-07-12 18:12:27,828 [run_pretraining.py:  558]:	worker_index: 7, step: 96, cost: 10.306895, mlm loss: 10.306895, speed: 1.046581 steps/s, speed: 8.372646 samples/s, speed: 4286.794522 tokens/s, learning rate: 9.500e-07, loss_scalings: 26214.400391, pp_loss: 10.224436
[INFO] 2021-07-12 18:12:27,828 [run_pretraining.py:  512]:	********exe.run_96******* 
[INFO] 2021-07-12 18:12:51,364 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:51,364 [run_pretraining.py:  534]:	loss/total_loss, 10.181536674499512, 97
[INFO] 2021-07-12 18:12:51,364 [run_pretraining.py:  535]:	loss/mlm_loss, 10.181536674499512, 97
[INFO] 2021-07-12 18:12:51,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999657439184e-07, 97
[INFO] 2021-07-12 18:12:51,364 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 97
[INFO] 2021-07-12 18:12:51,364 [run_pretraining.py:  558]:	worker_index: 7, step: 97, cost: 10.181537, mlm loss: 10.181537, speed: 0.042488 steps/s, speed: 0.339901 samples/s, speed: 174.029344 tokens/s, learning rate: 9.600e-07, loss_scalings: 26214.400391, pp_loss: 10.219259
[INFO] 2021-07-12 18:12:51,365 [run_pretraining.py:  512]:	********exe.run_97******* 
[INFO] 2021-07-12 18:12:52,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:12:52,330 [run_pretraining.py:  534]:	loss/total_loss, 10.143829345703125, 98
[INFO] 2021-07-12 18:12:52,330 [run_pretraining.py:  535]:	loss/mlm_loss, 10.143829345703125, 98
[INFO] 2021-07-12 18:12:52,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.699999736767495e-07, 98
[INFO] 2021-07-12 18:12:52,331 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 98
[INFO] 2021-07-12 18:12:52,331 [run_pretraining.py:  558]:	worker_index: 7, step: 98, cost: 10.143829, mlm loss: 10.143829, speed: 1.035623 steps/s, speed: 8.284986 samples/s, speed: 4241.912634 tokens/s, learning rate: 9.700e-07, loss_scalings: 26214.400391, pp_loss: 10.214737
[INFO] 2021-07-12 18:12:52,331 [run_pretraining.py:  512]:	********exe.run_98******* 
[INFO] 2021-07-12 18:13:17,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:17,578 [run_pretraining.py:  534]:	loss/total_loss, 10.194437980651855, 99
[INFO] 2021-07-12 18:13:17,578 [run_pretraining.py:  535]:	loss/mlm_loss, 10.194437980651855, 99
[INFO] 2021-07-12 18:13:17,579 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.799999816095806e-07, 99
[INFO] 2021-07-12 18:13:17,579 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 99
[INFO] 2021-07-12 18:13:17,579 [run_pretraining.py:  558]:	worker_index: 7, step: 99, cost: 10.194438, mlm loss: 10.194438, speed: 0.039608 steps/s, speed: 0.316865 samples/s, speed: 162.234770 tokens/s, learning rate: 9.800e-07, loss_scalings: 26214.400391, pp_loss: 10.259301
[INFO] 2021-07-12 18:13:17,579 [run_pretraining.py:  512]:	********exe.run_99******* 
[INFO] 2021-07-12 18:13:18,522 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:18,523 [run_pretraining.py:  534]:	loss/total_loss, 10.238973617553711, 100
[INFO] 2021-07-12 18:13:18,523 [run_pretraining.py:  535]:	loss/mlm_loss, 10.238973617553711, 100
[INFO] 2021-07-12 18:13:18,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-07, 100
[INFO] 2021-07-12 18:13:18,523 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 100
[INFO] 2021-07-12 18:13:18,523 [run_pretraining.py:  558]:	worker_index: 7, step: 100, cost: 10.238974, mlm loss: 10.238974, speed: 1.059565 steps/s, speed: 8.476520 samples/s, speed: 4339.978296 tokens/s, learning rate: 9.900e-07, loss_scalings: 26214.400391, pp_loss: 10.204462
[INFO] 2021-07-12 18:13:18,523 [run_pretraining.py:  512]:	********exe.run_100******* 
[INFO] 2021-07-12 18:13:19,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:19,464 [run_pretraining.py:  534]:	loss/total_loss, 10.118715286254883, 101
[INFO] 2021-07-12 18:13:19,464 [run_pretraining.py:  535]:	loss/mlm_loss, 10.118715286254883, 101
[INFO] 2021-07-12 18:13:19,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999974752427e-07, 101
[INFO] 2021-07-12 18:13:19,464 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 101
[INFO] 2021-07-12 18:13:19,464 [run_pretraining.py:  558]:	worker_index: 7, step: 101, cost: 10.118715, mlm loss: 10.118715, speed: 1.063608 steps/s, speed: 8.508866 samples/s, speed: 4356.539356 tokens/s, learning rate: 1.000e-06, loss_scalings: 26214.400391, pp_loss: 10.251323
[INFO] 2021-07-12 18:13:19,464 [run_pretraining.py:  512]:	********exe.run_101******* 
[INFO] 2021-07-12 18:13:44,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:44,839 [run_pretraining.py:  534]:	loss/total_loss, 10.169376373291016, 102
[INFO] 2021-07-12 18:13:44,839 [run_pretraining.py:  535]:	loss/mlm_loss, 10.169376373291016, 102
[INFO] 2021-07-12 18:13:44,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.009999891721236e-06, 102
[INFO] 2021-07-12 18:13:44,839 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 102
[INFO] 2021-07-12 18:13:44,839 [run_pretraining.py:  558]:	worker_index: 7, step: 102, cost: 10.169376, mlm loss: 10.169376, speed: 0.039410 steps/s, speed: 0.315277 samples/s, speed: 161.421856 tokens/s, learning rate: 1.010e-06, loss_scalings: 26214.400391, pp_loss: 9.079311
[INFO] 2021-07-12 18:13:44,839 [run_pretraining.py:  512]:	********exe.run_102******* 
[INFO] 2021-07-12 18:13:45,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:13:45,826 [run_pretraining.py:  534]:	loss/total_loss, 10.217184066772461, 103
[INFO] 2021-07-12 18:13:45,827 [run_pretraining.py:  535]:	loss/mlm_loss, 10.217184066772461, 103
[INFO] 2021-07-12 18:13:45,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0200000133409048e-06, 103
[INFO] 2021-07-12 18:13:45,827 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 103
[INFO] 2021-07-12 18:13:45,827 [run_pretraining.py:  558]:	worker_index: 7, step: 103, cost: 10.217184, mlm loss: 10.217184, speed: 1.013288 steps/s, speed: 8.106300 samples/s, speed: 4150.425611 tokens/s, learning rate: 1.020e-06, loss_scalings: 26214.400391, pp_loss: 10.205418
[INFO] 2021-07-12 18:13:45,827 [run_pretraining.py:  512]:	********exe.run_103******* 
[INFO] 2021-07-12 18:14:11,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:11,867 [run_pretraining.py:  534]:	loss/total_loss, 10.141057014465332, 104
[INFO] 2021-07-12 18:14:11,867 [run_pretraining.py:  535]:	loss/mlm_loss, 10.141057014465332, 104
[INFO] 2021-07-12 18:14:11,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.030000021273736e-06, 104
[INFO] 2021-07-12 18:14:11,867 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 104
[INFO] 2021-07-12 18:14:11,867 [run_pretraining.py:  558]:	worker_index: 7, step: 104, cost: 10.141057, mlm loss: 10.141057, speed: 0.038403 steps/s, speed: 0.307226 samples/s, speed: 157.299796 tokens/s, learning rate: 1.030e-06, loss_scalings: 26214.400391, pp_loss: 10.191705
[INFO] 2021-07-12 18:14:11,867 [run_pretraining.py:  512]:	********exe.run_104******* 
[INFO] 2021-07-12 18:14:37,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:37,277 [run_pretraining.py:  534]:	loss/total_loss, 10.03530502319336, 105
[INFO] 2021-07-12 18:14:37,277 [run_pretraining.py:  535]:	loss/mlm_loss, 10.03530502319336, 105
[INFO] 2021-07-12 18:14:37,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.040000029206567e-06, 105
[INFO] 2021-07-12 18:14:37,277 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 105
[INFO] 2021-07-12 18:14:37,277 [run_pretraining.py:  558]:	worker_index: 7, step: 105, cost: 10.035305, mlm loss: 10.035305, speed: 0.039355 steps/s, speed: 0.314841 samples/s, speed: 161.198654 tokens/s, learning rate: 1.040e-06, loss_scalings: 26214.400391, pp_loss: 10.142605
[INFO] 2021-07-12 18:14:37,277 [run_pretraining.py:  512]:	********exe.run_105******* 
[INFO] 2021-07-12 18:14:38,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:38,258 [run_pretraining.py:  534]:	loss/total_loss, 10.146753311157227, 106
[INFO] 2021-07-12 18:14:38,258 [run_pretraining.py:  535]:	loss/mlm_loss, 10.146753311157227, 106
[INFO] 2021-07-12 18:14:38,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999234525603e-06, 106
[INFO] 2021-07-12 18:14:38,259 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 106
[INFO] 2021-07-12 18:14:38,259 [run_pretraining.py:  558]:	worker_index: 7, step: 106, cost: 10.146753, mlm loss: 10.146753, speed: 1.019485 steps/s, speed: 8.155876 samples/s, speed: 4175.808512 tokens/s, learning rate: 1.050e-06, loss_scalings: 26214.400391, pp_loss: 10.145021
[INFO] 2021-07-12 18:14:38,259 [run_pretraining.py:  512]:	********exe.run_106******* 
[INFO] 2021-07-12 18:14:39,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:39,226 [run_pretraining.py:  534]:	loss/total_loss, 10.234644889831543, 107
[INFO] 2021-07-12 18:14:39,226 [run_pretraining.py:  535]:	loss/mlm_loss, 10.234644889831543, 107
[INFO] 2021-07-12 18:14:39,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999313853914e-06, 107
[INFO] 2021-07-12 18:14:39,227 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 107
[INFO] 2021-07-12 18:14:39,227 [run_pretraining.py:  558]:	worker_index: 7, step: 107, cost: 10.234645, mlm loss: 10.234645, speed: 1.033776 steps/s, speed: 8.270212 samples/s, speed: 4234.348365 tokens/s, learning rate: 1.060e-06, loss_scalings: 26214.400391, pp_loss: 10.185075
[INFO] 2021-07-12 18:14:39,227 [run_pretraining.py:  512]:	********exe.run_107******* 
[INFO] 2021-07-12 18:14:40,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:40,195 [run_pretraining.py:  534]:	loss/total_loss, 10.080101013183594, 108
[INFO] 2021-07-12 18:14:40,195 [run_pretraining.py:  535]:	loss/mlm_loss, 10.080101013183594, 108
[INFO] 2021-07-12 18:14:40,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0700000530050602e-06, 108
[INFO] 2021-07-12 18:14:40,195 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 108
[INFO] 2021-07-12 18:14:40,195 [run_pretraining.py:  558]:	worker_index: 7, step: 108, cost: 10.080101, mlm loss: 10.080101, speed: 1.033226 steps/s, speed: 8.265807 samples/s, speed: 4232.093203 tokens/s, learning rate: 1.070e-06, loss_scalings: 26214.400391, pp_loss: 10.124497
[INFO] 2021-07-12 18:14:40,195 [run_pretraining.py:  512]:	********exe.run_108******* 
[INFO] 2021-07-12 18:14:41,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:41,130 [run_pretraining.py:  534]:	loss/total_loss, 10.109811782836914, 109
[INFO] 2021-07-12 18:14:41,130 [run_pretraining.py:  535]:	loss/mlm_loss, 10.109811782836914, 109
[INFO] 2021-07-12 18:14:41,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0799999472510535e-06, 109
[INFO] 2021-07-12 18:14:41,131 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 109
[INFO] 2021-07-12 18:14:41,131 [run_pretraining.py:  558]:	worker_index: 7, step: 109, cost: 10.109812, mlm loss: 10.109812, speed: 1.069608 steps/s, speed: 8.556864 samples/s, speed: 4381.114241 tokens/s, learning rate: 1.080e-06, loss_scalings: 26214.400391, pp_loss: 10.135971
[INFO] 2021-07-12 18:14:41,131 [run_pretraining.py:  512]:	********exe.run_109******* 
[INFO] 2021-07-12 18:14:42,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:42,063 [run_pretraining.py:  534]:	loss/total_loss, 10.136098861694336, 110
[INFO] 2021-07-12 18:14:42,063 [run_pretraining.py:  535]:	loss/mlm_loss, 10.136098861694336, 110
[INFO] 2021-07-12 18:14:42,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0899999551838846e-06, 110
[INFO] 2021-07-12 18:14:42,063 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 110
[INFO] 2021-07-12 18:14:42,063 [run_pretraining.py:  558]:	worker_index: 7, step: 110, cost: 10.136099, mlm loss: 10.136099, speed: 1.073376 steps/s, speed: 8.587004 samples/s, speed: 4396.546199 tokens/s, learning rate: 1.090e-06, loss_scalings: 26214.400391, pp_loss: 10.158434
[INFO] 2021-07-12 18:14:42,063 [run_pretraining.py:  512]:	********exe.run_110******* 
[INFO] 2021-07-12 18:14:43,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:43,002 [run_pretraining.py:  534]:	loss/total_loss, 9.965267181396484, 111
[INFO] 2021-07-12 18:14:43,002 [run_pretraining.py:  535]:	loss/mlm_loss, 9.965267181396484, 111
[INFO] 2021-07-12 18:14:43,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0999999631167157e-06, 111
[INFO] 2021-07-12 18:14:43,002 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 111
[INFO] 2021-07-12 18:14:43,002 [run_pretraining.py:  558]:	worker_index: 7, step: 111, cost: 9.965267, mlm loss: 9.965267, speed: 1.065736 steps/s, speed: 8.525888 samples/s, speed: 4365.254440 tokens/s, learning rate: 1.100e-06, loss_scalings: 26214.400391, pp_loss: 10.127289
[INFO] 2021-07-12 18:14:43,002 [run_pretraining.py:  512]:	********exe.run_111******* 
[INFO] 2021-07-12 18:14:43,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:43,937 [run_pretraining.py:  534]:	loss/total_loss, 10.223291397094727, 112
[INFO] 2021-07-12 18:14:43,937 [run_pretraining.py:  535]:	loss/mlm_loss, 10.223291397094727, 112
[INFO] 2021-07-12 18:14:43,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999710495467e-06, 112
[INFO] 2021-07-12 18:14:43,937 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 112
[INFO] 2021-07-12 18:14:43,937 [run_pretraining.py:  558]:	worker_index: 7, step: 112, cost: 10.223291, mlm loss: 10.223291, speed: 1.070313 steps/s, speed: 8.562506 samples/s, speed: 4384.003111 tokens/s, learning rate: 1.110e-06, loss_scalings: 26214.400391, pp_loss: 10.214086
[INFO] 2021-07-12 18:14:43,937 [run_pretraining.py:  512]:	********exe.run_112******* 
[INFO] 2021-07-12 18:14:44,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:14:44,870 [run_pretraining.py:  534]:	loss/total_loss, 7.266439437866211, 113
[INFO] 2021-07-12 18:14:44,870 [run_pretraining.py:  535]:	loss/mlm_loss, 7.266439437866211, 113
[INFO] 2021-07-12 18:14:44,870 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-06, 113
[INFO] 2021-07-12 18:14:44,870 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 113
[INFO] 2021-07-12 18:14:44,870 [run_pretraining.py:  558]:	worker_index: 7, step: 113, cost: 7.266439, mlm loss: 7.266439, speed: 1.072157 steps/s, speed: 8.577256 samples/s, speed: 4391.555160 tokens/s, learning rate: 1.120e-06, loss_scalings: 26214.400391, pp_loss: 9.439896
[INFO] 2021-07-12 18:14:44,870 [run_pretraining.py:  512]:	********exe.run_113******* 
[INFO] 2021-07-12 18:15:08,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:08,569 [run_pretraining.py:  534]:	loss/total_loss, 10.070816993713379, 114
[INFO] 2021-07-12 18:15:08,569 [run_pretraining.py:  535]:	loss/mlm_loss, 10.070816993713379, 114
[INFO] 2021-07-12 18:15:08,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999869152089e-06, 114
[INFO] 2021-07-12 18:15:08,570 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 114
[INFO] 2021-07-12 18:15:08,570 [run_pretraining.py:  558]:	worker_index: 7, step: 114, cost: 10.070817, mlm loss: 10.070817, speed: 0.042196 steps/s, speed: 0.337572 samples/s, speed: 172.836723 tokens/s, learning rate: 1.130e-06, loss_scalings: 26214.400391, pp_loss: 10.214017
[INFO] 2021-07-12 18:15:08,570 [run_pretraining.py:  512]:	********exe.run_114******* 
[INFO] 2021-07-12 18:15:33,785 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:33,785 [run_pretraining.py:  534]:	loss/total_loss, 10.185248374938965, 115
[INFO] 2021-07-12 18:15:33,785 [run_pretraining.py:  535]:	loss/mlm_loss, 10.185248374938965, 115
[INFO] 2021-07-12 18:15:33,786 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13999999484804e-06, 115
[INFO] 2021-07-12 18:15:33,786 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 115
[INFO] 2021-07-12 18:15:33,786 [run_pretraining.py:  558]:	worker_index: 7, step: 115, cost: 10.185248, mlm loss: 10.185248, speed: 0.039658 steps/s, speed: 0.317267 samples/s, speed: 162.440520 tokens/s, learning rate: 1.140e-06, loss_scalings: 26214.400391, pp_loss: 10.168254
[INFO] 2021-07-12 18:15:33,786 [run_pretraining.py:  512]:	********exe.run_115******* 
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  534]:	loss/total_loss, 10.168088912963867, 116
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  535]:	loss/mlm_loss, 10.168088912963867, 116
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.150000002780871e-06, 116
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 116
[INFO] 2021-07-12 18:15:34,738 [run_pretraining.py:  558]:	worker_index: 7, step: 116, cost: 10.168089, mlm loss: 10.168089, speed: 1.050252 steps/s, speed: 8.402018 samples/s, speed: 4301.833022 tokens/s, learning rate: 1.150e-06, loss_scalings: 26214.400391, pp_loss: 10.168574
[INFO] 2021-07-12 18:15:34,739 [run_pretraining.py:  512]:	********exe.run_116******* 
[INFO] 2021-07-12 18:15:35,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:15:35,679 [run_pretraining.py:  534]:	loss/total_loss, 10.215261459350586, 117
[INFO] 2021-07-12 18:15:35,680 [run_pretraining.py:  535]:	loss/mlm_loss, 10.215261459350586, 117
[INFO] 2021-07-12 18:15:35,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.160000010713702e-06, 117
[INFO] 2021-07-12 18:15:35,680 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 117
[INFO] 2021-07-12 18:15:35,680 [run_pretraining.py:  558]:	worker_index: 7, step: 117, cost: 10.215261, mlm loss: 10.215261, speed: 1.063123 steps/s, speed: 8.504982 samples/s, speed: 4354.550612 tokens/s, learning rate: 1.160e-06, loss_scalings: 26214.400391, pp_loss: 10.184546
[INFO] 2021-07-12 18:15:35,680 [run_pretraining.py:  512]:	********exe.run_117******* 
[INFO] 2021-07-12 18:16:01,604 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  534]:	loss/total_loss, 10.272600173950195, 118
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  535]:	loss/mlm_loss, 10.272600173950195, 118
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999049596954e-06, 118
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 118
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  558]:	worker_index: 7, step: 118, cost: 10.272600, mlm loss: 10.272600, speed: 0.038574 steps/s, speed: 0.308589 samples/s, speed: 157.997642 tokens/s, learning rate: 1.170e-06, loss_scalings: 26214.400391, pp_loss: 10.193257
[INFO] 2021-07-12 18:16:01,605 [run_pretraining.py:  512]:	********exe.run_118******* 
[INFO] 2021-07-12 18:16:02,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:02,560 [run_pretraining.py:  534]:	loss/total_loss, 10.24244499206543, 119
[INFO] 2021-07-12 18:16:02,560 [run_pretraining.py:  535]:	loss/mlm_loss, 10.24244499206543, 119
[INFO] 2021-07-12 18:16:02,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1800000265793642e-06, 119
[INFO] 2021-07-12 18:16:02,560 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 119
[INFO] 2021-07-12 18:16:02,560 [run_pretraining.py:  558]:	worker_index: 7, step: 119, cost: 10.242445, mlm loss: 10.242445, speed: 1.047188 steps/s, speed: 8.377508 samples/s, speed: 4289.283995 tokens/s, learning rate: 1.180e-06, loss_scalings: 26214.400391, pp_loss: 10.136723
[INFO] 2021-07-12 18:16:02,561 [run_pretraining.py:  512]:	********exe.run_119******* 
[INFO] 2021-07-12 18:16:03,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:03,491 [run_pretraining.py:  534]:	loss/total_loss, 10.26170825958252, 120
[INFO] 2021-07-12 18:16:03,491 [run_pretraining.py:  535]:	loss/mlm_loss, 10.26170825958252, 120
[INFO] 2021-07-12 18:16:03,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1900000345121953e-06, 120
[INFO] 2021-07-12 18:16:03,492 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 120
[INFO] 2021-07-12 18:16:03,492 [run_pretraining.py:  558]:	worker_index: 7, step: 120, cost: 10.261708, mlm loss: 10.261708, speed: 1.074658 steps/s, speed: 8.597266 samples/s, speed: 4401.800085 tokens/s, learning rate: 1.190e-06, loss_scalings: 26214.400391, pp_loss: 10.111670
[INFO] 2021-07-12 18:16:03,492 [run_pretraining.py:  512]:	********exe.run_120******* 
[INFO] 2021-07-12 18:16:04,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:04,425 [run_pretraining.py:  534]:	loss/total_loss, 10.149293899536133, 121
[INFO] 2021-07-12 18:16:04,425 [run_pretraining.py:  535]:	loss/mlm_loss, 10.149293899536133, 121
[INFO] 2021-07-12 18:16:04,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999287581886e-06, 121
[INFO] 2021-07-12 18:16:04,425 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 121
[INFO] 2021-07-12 18:16:04,425 [run_pretraining.py:  558]:	worker_index: 7, step: 121, cost: 10.149294, mlm loss: 10.149294, speed: 1.071781 steps/s, speed: 8.574245 samples/s, speed: 4390.013278 tokens/s, learning rate: 1.200e-06, loss_scalings: 26214.400391, pp_loss: 10.191002
[INFO] 2021-07-12 18:16:04,425 [run_pretraining.py:  512]:	********exe.run_121******* 
[INFO] 2021-07-12 18:16:30,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:30,658 [run_pretraining.py:  534]:	loss/total_loss, 10.281230926513672, 122
[INFO] 2021-07-12 18:16:30,659 [run_pretraining.py:  535]:	loss/mlm_loss, 10.281230926513672, 122
[INFO] 2021-07-12 18:16:30,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-06, 122
[INFO] 2021-07-12 18:16:30,659 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 122
[INFO] 2021-07-12 18:16:30,659 [run_pretraining.py:  558]:	worker_index: 7, step: 122, cost: 10.281231, mlm loss: 10.281231, speed: 0.038120 steps/s, speed: 0.304962 samples/s, speed: 156.140620 tokens/s, learning rate: 1.210e-06, loss_scalings: 26214.400391, pp_loss: 10.121057
[INFO] 2021-07-12 18:16:30,659 [run_pretraining.py:  512]:	********exe.run_122******* 
[INFO] 2021-07-12 18:16:31,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:31,610 [run_pretraining.py:  534]:	loss/total_loss, 10.223288536071777, 123
[INFO] 2021-07-12 18:16:31,611 [run_pretraining.py:  535]:	loss/mlm_loss, 10.223288536071777, 123
[INFO] 2021-07-12 18:16:31,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2199999446238508e-06, 123
[INFO] 2021-07-12 18:16:31,611 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 123
[INFO] 2021-07-12 18:16:31,611 [run_pretraining.py:  558]:	worker_index: 7, step: 123, cost: 10.223289, mlm loss: 10.223289, speed: 1.051140 steps/s, speed: 8.409122 samples/s, speed: 4305.470491 tokens/s, learning rate: 1.220e-06, loss_scalings: 26214.400391, pp_loss: 10.131280
[INFO] 2021-07-12 18:16:31,611 [run_pretraining.py:  512]:	********exe.run_123******* 
[INFO] 2021-07-12 18:16:32,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:32,554 [run_pretraining.py:  534]:	loss/total_loss, 10.113363265991211, 124
[INFO] 2021-07-12 18:16:32,555 [run_pretraining.py:  535]:	loss/mlm_loss, 10.113363265991211, 124
[INFO] 2021-07-12 18:16:32,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999525566818e-06, 124
[INFO] 2021-07-12 18:16:32,555 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 124
[INFO] 2021-07-12 18:16:32,555 [run_pretraining.py:  558]:	worker_index: 7, step: 124, cost: 10.113363, mlm loss: 10.113363, speed: 1.060166 steps/s, speed: 8.481328 samples/s, speed: 4342.439935 tokens/s, learning rate: 1.230e-06, loss_scalings: 26214.400391, pp_loss: 10.220631
[INFO] 2021-07-12 18:16:32,555 [run_pretraining.py:  512]:	********exe.run_124******* 
[INFO] 2021-07-12 18:16:33,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:33,488 [run_pretraining.py:  534]:	loss/total_loss, 10.253453254699707, 125
[INFO] 2021-07-12 18:16:33,488 [run_pretraining.py:  535]:	loss/mlm_loss, 10.253453254699707, 125
[INFO] 2021-07-12 18:16:33,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999604895129e-06, 125
[INFO] 2021-07-12 18:16:33,488 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 125
[INFO] 2021-07-12 18:16:33,488 [run_pretraining.py:  558]:	worker_index: 7, step: 125, cost: 10.253453, mlm loss: 10.253453, speed: 1.071992 steps/s, speed: 8.575939 samples/s, speed: 4390.880594 tokens/s, learning rate: 1.240e-06, loss_scalings: 26214.400391, pp_loss: 10.182522
[INFO] 2021-07-12 18:16:33,488 [run_pretraining.py:  512]:	********exe.run_125******* 
[INFO] 2021-07-12 18:16:58,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:58,778 [run_pretraining.py:  534]:	loss/total_loss, 9.97063159942627, 126
[INFO] 2021-07-12 18:16:58,778 [run_pretraining.py:  535]:	loss/mlm_loss, 9.97063159942627, 126
[INFO] 2021-07-12 18:16:58,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-06, 126
[INFO] 2021-07-12 18:16:58,778 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 126
[INFO] 2021-07-12 18:16:58,778 [run_pretraining.py:  558]:	worker_index: 7, step: 126, cost: 9.970632, mlm loss: 9.970632, speed: 0.039543 steps/s, speed: 0.316342 samples/s, speed: 161.967157 tokens/s, learning rate: 1.250e-06, loss_scalings: 26214.400391, pp_loss: 10.138552
[INFO] 2021-07-12 18:16:58,778 [run_pretraining.py:  512]:	********exe.run_126******* 
[INFO] 2021-07-12 18:16:59,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:16:59,715 [run_pretraining.py:  534]:	loss/total_loss, 10.252567291259766, 127
[INFO] 2021-07-12 18:16:59,715 [run_pretraining.py:  535]:	loss/mlm_loss, 10.252567291259766, 127
[INFO] 2021-07-12 18:16:59,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.259999976355175e-06, 127
[INFO] 2021-07-12 18:16:59,716 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 127
[INFO] 2021-07-12 18:16:59,716 [run_pretraining.py:  558]:	worker_index: 7, step: 127, cost: 10.252567, mlm loss: 10.252567, speed: 1.067113 steps/s, speed: 8.536900 samples/s, speed: 4370.892985 tokens/s, learning rate: 1.260e-06, loss_scalings: 26214.400391, pp_loss: 9.322489
[INFO] 2021-07-12 18:16:59,716 [run_pretraining.py:  512]:	********exe.run_127******* 
[INFO] 2021-07-12 18:17:26,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:17:26,185 [run_pretraining.py:  534]:	loss/total_loss, 10.233404159545898, 128
[INFO] 2021-07-12 18:17:26,185 [run_pretraining.py:  535]:	loss/mlm_loss, 10.233404159545898, 128
[INFO] 2021-07-12 18:17:26,185 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.269999984288006e-06, 128
[INFO] 2021-07-12 18:17:26,186 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 128
[INFO] 2021-07-12 18:17:26,186 [run_pretraining.py:  558]:	worker_index: 7, step: 128, cost: 10.233404, mlm loss: 10.233404, speed: 0.037780 steps/s, speed: 0.302238 samples/s, speed: 154.745674 tokens/s, learning rate: 1.270e-06, loss_scalings: 26214.400391, pp_loss: 10.106144
[INFO] 2021-07-12 18:17:26,186 [run_pretraining.py:  512]:	********exe.run_128******* 
[INFO] 2021-07-12 18:18:14,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:18:14,910 [run_pretraining.py:  534]:	loss/total_loss, 10.104618072509766, 129
[INFO] 2021-07-12 18:18:14,910 [run_pretraining.py:  535]:	loss/mlm_loss, 10.104618072509766, 129
[INFO] 2021-07-12 18:18:14,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2799998785339994e-06, 129
[INFO] 2021-07-12 18:18:14,910 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 129
[INFO] 2021-07-12 18:18:14,910 [run_pretraining.py:  558]:	worker_index: 7, step: 129, cost: 10.104618, mlm loss: 10.104618, speed: 0.020524 steps/s, speed: 0.164192 samples/s, speed: 84.066177 tokens/s, learning rate: 1.280e-06, loss_scalings: 26214.400391, pp_loss: 10.091624
[INFO] 2021-07-12 18:18:14,910 [run_pretraining.py:  512]:	********exe.run_129******* 
[INFO] 2021-07-12 18:18:15,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:18:15,868 [run_pretraining.py:  534]:	loss/total_loss, 10.170656204223633, 130
[INFO] 2021-07-12 18:18:15,868 [run_pretraining.py:  535]:	loss/mlm_loss, 10.170656204223633, 130
[INFO] 2021-07-12 18:18:15,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2900000001536682e-06, 130
[INFO] 2021-07-12 18:18:15,868 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 130
[INFO] 2021-07-12 18:18:15,869 [run_pretraining.py:  558]:	worker_index: 7, step: 130, cost: 10.170656, mlm loss: 10.170656, speed: 1.043822 steps/s, speed: 8.350573 samples/s, speed: 4275.493492 tokens/s, learning rate: 1.290e-06, loss_scalings: 26214.400391, pp_loss: 10.101957
[INFO] 2021-07-12 18:18:15,869 [run_pretraining.py:  512]:	********exe.run_130******* 
[INFO] 2021-07-12 18:19:03,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:03,081 [run_pretraining.py:  534]:	loss/total_loss, 10.16873836517334, 131
[INFO] 2021-07-12 18:19:03,082 [run_pretraining.py:  535]:	loss/mlm_loss, 10.16873836517334, 131
[INFO] 2021-07-12 18:19:03,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3000000080864993e-06, 131
[INFO] 2021-07-12 18:19:03,082 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 131
[INFO] 2021-07-12 18:19:03,082 [run_pretraining.py:  558]:	worker_index: 7, step: 131, cost: 10.168738, mlm loss: 10.168738, speed: 0.021181 steps/s, speed: 0.169447 samples/s, speed: 86.756672 tokens/s, learning rate: 1.300e-06, loss_scalings: 26214.400391, pp_loss: 10.146484
[INFO] 2021-07-12 18:19:03,082 [run_pretraining.py:  512]:	********exe.run_131******* 
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  534]:	loss/total_loss, 10.245624542236328, 132
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  535]:	loss/mlm_loss, 10.245624542236328, 132
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3100000160193304e-06, 132
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 132
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  558]:	worker_index: 7, step: 132, cost: 10.245625, mlm loss: 10.245625, speed: 1.043808 steps/s, speed: 8.350465 samples/s, speed: 4275.438163 tokens/s, learning rate: 1.310e-06, loss_scalings: 26214.400391, pp_loss: 10.109450
[INFO] 2021-07-12 18:19:04,040 [run_pretraining.py:  512]:	********exe.run_132******* 
[INFO] 2021-07-12 18:19:04,979 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:04,979 [run_pretraining.py:  534]:	loss/total_loss, 9.950255393981934, 133
[INFO] 2021-07-12 18:19:04,980 [run_pretraining.py:  535]:	loss/mlm_loss, 9.950255393981934, 133
[INFO] 2021-07-12 18:19:04,980 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999102653237e-06, 133
[INFO] 2021-07-12 18:19:04,980 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 133
[INFO] 2021-07-12 18:19:04,980 [run_pretraining.py:  558]:	worker_index: 7, step: 133, cost: 9.950255, mlm loss: 9.950255, speed: 1.065348 steps/s, speed: 8.522784 samples/s, speed: 4363.665574 tokens/s, learning rate: 1.320e-06, loss_scalings: 26214.400391, pp_loss: 10.101254
[INFO] 2021-07-12 18:19:04,980 [run_pretraining.py:  512]:	********exe.run_133******* 
[INFO] 2021-07-12 18:19:05,921 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:05,922 [run_pretraining.py:  534]:	loss/total_loss, 10.103299140930176, 134
[INFO] 2021-07-12 18:19:05,922 [run_pretraining.py:  535]:	loss/mlm_loss, 10.103299140930176, 134
[INFO] 2021-07-12 18:19:05,922 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999181981548e-06, 134
[INFO] 2021-07-12 18:19:05,922 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 134
[INFO] 2021-07-12 18:19:05,922 [run_pretraining.py:  558]:	worker_index: 7, step: 134, cost: 10.103299, mlm loss: 10.103299, speed: 1.062232 steps/s, speed: 8.497856 samples/s, speed: 4350.902499 tokens/s, learning rate: 1.330e-06, loss_scalings: 26214.400391, pp_loss: 10.124377
[INFO] 2021-07-12 18:19:05,922 [run_pretraining.py:  512]:	********exe.run_134******* 
[INFO] 2021-07-12 18:19:52,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:52,318 [run_pretraining.py:  534]:	loss/total_loss, 8.254450798034668, 135
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  535]:	loss/mlm_loss, 8.254450798034668, 135
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3399999261309858e-06, 135
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 135
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  558]:	worker_index: 7, step: 135, cost: 8.254451, mlm loss: 8.254451, speed: 0.021553 steps/s, speed: 0.172427 samples/s, speed: 88.282833 tokens/s, learning rate: 1.340e-06, loss_scalings: 26214.400391, pp_loss: 9.648714
[INFO] 2021-07-12 18:19:52,319 [run_pretraining.py:  512]:	********exe.run_135******* 
[INFO] 2021-07-12 18:19:53,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:53,253 [run_pretraining.py:  534]:	loss/total_loss, 10.164695739746094, 136
[INFO] 2021-07-12 18:19:53,254 [run_pretraining.py:  535]:	loss/mlm_loss, 10.164695739746094, 136
[INFO] 2021-07-12 18:19:53,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000477506546e-06, 136
[INFO] 2021-07-12 18:19:53,254 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 136
[INFO] 2021-07-12 18:19:53,254 [run_pretraining.py:  558]:	worker_index: 7, step: 136, cost: 10.164696, mlm loss: 10.164696, speed: 1.070341 steps/s, speed: 8.562727 samples/s, speed: 4384.116105 tokens/s, learning rate: 1.350e-06, loss_scalings: 26214.400391, pp_loss: 10.089399
[INFO] 2021-07-12 18:19:53,254 [run_pretraining.py:  512]:	********exe.run_136******* 
[INFO] 2021-07-12 18:19:54,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:54,186 [run_pretraining.py:  534]:	loss/total_loss, 9.992401123046875, 137
[INFO] 2021-07-12 18:19:54,186 [run_pretraining.py:  535]:	loss/mlm_loss, 9.992401123046875, 137
[INFO] 2021-07-12 18:19:54,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.359999941996648e-06, 137
[INFO] 2021-07-12 18:19:54,186 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 137
[INFO] 2021-07-12 18:19:54,187 [run_pretraining.py:  558]:	worker_index: 7, step: 137, cost: 9.992401, mlm loss: 9.992401, speed: 1.072759 steps/s, speed: 8.582074 samples/s, speed: 4394.021728 tokens/s, learning rate: 1.360e-06, loss_scalings: 26214.400391, pp_loss: 10.050594
[INFO] 2021-07-12 18:19:54,187 [run_pretraining.py:  512]:	********exe.run_137******* 
[INFO] 2021-07-12 18:19:55,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:55,124 [run_pretraining.py:  534]:	loss/total_loss, 10.184595108032227, 138
[INFO] 2021-07-12 18:19:55,124 [run_pretraining.py:  535]:	loss/mlm_loss, 10.184595108032227, 138
[INFO] 2021-07-12 18:19:55,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.369999949929479e-06, 138
[INFO] 2021-07-12 18:19:55,124 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 138
[INFO] 2021-07-12 18:19:55,124 [run_pretraining.py:  558]:	worker_index: 7, step: 138, cost: 10.184595, mlm loss: 10.184595, speed: 1.067250 steps/s, speed: 8.538002 samples/s, speed: 4371.456862 tokens/s, learning rate: 1.370e-06, loss_scalings: 26214.400391, pp_loss: 10.131102
[INFO] 2021-07-12 18:19:55,124 [run_pretraining.py:  512]:	********exe.run_138******* 
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  534]:	loss/total_loss, 9.709537506103516, 139
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  535]:	loss/mlm_loss, 9.709537506103516, 139
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-06, 139
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 139
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  558]:	worker_index: 7, step: 139, cost: 9.709538, mlm loss: 9.709538, speed: 1.073454 steps/s, speed: 8.587633 samples/s, speed: 4396.868010 tokens/s, learning rate: 1.380e-06, loss_scalings: 26214.400391, pp_loss: 10.023581
[INFO] 2021-07-12 18:19:56,056 [run_pretraining.py:  512]:	********exe.run_139******* 
[INFO] 2021-07-12 18:20:19,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:19,887 [run_pretraining.py:  534]:	loss/total_loss, 10.066786766052246, 140
[INFO] 2021-07-12 18:20:19,887 [run_pretraining.py:  535]:	loss/mlm_loss, 10.066786766052246, 140
[INFO] 2021-07-12 18:20:19,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999657951412e-06, 140
[INFO] 2021-07-12 18:20:19,888 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 140
[INFO] 2021-07-12 18:20:19,888 [run_pretraining.py:  558]:	worker_index: 7, step: 140, cost: 10.066787, mlm loss: 10.066787, speed: 0.041963 steps/s, speed: 0.335703 samples/s, speed: 171.879852 tokens/s, learning rate: 1.390e-06, loss_scalings: 26214.400391, pp_loss: 8.909462
[INFO] 2021-07-12 18:20:19,888 [run_pretraining.py:  512]:	********exe.run_140******* 
[INFO] 2021-07-12 18:20:20,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:20,828 [run_pretraining.py:  534]:	loss/total_loss, 9.875968933105469, 141
[INFO] 2021-07-12 18:20:20,828 [run_pretraining.py:  535]:	loss/mlm_loss, 9.875968933105469, 141
[INFO] 2021-07-12 18:20:20,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999737279722e-06, 141
[INFO] 2021-07-12 18:20:20,828 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 141
[INFO] 2021-07-12 18:20:20,828 [run_pretraining.py:  558]:	worker_index: 7, step: 141, cost: 9.875969, mlm loss: 9.875969, speed: 1.063870 steps/s, speed: 8.510962 samples/s, speed: 4357.612331 tokens/s, learning rate: 1.400e-06, loss_scalings: 26214.400391, pp_loss: 9.962970
[INFO] 2021-07-12 18:20:20,828 [run_pretraining.py:  512]:	********exe.run_141******* 
[INFO] 2021-07-12 18:20:21,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:21,765 [run_pretraining.py:  534]:	loss/total_loss, 9.882378578186035, 142
[INFO] 2021-07-12 18:20:21,765 [run_pretraining.py:  535]:	loss/mlm_loss, 9.882378578186035, 142
[INFO] 2021-07-12 18:20:21,765 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4099999816608033e-06, 142
[INFO] 2021-07-12 18:20:21,765 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 142
[INFO] 2021-07-12 18:20:21,765 [run_pretraining.py:  558]:	worker_index: 7, step: 142, cost: 9.882379, mlm loss: 9.882379, speed: 1.067846 steps/s, speed: 8.542771 samples/s, speed: 4373.898671 tokens/s, learning rate: 1.410e-06, loss_scalings: 26214.400391, pp_loss: 9.433588
[INFO] 2021-07-12 18:20:21,765 [run_pretraining.py:  512]:	********exe.run_142******* 
[INFO] 2021-07-12 18:20:45,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:20:45,284 [run_pretraining.py:  534]:	loss/total_loss, 9.906455993652344, 143
[INFO] 2021-07-12 18:20:45,284 [run_pretraining.py:  535]:	loss/mlm_loss, 9.906455993652344, 143
[INFO] 2021-07-12 18:20:45,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-06, 143
[INFO] 2021-07-12 18:20:45,284 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 143
[INFO] 2021-07-12 18:20:45,284 [run_pretraining.py:  558]:	worker_index: 7, step: 143, cost: 9.906456, mlm loss: 9.906456, speed: 0.042520 steps/s, speed: 0.340162 samples/s, speed: 174.163159 tokens/s, learning rate: 1.420e-06, loss_scalings: 26214.400391, pp_loss: 10.094070
[INFO] 2021-07-12 18:20:45,284 [run_pretraining.py:  512]:	********exe.run_143******* 
[INFO] 2021-07-12 18:21:08,577 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:08,578 [run_pretraining.py:  534]:	loss/total_loss, 10.219444274902344, 144
[INFO] 2021-07-12 18:21:08,578 [run_pretraining.py:  535]:	loss/mlm_loss, 10.219444274902344, 144
[INFO] 2021-07-12 18:21:08,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4299999975264654e-06, 144
[INFO] 2021-07-12 18:21:08,578 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 144
[INFO] 2021-07-12 18:21:08,578 [run_pretraining.py:  558]:	worker_index: 7, step: 144, cost: 10.219444, mlm loss: 10.219444, speed: 0.042931 steps/s, speed: 0.343449 samples/s, speed: 175.845729 tokens/s, learning rate: 1.430e-06, loss_scalings: 26214.400391, pp_loss: 9.240079
[INFO] 2021-07-12 18:21:08,578 [run_pretraining.py:  512]:	********exe.run_144******* 
[INFO] 2021-07-12 18:21:09,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:09,537 [run_pretraining.py:  534]:	loss/total_loss, 10.07605266571045, 145
[INFO] 2021-07-12 18:21:09,537 [run_pretraining.py:  535]:	loss/mlm_loss, 10.07605266571045, 145
[INFO] 2021-07-12 18:21:09,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998917724588e-06, 145
[INFO] 2021-07-12 18:21:09,537 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 145
[INFO] 2021-07-12 18:21:09,537 [run_pretraining.py:  558]:	worker_index: 7, step: 145, cost: 10.076053, mlm loss: 10.076053, speed: 1.043614 steps/s, speed: 8.348915 samples/s, speed: 4274.644567 tokens/s, learning rate: 1.440e-06, loss_scalings: 26214.400391, pp_loss: 10.010457
[INFO] 2021-07-12 18:21:09,537 [run_pretraining.py:  512]:	********exe.run_145******* 
[INFO] 2021-07-12 18:21:10,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:10,482 [run_pretraining.py:  534]:	loss/total_loss, 10.100489616394043, 146
[INFO] 2021-07-12 18:21:10,482 [run_pretraining.py:  535]:	loss/mlm_loss, 10.100489616394043, 146
[INFO] 2021-07-12 18:21:10,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4499998997052899e-06, 146
[INFO] 2021-07-12 18:21:10,482 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 146
[INFO] 2021-07-12 18:21:10,482 [run_pretraining.py:  558]:	worker_index: 7, step: 146, cost: 10.100490, mlm loss: 10.100490, speed: 1.058756 steps/s, speed: 8.470045 samples/s, speed: 4336.663229 tokens/s, learning rate: 1.450e-06, loss_scalings: 26214.400391, pp_loss: 9.985934
[INFO] 2021-07-12 18:21:10,482 [run_pretraining.py:  512]:	********exe.run_146******* 
[INFO] 2021-07-12 18:21:11,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:11,469 [run_pretraining.py:  534]:	loss/total_loss, 10.185506820678711, 147
[INFO] 2021-07-12 18:21:11,470 [run_pretraining.py:  535]:	loss/mlm_loss, 10.185506820678711, 147
[INFO] 2021-07-12 18:21:11,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4600000213249587e-06, 147
[INFO] 2021-07-12 18:21:11,470 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 147
[INFO] 2021-07-12 18:21:11,470 [run_pretraining.py:  558]:	worker_index: 7, step: 147, cost: 10.185507, mlm loss: 10.185507, speed: 1.012998 steps/s, speed: 8.103986 samples/s, speed: 4149.240773 tokens/s, learning rate: 1.460e-06, loss_scalings: 26214.400391, pp_loss: 9.993088
[INFO] 2021-07-12 18:21:11,470 [run_pretraining.py:  512]:	********exe.run_147******* 
[INFO] 2021-07-12 18:21:12,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:12,417 [run_pretraining.py:  534]:	loss/total_loss, 10.114372253417969, 148
[INFO] 2021-07-12 18:21:12,417 [run_pretraining.py:  535]:	loss/mlm_loss, 10.114372253417969, 148
[INFO] 2021-07-12 18:21:12,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000292577897e-06, 148
[INFO] 2021-07-12 18:21:12,418 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 148
[INFO] 2021-07-12 18:21:12,418 [run_pretraining.py:  558]:	worker_index: 7, step: 148, cost: 10.114372, mlm loss: 10.114372, speed: 1.055695 steps/s, speed: 8.445561 samples/s, speed: 4324.127047 tokens/s, learning rate: 1.470e-06, loss_scalings: 26214.400391, pp_loss: 10.042971
[INFO] 2021-07-12 18:21:12,418 [run_pretraining.py:  512]:	********exe.run_148******* 
[INFO] 2021-07-12 18:21:13,363 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:13,363 [run_pretraining.py:  534]:	loss/total_loss, 10.02727222442627, 149
[INFO] 2021-07-12 18:21:13,363 [run_pretraining.py:  535]:	loss/mlm_loss, 10.02727222442627, 149
[INFO] 2021-07-12 18:21:13,363 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.479999923503783e-06, 149
[INFO] 2021-07-12 18:21:13,363 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 149
[INFO] 2021-07-12 18:21:13,363 [run_pretraining.py:  558]:	worker_index: 7, step: 149, cost: 10.027272, mlm loss: 10.027272, speed: 1.058118 steps/s, speed: 8.464945 samples/s, speed: 4334.051775 tokens/s, learning rate: 1.480e-06, loss_scalings: 26214.400391, pp_loss: 10.024408
[INFO] 2021-07-12 18:21:13,364 [run_pretraining.py:  512]:	********exe.run_149******* 
[INFO] 2021-07-12 18:21:14,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:14,304 [run_pretraining.py:  534]:	loss/total_loss, 10.118955612182617, 150
[INFO] 2021-07-12 18:21:14,304 [run_pretraining.py:  535]:	loss/mlm_loss, 10.118955612182617, 150
[INFO] 2021-07-12 18:21:14,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999314366141e-06, 150
[INFO] 2021-07-12 18:21:14,304 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 150
[INFO] 2021-07-12 18:21:14,304 [run_pretraining.py:  558]:	worker_index: 7, step: 150, cost: 10.118956, mlm loss: 10.118956, speed: 1.063537 steps/s, speed: 8.508292 samples/s, speed: 4356.245513 tokens/s, learning rate: 1.490e-06, loss_scalings: 26214.400391, pp_loss: 8.985193
[INFO] 2021-07-12 18:21:14,304 [run_pretraining.py:  512]:	********exe.run_150******* 
[INFO] 2021-07-12 18:21:15,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:15,245 [run_pretraining.py:  534]:	loss/total_loss, 9.871845245361328, 151
[INFO] 2021-07-12 18:21:15,245 [run_pretraining.py:  535]:	loss/mlm_loss, 9.871845245361328, 151
[INFO] 2021-07-12 18:21:15,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4999999393694452e-06, 151
[INFO] 2021-07-12 18:21:15,245 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 151
[INFO] 2021-07-12 18:21:15,245 [run_pretraining.py:  558]:	worker_index: 7, step: 151, cost: 9.871845, mlm loss: 9.871845, speed: 1.063324 steps/s, speed: 8.506590 samples/s, speed: 4355.374158 tokens/s, learning rate: 1.500e-06, loss_scalings: 26214.400391, pp_loss: 9.962328
[INFO] 2021-07-12 18:21:15,246 [run_pretraining.py:  512]:	********exe.run_151******* 
[INFO] 2021-07-12 18:21:16,197 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:16,197 [run_pretraining.py:  534]:	loss/total_loss, 10.033825874328613, 152
[INFO] 2021-07-12 18:21:16,197 [run_pretraining.py:  535]:	loss/mlm_loss, 10.033825874328613, 152
[INFO] 2021-07-12 18:21:16,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.510000060989114e-06, 152
[INFO] 2021-07-12 18:21:16,197 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 152
[INFO] 2021-07-12 18:21:16,198 [run_pretraining.py:  558]:	worker_index: 7, step: 152, cost: 10.033826, mlm loss: 10.033826, speed: 1.051036 steps/s, speed: 8.408290 samples/s, speed: 4305.044329 tokens/s, learning rate: 1.510e-06, loss_scalings: 26214.400391, pp_loss: 10.054022
[INFO] 2021-07-12 18:21:16,198 [run_pretraining.py:  512]:	********exe.run_152******* 
[INFO] 2021-07-12 18:21:17,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:17,145 [run_pretraining.py:  534]:	loss/total_loss, 10.066978454589844, 153
[INFO] 2021-07-12 18:21:17,145 [run_pretraining.py:  535]:	loss/mlm_loss, 10.066978454589844, 153
[INFO] 2021-07-12 18:21:17,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999552351073e-06, 153
[INFO] 2021-07-12 18:21:17,145 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 153
[INFO] 2021-07-12 18:21:17,145 [run_pretraining.py:  558]:	worker_index: 7, step: 153, cost: 10.066978, mlm loss: 10.066978, speed: 1.055608 steps/s, speed: 8.444861 samples/s, speed: 4323.769002 tokens/s, learning rate: 1.520e-06, loss_scalings: 26214.400391, pp_loss: 10.062163
[INFO] 2021-07-12 18:21:17,146 [run_pretraining.py:  512]:	********exe.run_153******* 
[INFO] 2021-07-12 18:21:42,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:42,904 [run_pretraining.py:  534]:	loss/total_loss, 9.937844276428223, 154
[INFO] 2021-07-12 18:21:42,904 [run_pretraining.py:  535]:	loss/mlm_loss, 9.937844276428223, 154
[INFO] 2021-07-12 18:21:42,904 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5299999631679384e-06, 154
[INFO] 2021-07-12 18:21:42,904 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 154
[INFO] 2021-07-12 18:21:42,904 [run_pretraining.py:  558]:	worker_index: 7, step: 154, cost: 9.937844, mlm loss: 9.937844, speed: 0.038823 steps/s, speed: 0.310585 samples/s, speed: 159.019659 tokens/s, learning rate: 1.530e-06, loss_scalings: 26214.400391, pp_loss: 9.884177
[INFO] 2021-07-12 18:21:42,904 [run_pretraining.py:  512]:	********exe.run_154******* 
[INFO] 2021-07-12 18:21:43,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:43,899 [run_pretraining.py:  534]:	loss/total_loss, 9.954168319702148, 155
[INFO] 2021-07-12 18:21:43,899 [run_pretraining.py:  535]:	loss/mlm_loss, 9.954168319702148, 155
[INFO] 2021-07-12 18:21:43,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5399999711007695e-06, 155
[INFO] 2021-07-12 18:21:43,899 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 155
[INFO] 2021-07-12 18:21:43,900 [run_pretraining.py:  558]:	worker_index: 7, step: 155, cost: 9.954168, mlm loss: 9.954168, speed: 1.005055 steps/s, speed: 8.040439 samples/s, speed: 4116.704719 tokens/s, learning rate: 1.540e-06, loss_scalings: 26214.400391, pp_loss: 9.979314
[INFO] 2021-07-12 18:21:43,900 [run_pretraining.py:  512]:	********exe.run_155******* 
[INFO] 2021-07-12 18:21:44,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:44,867 [run_pretraining.py:  534]:	loss/total_loss, 10.077375411987305, 156
[INFO] 2021-07-12 18:21:44,867 [run_pretraining.py:  535]:	loss/mlm_loss, 10.077375411987305, 156
[INFO] 2021-07-12 18:21:44,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-06, 156
[INFO] 2021-07-12 18:21:44,867 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 156
[INFO] 2021-07-12 18:21:44,867 [run_pretraining.py:  558]:	worker_index: 7, step: 156, cost: 10.077375, mlm loss: 10.077375, speed: 1.034466 steps/s, speed: 8.275727 samples/s, speed: 4237.172266 tokens/s, learning rate: 1.550e-06, loss_scalings: 26214.400391, pp_loss: 9.971235
[INFO] 2021-07-12 18:21:44,867 [run_pretraining.py:  512]:	********exe.run_156******* 
[INFO] 2021-07-12 18:21:45,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  534]:	loss/total_loss, 9.97628402709961, 157
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  535]:	loss/mlm_loss, 9.97628402709961, 157
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5599998732795939e-06, 157
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 157
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  558]:	worker_index: 7, step: 157, cost: 9.976284, mlm loss: 9.976284, speed: 1.031272 steps/s, speed: 8.250178 samples/s, speed: 4224.091269 tokens/s, learning rate: 1.560e-06, loss_scalings: 26214.400391, pp_loss: 9.955172
[INFO] 2021-07-12 18:21:45,837 [run_pretraining.py:  512]:	********exe.run_157******* 
[INFO] 2021-07-12 18:22:11,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:11,590 [run_pretraining.py:  534]:	loss/total_loss, 10.072456359863281, 158
[INFO] 2021-07-12 18:22:11,590 [run_pretraining.py:  535]:	loss/mlm_loss, 10.072456359863281, 158
[INFO] 2021-07-12 18:22:11,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.569999881212425e-06, 158
[INFO] 2021-07-12 18:22:11,590 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 158
[INFO] 2021-07-12 18:22:11,590 [run_pretraining.py:  558]:	worker_index: 7, step: 158, cost: 10.072456, mlm loss: 10.072456, speed: 0.038832 steps/s, speed: 0.310652 samples/s, speed: 159.054038 tokens/s, learning rate: 1.570e-06, loss_scalings: 26214.400391, pp_loss: 10.010797
[INFO] 2021-07-12 18:22:11,590 [run_pretraining.py:  512]:	********exe.run_158******* 
[INFO] 2021-07-12 18:22:12,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:12,589 [run_pretraining.py:  534]:	loss/total_loss, 9.997444152832031, 159
[INFO] 2021-07-12 18:22:12,589 [run_pretraining.py:  535]:	loss/mlm_loss, 9.997444152832031, 159
[INFO] 2021-07-12 18:22:12,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.579999889145256e-06, 159
[INFO] 2021-07-12 18:22:12,589 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 159
[INFO] 2021-07-12 18:22:12,589 [run_pretraining.py:  558]:	worker_index: 7, step: 159, cost: 9.997444, mlm loss: 9.997444, speed: 1.001592 steps/s, speed: 8.012735 samples/s, speed: 4102.520128 tokens/s, learning rate: 1.580e-06, loss_scalings: 26214.400391, pp_loss: 9.985000
[INFO] 2021-07-12 18:22:12,589 [run_pretraining.py:  512]:	********exe.run_159******* 
[INFO] 2021-07-12 18:22:13,558 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:13,558 [run_pretraining.py:  534]:	loss/total_loss, 10.073369026184082, 160
[INFO] 2021-07-12 18:22:13,559 [run_pretraining.py:  535]:	loss/mlm_loss, 10.073369026184082, 160
[INFO] 2021-07-12 18:22:13,559 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5900000107649248e-06, 160
[INFO] 2021-07-12 18:22:13,559 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 160
[INFO] 2021-07-12 18:22:13,559 [run_pretraining.py:  558]:	worker_index: 7, step: 160, cost: 10.073369, mlm loss: 10.073369, speed: 1.032026 steps/s, speed: 8.256209 samples/s, speed: 4227.179194 tokens/s, learning rate: 1.590e-06, loss_scalings: 26214.400391, pp_loss: 10.147554
[INFO] 2021-07-12 18:22:13,559 [run_pretraining.py:  512]:	********exe.run_160******* 
[INFO] 2021-07-12 18:22:14,528 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  534]:	loss/total_loss, 9.995667457580566, 161
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  535]:	loss/mlm_loss, 9.995667457580566, 161
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6000000186977559e-06, 161
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 161
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  558]:	worker_index: 7, step: 161, cost: 9.995667, mlm loss: 9.995667, speed: 1.031504 steps/s, speed: 8.252035 samples/s, speed: 4225.041798 tokens/s, learning rate: 1.600e-06, loss_scalings: 26214.400391, pp_loss: 9.968234
[INFO] 2021-07-12 18:22:14,529 [run_pretraining.py:  512]:	********exe.run_161******* 
[INFO] 2021-07-12 18:22:15,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:15,499 [run_pretraining.py:  534]:	loss/total_loss, 10.115636825561523, 162
[INFO] 2021-07-12 18:22:15,499 [run_pretraining.py:  535]:	loss/mlm_loss, 10.115636825561523, 162
[INFO] 2021-07-12 18:22:15,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.610000026630587e-06, 162
[INFO] 2021-07-12 18:22:15,500 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 162
[INFO] 2021-07-12 18:22:15,500 [run_pretraining.py:  558]:	worker_index: 7, step: 162, cost: 10.115637, mlm loss: 10.115637, speed: 1.030852 steps/s, speed: 8.246816 samples/s, speed: 4222.369978 tokens/s, learning rate: 1.610e-06, loss_scalings: 26214.400391, pp_loss: 10.048912
[INFO] 2021-07-12 18:22:15,500 [run_pretraining.py:  512]:	********exe.run_162******* 
[INFO] 2021-07-12 18:22:16,467 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:16,467 [run_pretraining.py:  534]:	loss/total_loss, 9.729217529296875, 163
[INFO] 2021-07-12 18:22:16,467 [run_pretraining.py:  535]:	loss/mlm_loss, 9.729217529296875, 163
[INFO] 2021-07-12 18:22:16,467 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.620000034563418e-06, 163
[INFO] 2021-07-12 18:22:16,467 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 163
[INFO] 2021-07-12 18:22:16,467 [run_pretraining.py:  558]:	worker_index: 7, step: 163, cost: 9.729218, mlm loss: 9.729218, speed: 1.033919 steps/s, speed: 8.271353 samples/s, speed: 4234.932887 tokens/s, learning rate: 1.620e-06, loss_scalings: 26214.400391, pp_loss: 9.973940
[INFO] 2021-07-12 18:22:16,468 [run_pretraining.py:  512]:	********exe.run_163******* 
[INFO] 2021-07-12 18:22:17,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:17,440 [run_pretraining.py:  534]:	loss/total_loss, 9.938814163208008, 164
[INFO] 2021-07-12 18:22:17,440 [run_pretraining.py:  535]:	loss/mlm_loss, 9.938814163208008, 164
[INFO] 2021-07-12 18:22:17,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6299999288094114e-06, 164
[INFO] 2021-07-12 18:22:17,440 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 164
[INFO] 2021-07-12 18:22:17,440 [run_pretraining.py:  558]:	worker_index: 7, step: 164, cost: 9.938814, mlm loss: 9.938814, speed: 1.029065 steps/s, speed: 8.232519 samples/s, speed: 4215.049949 tokens/s, learning rate: 1.630e-06, loss_scalings: 26214.400391, pp_loss: 9.969177
[INFO] 2021-07-12 18:22:17,440 [run_pretraining.py:  512]:	********exe.run_164******* 
[INFO] 2021-07-12 18:22:18,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:18,411 [run_pretraining.py:  534]:	loss/total_loss, 9.93701457977295, 165
[INFO] 2021-07-12 18:22:18,411 [run_pretraining.py:  535]:	loss/mlm_loss, 9.93701457977295, 165
[INFO] 2021-07-12 18:22:18,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-06, 165
[INFO] 2021-07-12 18:22:18,411 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 165
[INFO] 2021-07-12 18:22:18,411 [run_pretraining.py:  558]:	worker_index: 7, step: 165, cost: 9.937015, mlm loss: 9.937015, speed: 1.029965 steps/s, speed: 8.239716 samples/s, speed: 4218.734759 tokens/s, learning rate: 1.640e-06, loss_scalings: 26214.400391, pp_loss: 9.903803
[INFO] 2021-07-12 18:22:18,412 [run_pretraining.py:  512]:	********exe.run_165******* 
[INFO] 2021-07-12 18:22:19,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:19,374 [run_pretraining.py:  534]:	loss/total_loss, 9.831064224243164, 166
[INFO] 2021-07-12 18:22:19,375 [run_pretraining.py:  535]:	loss/mlm_loss, 9.831064224243164, 166
[INFO] 2021-07-12 18:22:19,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6499999446750735e-06, 166
[INFO] 2021-07-12 18:22:19,375 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 166
[INFO] 2021-07-12 18:22:19,375 [run_pretraining.py:  558]:	worker_index: 7, step: 166, cost: 9.831064, mlm loss: 9.831064, speed: 1.038773 steps/s, speed: 8.310185 samples/s, speed: 4254.814611 tokens/s, learning rate: 1.650e-06, loss_scalings: 26214.400391, pp_loss: 9.964832
[INFO] 2021-07-12 18:22:19,375 [run_pretraining.py:  512]:	********exe.run_166******* 
[INFO] 2021-07-12 18:22:20,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:20,342 [run_pretraining.py:  534]:	loss/total_loss, 9.843070983886719, 167
[INFO] 2021-07-12 18:22:20,342 [run_pretraining.py:  535]:	loss/mlm_loss, 9.843070983886719, 167
[INFO] 2021-07-12 18:22:20,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999526079046e-06, 167
[INFO] 2021-07-12 18:22:20,342 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 167
[INFO] 2021-07-12 18:22:20,342 [run_pretraining.py:  558]:	worker_index: 7, step: 167, cost: 9.843071, mlm loss: 9.843071, speed: 1.034216 steps/s, speed: 8.273729 samples/s, speed: 4236.149420 tokens/s, learning rate: 1.660e-06, loss_scalings: 26214.400391, pp_loss: 9.921198
[INFO] 2021-07-12 18:22:20,342 [run_pretraining.py:  512]:	********exe.run_167******* 
[INFO] 2021-07-12 18:22:21,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:21,311 [run_pretraining.py:  534]:	loss/total_loss, 9.879288673400879, 168
[INFO] 2021-07-12 18:22:21,311 [run_pretraining.py:  535]:	loss/mlm_loss, 9.879288673400879, 168
[INFO] 2021-07-12 18:22:21,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999605407356e-06, 168
[INFO] 2021-07-12 18:22:21,311 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 168
[INFO] 2021-07-12 18:22:21,311 [run_pretraining.py:  558]:	worker_index: 7, step: 168, cost: 9.879289, mlm loss: 9.879289, speed: 1.033238 steps/s, speed: 8.265907 samples/s, speed: 4232.144288 tokens/s, learning rate: 1.670e-06, loss_scalings: 26214.400391, pp_loss: 9.960245
[INFO] 2021-07-12 18:22:21,311 [run_pretraining.py:  512]:	********exe.run_168******* 
[INFO] 2021-07-12 18:22:22,376 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:22,376 [run_pretraining.py:  534]:	loss/total_loss, 10.073660850524902, 169
[INFO] 2021-07-12 18:22:22,376 [run_pretraining.py:  535]:	loss/mlm_loss, 10.073660850524902, 169
[INFO] 2021-07-12 18:22:22,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.679999854786729e-06, 169
[INFO] 2021-07-12 18:22:22,376 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 169
[INFO] 2021-07-12 18:22:22,377 [run_pretraining.py:  558]:	worker_index: 7, step: 169, cost: 10.073661, mlm loss: 10.073661, speed: 0.938928 steps/s, speed: 7.511426 samples/s, speed: 3845.849905 tokens/s, learning rate: 1.680e-06, loss_scalings: 26214.400391, pp_loss: 9.994106
[INFO] 2021-07-12 18:22:22,377 [run_pretraining.py:  512]:	********exe.run_169******* 
[INFO] 2021-07-12 18:22:23,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:23,457 [run_pretraining.py:  534]:	loss/total_loss, 9.917149543762207, 170
[INFO] 2021-07-12 18:22:23,457 [run_pretraining.py:  535]:	loss/mlm_loss, 9.917149543762207, 170
[INFO] 2021-07-12 18:22:23,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.68999986271956e-06, 170
[INFO] 2021-07-12 18:22:23,457 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 170
[INFO] 2021-07-12 18:22:23,457 [run_pretraining.py:  558]:	worker_index: 7, step: 170, cost: 9.917150, mlm loss: 9.917150, speed: 0.925720 steps/s, speed: 7.405763 samples/s, speed: 3791.750779 tokens/s, learning rate: 1.690e-06, loss_scalings: 26214.400391, pp_loss: 9.898793
[INFO] 2021-07-12 18:22:23,457 [run_pretraining.py:  512]:	********exe.run_170******* 
[INFO] 2021-07-12 18:22:24,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:24,497 [run_pretraining.py:  534]:	loss/total_loss, 9.970039367675781, 171
[INFO] 2021-07-12 18:22:24,497 [run_pretraining.py:  535]:	loss/mlm_loss, 9.970039367675781, 171
[INFO] 2021-07-12 18:22:24,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7000000980260666e-06, 171
[INFO] 2021-07-12 18:22:24,498 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 171
[INFO] 2021-07-12 18:22:24,498 [run_pretraining.py:  558]:	worker_index: 7, step: 171, cost: 9.970039, mlm loss: 9.970039, speed: 0.961892 steps/s, speed: 7.695136 samples/s, speed: 3939.909543 tokens/s, learning rate: 1.700e-06, loss_scalings: 26214.400391, pp_loss: 9.928875
[INFO] 2021-07-12 18:22:24,498 [run_pretraining.py:  512]:	********exe.run_171******* 
[INFO] 2021-07-12 18:22:25,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:25,549 [run_pretraining.py:  534]:	loss/total_loss, 9.878783226013184, 172
[INFO] 2021-07-12 18:22:25,549 [run_pretraining.py:  535]:	loss/mlm_loss, 9.878783226013184, 172
[INFO] 2021-07-12 18:22:25,549 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70999999227206e-06, 172
[INFO] 2021-07-12 18:22:25,550 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 172
[INFO] 2021-07-12 18:22:25,550 [run_pretraining.py:  558]:	worker_index: 7, step: 172, cost: 9.878783, mlm loss: 9.878783, speed: 0.951196 steps/s, speed: 7.609567 samples/s, speed: 3896.098380 tokens/s, learning rate: 1.710e-06, loss_scalings: 26214.400391, pp_loss: 10.008396
[INFO] 2021-07-12 18:22:25,550 [run_pretraining.py:  512]:	********exe.run_172******* 
[INFO] 2021-07-12 18:22:26,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:26,605 [run_pretraining.py:  534]:	loss/total_loss, 10.02984619140625, 173
[INFO] 2021-07-12 18:22:26,605 [run_pretraining.py:  535]:	loss/mlm_loss, 10.02984619140625, 173
[INFO] 2021-07-12 18:22:26,605 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-06, 173
[INFO] 2021-07-12 18:22:26,605 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 173
[INFO] 2021-07-12 18:22:26,605 [run_pretraining.py:  558]:	worker_index: 7, step: 173, cost: 10.029846, mlm loss: 10.029846, speed: 0.947735 steps/s, speed: 7.581877 samples/s, speed: 3881.921178 tokens/s, learning rate: 1.720e-06, loss_scalings: 26214.400391, pp_loss: 9.925013
[INFO] 2021-07-12 18:22:26,605 [run_pretraining.py:  512]:	********exe.run_173******* 
[INFO] 2021-07-12 18:22:52,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:22:52,561 [run_pretraining.py:  534]:	loss/total_loss, 9.969785690307617, 174
[INFO] 2021-07-12 18:22:52,561 [run_pretraining.py:  535]:	loss/mlm_loss, 9.969785690307617, 174
[INFO] 2021-07-12 18:22:52,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.730000008137722e-06, 174
[INFO] 2021-07-12 18:22:52,561 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 174
[INFO] 2021-07-12 18:22:52,561 [run_pretraining.py:  558]:	worker_index: 7, step: 174, cost: 9.969786, mlm loss: 9.969786, speed: 0.038528 steps/s, speed: 0.308224 samples/s, speed: 157.810815 tokens/s, learning rate: 1.730e-06, loss_scalings: 26214.400391, pp_loss: 9.958899
[INFO] 2021-07-12 18:22:52,561 [run_pretraining.py:  512]:	********exe.run_174******* 
[INFO] 2021-07-12 18:23:41,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:41,452 [run_pretraining.py:  534]:	loss/total_loss, 9.321670532226562, 175
[INFO] 2021-07-12 18:23:41,452 [run_pretraining.py:  535]:	loss/mlm_loss, 9.321670532226562, 175
[INFO] 2021-07-12 18:23:41,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.740000016070553e-06, 175
[INFO] 2021-07-12 18:23:41,452 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 175
[INFO] 2021-07-12 18:23:41,452 [run_pretraining.py:  558]:	worker_index: 7, step: 175, cost: 9.321671, mlm loss: 9.321671, speed: 0.020454 steps/s, speed: 0.163632 samples/s, speed: 83.779418 tokens/s, learning rate: 1.740e-06, loss_scalings: 26214.400391, pp_loss: 9.776901
[INFO] 2021-07-12 18:23:41,452 [run_pretraining.py:  512]:	********exe.run_175******* 
[INFO] 2021-07-12 18:23:42,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:42,435 [run_pretraining.py:  534]:	loss/total_loss, 10.057619094848633, 176
[INFO] 2021-07-12 18:23:42,435 [run_pretraining.py:  535]:	loss/mlm_loss, 10.057619094848633, 176
[INFO] 2021-07-12 18:23:42,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499999103165464e-06, 176
[INFO] 2021-07-12 18:23:42,435 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 176
[INFO] 2021-07-12 18:23:42,435 [run_pretraining.py:  558]:	worker_index: 7, step: 176, cost: 10.057619, mlm loss: 10.057619, speed: 1.017947 steps/s, speed: 8.143580 samples/s, speed: 4169.512907 tokens/s, learning rate: 1.750e-06, loss_scalings: 26214.400391, pp_loss: 9.990638
[INFO] 2021-07-12 18:23:42,435 [run_pretraining.py:  512]:	********exe.run_176******* 
[INFO] 2021-07-12 18:23:43,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:43,393 [run_pretraining.py:  534]:	loss/total_loss, 9.776834487915039, 177
[INFO] 2021-07-12 18:23:43,393 [run_pretraining.py:  535]:	loss/mlm_loss, 9.776834487915039, 177
[INFO] 2021-07-12 18:23:43,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7599999182493775e-06, 177
[INFO] 2021-07-12 18:23:43,393 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 177
[INFO] 2021-07-12 18:23:43,393 [run_pretraining.py:  558]:	worker_index: 7, step: 177, cost: 9.776834, mlm loss: 9.776834, speed: 1.044371 steps/s, speed: 8.354969 samples/s, speed: 4277.744029 tokens/s, learning rate: 1.760e-06, loss_scalings: 26214.400391, pp_loss: 9.903682
[INFO] 2021-07-12 18:23:43,393 [run_pretraining.py:  512]:	********exe.run_177******* 
[INFO] 2021-07-12 18:23:44,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:44,372 [run_pretraining.py:  534]:	loss/total_loss, 10.055739402770996, 178
[INFO] 2021-07-12 18:23:44,372 [run_pretraining.py:  535]:	loss/mlm_loss, 10.055739402770996, 178
[INFO] 2021-07-12 18:23:44,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7699999261822086e-06, 178
[INFO] 2021-07-12 18:23:44,372 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 178
[INFO] 2021-07-12 18:23:44,372 [run_pretraining.py:  558]:	worker_index: 7, step: 178, cost: 10.055739, mlm loss: 10.055739, speed: 1.022173 steps/s, speed: 8.177386 samples/s, speed: 4186.821692 tokens/s, learning rate: 1.770e-06, loss_scalings: 26214.400391, pp_loss: 10.070041
[INFO] 2021-07-12 18:23:44,372 [run_pretraining.py:  512]:	********exe.run_178******* 
[INFO] 2021-07-12 18:23:45,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:45,429 [run_pretraining.py:  534]:	loss/total_loss, 9.936336517333984, 179
[INFO] 2021-07-12 18:23:45,429 [run_pretraining.py:  535]:	loss/mlm_loss, 9.936336517333984, 179
[INFO] 2021-07-12 18:23:45,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7799999341150397e-06, 179
[INFO] 2021-07-12 18:23:45,430 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 179
[INFO] 2021-07-12 18:23:45,430 [run_pretraining.py:  558]:	worker_index: 7, step: 179, cost: 9.936337, mlm loss: 9.936337, speed: 0.946367 steps/s, speed: 7.570936 samples/s, speed: 3876.319027 tokens/s, learning rate: 1.780e-06, loss_scalings: 26214.400391, pp_loss: 9.982561
[INFO] 2021-07-12 18:23:45,430 [run_pretraining.py:  512]:	********exe.run_179******* 
[INFO] 2021-07-12 18:23:46,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:23:46,492 [run_pretraining.py:  534]:	loss/total_loss, 9.934575080871582, 180
[INFO] 2021-07-12 18:23:46,492 [run_pretraining.py:  535]:	loss/mlm_loss, 9.934575080871582, 180
[INFO] 2021-07-12 18:23:46,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999420478707e-06, 180
[INFO] 2021-07-12 18:23:46,492 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 180
[INFO] 2021-07-12 18:23:46,492 [run_pretraining.py:  558]:	worker_index: 7, step: 180, cost: 9.934575, mlm loss: 9.934575, speed: 0.941869 steps/s, speed: 7.534953 samples/s, speed: 3857.895685 tokens/s, learning rate: 1.790e-06, loss_scalings: 26214.400391, pp_loss: 9.924709
[INFO] 2021-07-12 18:23:46,492 [run_pretraining.py:  512]:	********exe.run_180******* 
[INFO] 2021-07-12 18:24:11,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  534]:	loss/total_loss, 9.875370979309082, 181
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  535]:	loss/mlm_loss, 9.875370979309082, 181
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.799999836293864e-06, 181
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 181
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  558]:	worker_index: 7, step: 181, cost: 9.875371, mlm loss: 9.875371, speed: 0.039497 steps/s, speed: 0.315973 samples/s, speed: 161.778107 tokens/s, learning rate: 1.800e-06, loss_scalings: 26214.400391, pp_loss: 9.837382
[INFO] 2021-07-12 18:24:11,811 [run_pretraining.py:  512]:	********exe.run_181******* 
[INFO] 2021-07-12 18:24:12,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:12,848 [run_pretraining.py:  534]:	loss/total_loss, 10.052874565124512, 182
[INFO] 2021-07-12 18:24:12,848 [run_pretraining.py:  535]:	loss/mlm_loss, 10.052874565124512, 182
[INFO] 2021-07-12 18:24:12,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8100000716003706e-06, 182
[INFO] 2021-07-12 18:24:12,848 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 182
[INFO] 2021-07-12 18:24:12,848 [run_pretraining.py:  558]:	worker_index: 7, step: 182, cost: 10.052875, mlm loss: 10.052875, speed: 0.965309 steps/s, speed: 7.722470 samples/s, speed: 3953.904484 tokens/s, learning rate: 1.810e-06, loss_scalings: 26214.400391, pp_loss: 9.927640
[INFO] 2021-07-12 18:24:12,848 [run_pretraining.py:  512]:	********exe.run_182******* 
[INFO] 2021-07-12 18:24:13,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:13,896 [run_pretraining.py:  534]:	loss/total_loss, 9.859028816223145, 183
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  535]:	loss/mlm_loss, 9.859028816223145, 183
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8200000795332016e-06, 183
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 183
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  558]:	worker_index: 7, step: 183, cost: 9.859029, mlm loss: 9.859029, speed: 0.954000 steps/s, speed: 7.632004 samples/s, speed: 3907.585843 tokens/s, learning rate: 1.820e-06, loss_scalings: 26214.400391, pp_loss: 9.860137
[INFO] 2021-07-12 18:24:13,897 [run_pretraining.py:  512]:	********exe.run_183******* 
[INFO] 2021-07-12 18:24:39,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:39,793 [run_pretraining.py:  534]:	loss/total_loss, 10.010797500610352, 184
[INFO] 2021-07-12 18:24:39,793 [run_pretraining.py:  535]:	loss/mlm_loss, 10.010797500610352, 184
[INFO] 2021-07-12 18:24:39,793 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.829999973779195e-06, 184
[INFO] 2021-07-12 18:24:39,794 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 184
[INFO] 2021-07-12 18:24:39,794 [run_pretraining.py:  558]:	worker_index: 7, step: 184, cost: 10.010798, mlm loss: 10.010798, speed: 0.038616 steps/s, speed: 0.308925 samples/s, speed: 158.169772 tokens/s, learning rate: 1.830e-06, loss_scalings: 26214.400391, pp_loss: 9.964436
[INFO] 2021-07-12 18:24:39,794 [run_pretraining.py:  512]:	********exe.run_184******* 
[INFO] 2021-07-12 18:24:40,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:40,773 [run_pretraining.py:  534]:	loss/total_loss, 9.770864486694336, 185
[INFO] 2021-07-12 18:24:40,773 [run_pretraining.py:  535]:	loss/mlm_loss, 9.770864486694336, 185
[INFO] 2021-07-12 18:24:40,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.839999981712026e-06, 185
[INFO] 2021-07-12 18:24:40,773 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 185
[INFO] 2021-07-12 18:24:40,774 [run_pretraining.py:  558]:	worker_index: 7, step: 185, cost: 9.770864, mlm loss: 9.770864, speed: 1.021138 steps/s, speed: 8.169104 samples/s, speed: 4182.581336 tokens/s, learning rate: 1.840e-06, loss_scalings: 26214.400391, pp_loss: 9.818544
[INFO] 2021-07-12 18:24:40,774 [run_pretraining.py:  512]:	********exe.run_185******* 
[INFO] 2021-07-12 18:24:41,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:41,729 [run_pretraining.py:  534]:	loss/total_loss, 9.664363861083984, 186
[INFO] 2021-07-12 18:24:41,729 [run_pretraining.py:  535]:	loss/mlm_loss, 9.664363861083984, 186
[INFO] 2021-07-12 18:24:41,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8499999896448571e-06, 186
[INFO] 2021-07-12 18:24:41,729 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 186
[INFO] 2021-07-12 18:24:41,729 [run_pretraining.py:  558]:	worker_index: 7, step: 186, cost: 9.664364, mlm loss: 9.664364, speed: 1.047406 steps/s, speed: 8.379244 samples/s, speed: 4290.173028 tokens/s, learning rate: 1.850e-06, loss_scalings: 26214.400391, pp_loss: 10.088254
[INFO] 2021-07-12 18:24:41,729 [run_pretraining.py:  512]:	********exe.run_186******* 
[INFO] 2021-07-12 18:24:42,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:24:42,688 [run_pretraining.py:  534]:	loss/total_loss, 9.876566886901855, 187
[INFO] 2021-07-12 18:24:42,688 [run_pretraining.py:  535]:	loss/mlm_loss, 9.876566886901855, 187
[INFO] 2021-07-12 18:24:42,688 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999975776882e-06, 187
[INFO] 2021-07-12 18:24:42,689 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 187
[INFO] 2021-07-12 18:24:42,689 [run_pretraining.py:  558]:	worker_index: 7, step: 187, cost: 9.876567, mlm loss: 9.876567, speed: 1.042672 steps/s, speed: 8.341375 samples/s, speed: 4270.783982 tokens/s, learning rate: 1.860e-06, loss_scalings: 26214.400391, pp_loss: 9.817842
[INFO] 2021-07-12 18:24:42,689 [run_pretraining.py:  512]:	********exe.run_187******* 
[INFO] 2021-07-12 18:25:06,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:06,936 [run_pretraining.py:  534]:	loss/total_loss, 9.924895286560059, 188
[INFO] 2021-07-12 18:25:06,936 [run_pretraining.py:  535]:	loss/mlm_loss, 9.924895286560059, 188
[INFO] 2021-07-12 18:25:06,936 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8699998918236815e-06, 188
[INFO] 2021-07-12 18:25:06,936 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 188
[INFO] 2021-07-12 18:25:06,936 [run_pretraining.py:  558]:	worker_index: 7, step: 188, cost: 9.924895, mlm loss: 9.924895, speed: 0.041243 steps/s, speed: 0.329940 samples/s, speed: 168.929419 tokens/s, learning rate: 1.870e-06, loss_scalings: 26214.400391, pp_loss: 9.835280
[INFO] 2021-07-12 18:25:06,936 [run_pretraining.py:  512]:	********exe.run_188******* 
[INFO] 2021-07-12 18:25:07,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:07,900 [run_pretraining.py:  534]:	loss/total_loss, 9.928439140319824, 189
[INFO] 2021-07-12 18:25:07,900 [run_pretraining.py:  535]:	loss/mlm_loss, 9.928439140319824, 189
[INFO] 2021-07-12 18:25:07,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799998997565126e-06, 189
[INFO] 2021-07-12 18:25:07,901 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 189
[INFO] 2021-07-12 18:25:07,901 [run_pretraining.py:  558]:	worker_index: 7, step: 189, cost: 9.928439, mlm loss: 9.928439, speed: 1.037423 steps/s, speed: 8.299388 samples/s, speed: 4249.286405 tokens/s, learning rate: 1.880e-06, loss_scalings: 26214.400391, pp_loss: 9.129336
[INFO] 2021-07-12 18:25:07,901 [run_pretraining.py:  512]:	********exe.run_189******* 
[INFO] 2021-07-12 18:25:30,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:30,900 [run_pretraining.py:  534]:	loss/total_loss, 9.914131164550781, 190
[INFO] 2021-07-12 18:25:30,900 [run_pretraining.py:  535]:	loss/mlm_loss, 9.914131164550781, 190
[INFO] 2021-07-12 18:25:30,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8899999076893437e-06, 190
[INFO] 2021-07-12 18:25:30,900 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 190
[INFO] 2021-07-12 18:25:30,900 [run_pretraining.py:  558]:	worker_index: 7, step: 190, cost: 9.914131, mlm loss: 9.914131, speed: 0.043481 steps/s, speed: 0.347845 samples/s, speed: 178.096741 tokens/s, learning rate: 1.890e-06, loss_scalings: 26214.400391, pp_loss: 9.765461
[INFO] 2021-07-12 18:25:30,900 [run_pretraining.py:  512]:	********exe.run_190******* 
[INFO] 2021-07-12 18:25:31,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:31,873 [run_pretraining.py:  534]:	loss/total_loss, 9.757948875427246, 191
[INFO] 2021-07-12 18:25:31,873 [run_pretraining.py:  535]:	loss/mlm_loss, 9.757948875427246, 191
[INFO] 2021-07-12 18:25:31,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-06, 191
[INFO] 2021-07-12 18:25:31,873 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 191
[INFO] 2021-07-12 18:25:31,873 [run_pretraining.py:  558]:	worker_index: 7, step: 191, cost: 9.757949, mlm loss: 9.757949, speed: 1.028451 steps/s, speed: 8.227608 samples/s, speed: 4212.535351 tokens/s, learning rate: 1.900e-06, loss_scalings: 26214.400391, pp_loss: 9.746749
[INFO] 2021-07-12 18:25:31,873 [run_pretraining.py:  512]:	********exe.run_191******* 
[INFO] 2021-07-12 18:25:32,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:32,829 [run_pretraining.py:  534]:	loss/total_loss, 9.95959186553955, 192
[INFO] 2021-07-12 18:25:32,829 [run_pretraining.py:  535]:	loss/mlm_loss, 9.95959186553955, 192
[INFO] 2021-07-12 18:25:32,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.909999809868168e-06, 192
[INFO] 2021-07-12 18:25:32,829 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 192
[INFO] 2021-07-12 18:25:32,830 [run_pretraining.py:  558]:	worker_index: 7, step: 192, cost: 9.959592, mlm loss: 9.959592, speed: 1.046072 steps/s, speed: 8.368580 samples/s, speed: 4284.712907 tokens/s, learning rate: 1.910e-06, loss_scalings: 26214.400391, pp_loss: 9.747871
[INFO] 2021-07-12 18:25:32,830 [run_pretraining.py:  512]:	********exe.run_192******* 
[INFO] 2021-07-12 18:25:58,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:25:58,174 [run_pretraining.py:  534]:	loss/total_loss, 9.813632011413574, 193
[INFO] 2021-07-12 18:25:58,174 [run_pretraining.py:  535]:	loss/mlm_loss, 9.813632011413574, 193
[INFO] 2021-07-12 18:25:58,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.919999931487837e-06, 193
[INFO] 2021-07-12 18:25:58,174 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 193
[INFO] 2021-07-12 18:25:58,175 [run_pretraining.py:  558]:	worker_index: 7, step: 193, cost: 9.813632, mlm loss: 9.813632, speed: 0.039457 steps/s, speed: 0.315653 samples/s, speed: 161.614107 tokens/s, learning rate: 1.920e-06, loss_scalings: 26214.400391, pp_loss: 9.775380
[INFO] 2021-07-12 18:25:58,175 [run_pretraining.py:  512]:	********exe.run_193******* 
[INFO] 2021-07-12 18:26:21,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:21,189 [run_pretraining.py:  534]:	loss/total_loss, 9.985038757324219, 194
[INFO] 2021-07-12 18:26:21,189 [run_pretraining.py:  535]:	loss/mlm_loss, 9.985038757324219, 194
[INFO] 2021-07-12 18:26:21,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9300000531075057e-06, 194
[INFO] 2021-07-12 18:26:21,189 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 194
[INFO] 2021-07-12 18:26:21,189 [run_pretraining.py:  558]:	worker_index: 7, step: 194, cost: 9.985039, mlm loss: 9.985039, speed: 0.043452 steps/s, speed: 0.347620 samples/s, speed: 177.981275 tokens/s, learning rate: 1.930e-06, loss_scalings: 26214.400391, pp_loss: 8.911297
[INFO] 2021-07-12 18:26:21,189 [run_pretraining.py:  512]:	********exe.run_194******* 
[INFO] 2021-07-12 18:26:22,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  534]:	loss/total_loss, 9.81505298614502, 195
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  535]:	loss/mlm_loss, 9.81505298614502, 195
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.939999947353499e-06, 195
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 195
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  558]:	worker_index: 7, step: 195, cost: 9.815053, mlm loss: 9.815053, speed: 1.041851 steps/s, speed: 8.334805 samples/s, speed: 4267.420033 tokens/s, learning rate: 1.940e-06, loss_scalings: 26214.400391, pp_loss: 9.837119
[INFO] 2021-07-12 18:26:22,149 [run_pretraining.py:  512]:	********exe.run_195******* 
[INFO] 2021-07-12 18:26:23,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:23,110 [run_pretraining.py:  534]:	loss/total_loss, 9.821687698364258, 196
[INFO] 2021-07-12 18:26:23,110 [run_pretraining.py:  535]:	loss/mlm_loss, 9.821687698364258, 196
[INFO] 2021-07-12 18:26:23,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.950000068973168e-06, 196
[INFO] 2021-07-12 18:26:23,110 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 196
[INFO] 2021-07-12 18:26:23,110 [run_pretraining.py:  558]:	worker_index: 7, step: 196, cost: 9.821688, mlm loss: 9.821688, speed: 1.041500 steps/s, speed: 8.332000 samples/s, speed: 4265.984199 tokens/s, learning rate: 1.950e-06, loss_scalings: 26214.400391, pp_loss: 9.700796
[INFO] 2021-07-12 18:26:23,110 [run_pretraining.py:  512]:	********exe.run_196******* 
[INFO] 2021-07-12 18:26:24,070 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:24,071 [run_pretraining.py:  534]:	loss/total_loss, 9.908626556396484, 197
[INFO] 2021-07-12 18:26:24,071 [run_pretraining.py:  535]:	loss/mlm_loss, 9.908626556396484, 197
[INFO] 2021-07-12 18:26:24,071 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999963219161e-06, 197
[INFO] 2021-07-12 18:26:24,071 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 197
[INFO] 2021-07-12 18:26:24,071 [run_pretraining.py:  558]:	worker_index: 7, step: 197, cost: 9.908627, mlm loss: 9.908627, speed: 1.041267 steps/s, speed: 8.330135 samples/s, speed: 4265.028925 tokens/s, learning rate: 1.960e-06, loss_scalings: 26214.400391, pp_loss: 9.854709
[INFO] 2021-07-12 18:26:24,071 [run_pretraining.py:  512]:	********exe.run_197******* 
[INFO] 2021-07-12 18:26:25,032 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:26:25,032 [run_pretraining.py:  534]:	loss/total_loss, 10.01488971710205, 198
[INFO] 2021-07-12 18:26:25,032 [run_pretraining.py:  535]:	loss/mlm_loss, 10.01488971710205, 198
[INFO] 2021-07-12 18:26:25,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699998574651545e-06, 198
[INFO] 2021-07-12 18:26:25,032 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 198
[INFO] 2021-07-12 18:26:25,032 [run_pretraining.py:  558]:	worker_index: 7, step: 198, cost: 10.014890, mlm loss: 10.014890, speed: 1.041021 steps/s, speed: 8.328170 samples/s, speed: 4264.023279 tokens/s, learning rate: 1.970e-06, loss_scalings: 26214.400391, pp_loss: 9.811068
[INFO] 2021-07-12 18:26:25,032 [run_pretraining.py:  512]:	********exe.run_198******* 
[INFO] 2021-07-12 18:27:15,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:27:15,713 [run_pretraining.py:  534]:	loss/total_loss, 9.965923309326172, 199
[INFO] 2021-07-12 18:27:15,713 [run_pretraining.py:  535]:	loss/mlm_loss, 9.965923309326172, 199
[INFO] 2021-07-12 18:27:15,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-06, 199
[INFO] 2021-07-12 18:27:15,713 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 199
[INFO] 2021-07-12 18:27:15,713 [run_pretraining.py:  558]:	worker_index: 7, step: 199, cost: 9.965923, mlm loss: 9.965923, speed: 0.019732 steps/s, speed: 0.157853 samples/s, speed: 80.820742 tokens/s, learning rate: 1.980e-06, loss_scalings: 26214.400391, pp_loss: 9.951736
[INFO] 2021-07-12 18:27:15,713 [run_pretraining.py:  512]:	********exe.run_199******* 
[INFO] 2021-07-12 18:27:40,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:27:40,974 [run_pretraining.py:  534]:	loss/total_loss, 9.914244651794434, 200
[INFO] 2021-07-12 18:27:40,974 [run_pretraining.py:  535]:	loss/mlm_loss, 9.914244651794434, 200
[INFO] 2021-07-12 18:27:40,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-06, 200
[INFO] 2021-07-12 18:27:40,974 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 200
[INFO] 2021-07-12 18:27:40,974 [run_pretraining.py:  558]:	worker_index: 7, step: 200, cost: 9.914245, mlm loss: 9.914245, speed: 0.039588 steps/s, speed: 0.316705 samples/s, speed: 162.152992 tokens/s, learning rate: 1.990e-06, loss_scalings: 26214.400391, pp_loss: 8.892097
[INFO] 2021-07-12 18:27:40,974 [run_pretraining.py:  512]:	********exe.run_200******* 
[INFO] 2021-07-12 18:28:05,992 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:05,992 [run_pretraining.py:  534]:	loss/total_loss, 9.620574951171875, 201
[INFO] 2021-07-12 18:28:05,993 [run_pretraining.py:  535]:	loss/mlm_loss, 9.620574951171875, 201
[INFO] 2021-07-12 18:28:05,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999949504854e-06, 201
[INFO] 2021-07-12 18:28:05,993 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 201
[INFO] 2021-07-12 18:28:05,993 [run_pretraining.py:  558]:	worker_index: 7, step: 201, cost: 9.620575, mlm loss: 9.620575, speed: 0.039971 steps/s, speed: 0.319767 samples/s, speed: 163.720904 tokens/s, learning rate: 2.000e-06, loss_scalings: 26214.400391, pp_loss: 9.700459
[INFO] 2021-07-12 18:28:05,993 [run_pretraining.py:  512]:	********exe.run_201******* 
[INFO] 2021-07-12 18:28:06,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:06,925 [run_pretraining.py:  534]:	loss/total_loss, 9.456271171569824, 202
[INFO] 2021-07-12 18:28:06,925 [run_pretraining.py:  535]:	loss/mlm_loss, 9.456271171569824, 202
[INFO] 2021-07-12 18:28:06,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0099998891964788e-06, 202
[INFO] 2021-07-12 18:28:06,925 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 202
[INFO] 2021-07-12 18:28:06,926 [run_pretraining.py:  558]:	worker_index: 7, step: 202, cost: 9.456271, mlm loss: 9.456271, speed: 1.072751 steps/s, speed: 8.582008 samples/s, speed: 4393.988013 tokens/s, learning rate: 2.010e-06, loss_scalings: 26214.400391, pp_loss: 9.334278
[INFO] 2021-07-12 18:28:06,926 [run_pretraining.py:  512]:	********exe.run_202******* 
[INFO] 2021-07-12 18:28:07,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:07,947 [run_pretraining.py:  534]:	loss/total_loss, 9.778831481933594, 203
[INFO] 2021-07-12 18:28:07,947 [run_pretraining.py:  535]:	loss/mlm_loss, 9.778831481933594, 203
[INFO] 2021-07-12 18:28:07,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.019999783442472e-06, 203
[INFO] 2021-07-12 18:28:07,947 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 203
[INFO] 2021-07-12 18:28:07,947 [run_pretraining.py:  558]:	worker_index: 7, step: 203, cost: 9.778831, mlm loss: 9.778831, speed: 0.979394 steps/s, speed: 7.835152 samples/s, speed: 4011.598039 tokens/s, learning rate: 2.020e-06, loss_scalings: 26214.400391, pp_loss: 9.857418
[INFO] 2021-07-12 18:28:07,947 [run_pretraining.py:  512]:	********exe.run_203******* 
[INFO] 2021-07-12 18:28:08,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:08,867 [run_pretraining.py:  534]:	loss/total_loss, 10.173567771911621, 204
[INFO] 2021-07-12 18:28:08,867 [run_pretraining.py:  535]:	loss/mlm_loss, 10.173567771911621, 204
[INFO] 2021-07-12 18:28:08,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0300001324358163e-06, 204
[INFO] 2021-07-12 18:28:08,867 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 204
[INFO] 2021-07-12 18:28:08,868 [run_pretraining.py:  558]:	worker_index: 7, step: 204, cost: 10.173568, mlm loss: 10.173568, speed: 1.087358 steps/s, speed: 8.698862 samples/s, speed: 4453.817138 tokens/s, learning rate: 2.030e-06, loss_scalings: 26214.400391, pp_loss: 9.311423
[INFO] 2021-07-12 18:28:08,868 [run_pretraining.py:  512]:	********exe.run_204******* 
[INFO] 2021-07-12 18:28:09,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:09,776 [run_pretraining.py:  534]:	loss/total_loss, 10.029820442199707, 205
[INFO] 2021-07-12 18:28:09,777 [run_pretraining.py:  535]:	loss/mlm_loss, 10.029820442199707, 205
[INFO] 2021-07-12 18:28:09,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0400000266818097e-06, 205
[INFO] 2021-07-12 18:28:09,777 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 205
[INFO] 2021-07-12 18:28:09,777 [run_pretraining.py:  558]:	worker_index: 7, step: 205, cost: 10.029820, mlm loss: 10.029820, speed: 1.100548 steps/s, speed: 8.804384 samples/s, speed: 4507.844624 tokens/s, learning rate: 2.040e-06, loss_scalings: 26214.400391, pp_loss: 9.773123
[INFO] 2021-07-12 18:28:09,777 [run_pretraining.py:  512]:	********exe.run_205******* 
[INFO] 2021-07-12 18:28:10,689 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:10,689 [run_pretraining.py:  534]:	loss/total_loss, 9.804275512695312, 206
[INFO] 2021-07-12 18:28:10,690 [run_pretraining.py:  535]:	loss/mlm_loss, 9.804275512695312, 206
[INFO] 2021-07-12 18:28:10,690 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999920927803e-06, 206
[INFO] 2021-07-12 18:28:10,690 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 206
[INFO] 2021-07-12 18:28:10,690 [run_pretraining.py:  558]:	worker_index: 7, step: 206, cost: 9.804276, mlm loss: 9.804276, speed: 1.096186 steps/s, speed: 8.769487 samples/s, speed: 4489.977104 tokens/s, learning rate: 2.050e-06, loss_scalings: 26214.400391, pp_loss: 9.765657
[INFO] 2021-07-12 18:28:10,690 [run_pretraining.py:  512]:	********exe.run_206******* 
[INFO] 2021-07-12 18:28:11,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:11,597 [run_pretraining.py:  534]:	loss/total_loss, 10.375977516174316, 207
[INFO] 2021-07-12 18:28:11,597 [run_pretraining.py:  535]:	loss/mlm_loss, 10.375977516174316, 207
[INFO] 2021-07-12 18:28:11,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060000042547472e-06, 207
[INFO] 2021-07-12 18:28:11,597 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 207
[INFO] 2021-07-12 18:28:11,597 [run_pretraining.py:  558]:	worker_index: 7, step: 207, cost: 10.375978, mlm loss: 10.375978, speed: 1.102925 steps/s, speed: 8.823403 samples/s, speed: 4517.582466 tokens/s, learning rate: 2.060e-06, loss_scalings: 26214.400391, pp_loss: 9.942239
[INFO] 2021-07-12 18:28:11,597 [run_pretraining.py:  512]:	********exe.run_207******* 
[INFO] 2021-07-12 18:28:12,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:12,508 [run_pretraining.py:  534]:	loss/total_loss, 5.267703056335449, 208
[INFO] 2021-07-12 18:28:12,508 [run_pretraining.py:  535]:	loss/mlm_loss, 5.267703056335449, 208
[INFO] 2021-07-12 18:28:12,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-06, 208
[INFO] 2021-07-12 18:28:12,508 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 208
[INFO] 2021-07-12 18:28:12,508 [run_pretraining.py:  558]:	worker_index: 7, step: 208, cost: 5.267703, mlm loss: 5.267703, speed: 1.098160 steps/s, speed: 8.785279 samples/s, speed: 4498.062698 tokens/s, learning rate: 2.070e-06, loss_scalings: 26214.400391, pp_loss: 8.537156
[INFO] 2021-07-12 18:28:12,508 [run_pretraining.py:  512]:	********exe.run_208******* 
[INFO] 2021-07-12 18:28:13,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:13,450 [run_pretraining.py:  534]:	loss/total_loss, 9.661911964416504, 209
[INFO] 2021-07-12 18:28:13,450 [run_pretraining.py:  535]:	loss/mlm_loss, 9.661911964416504, 209
[INFO] 2021-07-12 18:28:13,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000058413134e-06, 209
[INFO] 2021-07-12 18:28:13,450 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 209
[INFO] 2021-07-12 18:28:13,450 [run_pretraining.py:  558]:	worker_index: 7, step: 209, cost: 9.661912, mlm loss: 9.661912, speed: 1.062154 steps/s, speed: 8.497228 samples/s, speed: 4350.580770 tokens/s, learning rate: 2.080e-06, loss_scalings: 26214.400391, pp_loss: 9.672984
[INFO] 2021-07-12 18:28:13,451 [run_pretraining.py:  512]:	********exe.run_209******* 
[INFO] 2021-07-12 18:28:14,360 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:14,361 [run_pretraining.py:  534]:	loss/total_loss, 9.697373390197754, 210
[INFO] 2021-07-12 18:28:14,361 [run_pretraining.py:  535]:	loss/mlm_loss, 9.697373390197754, 210
[INFO] 2021-07-12 18:28:14,361 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0899999526591273e-06, 210
[INFO] 2021-07-12 18:28:14,361 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 210
[INFO] 2021-07-12 18:28:14,361 [run_pretraining.py:  558]:	worker_index: 7, step: 210, cost: 9.697373, mlm loss: 9.697373, speed: 1.098797 steps/s, speed: 8.790374 samples/s, speed: 4500.671617 tokens/s, learning rate: 2.090e-06, loss_scalings: 26214.400391, pp_loss: 9.778462
[INFO] 2021-07-12 18:28:14,361 [run_pretraining.py:  512]:	********exe.run_210******* 
[INFO] 2021-07-12 18:28:15,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:15,272 [run_pretraining.py:  534]:	loss/total_loss, 9.75978946685791, 211
[INFO] 2021-07-12 18:28:15,272 [run_pretraining.py:  535]:	loss/mlm_loss, 9.75978946685791, 211
[INFO] 2021-07-12 18:28:15,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998469051206e-06, 211
[INFO] 2021-07-12 18:28:15,272 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 211
[INFO] 2021-07-12 18:28:15,272 [run_pretraining.py:  558]:	worker_index: 7, step: 211, cost: 9.759789, mlm loss: 9.759789, speed: 1.098156 steps/s, speed: 8.785244 samples/s, speed: 4498.045033 tokens/s, learning rate: 2.100e-06, loss_scalings: 26214.400391, pp_loss: 9.831940
[INFO] 2021-07-12 18:28:15,273 [run_pretraining.py:  512]:	********exe.run_211******* 
[INFO] 2021-07-12 18:28:16,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:16,179 [run_pretraining.py:  534]:	loss/total_loss, 9.72191047668457, 212
[INFO] 2021-07-12 18:28:16,179 [run_pretraining.py:  535]:	loss/mlm_loss, 9.72191047668457, 212
[INFO] 2021-07-12 18:28:16,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099999685247894e-06, 212
[INFO] 2021-07-12 18:28:16,179 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 212
[INFO] 2021-07-12 18:28:16,179 [run_pretraining.py:  558]:	worker_index: 7, step: 212, cost: 9.721910, mlm loss: 9.721910, speed: 1.103402 steps/s, speed: 8.827219 samples/s, speed: 4519.536274 tokens/s, learning rate: 2.110e-06, loss_scalings: 26214.400391, pp_loss: 9.752853
[INFO] 2021-07-12 18:28:16,179 [run_pretraining.py:  512]:	********exe.run_212******* 
[INFO] 2021-07-12 18:28:17,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:17,087 [run_pretraining.py:  534]:	loss/total_loss, 9.94740104675293, 213
[INFO] 2021-07-12 18:28:17,087 [run_pretraining.py:  535]:	loss/mlm_loss, 9.94740104675293, 213
[INFO] 2021-07-12 18:28:17,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1199998627707828e-06, 213
[INFO] 2021-07-12 18:28:17,087 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 213
[INFO] 2021-07-12 18:28:17,087 [run_pretraining.py:  558]:	worker_index: 7, step: 213, cost: 9.947401, mlm loss: 9.947401, speed: 1.102694 steps/s, speed: 8.821552 samples/s, speed: 4516.634693 tokens/s, learning rate: 2.120e-06, loss_scalings: 26214.400391, pp_loss: 9.836966
[INFO] 2021-07-12 18:28:17,087 [run_pretraining.py:  512]:	********exe.run_213******* 
[INFO] 2021-07-12 18:28:17,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:17,999 [run_pretraining.py:  534]:	loss/total_loss, 9.640456199645996, 214
[INFO] 2021-07-12 18:28:17,999 [run_pretraining.py:  535]:	loss/mlm_loss, 9.640456199645996, 214
[INFO] 2021-07-12 18:28:17,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.129999757016776e-06, 214
[INFO] 2021-07-12 18:28:17,999 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 214
[INFO] 2021-07-12 18:28:18,000 [run_pretraining.py:  558]:	worker_index: 7, step: 214, cost: 9.640456, mlm loss: 9.640456, speed: 1.096541 steps/s, speed: 8.772329 samples/s, speed: 4491.432667 tokens/s, learning rate: 2.130e-06, loss_scalings: 26214.400391, pp_loss: 9.632775
[INFO] 2021-07-12 18:28:18,000 [run_pretraining.py:  512]:	********exe.run_214******* 
[INFO] 2021-07-12 18:28:18,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:18,908 [run_pretraining.py:  534]:	loss/total_loss, 9.541937828063965, 215
[INFO] 2021-07-12 18:28:18,908 [run_pretraining.py:  535]:	loss/mlm_loss, 9.541937828063965, 215
[INFO] 2021-07-12 18:28:18,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1400001060101204e-06, 215
[INFO] 2021-07-12 18:28:18,908 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 215
[INFO] 2021-07-12 18:28:18,908 [run_pretraining.py:  558]:	worker_index: 7, step: 215, cost: 9.541938, mlm loss: 9.541938, speed: 1.101372 steps/s, speed: 8.810980 samples/s, speed: 4511.221732 tokens/s, learning rate: 2.140e-06, loss_scalings: 26214.400391, pp_loss: 9.712344
[INFO] 2021-07-12 18:28:18,908 [run_pretraining.py:  512]:	********exe.run_215******* 
[INFO] 2021-07-12 18:28:19,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:19,820 [run_pretraining.py:  534]:	loss/total_loss, 9.731552124023438, 216
[INFO] 2021-07-12 18:28:19,820 [run_pretraining.py:  535]:	loss/mlm_loss, 9.731552124023438, 216
[INFO] 2021-07-12 18:28:19,821 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-06, 216
[INFO] 2021-07-12 18:28:19,821 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 216
[INFO] 2021-07-12 18:28:19,821 [run_pretraining.py:  558]:	worker_index: 7, step: 216, cost: 9.731552, mlm loss: 9.731552, speed: 1.096594 steps/s, speed: 8.772754 samples/s, speed: 4491.649908 tokens/s, learning rate: 2.150e-06, loss_scalings: 26214.400391, pp_loss: 8.482186
[INFO] 2021-07-12 18:28:19,821 [run_pretraining.py:  512]:	********exe.run_216******* 
[INFO] 2021-07-12 18:28:20,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:20,727 [run_pretraining.py:  534]:	loss/total_loss, 9.720237731933594, 217
[INFO] 2021-07-12 18:28:20,727 [run_pretraining.py:  535]:	loss/mlm_loss, 9.720237731933594, 217
[INFO] 2021-07-12 18:28:20,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.159999894502107e-06, 217
[INFO] 2021-07-12 18:28:20,727 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 217
[INFO] 2021-07-12 18:28:20,727 [run_pretraining.py:  558]:	worker_index: 7, step: 217, cost: 9.720238, mlm loss: 9.720238, speed: 1.103749 steps/s, speed: 8.829995 samples/s, speed: 4520.957530 tokens/s, learning rate: 2.160e-06, loss_scalings: 26214.400391, pp_loss: 9.610692
[INFO] 2021-07-12 18:28:20,727 [run_pretraining.py:  512]:	********exe.run_217******* 
[INFO] 2021-07-12 18:28:46,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:46,556 [run_pretraining.py:  534]:	loss/total_loss, 9.700516700744629, 218
[INFO] 2021-07-12 18:28:46,556 [run_pretraining.py:  535]:	loss/mlm_loss, 9.700516700744629, 218
[INFO] 2021-07-12 18:28:46,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.170000016121776e-06, 218
[INFO] 2021-07-12 18:28:46,556 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 218
[INFO] 2021-07-12 18:28:46,556 [run_pretraining.py:  558]:	worker_index: 7, step: 218, cost: 9.700517, mlm loss: 9.700517, speed: 0.038717 steps/s, speed: 0.309739 samples/s, speed: 158.586493 tokens/s, learning rate: 2.170e-06, loss_scalings: 26214.400391, pp_loss: 9.752904
[INFO] 2021-07-12 18:28:46,556 [run_pretraining.py:  512]:	********exe.run_218******* 
[INFO] 2021-07-12 18:28:47,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:47,465 [run_pretraining.py:  534]:	loss/total_loss, 9.695344924926758, 219
[INFO] 2021-07-12 18:28:47,465 [run_pretraining.py:  535]:	loss/mlm_loss, 9.695344924926758, 219
[INFO] 2021-07-12 18:28:47,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999910367769e-06, 219
[INFO] 2021-07-12 18:28:47,466 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 219
[INFO] 2021-07-12 18:28:47,466 [run_pretraining.py:  558]:	worker_index: 7, step: 219, cost: 9.695345, mlm loss: 9.695345, speed: 1.100376 steps/s, speed: 8.803005 samples/s, speed: 4507.138592 tokens/s, learning rate: 2.180e-06, loss_scalings: 26214.400391, pp_loss: 9.803236
[INFO] 2021-07-12 18:28:47,466 [run_pretraining.py:  512]:	********exe.run_219******* 
[INFO] 2021-07-12 18:28:48,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:48,374 [run_pretraining.py:  534]:	loss/total_loss, 9.751843452453613, 220
[INFO] 2021-07-12 18:28:48,375 [run_pretraining.py:  535]:	loss/mlm_loss, 9.751843452453613, 220
[INFO] 2021-07-12 18:28:48,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190000031987438e-06, 220
[INFO] 2021-07-12 18:28:48,375 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 220
[INFO] 2021-07-12 18:28:48,375 [run_pretraining.py:  558]:	worker_index: 7, step: 220, cost: 9.751843, mlm loss: 9.751843, speed: 1.100652 steps/s, speed: 8.805218 samples/s, speed: 4508.271661 tokens/s, learning rate: 2.190e-06, loss_scalings: 26214.400391, pp_loss: 9.419414
[INFO] 2021-07-12 18:28:48,375 [run_pretraining.py:  512]:	********exe.run_220******* 
[INFO] 2021-07-12 18:28:49,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:49,286 [run_pretraining.py:  534]:	loss/total_loss, 9.586137771606445, 221
[INFO] 2021-07-12 18:28:49,287 [run_pretraining.py:  535]:	loss/mlm_loss, 9.586137771606445, 221
[INFO] 2021-07-12 18:28:49,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1999999262334313e-06, 221
[INFO] 2021-07-12 18:28:49,287 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 221
[INFO] 2021-07-12 18:28:49,287 [run_pretraining.py:  558]:	worker_index: 7, step: 221, cost: 9.586138, mlm loss: 9.586138, speed: 1.097381 steps/s, speed: 8.779045 samples/s, speed: 4494.871068 tokens/s, learning rate: 2.200e-06, loss_scalings: 26214.400391, pp_loss: 9.690170
[INFO] 2021-07-12 18:28:49,287 [run_pretraining.py:  512]:	********exe.run_221******* 
[INFO] 2021-07-12 18:28:50,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:50,196 [run_pretraining.py:  534]:	loss/total_loss, 9.9730863571167, 222
[INFO] 2021-07-12 18:28:50,196 [run_pretraining.py:  535]:	loss/mlm_loss, 9.9730863571167, 222
[INFO] 2021-07-12 18:28:50,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2099998204794247e-06, 222
[INFO] 2021-07-12 18:28:50,196 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 222
[INFO] 2021-07-12 18:28:50,197 [run_pretraining.py:  558]:	worker_index: 7, step: 222, cost: 9.973086, mlm loss: 9.973086, speed: 1.099927 steps/s, speed: 8.799418 samples/s, speed: 4505.301817 tokens/s, learning rate: 2.210e-06, loss_scalings: 26214.400391, pp_loss: 9.809256
[INFO] 2021-07-12 18:28:50,197 [run_pretraining.py:  512]:	********exe.run_222******* 
[INFO] 2021-07-12 18:28:51,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:51,103 [run_pretraining.py:  534]:	loss/total_loss, 9.579198837280273, 223
[INFO] 2021-07-12 18:28:51,103 [run_pretraining.py:  535]:	loss/mlm_loss, 9.579198837280273, 223
[INFO] 2021-07-12 18:28:51,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999420990935e-06, 223
[INFO] 2021-07-12 18:28:51,103 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 223
[INFO] 2021-07-12 18:28:51,103 [run_pretraining.py:  558]:	worker_index: 7, step: 223, cost: 9.579199, mlm loss: 9.579199, speed: 1.104115 steps/s, speed: 8.832917 samples/s, speed: 4522.453490 tokens/s, learning rate: 2.220e-06, loss_scalings: 26214.400391, pp_loss: 9.679667
[INFO] 2021-07-12 18:28:51,103 [run_pretraining.py:  512]:	********exe.run_223******* 
[INFO] 2021-07-12 18:28:52,019 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  534]:	loss/total_loss, 9.670825958251953, 224
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  535]:	loss/mlm_loss, 9.670825958251953, 224
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.229999836345087e-06, 224
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 224
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  558]:	worker_index: 7, step: 224, cost: 9.670826, mlm loss: 9.670826, speed: 1.090921 steps/s, speed: 8.727370 samples/s, speed: 4468.413224 tokens/s, learning rate: 2.230e-06, loss_scalings: 26214.400391, pp_loss: 9.565049
[INFO] 2021-07-12 18:28:52,020 [run_pretraining.py:  512]:	********exe.run_224******* 
[INFO] 2021-07-12 18:28:52,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:52,932 [run_pretraining.py:  534]:	loss/total_loss, 9.643178939819336, 225
[INFO] 2021-07-12 18:28:52,932 [run_pretraining.py:  535]:	loss/mlm_loss, 9.643178939819336, 225
[INFO] 2021-07-12 18:28:52,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-06, 225
[INFO] 2021-07-12 18:28:52,932 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 225
[INFO] 2021-07-12 18:28:52,932 [run_pretraining.py:  558]:	worker_index: 7, step: 225, cost: 9.643179, mlm loss: 9.643179, speed: 1.097514 steps/s, speed: 8.780109 samples/s, speed: 4495.415631 tokens/s, learning rate: 2.240e-06, loss_scalings: 26214.400391, pp_loss: 9.593079
[INFO] 2021-07-12 18:28:52,932 [run_pretraining.py:  512]:	********exe.run_225******* 
[INFO] 2021-07-12 18:28:53,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:53,847 [run_pretraining.py:  534]:	loss/total_loss, 9.608053207397461, 226
[INFO] 2021-07-12 18:28:53,847 [run_pretraining.py:  535]:	loss/mlm_loss, 9.608053207397461, 226
[INFO] 2021-07-12 18:28:53,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2500000795844244e-06, 226
[INFO] 2021-07-12 18:28:53,848 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 226
[INFO] 2021-07-12 18:28:53,848 [run_pretraining.py:  558]:	worker_index: 7, step: 226, cost: 9.608053, mlm loss: 9.608053, speed: 1.092913 steps/s, speed: 8.743304 samples/s, speed: 4476.571739 tokens/s, learning rate: 2.250e-06, loss_scalings: 26214.400391, pp_loss: 9.723215
[INFO] 2021-07-12 18:28:53,848 [run_pretraining.py:  512]:	********exe.run_226******* 
[INFO] 2021-07-12 18:28:54,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:54,756 [run_pretraining.py:  534]:	loss/total_loss, 9.570693969726562, 227
[INFO] 2021-07-12 18:28:54,756 [run_pretraining.py:  535]:	loss/mlm_loss, 9.570693969726562, 227
[INFO] 2021-07-12 18:28:54,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999738304177e-06, 227
[INFO] 2021-07-12 18:28:54,757 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 227
[INFO] 2021-07-12 18:28:54,757 [run_pretraining.py:  558]:	worker_index: 7, step: 227, cost: 9.570694, mlm loss: 9.570694, speed: 1.100833 steps/s, speed: 8.806667 samples/s, speed: 4509.013551 tokens/s, learning rate: 2.260e-06, loss_scalings: 26214.400391, pp_loss: 8.403860
[INFO] 2021-07-12 18:28:54,757 [run_pretraining.py:  512]:	********exe.run_227******* 
[INFO] 2021-07-12 18:28:55,662 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:55,662 [run_pretraining.py:  534]:	loss/total_loss, 9.74920654296875, 228
[INFO] 2021-07-12 18:28:55,662 [run_pretraining.py:  535]:	loss/mlm_loss, 9.74920654296875, 228
[INFO] 2021-07-12 18:28:55,662 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000954500865e-06, 228
[INFO] 2021-07-12 18:28:55,662 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 228
[INFO] 2021-07-12 18:28:55,662 [run_pretraining.py:  558]:	worker_index: 7, step: 228, cost: 9.749207, mlm loss: 9.749207, speed: 1.104880 steps/s, speed: 8.839036 samples/s, speed: 4525.586667 tokens/s, learning rate: 2.270e-06, loss_scalings: 26214.400391, pp_loss: 9.663332
[INFO] 2021-07-12 18:28:55,662 [run_pretraining.py:  512]:	********exe.run_228******* 
[INFO] 2021-07-12 18:28:56,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:56,567 [run_pretraining.py:  534]:	loss/total_loss, 9.590301513671875, 229
[INFO] 2021-07-12 18:28:56,567 [run_pretraining.py:  535]:	loss/mlm_loss, 9.590301513671875, 229
[INFO] 2021-07-12 18:28:56,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.27999998969608e-06, 229
[INFO] 2021-07-12 18:28:56,567 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 229
[INFO] 2021-07-12 18:28:56,567 [run_pretraining.py:  558]:	worker_index: 7, step: 229, cost: 9.590302, mlm loss: 9.590302, speed: 1.106330 steps/s, speed: 8.850638 samples/s, speed: 4531.526578 tokens/s, learning rate: 2.280e-06, loss_scalings: 26214.400391, pp_loss: 9.674702
[INFO] 2021-07-12 18:28:56,567 [run_pretraining.py:  512]:	********exe.run_229******* 
[INFO] 2021-07-12 18:28:57,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:57,478 [run_pretraining.py:  534]:	loss/total_loss, 9.837421417236328, 230
[INFO] 2021-07-12 18:28:57,478 [run_pretraining.py:  535]:	loss/mlm_loss, 9.837421417236328, 230
[INFO] 2021-07-12 18:28:57,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.289999883942073e-06, 230
[INFO] 2021-07-12 18:28:57,479 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 230
[INFO] 2021-07-12 18:28:57,479 [run_pretraining.py:  558]:	worker_index: 7, step: 230, cost: 9.837421, mlm loss: 9.837421, speed: 1.097521 steps/s, speed: 8.780171 samples/s, speed: 4495.447392 tokens/s, learning rate: 2.290e-06, loss_scalings: 26214.400391, pp_loss: 9.690517
[INFO] 2021-07-12 18:28:57,479 [run_pretraining.py:  512]:	********exe.run_230******* 
[INFO] 2021-07-12 18:28:58,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:58,386 [run_pretraining.py:  534]:	loss/total_loss, 9.566083908081055, 231
[INFO] 2021-07-12 18:28:58,386 [run_pretraining.py:  535]:	loss/mlm_loss, 9.566083908081055, 231
[INFO] 2021-07-12 18:28:58,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000005561742e-06, 231
[INFO] 2021-07-12 18:28:58,386 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 231
[INFO] 2021-07-12 18:28:58,386 [run_pretraining.py:  558]:	worker_index: 7, step: 231, cost: 9.566084, mlm loss: 9.566084, speed: 1.102851 steps/s, speed: 8.822812 samples/s, speed: 4517.279563 tokens/s, learning rate: 2.300e-06, loss_scalings: 26214.400391, pp_loss: 9.637733
[INFO] 2021-07-12 18:28:58,386 [run_pretraining.py:  512]:	********exe.run_231******* 
[INFO] 2021-07-12 18:28:59,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:28:59,299 [run_pretraining.py:  534]:	loss/total_loss, 9.272605895996094, 232
[INFO] 2021-07-12 18:28:59,299 [run_pretraining.py:  535]:	loss/mlm_loss, 9.272605895996094, 232
[INFO] 2021-07-12 18:28:59,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099998998077353e-06, 232
[INFO] 2021-07-12 18:28:59,299 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 232
[INFO] 2021-07-12 18:28:59,299 [run_pretraining.py:  558]:	worker_index: 7, step: 232, cost: 9.272606, mlm loss: 9.272606, speed: 1.095857 steps/s, speed: 8.766856 samples/s, speed: 4488.630376 tokens/s, learning rate: 2.310e-06, loss_scalings: 26214.400391, pp_loss: 9.519617
[INFO] 2021-07-12 18:28:59,299 [run_pretraining.py:  512]:	********exe.run_232******* 
[INFO] 2021-07-12 18:29:00,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:00,214 [run_pretraining.py:  534]:	loss/total_loss, 9.47756576538086, 233
[INFO] 2021-07-12 18:29:00,214 [run_pretraining.py:  535]:	loss/mlm_loss, 9.47756576538086, 233
[INFO] 2021-07-12 18:29:00,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.320000021427404e-06, 233
[INFO] 2021-07-12 18:29:00,215 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 233
[INFO] 2021-07-12 18:29:00,215 [run_pretraining.py:  558]:	worker_index: 7, step: 233, cost: 9.477566, mlm loss: 9.477566, speed: 1.093174 steps/s, speed: 8.745389 samples/s, speed: 4477.639308 tokens/s, learning rate: 2.320e-06, loss_scalings: 26214.400391, pp_loss: 9.538767
[INFO] 2021-07-12 18:29:00,215 [run_pretraining.py:  512]:	********exe.run_233******* 
[INFO] 2021-07-12 18:29:01,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:01,123 [run_pretraining.py:  534]:	loss/total_loss, 9.889601707458496, 234
[INFO] 2021-07-12 18:29:01,123 [run_pretraining.py:  535]:	loss/mlm_loss, 9.889601707458496, 234
[INFO] 2021-07-12 18:29:01,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-06, 234
[INFO] 2021-07-12 18:29:01,123 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 234
[INFO] 2021-07-12 18:29:01,123 [run_pretraining.py:  558]:	worker_index: 7, step: 234, cost: 9.889602, mlm loss: 9.889602, speed: 1.101103 steps/s, speed: 8.808822 samples/s, speed: 4510.116779 tokens/s, learning rate: 2.330e-06, loss_scalings: 26214.400391, pp_loss: 9.490746
[INFO] 2021-07-12 18:29:01,124 [run_pretraining.py:  512]:	********exe.run_234******* 
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  534]:	loss/total_loss, 9.91966438293457, 235
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  535]:	loss/mlm_loss, 9.91966438293457, 235
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.339999809919391e-06, 235
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 235
[INFO] 2021-07-12 18:29:02,026 [run_pretraining.py:  558]:	worker_index: 7, step: 235, cost: 9.919664, mlm loss: 9.919664, speed: 1.108304 steps/s, speed: 8.866436 samples/s, speed: 4539.615098 tokens/s, learning rate: 2.340e-06, loss_scalings: 26214.400391, pp_loss: 9.635675
[INFO] 2021-07-12 18:29:02,027 [run_pretraining.py:  512]:	********exe.run_235******* 
[INFO] 2021-07-12 18:29:02,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:02,940 [run_pretraining.py:  534]:	loss/total_loss, 9.514740943908691, 236
[INFO] 2021-07-12 18:29:02,940 [run_pretraining.py:  535]:	loss/mlm_loss, 9.514740943908691, 236
[INFO] 2021-07-12 18:29:02,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499999315390596e-06, 236
[INFO] 2021-07-12 18:29:02,940 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 236
[INFO] 2021-07-12 18:29:02,940 [run_pretraining.py:  558]:	worker_index: 7, step: 236, cost: 9.514741, mlm loss: 9.514741, speed: 1.095035 steps/s, speed: 8.760278 samples/s, speed: 4485.262403 tokens/s, learning rate: 2.350e-06, loss_scalings: 26214.400391, pp_loss: 9.567245
[INFO] 2021-07-12 18:29:02,940 [run_pretraining.py:  512]:	********exe.run_236******* 
[INFO] 2021-07-12 18:29:03,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  534]:	loss/total_loss, 9.768728256225586, 237
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  535]:	loss/mlm_loss, 9.768728256225586, 237
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3600000531587284e-06, 237
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 237
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  558]:	worker_index: 7, step: 237, cost: 9.768728, mlm loss: 9.768728, speed: 1.084451 steps/s, speed: 8.675608 samples/s, speed: 4441.911273 tokens/s, learning rate: 2.360e-06, loss_scalings: 26214.400391, pp_loss: 9.614332
[INFO] 2021-07-12 18:29:03,863 [run_pretraining.py:  512]:	********exe.run_237******* 
[INFO] 2021-07-12 18:29:04,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:04,771 [run_pretraining.py:  534]:	loss/total_loss, 9.519380569458008, 238
[INFO] 2021-07-12 18:29:04,771 [run_pretraining.py:  535]:	loss/mlm_loss, 9.519380569458008, 238
[INFO] 2021-07-12 18:29:04,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3699999474047218e-06, 238
[INFO] 2021-07-12 18:29:04,772 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 238
[INFO] 2021-07-12 18:29:04,772 [run_pretraining.py:  558]:	worker_index: 7, step: 238, cost: 9.519381, mlm loss: 9.519381, speed: 1.101445 steps/s, speed: 8.811558 samples/s, speed: 4511.517899 tokens/s, learning rate: 2.370e-06, loss_scalings: 26214.400391, pp_loss: 9.624334
[INFO] 2021-07-12 18:29:04,772 [run_pretraining.py:  512]:	********exe.run_238******* 
[INFO] 2021-07-12 18:29:27,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:27,924 [run_pretraining.py:  534]:	loss/total_loss, 9.43729019165039, 239
[INFO] 2021-07-12 18:29:27,924 [run_pretraining.py:  535]:	loss/mlm_loss, 9.43729019165039, 239
[INFO] 2021-07-12 18:29:27,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3800000690243905e-06, 239
[INFO] 2021-07-12 18:29:27,924 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 239
[INFO] 2021-07-12 18:29:27,925 [run_pretraining.py:  558]:	worker_index: 7, step: 239, cost: 9.437290, mlm loss: 9.437290, speed: 0.043192 steps/s, speed: 0.345538 samples/s, speed: 176.915604 tokens/s, learning rate: 2.380e-06, loss_scalings: 26214.400391, pp_loss: 9.538453
[INFO] 2021-07-12 18:29:27,925 [run_pretraining.py:  512]:	********exe.run_239******* 
[INFO] 2021-07-12 18:29:28,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:28,825 [run_pretraining.py:  534]:	loss/total_loss, 9.65402603149414, 240
[INFO] 2021-07-12 18:29:28,825 [run_pretraining.py:  535]:	loss/mlm_loss, 9.65402603149414, 240
[INFO] 2021-07-12 18:29:28,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.389999963270384e-06, 240
[INFO] 2021-07-12 18:29:28,825 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 240
[INFO] 2021-07-12 18:29:28,825 [run_pretraining.py:  558]:	worker_index: 7, step: 240, cost: 9.654026, mlm loss: 9.654026, speed: 1.111061 steps/s, speed: 8.888488 samples/s, speed: 4550.905681 tokens/s, learning rate: 2.390e-06, loss_scalings: 26214.400391, pp_loss: 8.403551
[INFO] 2021-07-12 18:29:28,825 [run_pretraining.py:  512]:	********exe.run_240******* 
[INFO] 2021-07-12 18:29:29,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:29,733 [run_pretraining.py:  534]:	loss/total_loss, 9.91370964050293, 241
[INFO] 2021-07-12 18:29:29,733 [run_pretraining.py:  535]:	loss/mlm_loss, 9.91370964050293, 241
[INFO] 2021-07-12 18:29:29,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999998575163772e-06, 241
[INFO] 2021-07-12 18:29:29,734 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 241
[INFO] 2021-07-12 18:29:29,734 [run_pretraining.py:  558]:	worker_index: 7, step: 241, cost: 9.913710, mlm loss: 9.913710, speed: 1.101679 steps/s, speed: 8.813428 samples/s, speed: 4512.475378 tokens/s, learning rate: 2.400e-06, loss_scalings: 26214.400391, pp_loss: 9.665051
[INFO] 2021-07-12 18:29:29,734 [run_pretraining.py:  512]:	********exe.run_241******* 
[INFO] 2021-07-12 18:29:30,640 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:30,641 [run_pretraining.py:  534]:	loss/total_loss, 9.48077392578125, 242
[INFO] 2021-07-12 18:29:30,642 [run_pretraining.py:  535]:	loss/mlm_loss, 9.48077392578125, 242
[INFO] 2021-07-12 18:29:30,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-06, 242
[INFO] 2021-07-12 18:29:30,643 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 242
[INFO] 2021-07-12 18:29:30,643 [run_pretraining.py:  558]:	worker_index: 7, step: 242, cost: 9.480774, mlm loss: 9.480774, speed: 1.101894 steps/s, speed: 8.815151 samples/s, speed: 4513.357376 tokens/s, learning rate: 2.410e-06, loss_scalings: 26214.400391, pp_loss: 9.636829
[INFO] 2021-07-12 18:29:30,644 [run_pretraining.py:  512]:	********exe.run_242******* 
[INFO] 2021-07-12 18:29:31,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:31,547 [run_pretraining.py:  534]:	loss/total_loss, 9.674482345581055, 243
[INFO] 2021-07-12 18:29:31,547 [run_pretraining.py:  535]:	loss/mlm_loss, 9.674482345581055, 243
[INFO] 2021-07-12 18:29:31,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-06, 243
[INFO] 2021-07-12 18:29:31,547 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 243
[INFO] 2021-07-12 18:29:31,547 [run_pretraining.py:  558]:	worker_index: 7, step: 243, cost: 9.674482, mlm loss: 9.674482, speed: 1.107176 steps/s, speed: 8.857408 samples/s, speed: 4534.993146 tokens/s, learning rate: 2.420e-06, loss_scalings: 26214.400391, pp_loss: 8.803999
[INFO] 2021-07-12 18:29:31,547 [run_pretraining.py:  512]:	********exe.run_243******* 
[INFO] 2021-07-12 18:29:32,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:32,451 [run_pretraining.py:  534]:	loss/total_loss, 9.443524360656738, 244
[INFO] 2021-07-12 18:29:32,451 [run_pretraining.py:  535]:	loss/mlm_loss, 9.443524360656738, 244
[INFO] 2021-07-12 18:29:32,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999995001708e-06, 244
[INFO] 2021-07-12 18:29:32,451 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 244
[INFO] 2021-07-12 18:29:32,451 [run_pretraining.py:  558]:	worker_index: 7, step: 244, cost: 9.443524, mlm loss: 9.443524, speed: 1.106940 steps/s, speed: 8.855522 samples/s, speed: 4534.027285 tokens/s, learning rate: 2.430e-06, loss_scalings: 26214.400391, pp_loss: 9.419167
[INFO] 2021-07-12 18:29:32,451 [run_pretraining.py:  512]:	********exe.run_244******* 
[INFO] 2021-07-12 18:29:33,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:33,354 [run_pretraining.py:  534]:	loss/total_loss, 9.600837707519531, 245
[INFO] 2021-07-12 18:29:33,354 [run_pretraining.py:  535]:	loss/mlm_loss, 9.600837707519531, 245
[INFO] 2021-07-12 18:29:33,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4399998892477015e-06, 245
[INFO] 2021-07-12 18:29:33,354 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 245
[INFO] 2021-07-12 18:29:33,354 [run_pretraining.py:  558]:	worker_index: 7, step: 245, cost: 9.600838, mlm loss: 9.600838, speed: 1.108148 steps/s, speed: 8.865187 samples/s, speed: 4538.975828 tokens/s, learning rate: 2.440e-06, loss_scalings: 26214.400391, pp_loss: 9.458179
[INFO] 2021-07-12 18:29:33,355 [run_pretraining.py:  512]:	********exe.run_245******* 
[INFO] 2021-07-12 18:29:34,259 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:34,260 [run_pretraining.py:  534]:	loss/total_loss, 9.498233795166016, 246
[INFO] 2021-07-12 18:29:34,260 [run_pretraining.py:  535]:	loss/mlm_loss, 9.498233795166016, 246
[INFO] 2021-07-12 18:29:34,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449999783493695e-06, 246
[INFO] 2021-07-12 18:29:34,260 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 246
[INFO] 2021-07-12 18:29:34,260 [run_pretraining.py:  558]:	worker_index: 7, step: 246, cost: 9.498234, mlm loss: 9.498234, speed: 1.105072 steps/s, speed: 8.840578 samples/s, speed: 4526.376006 tokens/s, learning rate: 2.450e-06, loss_scalings: 26214.400391, pp_loss: 9.374678
[INFO] 2021-07-12 18:29:34,260 [run_pretraining.py:  512]:	********exe.run_246******* 
[INFO] 2021-07-12 18:29:35,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:35,160 [run_pretraining.py:  534]:	loss/total_loss, 9.258499145507812, 247
[INFO] 2021-07-12 18:29:35,160 [run_pretraining.py:  535]:	loss/mlm_loss, 9.258499145507812, 247
[INFO] 2021-07-12 18:29:35,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999051133636e-06, 247
[INFO] 2021-07-12 18:29:35,160 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 247
[INFO] 2021-07-12 18:29:35,160 [run_pretraining.py:  558]:	worker_index: 7, step: 247, cost: 9.258499, mlm loss: 9.258499, speed: 1.111515 steps/s, speed: 8.892122 samples/s, speed: 4552.766565 tokens/s, learning rate: 2.460e-06, loss_scalings: 26214.400391, pp_loss: 9.411548
[INFO] 2021-07-12 18:29:35,160 [run_pretraining.py:  512]:	********exe.run_247******* 
[INFO] 2021-07-12 18:29:36,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:36,066 [run_pretraining.py:  534]:	loss/total_loss, 9.744651794433594, 248
[INFO] 2021-07-12 18:29:36,066 [run_pretraining.py:  535]:	loss/mlm_loss, 9.744651794433594, 248
[INFO] 2021-07-12 18:29:36,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4700000267330324e-06, 248
[INFO] 2021-07-12 18:29:36,066 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 248
[INFO] 2021-07-12 18:29:36,066 [run_pretraining.py:  558]:	worker_index: 7, step: 248, cost: 9.744652, mlm loss: 9.744652, speed: 1.104422 steps/s, speed: 8.835375 samples/s, speed: 4523.712196 tokens/s, learning rate: 2.470e-06, loss_scalings: 26214.400391, pp_loss: 9.668681
[INFO] 2021-07-12 18:29:36,066 [run_pretraining.py:  512]:	********exe.run_248******* 
[INFO] 2021-07-12 18:29:36,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:29:36,981 [run_pretraining.py:  534]:	loss/total_loss, 9.759889602661133, 249
[INFO] 2021-07-12 18:29:36,983 [run_pretraining.py:  535]:	loss/mlm_loss, 9.759889602661133, 249
[INFO] 2021-07-12 18:29:36,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4799999209790258e-06, 249
[INFO] 2021-07-12 18:29:36,983 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 249
[INFO] 2021-07-12 18:29:36,983 [run_pretraining.py:  558]:	worker_index: 7, step: 249, cost: 9.759890, mlm loss: 9.759890, speed: 1.094219 steps/s, speed: 8.753756 samples/s, speed: 4481.922865 tokens/s, learning rate: 2.480e-06, loss_scalings: 26214.400391, pp_loss: 9.710690
[INFO] 2021-07-12 18:29:36,983 [run_pretraining.py:  512]:	********exe.run_249******* 
[INFO] 2021-07-12 18:30:02,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:02,776 [run_pretraining.py:  534]:	loss/total_loss, 9.718134880065918, 250
[INFO] 2021-07-12 18:30:02,776 [run_pretraining.py:  535]:	loss/mlm_loss, 9.718134880065918, 250
[INFO] 2021-07-12 18:30:02,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4900000425986946e-06, 250
[INFO] 2021-07-12 18:30:02,776 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 250
[INFO] 2021-07-12 18:30:02,776 [run_pretraining.py:  558]:	worker_index: 7, step: 250, cost: 9.718135, mlm loss: 9.718135, speed: 0.038771 steps/s, speed: 0.310168 samples/s, speed: 158.805785 tokens/s, learning rate: 2.490e-06, loss_scalings: 26214.400391, pp_loss: 9.594596
[INFO] 2021-07-12 18:30:02,776 [run_pretraining.py:  512]:	********exe.run_250******* 
[INFO] 2021-07-12 18:30:03,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:03,694 [run_pretraining.py:  534]:	loss/total_loss, 9.69323444366455, 251
[INFO] 2021-07-12 18:30:03,694 [run_pretraining.py:  535]:	loss/mlm_loss, 9.69323444366455, 251
[INFO] 2021-07-12 18:30:03,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-06, 251
[INFO] 2021-07-12 18:30:03,694 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 251
[INFO] 2021-07-12 18:30:03,694 [run_pretraining.py:  558]:	worker_index: 7, step: 251, cost: 9.693234, mlm loss: 9.693234, speed: 1.090591 steps/s, speed: 8.724730 samples/s, speed: 4467.061975 tokens/s, learning rate: 2.500e-06, loss_scalings: 26214.400391, pp_loss: 9.682489
[INFO] 2021-07-12 18:30:03,694 [run_pretraining.py:  512]:	********exe.run_251******* 
[INFO] 2021-07-12 18:30:04,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:04,606 [run_pretraining.py:  534]:	loss/total_loss, 9.655830383300781, 252
[INFO] 2021-07-12 18:30:04,606 [run_pretraining.py:  535]:	loss/mlm_loss, 9.655830383300781, 252
[INFO] 2021-07-12 18:30:04,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5100000584643567e-06, 252
[INFO] 2021-07-12 18:30:04,606 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 252
[INFO] 2021-07-12 18:30:04,606 [run_pretraining.py:  558]:	worker_index: 7, step: 252, cost: 9.655830, mlm loss: 9.655830, speed: 1.096812 steps/s, speed: 8.774495 samples/s, speed: 4492.541405 tokens/s, learning rate: 2.510e-06, loss_scalings: 26214.400391, pp_loss: 9.527781
[INFO] 2021-07-12 18:30:04,606 [run_pretraining.py:  512]:	********exe.run_252******* 
[INFO] 2021-07-12 18:30:05,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:05,524 [run_pretraining.py:  534]:	loss/total_loss, 9.698894500732422, 253
[INFO] 2021-07-12 18:30:05,524 [run_pretraining.py:  535]:	loss/mlm_loss, 9.698894500732422, 253
[INFO] 2021-07-12 18:30:05,524 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51999995271035e-06, 253
[INFO] 2021-07-12 18:30:05,524 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 253
[INFO] 2021-07-12 18:30:05,524 [run_pretraining.py:  558]:	worker_index: 7, step: 253, cost: 9.698895, mlm loss: 9.698895, speed: 1.090169 steps/s, speed: 8.721349 samples/s, speed: 4465.330831 tokens/s, learning rate: 2.520e-06, loss_scalings: 26214.400391, pp_loss: 9.562936
[INFO] 2021-07-12 18:30:05,524 [run_pretraining.py:  512]:	********exe.run_253******* 
[INFO] 2021-07-12 18:30:06,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:06,442 [run_pretraining.py:  534]:	loss/total_loss, 9.511679649353027, 254
[INFO] 2021-07-12 18:30:06,443 [run_pretraining.py:  535]:	loss/mlm_loss, 9.511679649353027, 254
[INFO] 2021-07-12 18:30:06,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998469563434e-06, 254
[INFO] 2021-07-12 18:30:06,443 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 254
[INFO] 2021-07-12 18:30:06,443 [run_pretraining.py:  558]:	worker_index: 7, step: 254, cost: 9.511680, mlm loss: 9.511680, speed: 1.089405 steps/s, speed: 8.715238 samples/s, speed: 4462.201691 tokens/s, learning rate: 2.530e-06, loss_scalings: 26214.400391, pp_loss: 9.461847
[INFO] 2021-07-12 18:30:06,443 [run_pretraining.py:  512]:	********exe.run_254******* 
[INFO] 2021-07-12 18:30:07,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:07,406 [run_pretraining.py:  534]:	loss/total_loss, 9.647198677062988, 255
[INFO] 2021-07-12 18:30:07,406 [run_pretraining.py:  535]:	loss/mlm_loss, 9.647198677062988, 255
[INFO] 2021-07-12 18:30:07,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.539999968576012e-06, 255
[INFO] 2021-07-12 18:30:07,406 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 255
[INFO] 2021-07-12 18:30:07,406 [run_pretraining.py:  558]:	worker_index: 7, step: 255, cost: 9.647199, mlm loss: 9.647199, speed: 1.038287 steps/s, speed: 8.306297 samples/s, speed: 4252.823937 tokens/s, learning rate: 2.540e-06, loss_scalings: 26214.400391, pp_loss: 9.710818
[INFO] 2021-07-12 18:30:07,407 [run_pretraining.py:  512]:	********exe.run_255******* 
[INFO] 2021-07-12 18:30:34,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:34,022 [run_pretraining.py:  534]:	loss/total_loss, 8.950713157653809, 256
[INFO] 2021-07-12 18:30:34,022 [run_pretraining.py:  535]:	loss/mlm_loss, 8.950713157653809, 256
[INFO] 2021-07-12 18:30:34,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499998628220055e-06, 256
[INFO] 2021-07-12 18:30:34,022 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 256
[INFO] 2021-07-12 18:30:34,022 [run_pretraining.py:  558]:	worker_index: 7, step: 256, cost: 8.950713, mlm loss: 8.950713, speed: 0.037573 steps/s, speed: 0.300584 samples/s, speed: 153.898924 tokens/s, learning rate: 2.550e-06, loss_scalings: 26214.400391, pp_loss: 9.493094
[INFO] 2021-07-12 18:30:34,022 [run_pretraining.py:  512]:	********exe.run_256******* 
[INFO] 2021-07-12 18:30:34,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:34,948 [run_pretraining.py:  534]:	loss/total_loss, 9.670544624328613, 257
[INFO] 2021-07-12 18:30:34,949 [run_pretraining.py:  535]:	loss/mlm_loss, 9.670544624328613, 257
[INFO] 2021-07-12 18:30:34,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.559999757067999e-06, 257
[INFO] 2021-07-12 18:30:34,949 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 257
[INFO] 2021-07-12 18:30:34,949 [run_pretraining.py:  558]:	worker_index: 7, step: 257, cost: 9.670545, mlm loss: 9.670545, speed: 1.079711 steps/s, speed: 8.637686 samples/s, speed: 4422.495481 tokens/s, learning rate: 2.560e-06, loss_scalings: 26214.400391, pp_loss: 9.514295
[INFO] 2021-07-12 18:30:34,949 [run_pretraining.py:  512]:	********exe.run_257******* 
[INFO] 2021-07-12 18:30:35,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:35,870 [run_pretraining.py:  534]:	loss/total_loss, 9.683794021606445, 258
[INFO] 2021-07-12 18:30:35,870 [run_pretraining.py:  535]:	loss/mlm_loss, 9.683794021606445, 258
[INFO] 2021-07-12 18:30:35,870 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699998786876677e-06, 258
[INFO] 2021-07-12 18:30:35,870 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 258
[INFO] 2021-07-12 18:30:35,871 [run_pretraining.py:  558]:	worker_index: 7, step: 258, cost: 9.683794, mlm loss: 9.683794, speed: 1.085633 steps/s, speed: 8.685066 samples/s, speed: 4446.753905 tokens/s, learning rate: 2.570e-06, loss_scalings: 26214.400391, pp_loss: 9.535315
[INFO] 2021-07-12 18:30:35,871 [run_pretraining.py:  512]:	********exe.run_258******* 
[INFO] 2021-07-12 18:30:36,782 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:36,782 [run_pretraining.py:  534]:	loss/total_loss, 9.662551879882812, 259
[INFO] 2021-07-12 18:30:36,782 [run_pretraining.py:  535]:	loss/mlm_loss, 9.662551879882812, 259
[INFO] 2021-07-12 18:30:36,782 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5800000003073364e-06, 259
[INFO] 2021-07-12 18:30:36,782 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 259
[INFO] 2021-07-12 18:30:36,782 [run_pretraining.py:  558]:	worker_index: 7, step: 259, cost: 9.662552, mlm loss: 9.662552, speed: 1.097413 steps/s, speed: 8.779305 samples/s, speed: 4495.003962 tokens/s, learning rate: 2.580e-06, loss_scalings: 26214.400391, pp_loss: 9.293406
[INFO] 2021-07-12 18:30:36,783 [run_pretraining.py:  512]:	********exe.run_259******* 
[INFO] 2021-07-12 18:30:37,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:37,699 [run_pretraining.py:  534]:	loss/total_loss, 9.300091743469238, 260
[INFO] 2021-07-12 18:30:37,699 [run_pretraining.py:  535]:	loss/mlm_loss, 9.300091743469238, 260
[INFO] 2021-07-12 18:30:37,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.58999989455333e-06, 260
[INFO] 2021-07-12 18:30:37,699 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 260
[INFO] 2021-07-12 18:30:37,699 [run_pretraining.py:  558]:	worker_index: 7, step: 260, cost: 9.300092, mlm loss: 9.300092, speed: 1.091983 steps/s, speed: 8.735861 samples/s, speed: 4472.760650 tokens/s, learning rate: 2.590e-06, loss_scalings: 26214.400391, pp_loss: 9.274543
[INFO] 2021-07-12 18:30:37,699 [run_pretraining.py:  512]:	********exe.run_260******* 
[INFO] 2021-07-12 18:30:38,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:38,607 [run_pretraining.py:  534]:	loss/total_loss, 9.449457168579102, 261
[INFO] 2021-07-12 18:30:38,607 [run_pretraining.py:  535]:	loss/mlm_loss, 9.449457168579102, 261
[INFO] 2021-07-12 18:30:38,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6000000161729986e-06, 261
[INFO] 2021-07-12 18:30:38,607 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 261
[INFO] 2021-07-12 18:30:38,607 [run_pretraining.py:  558]:	worker_index: 7, step: 261, cost: 9.449457, mlm loss: 9.449457, speed: 1.101456 steps/s, speed: 8.811646 samples/s, speed: 4511.562920 tokens/s, learning rate: 2.600e-06, loss_scalings: 26214.400391, pp_loss: 9.455650
[INFO] 2021-07-12 18:30:38,607 [run_pretraining.py:  512]:	********exe.run_261******* 
[INFO] 2021-07-12 18:30:39,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:39,517 [run_pretraining.py:  534]:	loss/total_loss, 9.105608940124512, 262
[INFO] 2021-07-12 18:30:39,518 [run_pretraining.py:  535]:	loss/mlm_loss, 9.105608940124512, 262
[INFO] 2021-07-12 18:30:39,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.609999910418992e-06, 262
[INFO] 2021-07-12 18:30:39,518 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 262
[INFO] 2021-07-12 18:30:39,518 [run_pretraining.py:  558]:	worker_index: 7, step: 262, cost: 9.105609, mlm loss: 9.105609, speed: 1.099188 steps/s, speed: 8.793503 samples/s, speed: 4502.273347 tokens/s, learning rate: 2.610e-06, loss_scalings: 26214.400391, pp_loss: 9.443863
[INFO] 2021-07-12 18:30:39,518 [run_pretraining.py:  512]:	********exe.run_262******* 
[INFO] 2021-07-12 18:30:40,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:40,428 [run_pretraining.py:  534]:	loss/total_loss, 9.477216720581055, 263
[INFO] 2021-07-12 18:30:40,428 [run_pretraining.py:  535]:	loss/mlm_loss, 9.477216720581055, 263
[INFO] 2021-07-12 18:30:40,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6200000320386607e-06, 263
[INFO] 2021-07-12 18:30:40,429 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 263
[INFO] 2021-07-12 18:30:40,429 [run_pretraining.py:  558]:	worker_index: 7, step: 263, cost: 9.477217, mlm loss: 9.477217, speed: 1.098674 steps/s, speed: 8.789396 samples/s, speed: 4500.170574 tokens/s, learning rate: 2.620e-06, loss_scalings: 26214.400391, pp_loss: 9.519098
[INFO] 2021-07-12 18:30:40,429 [run_pretraining.py:  512]:	********exe.run_263******* 
[INFO] 2021-07-12 18:30:41,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:41,334 [run_pretraining.py:  534]:	loss/total_loss, 9.821320533752441, 264
[INFO] 2021-07-12 18:30:41,334 [run_pretraining.py:  535]:	loss/mlm_loss, 9.821320533752441, 264
[INFO] 2021-07-12 18:30:41,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.629999926284654e-06, 264
[INFO] 2021-07-12 18:30:41,334 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 264
[INFO] 2021-07-12 18:30:41,334 [run_pretraining.py:  558]:	worker_index: 7, step: 264, cost: 9.821321, mlm loss: 9.821321, speed: 1.105412 steps/s, speed: 8.843295 samples/s, speed: 4527.766962 tokens/s, learning rate: 2.630e-06, loss_scalings: 26214.400391, pp_loss: 9.629497
[INFO] 2021-07-12 18:30:41,334 [run_pretraining.py:  512]:	********exe.run_264******* 
[INFO] 2021-07-12 18:30:42,242 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:42,242 [run_pretraining.py:  534]:	loss/total_loss, 9.631839752197266, 265
[INFO] 2021-07-12 18:30:42,242 [run_pretraining.py:  535]:	loss/mlm_loss, 9.631839752197266, 265
[INFO] 2021-07-12 18:30:42,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399998205306474e-06, 265
[INFO] 2021-07-12 18:30:42,242 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 265
[INFO] 2021-07-12 18:30:42,243 [run_pretraining.py:  558]:	worker_index: 7, step: 265, cost: 9.631840, mlm loss: 9.631840, speed: 1.101398 steps/s, speed: 8.811181 samples/s, speed: 4511.324794 tokens/s, learning rate: 2.640e-06, loss_scalings: 26214.400391, pp_loss: 8.420033
[INFO] 2021-07-12 18:30:42,243 [run_pretraining.py:  512]:	********exe.run_265******* 
[INFO] 2021-07-12 18:30:43,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:43,171 [run_pretraining.py:  534]:	loss/total_loss, 9.983255386352539, 266
[INFO] 2021-07-12 18:30:43,171 [run_pretraining.py:  535]:	loss/mlm_loss, 9.983255386352539, 266
[INFO] 2021-07-12 18:30:43,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999942150316e-06, 266
[INFO] 2021-07-12 18:30:43,171 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 266
[INFO] 2021-07-12 18:30:43,171 [run_pretraining.py:  558]:	worker_index: 7, step: 266, cost: 9.983255, mlm loss: 9.983255, speed: 1.077972 steps/s, speed: 8.623774 samples/s, speed: 4415.372291 tokens/s, learning rate: 2.650e-06, loss_scalings: 26214.400391, pp_loss: 9.764444
[INFO] 2021-07-12 18:30:43,171 [run_pretraining.py:  512]:	********exe.run_266******* 
[INFO] 2021-07-12 18:30:44,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:44,235 [run_pretraining.py:  534]:	loss/total_loss, 9.62877368927002, 267
[INFO] 2021-07-12 18:30:44,236 [run_pretraining.py:  535]:	loss/mlm_loss, 9.62877368927002, 267
[INFO] 2021-07-12 18:30:44,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998363963095e-06, 267
[INFO] 2021-07-12 18:30:44,236 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 267
[INFO] 2021-07-12 18:30:44,236 [run_pretraining.py:  558]:	worker_index: 7, step: 267, cost: 9.628774, mlm loss: 9.628774, speed: 0.939649 steps/s, speed: 7.517192 samples/s, speed: 3848.802557 tokens/s, learning rate: 2.660e-06, loss_scalings: 26214.400391, pp_loss: 9.420242
[INFO] 2021-07-12 18:30:44,236 [run_pretraining.py:  512]:	********exe.run_267******* 
[INFO] 2021-07-12 18:30:45,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:45,283 [run_pretraining.py:  534]:	loss/total_loss, 9.606287002563477, 268
[INFO] 2021-07-12 18:30:45,283 [run_pretraining.py:  535]:	loss/mlm_loss, 9.606287002563477, 268
[INFO] 2021-07-12 18:30:45,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6699999580159783e-06, 268
[INFO] 2021-07-12 18:30:45,283 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 268
[INFO] 2021-07-12 18:30:45,283 [run_pretraining.py:  558]:	worker_index: 7, step: 268, cost: 9.606287, mlm loss: 9.606287, speed: 0.955554 steps/s, speed: 7.644434 samples/s, speed: 3913.950122 tokens/s, learning rate: 2.670e-06, loss_scalings: 26214.400391, pp_loss: 9.550451
[INFO] 2021-07-12 18:30:45,283 [run_pretraining.py:  512]:	********exe.run_268******* 
[INFO] 2021-07-12 18:30:46,340 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:46,340 [run_pretraining.py:  534]:	loss/total_loss, 9.226279258728027, 269
[INFO] 2021-07-12 18:30:46,340 [run_pretraining.py:  535]:	loss/mlm_loss, 9.226279258728027, 269
[INFO] 2021-07-12 18:30:46,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6799998522619717e-06, 269
[INFO] 2021-07-12 18:30:46,340 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 269
[INFO] 2021-07-12 18:30:46,341 [run_pretraining.py:  558]:	worker_index: 7, step: 269, cost: 9.226279, mlm loss: 9.226279, speed: 0.946142 steps/s, speed: 7.569136 samples/s, speed: 3875.397397 tokens/s, learning rate: 2.680e-06, loss_scalings: 26214.400391, pp_loss: 9.507439
[INFO] 2021-07-12 18:30:46,341 [run_pretraining.py:  512]:	********exe.run_269******* 
[INFO] 2021-07-12 18:30:47,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:47,397 [run_pretraining.py:  534]:	loss/total_loss, 9.671319007873535, 270
[INFO] 2021-07-12 18:30:47,397 [run_pretraining.py:  535]:	loss/mlm_loss, 9.671319007873535, 270
[INFO] 2021-07-12 18:30:47,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999738816405e-06, 270
[INFO] 2021-07-12 18:30:47,397 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 270
[INFO] 2021-07-12 18:30:47,398 [run_pretraining.py:  558]:	worker_index: 7, step: 270, cost: 9.671319, mlm loss: 9.671319, speed: 0.946630 steps/s, speed: 7.573037 samples/s, speed: 3877.395107 tokens/s, learning rate: 2.690e-06, loss_scalings: 26214.400391, pp_loss: 9.635633
[INFO] 2021-07-12 18:30:47,398 [run_pretraining.py:  512]:	********exe.run_270******* 
[INFO] 2021-07-12 18:30:48,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:48,460 [run_pretraining.py:  534]:	loss/total_loss, 9.721116065979004, 271
[INFO] 2021-07-12 18:30:48,460 [run_pretraining.py:  535]:	loss/mlm_loss, 9.721116065979004, 271
[INFO] 2021-07-12 18:30:48,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7000000955013093e-06, 271
[INFO] 2021-07-12 18:30:48,460 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 271
[INFO] 2021-07-12 18:30:48,460 [run_pretraining.py:  558]:	worker_index: 7, step: 271, cost: 9.721116, mlm loss: 9.721116, speed: 0.941437 steps/s, speed: 7.531494 samples/s, speed: 3856.124862 tokens/s, learning rate: 2.700e-06, loss_scalings: 26214.400391, pp_loss: 9.574656
[INFO] 2021-07-12 18:30:48,460 [run_pretraining.py:  512]:	********exe.run_271******* 
[INFO] 2021-07-12 18:30:49,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:49,533 [run_pretraining.py:  534]:	loss/total_loss, 9.406243324279785, 272
[INFO] 2021-07-12 18:30:49,533 [run_pretraining.py:  535]:	loss/mlm_loss, 9.406243324279785, 272
[INFO] 2021-07-12 18:30:49,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099999897473026e-06, 272
[INFO] 2021-07-12 18:30:49,533 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 272
[INFO] 2021-07-12 18:30:49,533 [run_pretraining.py:  558]:	worker_index: 7, step: 272, cost: 9.406243, mlm loss: 9.406243, speed: 0.932536 steps/s, speed: 7.460287 samples/s, speed: 3819.667029 tokens/s, learning rate: 2.710e-06, loss_scalings: 26214.400391, pp_loss: 9.469608
[INFO] 2021-07-12 18:30:49,533 [run_pretraining.py:  512]:	********exe.run_272******* 
[INFO] 2021-07-12 18:30:50,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:50,594 [run_pretraining.py:  534]:	loss/total_loss, 7.057878017425537, 273
[INFO] 2021-07-12 18:30:50,594 [run_pretraining.py:  535]:	loss/mlm_loss, 7.057878017425537, 273
[INFO] 2021-07-12 18:30:50,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.719999883993296e-06, 273
[INFO] 2021-07-12 18:30:50,594 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 273
[INFO] 2021-07-12 18:30:50,594 [run_pretraining.py:  558]:	worker_index: 7, step: 273, cost: 7.057878, mlm loss: 7.057878, speed: 0.943190 steps/s, speed: 7.545521 samples/s, speed: 3863.306535 tokens/s, learning rate: 2.720e-06, loss_scalings: 26214.400391, pp_loss: 8.922461
[INFO] 2021-07-12 18:30:50,594 [run_pretraining.py:  512]:	********exe.run_273******* 
[INFO] 2021-07-12 18:30:51,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:51,646 [run_pretraining.py:  534]:	loss/total_loss, 9.473602294921875, 274
[INFO] 2021-07-12 18:30:51,646 [run_pretraining.py:  535]:	loss/mlm_loss, 9.473602294921875, 274
[INFO] 2021-07-12 18:30:51,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7300000056129647e-06, 274
[INFO] 2021-07-12 18:30:51,646 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 274
[INFO] 2021-07-12 18:30:51,646 [run_pretraining.py:  558]:	worker_index: 7, step: 274, cost: 9.473602, mlm loss: 9.473602, speed: 0.950996 steps/s, speed: 7.607966 samples/s, speed: 3895.278602 tokens/s, learning rate: 2.730e-06, loss_scalings: 26214.400391, pp_loss: 9.602475
[INFO] 2021-07-12 18:30:51,647 [run_pretraining.py:  512]:	********exe.run_274******* 
[INFO] 2021-07-12 18:30:52,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  534]:	loss/total_loss, 9.625683784484863, 275
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  535]:	loss/mlm_loss, 9.625683784484863, 275
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.739999899858958e-06, 275
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 275
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  558]:	worker_index: 7, step: 275, cost: 9.625684, mlm loss: 9.625684, speed: 0.945313 steps/s, speed: 7.562501 samples/s, speed: 3872.000599 tokens/s, learning rate: 2.740e-06, loss_scalings: 26214.400391, pp_loss: 9.492444
[INFO] 2021-07-12 18:30:52,705 [run_pretraining.py:  512]:	********exe.run_275******* 
[INFO] 2021-07-12 18:30:53,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:53,838 [run_pretraining.py:  534]:	loss/total_loss, 9.536124229431152, 276
[INFO] 2021-07-12 18:30:53,838 [run_pretraining.py:  535]:	loss/mlm_loss, 9.536124229431152, 276
[INFO] 2021-07-12 18:30:53,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-06, 276
[INFO] 2021-07-12 18:30:53,838 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 276
[INFO] 2021-07-12 18:30:53,839 [run_pretraining.py:  558]:	worker_index: 7, step: 276, cost: 9.536124, mlm loss: 9.536124, speed: 0.882695 steps/s, speed: 7.061562 samples/s, speed: 3615.519828 tokens/s, learning rate: 2.750e-06, loss_scalings: 26214.400391, pp_loss: 9.562173
[INFO] 2021-07-12 18:30:53,839 [run_pretraining.py:  512]:	********exe.run_276******* 
[INFO] 2021-07-12 18:30:54,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:54,935 [run_pretraining.py:  534]:	loss/total_loss, 9.461825370788574, 277
[INFO] 2021-07-12 18:30:54,935 [run_pretraining.py:  535]:	loss/mlm_loss, 9.461825370788574, 277
[INFO] 2021-07-12 18:30:54,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-06, 277
[INFO] 2021-07-12 18:30:54,935 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 277
[INFO] 2021-07-12 18:30:54,935 [run_pretraining.py:  558]:	worker_index: 7, step: 277, cost: 9.461825, mlm loss: 9.461825, speed: 0.912205 steps/s, speed: 7.297643 samples/s, speed: 3736.393310 tokens/s, learning rate: 2.760e-06, loss_scalings: 26214.400391, pp_loss: 9.572573
[INFO] 2021-07-12 18:30:54,935 [run_pretraining.py:  512]:	********exe.run_277******* 
[INFO] 2021-07-12 18:30:56,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:56,006 [run_pretraining.py:  534]:	loss/total_loss, 9.267544746398926, 278
[INFO] 2021-07-12 18:30:56,006 [run_pretraining.py:  535]:	loss/mlm_loss, 9.267544746398926, 278
[INFO] 2021-07-12 18:30:56,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7699998099706136e-06, 278
[INFO] 2021-07-12 18:30:56,006 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 278
[INFO] 2021-07-12 18:30:56,006 [run_pretraining.py:  558]:	worker_index: 7, step: 278, cost: 9.267545, mlm loss: 9.267545, speed: 0.934403 steps/s, speed: 7.475222 samples/s, speed: 3827.313589 tokens/s, learning rate: 2.770e-06, loss_scalings: 26214.400391, pp_loss: 9.475788
[INFO] 2021-07-12 18:30:56,006 [run_pretraining.py:  512]:	********exe.run_278******* 
[INFO] 2021-07-12 18:30:57,095 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:57,096 [run_pretraining.py:  534]:	loss/total_loss, 9.60867977142334, 279
[INFO] 2021-07-12 18:30:57,096 [run_pretraining.py:  535]:	loss/mlm_loss, 9.60867977142334, 279
[INFO] 2021-07-12 18:30:57,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799999315902824e-06, 279
[INFO] 2021-07-12 18:30:57,096 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 279
[INFO] 2021-07-12 18:30:57,096 [run_pretraining.py:  558]:	worker_index: 7, step: 279, cost: 9.608680, mlm loss: 9.608680, speed: 0.918082 steps/s, speed: 7.344652 samples/s, speed: 3760.461832 tokens/s, learning rate: 2.780e-06, loss_scalings: 26214.400391, pp_loss: 9.417394
[INFO] 2021-07-12 18:30:57,096 [run_pretraining.py:  512]:	********exe.run_279******* 
[INFO] 2021-07-12 18:30:58,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:58,182 [run_pretraining.py:  534]:	loss/total_loss, 9.640727043151855, 280
[INFO] 2021-07-12 18:30:58,182 [run_pretraining.py:  535]:	loss/mlm_loss, 9.640727043151855, 280
[INFO] 2021-07-12 18:30:58,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7899998258362757e-06, 280
[INFO] 2021-07-12 18:30:58,183 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 280
[INFO] 2021-07-12 18:30:58,183 [run_pretraining.py:  558]:	worker_index: 7, step: 280, cost: 9.640727, mlm loss: 9.640727, speed: 0.920959 steps/s, speed: 7.367675 samples/s, speed: 3772.249511 tokens/s, learning rate: 2.790e-06, loss_scalings: 26214.400391, pp_loss: 9.523568
[INFO] 2021-07-12 18:30:58,183 [run_pretraining.py:  512]:	********exe.run_280******* 
[INFO] 2021-07-12 18:30:59,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:30:59,270 [run_pretraining.py:  534]:	loss/total_loss, 9.671934127807617, 281
[INFO] 2021-07-12 18:30:59,270 [run_pretraining.py:  535]:	loss/mlm_loss, 9.671934127807617, 281
[INFO] 2021-07-12 18:30:59,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999999474559445e-06, 281
[INFO] 2021-07-12 18:30:59,270 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 281
[INFO] 2021-07-12 18:30:59,270 [run_pretraining.py:  558]:	worker_index: 7, step: 281, cost: 9.671934, mlm loss: 9.671934, speed: 0.919852 steps/s, speed: 7.358815 samples/s, speed: 3767.713473 tokens/s, learning rate: 2.800e-06, loss_scalings: 26214.400391, pp_loss: 9.601629
[INFO] 2021-07-12 18:30:59,271 [run_pretraining.py:  512]:	********exe.run_281******* 
[INFO] 2021-07-12 18:31:00,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:00,359 [run_pretraining.py:  534]:	loss/total_loss, 9.369499206542969, 282
[INFO] 2021-07-12 18:31:00,359 [run_pretraining.py:  535]:	loss/mlm_loss, 9.369499206542969, 282
[INFO] 2021-07-12 18:31:00,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8100000690756133e-06, 282
[INFO] 2021-07-12 18:31:00,359 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 282
[INFO] 2021-07-12 18:31:00,359 [run_pretraining.py:  558]:	worker_index: 7, step: 282, cost: 9.369499, mlm loss: 9.369499, speed: 0.918985 steps/s, speed: 7.351881 samples/s, speed: 3764.162921 tokens/s, learning rate: 2.810e-06, loss_scalings: 26214.400391, pp_loss: 9.454946
[INFO] 2021-07-12 18:31:00,359 [run_pretraining.py:  512]:	********exe.run_282******* 
[INFO] 2021-07-12 18:31:01,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:01,451 [run_pretraining.py:  534]:	loss/total_loss, 9.699260711669922, 283
[INFO] 2021-07-12 18:31:01,451 [run_pretraining.py:  535]:	loss/mlm_loss, 9.699260711669922, 283
[INFO] 2021-07-12 18:31:01,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8199999633216066e-06, 283
[INFO] 2021-07-12 18:31:01,451 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 283
[INFO] 2021-07-12 18:31:01,451 [run_pretraining.py:  558]:	worker_index: 7, step: 283, cost: 9.699261, mlm loss: 9.699261, speed: 0.916319 steps/s, speed: 7.330554 samples/s, speed: 3753.243792 tokens/s, learning rate: 2.820e-06, loss_scalings: 26214.400391, pp_loss: 9.452502
[INFO] 2021-07-12 18:31:01,451 [run_pretraining.py:  512]:	********exe.run_283******* 
[INFO] 2021-07-12 18:31:02,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:02,543 [run_pretraining.py:  534]:	loss/total_loss, 9.686705589294434, 284
[INFO] 2021-07-12 18:31:02,543 [run_pretraining.py:  535]:	loss/mlm_loss, 9.686705589294434, 284
[INFO] 2021-07-12 18:31:02,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8299998575676e-06, 284
[INFO] 2021-07-12 18:31:02,544 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 284
[INFO] 2021-07-12 18:31:02,544 [run_pretraining.py:  558]:	worker_index: 7, step: 284, cost: 9.686706, mlm loss: 9.686706, speed: 0.915938 steps/s, speed: 7.327505 samples/s, speed: 3751.682414 tokens/s, learning rate: 2.830e-06, loss_scalings: 26214.400391, pp_loss: 8.462873
[INFO] 2021-07-12 18:31:02,544 [run_pretraining.py:  512]:	********exe.run_284******* 
[INFO] 2021-07-12 18:31:03,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:03,634 [run_pretraining.py:  534]:	loss/total_loss, 8.945954322814941, 285
[INFO] 2021-07-12 18:31:03,634 [run_pretraining.py:  535]:	loss/mlm_loss, 8.945954322814941, 285
[INFO] 2021-07-12 18:31:03,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-06, 285
[INFO] 2021-07-12 18:31:03,634 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 285
[INFO] 2021-07-12 18:31:03,634 [run_pretraining.py:  558]:	worker_index: 7, step: 285, cost: 8.945954, mlm loss: 8.945954, speed: 0.917573 steps/s, speed: 7.340584 samples/s, speed: 3758.378850 tokens/s, learning rate: 2.840e-06, loss_scalings: 26214.400391, pp_loss: 9.516323
[INFO] 2021-07-12 18:31:03,634 [run_pretraining.py:  512]:	********exe.run_285******* 
[INFO] 2021-07-12 18:31:04,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:04,722 [run_pretraining.py:  534]:	loss/total_loss, 9.310731887817383, 286
[INFO] 2021-07-12 18:31:04,722 [run_pretraining.py:  535]:	loss/mlm_loss, 9.310731887817383, 286
[INFO] 2021-07-12 18:31:04,722 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-06, 286
[INFO] 2021-07-12 18:31:04,722 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 286
[INFO] 2021-07-12 18:31:04,722 [run_pretraining.py:  558]:	worker_index: 7, step: 286, cost: 9.310732, mlm loss: 9.310732, speed: 0.919625 steps/s, speed: 7.356999 samples/s, speed: 3766.783293 tokens/s, learning rate: 2.850e-06, loss_scalings: 26214.400391, pp_loss: 9.455545
[INFO] 2021-07-12 18:31:04,722 [run_pretraining.py:  512]:	********exe.run_286******* 
[INFO] 2021-07-12 18:31:05,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:05,812 [run_pretraining.py:  534]:	loss/total_loss, 9.36746597290039, 287
[INFO] 2021-07-12 18:31:05,813 [run_pretraining.py:  535]:	loss/mlm_loss, 9.36746597290039, 287
[INFO] 2021-07-12 18:31:05,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.859999995052931e-06, 287
[INFO] 2021-07-12 18:31:05,813 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 287
[INFO] 2021-07-12 18:31:05,813 [run_pretraining.py:  558]:	worker_index: 7, step: 287, cost: 9.367466, mlm loss: 9.367466, speed: 0.917533 steps/s, speed: 7.340264 samples/s, speed: 3758.215238 tokens/s, learning rate: 2.860e-06, loss_scalings: 26214.400391, pp_loss: 9.497776
[INFO] 2021-07-12 18:31:05,813 [run_pretraining.py:  512]:	********exe.run_287******* 
[INFO] 2021-07-12 18:31:06,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:06,905 [run_pretraining.py:  534]:	loss/total_loss, 9.323355674743652, 288
[INFO] 2021-07-12 18:31:06,905 [run_pretraining.py:  535]:	loss/mlm_loss, 9.323355674743652, 288
[INFO] 2021-07-12 18:31:06,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8699998892989242e-06, 288
[INFO] 2021-07-12 18:31:06,905 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 288
[INFO] 2021-07-12 18:31:06,905 [run_pretraining.py:  558]:	worker_index: 7, step: 288, cost: 9.323356, mlm loss: 9.323356, speed: 0.916214 steps/s, speed: 7.329710 samples/s, speed: 3752.811721 tokens/s, learning rate: 2.870e-06, loss_scalings: 26214.400391, pp_loss: 9.492521
[INFO] 2021-07-12 18:31:06,905 [run_pretraining.py:  512]:	********exe.run_288******* 
[INFO] 2021-07-12 18:31:07,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:07,997 [run_pretraining.py:  534]:	loss/total_loss, 9.277630805969238, 289
[INFO] 2021-07-12 18:31:07,998 [run_pretraining.py:  535]:	loss/mlm_loss, 9.277630805969238, 289
[INFO] 2021-07-12 18:31:07,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997835449176e-06, 289
[INFO] 2021-07-12 18:31:07,998 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 289
[INFO] 2021-07-12 18:31:07,998 [run_pretraining.py:  558]:	worker_index: 7, step: 289, cost: 9.277631, mlm loss: 9.277631, speed: 0.915531 steps/s, speed: 7.324251 samples/s, speed: 3750.016739 tokens/s, learning rate: 2.880e-06, loss_scalings: 26214.400391, pp_loss: 9.550624
[INFO] 2021-07-12 18:31:07,998 [run_pretraining.py:  512]:	********exe.run_289******* 
[INFO] 2021-07-12 18:31:09,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:09,088 [run_pretraining.py:  534]:	loss/total_loss, 9.54902172088623, 290
[INFO] 2021-07-12 18:31:09,089 [run_pretraining.py:  535]:	loss/mlm_loss, 9.54902172088623, 290
[INFO] 2021-07-12 18:31:09,089 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999051645864e-06, 290
[INFO] 2021-07-12 18:31:09,089 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 290
[INFO] 2021-07-12 18:31:09,089 [run_pretraining.py:  558]:	worker_index: 7, step: 290, cost: 9.549022, mlm loss: 9.549022, speed: 0.917099 steps/s, speed: 7.336789 samples/s, speed: 3756.436157 tokens/s, learning rate: 2.890e-06, loss_scalings: 26214.400391, pp_loss: 9.615930
[INFO] 2021-07-12 18:31:09,089 [run_pretraining.py:  512]:	********exe.run_290******* 
[INFO] 2021-07-12 18:31:10,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:10,166 [run_pretraining.py:  534]:	loss/total_loss, 9.580608367919922, 291
[INFO] 2021-07-12 18:31:10,166 [run_pretraining.py:  535]:	loss/mlm_loss, 9.580608367919922, 291
[INFO] 2021-07-12 18:31:10,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8999997994105797e-06, 291
[INFO] 2021-07-12 18:31:10,166 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 291
[INFO] 2021-07-12 18:31:10,166 [run_pretraining.py:  558]:	worker_index: 7, step: 291, cost: 9.580608, mlm loss: 9.580608, speed: 0.928831 steps/s, speed: 7.430645 samples/s, speed: 3804.490481 tokens/s, learning rate: 2.900e-06, loss_scalings: 26214.400391, pp_loss: 9.445303
[INFO] 2021-07-12 18:31:10,166 [run_pretraining.py:  512]:	********exe.run_291******* 
[INFO] 2021-07-12 18:31:11,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:11,258 [run_pretraining.py:  534]:	loss/total_loss, 9.411809921264648, 292
[INFO] 2021-07-12 18:31:11,258 [run_pretraining.py:  535]:	loss/mlm_loss, 9.411809921264648, 292
[INFO] 2021-07-12 18:31:11,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999210302485e-06, 292
[INFO] 2021-07-12 18:31:11,259 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 292
[INFO] 2021-07-12 18:31:11,259 [run_pretraining.py:  558]:	worker_index: 7, step: 292, cost: 9.411810, mlm loss: 9.411810, speed: 0.915809 steps/s, speed: 7.326474 samples/s, speed: 3751.154872 tokens/s, learning rate: 2.910e-06, loss_scalings: 26214.400391, pp_loss: 9.355500
[INFO] 2021-07-12 18:31:11,259 [run_pretraining.py:  512]:	********exe.run_292******* 
[INFO] 2021-07-12 18:31:12,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:12,350 [run_pretraining.py:  534]:	loss/total_loss, 9.664437294006348, 293
[INFO] 2021-07-12 18:31:12,350 [run_pretraining.py:  535]:	loss/mlm_loss, 9.664437294006348, 293
[INFO] 2021-07-12 18:31:12,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9200000426499173e-06, 293
[INFO] 2021-07-12 18:31:12,350 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 293
[INFO] 2021-07-12 18:31:12,350 [run_pretraining.py:  558]:	worker_index: 7, step: 293, cost: 9.664437, mlm loss: 9.664437, speed: 0.916667 steps/s, speed: 7.333332 samples/s, speed: 3754.666144 tokens/s, learning rate: 2.920e-06, loss_scalings: 26214.400391, pp_loss: 9.583369
[INFO] 2021-07-12 18:31:12,350 [run_pretraining.py:  512]:	********exe.run_293******* 
[INFO] 2021-07-12 18:31:13,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:13,435 [run_pretraining.py:  534]:	loss/total_loss, 9.55927848815918, 294
[INFO] 2021-07-12 18:31:13,435 [run_pretraining.py:  535]:	loss/mlm_loss, 9.55927848815918, 294
[INFO] 2021-07-12 18:31:13,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9299999368959107e-06, 294
[INFO] 2021-07-12 18:31:13,435 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 294
[INFO] 2021-07-12 18:31:13,435 [run_pretraining.py:  558]:	worker_index: 7, step: 294, cost: 9.559278, mlm loss: 9.559278, speed: 0.922513 steps/s, speed: 7.380101 samples/s, speed: 3778.611529 tokens/s, learning rate: 2.930e-06, loss_scalings: 26214.400391, pp_loss: 9.536074
[INFO] 2021-07-12 18:31:13,435 [run_pretraining.py:  512]:	********exe.run_294******* 
[INFO] 2021-07-12 18:31:14,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:14,528 [run_pretraining.py:  534]:	loss/total_loss, 9.473565101623535, 295
[INFO] 2021-07-12 18:31:14,528 [run_pretraining.py:  535]:	loss/mlm_loss, 9.473565101623535, 295
[INFO] 2021-07-12 18:31:14,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000585155794e-06, 295
[INFO] 2021-07-12 18:31:14,528 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 295
[INFO] 2021-07-12 18:31:14,528 [run_pretraining.py:  558]:	worker_index: 7, step: 295, cost: 9.473565, mlm loss: 9.473565, speed: 0.915163 steps/s, speed: 7.321308 samples/s, speed: 3748.509571 tokens/s, learning rate: 2.940e-06, loss_scalings: 26214.400391, pp_loss: 9.470454
[INFO] 2021-07-12 18:31:14,528 [run_pretraining.py:  512]:	********exe.run_295******* 
[INFO] 2021-07-12 18:31:15,613 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:15,613 [run_pretraining.py:  534]:	loss/total_loss, 9.790702819824219, 296
[INFO] 2021-07-12 18:31:15,613 [run_pretraining.py:  535]:	loss/mlm_loss, 9.790702819824219, 296
[INFO] 2021-07-12 18:31:15,614 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499999527615728e-06, 296
[INFO] 2021-07-12 18:31:15,614 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 296
[INFO] 2021-07-12 18:31:15,614 [run_pretraining.py:  558]:	worker_index: 7, step: 296, cost: 9.790703, mlm loss: 9.790703, speed: 0.921852 steps/s, speed: 7.374819 samples/s, speed: 3775.907457 tokens/s, learning rate: 2.950e-06, loss_scalings: 26214.400391, pp_loss: 9.508773
[INFO] 2021-07-12 18:31:15,614 [run_pretraining.py:  512]:	********exe.run_296******* 
[INFO] 2021-07-12 18:31:16,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:16,701 [run_pretraining.py:  534]:	loss/total_loss, 9.171992301940918, 297
[INFO] 2021-07-12 18:31:16,701 [run_pretraining.py:  535]:	loss/mlm_loss, 9.171992301940918, 297
[INFO] 2021-07-12 18:31:16,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.959999847007566e-06, 297
[INFO] 2021-07-12 18:31:16,701 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 297
[INFO] 2021-07-12 18:31:16,701 [run_pretraining.py:  558]:	worker_index: 7, step: 297, cost: 9.171992, mlm loss: 9.171992, speed: 0.920038 steps/s, speed: 7.360302 samples/s, speed: 3768.474645 tokens/s, learning rate: 2.960e-06, loss_scalings: 26214.400391, pp_loss: 9.296986
[INFO] 2021-07-12 18:31:16,701 [run_pretraining.py:  512]:	********exe.run_297******* 
[INFO] 2021-07-12 18:31:42,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:42,959 [run_pretraining.py:  534]:	loss/total_loss, 9.489248275756836, 298
[INFO] 2021-07-12 18:31:42,959 [run_pretraining.py:  535]:	loss/mlm_loss, 9.489248275756836, 298
[INFO] 2021-07-12 18:31:42,959 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.969999968627235e-06, 298
[INFO] 2021-07-12 18:31:42,959 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 298
[INFO] 2021-07-12 18:31:42,959 [run_pretraining.py:  558]:	worker_index: 7, step: 298, cost: 9.489248, mlm loss: 9.489248, speed: 0.038084 steps/s, speed: 0.304674 samples/s, speed: 155.993129 tokens/s, learning rate: 2.970e-06, loss_scalings: 26214.400391, pp_loss: 9.444681
[INFO] 2021-07-12 18:31:42,960 [run_pretraining.py:  512]:	********exe.run_298******* 
[INFO] 2021-07-12 18:31:43,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:43,910 [run_pretraining.py:  534]:	loss/total_loss, 9.500553131103516, 299
[INFO] 2021-07-12 18:31:43,911 [run_pretraining.py:  535]:	loss/mlm_loss, 9.500553131103516, 299
[INFO] 2021-07-12 18:31:43,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799998628732283e-06, 299
[INFO] 2021-07-12 18:31:43,911 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 299
[INFO] 2021-07-12 18:31:43,911 [run_pretraining.py:  558]:	worker_index: 7, step: 299, cost: 9.500553, mlm loss: 9.500553, speed: 1.051867 steps/s, speed: 8.414938 samples/s, speed: 4308.448431 tokens/s, learning rate: 2.980e-06, loss_scalings: 26214.400391, pp_loss: 9.492681
[INFO] 2021-07-12 18:31:43,911 [run_pretraining.py:  512]:	********exe.run_299******* 
[INFO] 2021-07-12 18:31:44,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:44,855 [run_pretraining.py:  534]:	loss/total_loss, 9.483574867248535, 300
[INFO] 2021-07-12 18:31:44,855 [run_pretraining.py:  535]:	loss/mlm_loss, 9.483574867248535, 300
[INFO] 2021-07-12 18:31:44,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.989999984492897e-06, 300
[INFO] 2021-07-12 18:31:44,855 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 300
[INFO] 2021-07-12 18:31:44,855 [run_pretraining.py:  558]:	worker_index: 7, step: 300, cost: 9.483575, mlm loss: 9.483575, speed: 1.059710 steps/s, speed: 8.477681 samples/s, speed: 4340.572607 tokens/s, learning rate: 2.990e-06, loss_scalings: 26214.400391, pp_loss: 9.478024
[INFO] 2021-07-12 18:31:44,855 [run_pretraining.py:  512]:	********exe.run_300******* 
[INFO] 2021-07-12 18:31:45,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:45,780 [run_pretraining.py:  534]:	loss/total_loss, 9.738839149475098, 301
[INFO] 2021-07-12 18:31:45,780 [run_pretraining.py:  535]:	loss/mlm_loss, 9.738839149475098, 301
[INFO] 2021-07-12 18:31:45,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9999998787388904e-06, 301
[INFO] 2021-07-12 18:31:45,780 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 301
[INFO] 2021-07-12 18:31:45,780 [run_pretraining.py:  558]:	worker_index: 7, step: 301, cost: 9.738839, mlm loss: 9.738839, speed: 1.081766 steps/s, speed: 8.654125 samples/s, speed: 4430.912110 tokens/s, learning rate: 3.000e-06, loss_scalings: 26214.400391, pp_loss: 9.655174
[INFO] 2021-07-12 18:31:45,780 [run_pretraining.py:  512]:	********exe.run_301******* 
[INFO] 2021-07-12 18:31:46,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:46,708 [run_pretraining.py:  534]:	loss/total_loss, 9.51810073852539, 302
[INFO] 2021-07-12 18:31:46,708 [run_pretraining.py:  535]:	loss/mlm_loss, 9.51810073852539, 302
[INFO] 2021-07-12 18:31:46,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0099997729848837e-06, 302
[INFO] 2021-07-12 18:31:46,708 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 302
[INFO] 2021-07-12 18:31:46,708 [run_pretraining.py:  558]:	worker_index: 7, step: 302, cost: 9.518101, mlm loss: 9.518101, speed: 1.078422 steps/s, speed: 8.627373 samples/s, speed: 4417.214820 tokens/s, learning rate: 3.010e-06, loss_scalings: 26214.400391, pp_loss: 9.315452
[INFO] 2021-07-12 18:31:46,708 [run_pretraining.py:  512]:	********exe.run_302******* 
[INFO] 2021-07-12 18:31:47,619 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:47,619 [run_pretraining.py:  534]:	loss/total_loss, 9.367461204528809, 303
[INFO] 2021-07-12 18:31:47,619 [run_pretraining.py:  535]:	loss/mlm_loss, 9.367461204528809, 303
[INFO] 2021-07-12 18:31:47,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.020000121978228e-06, 303
[INFO] 2021-07-12 18:31:47,619 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 303
[INFO] 2021-07-12 18:31:47,619 [run_pretraining.py:  558]:	worker_index: 7, step: 303, cost: 9.367461, mlm loss: 9.367461, speed: 1.098076 steps/s, speed: 8.784607 samples/s, speed: 4497.718839 tokens/s, learning rate: 3.020e-06, loss_scalings: 26214.400391, pp_loss: 9.387258
[INFO] 2021-07-12 18:31:47,620 [run_pretraining.py:  512]:	********exe.run_303******* 
[INFO] 2021-07-12 18:31:48,529 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  534]:	loss/total_loss, 9.123453140258789, 304
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  535]:	loss/mlm_loss, 9.123453140258789, 304
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0300000162242213e-06, 304
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 304
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  558]:	worker_index: 7, step: 304, cost: 9.123453, mlm loss: 9.123453, speed: 1.099226 steps/s, speed: 8.793811 samples/s, speed: 4502.431458 tokens/s, learning rate: 3.030e-06, loss_scalings: 26214.400391, pp_loss: 9.327415
[INFO] 2021-07-12 18:31:48,530 [run_pretraining.py:  512]:	********exe.run_304******* 
[INFO] 2021-07-12 18:31:49,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:49,442 [run_pretraining.py:  534]:	loss/total_loss, 9.679052352905273, 305
[INFO] 2021-07-12 18:31:49,442 [run_pretraining.py:  535]:	loss/mlm_loss, 9.679052352905273, 305
[INFO] 2021-07-12 18:31:49,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0399999104702147e-06, 305
[INFO] 2021-07-12 18:31:49,442 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 305
[INFO] 2021-07-12 18:31:49,442 [run_pretraining.py:  558]:	worker_index: 7, step: 305, cost: 9.679052, mlm loss: 9.679052, speed: 1.096580 steps/s, speed: 8.772644 samples/s, speed: 4491.593541 tokens/s, learning rate: 3.040e-06, loss_scalings: 26214.400391, pp_loss: 9.430046
[INFO] 2021-07-12 18:31:49,443 [run_pretraining.py:  512]:	********exe.run_305******* 
[INFO] 2021-07-12 18:31:50,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:50,354 [run_pretraining.py:  534]:	loss/total_loss, 9.298221588134766, 306
[INFO] 2021-07-12 18:31:50,355 [run_pretraining.py:  535]:	loss/mlm_loss, 9.298221588134766, 306
[INFO] 2021-07-12 18:31:50,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0500000320898835e-06, 306
[INFO] 2021-07-12 18:31:50,355 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 306
[INFO] 2021-07-12 18:31:50,355 [run_pretraining.py:  558]:	worker_index: 7, step: 306, cost: 9.298222, mlm loss: 9.298222, speed: 1.096910 steps/s, speed: 8.775277 samples/s, speed: 4492.942048 tokens/s, learning rate: 3.050e-06, loss_scalings: 26214.400391, pp_loss: 9.364463
[INFO] 2021-07-12 18:31:50,355 [run_pretraining.py:  512]:	********exe.run_306******* 
[INFO] 2021-07-12 18:31:51,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:51,264 [run_pretraining.py:  534]:	loss/total_loss, 9.394746780395508, 307
[INFO] 2021-07-12 18:31:51,264 [run_pretraining.py:  535]:	loss/mlm_loss, 9.394746780395508, 307
[INFO] 2021-07-12 18:31:51,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.059999926335877e-06, 307
[INFO] 2021-07-12 18:31:51,264 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 307
[INFO] 2021-07-12 18:31:51,264 [run_pretraining.py:  558]:	worker_index: 7, step: 307, cost: 9.394747, mlm loss: 9.394747, speed: 1.100312 steps/s, speed: 8.802492 samples/s, speed: 4506.876104 tokens/s, learning rate: 3.060e-06, loss_scalings: 26214.400391, pp_loss: 9.207479
[INFO] 2021-07-12 18:31:51,264 [run_pretraining.py:  512]:	********exe.run_307******* 
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  534]:	loss/total_loss, 9.467580795288086, 308
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  535]:	loss/mlm_loss, 9.467580795288086, 308
[INFO] 2021-07-12 18:31:52,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.06999982058187e-06, 308
[INFO] 2021-07-12 18:31:52,171 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 308
[INFO] 2021-07-12 18:31:52,171 [run_pretraining.py:  558]:	worker_index: 7, step: 308, cost: 9.467581, mlm loss: 9.467581, speed: 1.104047 steps/s, speed: 8.832375 samples/s, speed: 4522.176121 tokens/s, learning rate: 3.070e-06, loss_scalings: 26214.400391, pp_loss: 9.414814
[INFO] 2021-07-12 18:31:52,171 [run_pretraining.py:  512]:	********exe.run_308******* 
[INFO] 2021-07-12 18:31:53,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:31:53,084 [run_pretraining.py:  534]:	loss/total_loss, 9.789081573486328, 309
[INFO] 2021-07-12 18:31:53,084 [run_pretraining.py:  535]:	loss/mlm_loss, 9.789081573486328, 309
[INFO] 2021-07-12 18:31:53,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.079999942201539e-06, 309
[INFO] 2021-07-12 18:31:53,084 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 309
[INFO] 2021-07-12 18:31:53,084 [run_pretraining.py:  558]:	worker_index: 7, step: 309, cost: 9.789082, mlm loss: 9.789082, speed: 1.095077 steps/s, speed: 8.760614 samples/s, speed: 4485.434546 tokens/s, learning rate: 3.080e-06, loss_scalings: 26214.400391, pp_loss: 9.563667
[INFO] 2021-07-12 18:31:53,085 [run_pretraining.py:  512]:	********exe.run_309******* 
[INFO] 2021-07-12 18:32:18,916 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:18,916 [run_pretraining.py:  534]:	loss/total_loss, 8.83932113647461, 310
[INFO] 2021-07-12 18:32:18,916 [run_pretraining.py:  535]:	loss/mlm_loss, 8.83932113647461, 310
[INFO] 2021-07-12 18:32:18,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.0899998364475323e-06, 310
[INFO] 2021-07-12 18:32:18,917 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 310
[INFO] 2021-07-12 18:32:18,917 [run_pretraining.py:  558]:	worker_index: 7, step: 310, cost: 8.839321, mlm loss: 8.839321, speed: 0.038712 steps/s, speed: 0.309699 samples/s, speed: 158.565851 tokens/s, learning rate: 3.090e-06, loss_scalings: 26214.400391, pp_loss: 9.202630
[INFO] 2021-07-12 18:32:18,917 [run_pretraining.py:  512]:	********exe.run_310******* 
[INFO] 2021-07-12 18:32:19,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:19,830 [run_pretraining.py:  534]:	loss/total_loss, 9.76815414428711, 311
[INFO] 2021-07-12 18:32:19,830 [run_pretraining.py:  535]:	loss/mlm_loss, 9.76815414428711, 311
[INFO] 2021-07-12 18:32:19,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.099999958067201e-06, 311
[INFO] 2021-07-12 18:32:19,831 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 311
[INFO] 2021-07-12 18:32:19,831 [run_pretraining.py:  558]:	worker_index: 7, step: 311, cost: 9.768154, mlm loss: 9.768154, speed: 1.094817 steps/s, speed: 8.758538 samples/s, speed: 4484.371451 tokens/s, learning rate: 3.100e-06, loss_scalings: 26214.400391, pp_loss: 9.433932
[INFO] 2021-07-12 18:32:19,831 [run_pretraining.py:  512]:	********exe.run_311******* 
[INFO] 2021-07-12 18:32:20,741 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:20,742 [run_pretraining.py:  534]:	loss/total_loss, 9.085505485534668, 312
[INFO] 2021-07-12 18:32:20,742 [run_pretraining.py:  535]:	loss/mlm_loss, 9.085505485534668, 312
[INFO] 2021-07-12 18:32:20,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1099998523131944e-06, 312
[INFO] 2021-07-12 18:32:20,742 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 312
[INFO] 2021-07-12 18:32:20,742 [run_pretraining.py:  558]:	worker_index: 7, step: 312, cost: 9.085505, mlm loss: 9.085505, speed: 1.097686 steps/s, speed: 8.781490 samples/s, speed: 4496.122702 tokens/s, learning rate: 3.110e-06, loss_scalings: 26214.400391, pp_loss: 9.174555
[INFO] 2021-07-12 18:32:20,742 [run_pretraining.py:  512]:	********exe.run_312******* 
[INFO] 2021-07-12 18:32:21,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:21,653 [run_pretraining.py:  534]:	loss/total_loss, 9.25662612915039, 313
[INFO] 2021-07-12 18:32:21,653 [run_pretraining.py:  535]:	loss/mlm_loss, 9.25662612915039, 313
[INFO] 2021-07-12 18:32:21,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1199997465591878e-06, 313
[INFO] 2021-07-12 18:32:21,653 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 313
[INFO] 2021-07-12 18:32:21,653 [run_pretraining.py:  558]:	worker_index: 7, step: 313, cost: 9.256626, mlm loss: 9.256626, speed: 1.098576 steps/s, speed: 8.788611 samples/s, speed: 4499.768641 tokens/s, learning rate: 3.120e-06, loss_scalings: 26214.400391, pp_loss: 9.312851
[INFO] 2021-07-12 18:32:21,653 [run_pretraining.py:  512]:	********exe.run_313******* 
[INFO] 2021-07-12 18:32:48,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:32:48,143 [run_pretraining.py:  534]:	loss/total_loss, 9.449414253234863, 314
[INFO] 2021-07-12 18:32:48,144 [run_pretraining.py:  535]:	loss/mlm_loss, 9.449414253234863, 314
[INFO] 2021-07-12 18:32:48,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.130000095552532e-06, 314
[INFO] 2021-07-12 18:32:48,144 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 314
[INFO] 2021-07-12 18:32:48,144 [run_pretraining.py:  558]:	worker_index: 7, step: 314, cost: 9.449414, mlm loss: 9.449414, speed: 0.037750 steps/s, speed: 0.302003 samples/s, speed: 154.625565 tokens/s, learning rate: 3.130e-06, loss_scalings: 26214.400391, pp_loss: 9.330148
[INFO] 2021-07-12 18:32:48,144 [run_pretraining.py:  512]:	********exe.run_314******* 
[INFO] 2021-07-12 18:33:14,240 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:14,241 [run_pretraining.py:  534]:	loss/total_loss, 9.206804275512695, 315
[INFO] 2021-07-12 18:33:14,241 [run_pretraining.py:  535]:	loss/mlm_loss, 9.206804275512695, 315
[INFO] 2021-07-12 18:33:14,241 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.13999976242485e-06, 315
[INFO] 2021-07-12 18:33:14,241 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 315
[INFO] 2021-07-12 18:33:14,241 [run_pretraining.py:  558]:	worker_index: 7, step: 315, cost: 9.206804, mlm loss: 9.206804, speed: 0.038319 steps/s, speed: 0.306555 samples/s, speed: 156.956063 tokens/s, learning rate: 3.140e-06, loss_scalings: 26214.400391, pp_loss: 9.388165
[INFO] 2021-07-12 18:33:14,241 [run_pretraining.py:  512]:	********exe.run_315******* 
[INFO] 2021-07-12 18:33:15,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:15,183 [run_pretraining.py:  534]:	loss/total_loss, 9.68442440032959, 316
[INFO] 2021-07-12 18:33:15,183 [run_pretraining.py:  535]:	loss/mlm_loss, 9.68442440032959, 316
[INFO] 2021-07-12 18:33:15,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1499998840445187e-06, 316
[INFO] 2021-07-12 18:33:15,183 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 316
[INFO] 2021-07-12 18:33:15,183 [run_pretraining.py:  558]:	worker_index: 7, step: 316, cost: 9.684424, mlm loss: 9.684424, speed: 1.061673 steps/s, speed: 8.493387 samples/s, speed: 4348.613972 tokens/s, learning rate: 3.150e-06, loss_scalings: 26214.400391, pp_loss: 9.389070
[INFO] 2021-07-12 18:33:15,184 [run_pretraining.py:  512]:	********exe.run_316******* 
[INFO] 2021-07-12 18:33:16,098 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:16,098 [run_pretraining.py:  534]:	loss/total_loss, 9.39567756652832, 317
[INFO] 2021-07-12 18:33:16,098 [run_pretraining.py:  535]:	loss/mlm_loss, 9.39567756652832, 317
[INFO] 2021-07-12 18:33:16,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.159999778290512e-06, 317
[INFO] 2021-07-12 18:33:16,099 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 317
[INFO] 2021-07-12 18:33:16,099 [run_pretraining.py:  558]:	worker_index: 7, step: 317, cost: 9.395678, mlm loss: 9.395678, speed: 1.093333 steps/s, speed: 8.746664 samples/s, speed: 4478.291767 tokens/s, learning rate: 3.160e-06, loss_scalings: 26214.400391, pp_loss: 9.406261
[INFO] 2021-07-12 18:33:16,099 [run_pretraining.py:  512]:	********exe.run_317******* 
[INFO] 2021-07-12 18:33:17,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:17,011 [run_pretraining.py:  534]:	loss/total_loss, 9.386747360229492, 318
[INFO] 2021-07-12 18:33:17,011 [run_pretraining.py:  535]:	loss/mlm_loss, 9.386747360229492, 318
[INFO] 2021-07-12 18:33:17,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.169999899910181e-06, 318
[INFO] 2021-07-12 18:33:17,012 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 318
[INFO] 2021-07-12 18:33:17,012 [run_pretraining.py:  558]:	worker_index: 7, step: 318, cost: 9.386747, mlm loss: 9.386747, speed: 1.096158 steps/s, speed: 8.769262 samples/s, speed: 4489.862108 tokens/s, learning rate: 3.170e-06, loss_scalings: 26214.400391, pp_loss: 9.366699
[INFO] 2021-07-12 18:33:17,012 [run_pretraining.py:  512]:	********exe.run_318******* 
[INFO] 2021-07-12 18:33:17,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:17,924 [run_pretraining.py:  534]:	loss/total_loss, 9.31702709197998, 319
[INFO] 2021-07-12 18:33:17,924 [run_pretraining.py:  535]:	loss/mlm_loss, 9.31702709197998, 319
[INFO] 2021-07-12 18:33:17,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.1800000215298496e-06, 319
[INFO] 2021-07-12 18:33:17,924 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 319
[INFO] 2021-07-12 18:33:17,924 [run_pretraining.py:  558]:	worker_index: 7, step: 319, cost: 9.317027, mlm loss: 9.317027, speed: 1.096630 steps/s, speed: 8.773043 samples/s, speed: 4491.797879 tokens/s, learning rate: 3.180e-06, loss_scalings: 26214.400391, pp_loss: 9.340364
[INFO] 2021-07-12 18:33:17,924 [run_pretraining.py:  512]:	********exe.run_319******* 
[INFO] 2021-07-12 18:33:18,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:18,836 [run_pretraining.py:  534]:	loss/total_loss, 9.484709739685059, 320
[INFO] 2021-07-12 18:33:18,836 [run_pretraining.py:  535]:	loss/mlm_loss, 9.484709739685059, 320
[INFO] 2021-07-12 18:33:18,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.189999915775843e-06, 320
[INFO] 2021-07-12 18:33:18,837 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 320
[INFO] 2021-07-12 18:33:18,837 [run_pretraining.py:  558]:	worker_index: 7, step: 320, cost: 9.484710, mlm loss: 9.484710, speed: 1.096790 steps/s, speed: 8.774318 samples/s, speed: 4492.450947 tokens/s, learning rate: 3.190e-06, loss_scalings: 26214.400391, pp_loss: 9.388744
[INFO] 2021-07-12 18:33:18,837 [run_pretraining.py:  512]:	********exe.run_320******* 
[INFO] 2021-07-12 18:33:19,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:19,743 [run_pretraining.py:  534]:	loss/total_loss, 9.116393089294434, 321
[INFO] 2021-07-12 18:33:19,743 [run_pretraining.py:  535]:	loss/mlm_loss, 9.116393089294434, 321
[INFO] 2021-07-12 18:33:19,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2000000373955118e-06, 321
[INFO] 2021-07-12 18:33:19,744 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 321
[INFO] 2021-07-12 18:33:19,744 [run_pretraining.py:  558]:	worker_index: 7, step: 321, cost: 9.116393, mlm loss: 9.116393, speed: 1.103335 steps/s, speed: 8.826681 samples/s, speed: 4519.260452 tokens/s, learning rate: 3.200e-06, loss_scalings: 26214.400391, pp_loss: 9.290331
[INFO] 2021-07-12 18:33:19,744 [run_pretraining.py:  512]:	********exe.run_321******* 
[INFO] 2021-07-12 18:33:20,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:20,659 [run_pretraining.py:  534]:	loss/total_loss, 9.594554901123047, 322
[INFO] 2021-07-12 18:33:20,659 [run_pretraining.py:  535]:	loss/mlm_loss, 9.594554901123047, 322
[INFO] 2021-07-12 18:33:20,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.209999931641505e-06, 322
[INFO] 2021-07-12 18:33:20,659 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 322
[INFO] 2021-07-12 18:33:20,659 [run_pretraining.py:  558]:	worker_index: 7, step: 322, cost: 9.594555, mlm loss: 9.594555, speed: 1.093424 steps/s, speed: 8.747393 samples/s, speed: 4478.665354 tokens/s, learning rate: 3.210e-06, loss_scalings: 26214.400391, pp_loss: 9.383620
[INFO] 2021-07-12 18:33:20,659 [run_pretraining.py:  512]:	********exe.run_322******* 
[INFO] 2021-07-12 18:33:21,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:21,569 [run_pretraining.py:  534]:	loss/total_loss, 9.343324661254883, 323
[INFO] 2021-07-12 18:33:21,569 [run_pretraining.py:  535]:	loss/mlm_loss, 9.343324661254883, 323
[INFO] 2021-07-12 18:33:21,570 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.220000053261174e-06, 323
[INFO] 2021-07-12 18:33:21,570 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 323
[INFO] 2021-07-12 18:33:21,570 [run_pretraining.py:  558]:	worker_index: 7, step: 323, cost: 9.343325, mlm loss: 9.343325, speed: 1.098680 steps/s, speed: 8.789437 samples/s, speed: 4500.191792 tokens/s, learning rate: 3.220e-06, loss_scalings: 26214.400391, pp_loss: 9.321518
[INFO] 2021-07-12 18:33:21,570 [run_pretraining.py:  512]:	********exe.run_323******* 
[INFO] 2021-07-12 18:33:22,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:22,482 [run_pretraining.py:  534]:	loss/total_loss, 9.291329383850098, 324
[INFO] 2021-07-12 18:33:22,482 [run_pretraining.py:  535]:	loss/mlm_loss, 9.291329383850098, 324
[INFO] 2021-07-12 18:33:22,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.229999720133492e-06, 324
[INFO] 2021-07-12 18:33:22,483 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 324
[INFO] 2021-07-12 18:33:22,483 [run_pretraining.py:  558]:	worker_index: 7, step: 324, cost: 9.291329, mlm loss: 9.291329, speed: 1.096040 steps/s, speed: 8.768318 samples/s, speed: 4489.378719 tokens/s, learning rate: 3.230e-06, loss_scalings: 26214.400391, pp_loss: 9.349413
[INFO] 2021-07-12 18:33:22,483 [run_pretraining.py:  512]:	********exe.run_324******* 
[INFO] 2021-07-12 18:33:23,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:23,396 [run_pretraining.py:  534]:	loss/total_loss, 9.467382431030273, 325
[INFO] 2021-07-12 18:33:23,397 [run_pretraining.py:  535]:	loss/mlm_loss, 9.467382431030273, 325
[INFO] 2021-07-12 18:33:23,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.240000069126836e-06, 325
[INFO] 2021-07-12 18:33:23,397 [run_pretraining.py:  539]:	lr/loss_scaling, 26214.400390625, 325
[INFO] 2021-07-12 18:33:23,397 [run_pretraining.py:  558]:	worker_index: 7, step: 325, cost: 9.467382, mlm loss: 9.467382, speed: 1.094716 steps/s, speed: 8.757731 samples/s, speed: 4483.958291 tokens/s, learning rate: 3.240e-06, loss_scalings: 26214.400391, pp_loss: 9.452939
[INFO] 2021-07-12 18:33:23,397 [run_pretraining.py:  512]:	********exe.run_325******* 
[INFO] 2021-07-12 18:33:49,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:49,761 [run_pretraining.py:  534]:	loss/total_loss, 9.653607368469238, 326
[INFO] 2021-07-12 18:33:49,761 [run_pretraining.py:  535]:	loss/mlm_loss, 9.653607368469238, 326
[INFO] 2021-07-12 18:33:49,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.249999735999154e-06, 326
[INFO] 2021-07-12 18:33:49,761 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 326
[INFO] 2021-07-12 18:33:49,761 [run_pretraining.py:  558]:	worker_index: 7, step: 326, cost: 9.653607, mlm loss: 9.653607, speed: 0.037931 steps/s, speed: 0.303448 samples/s, speed: 155.365226 tokens/s, learning rate: 3.250e-06, loss_scalings: 20971.521484, pp_loss: 9.576204
[INFO] 2021-07-12 18:33:49,761 [run_pretraining.py:  512]:	********exe.run_326******* 
[INFO] 2021-07-12 18:33:50,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:50,694 [run_pretraining.py:  534]:	loss/total_loss, 9.269757270812988, 327
[INFO] 2021-07-12 18:33:50,694 [run_pretraining.py:  535]:	loss/mlm_loss, 9.269757270812988, 327
[INFO] 2021-07-12 18:33:50,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2599998576188227e-06, 327
[INFO] 2021-07-12 18:33:50,694 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 327
[INFO] 2021-07-12 18:33:50,694 [run_pretraining.py:  558]:	worker_index: 7, step: 327, cost: 9.269757, mlm loss: 9.269757, speed: 1.072369 steps/s, speed: 8.578951 samples/s, speed: 4392.423085 tokens/s, learning rate: 3.260e-06, loss_scalings: 20971.521484, pp_loss: 9.346903
[INFO] 2021-07-12 18:33:50,694 [run_pretraining.py:  512]:	********exe.run_327******* 
[INFO] 2021-07-12 18:33:51,625 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:51,625 [run_pretraining.py:  534]:	loss/total_loss, 9.539337158203125, 328
[INFO] 2021-07-12 18:33:51,625 [run_pretraining.py:  535]:	loss/mlm_loss, 9.539337158203125, 328
[INFO] 2021-07-12 18:33:51,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.269999751864816e-06, 328
[INFO] 2021-07-12 18:33:51,625 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 328
[INFO] 2021-07-12 18:33:51,625 [run_pretraining.py:  558]:	worker_index: 7, step: 328, cost: 9.539337, mlm loss: 9.539337, speed: 1.074763 steps/s, speed: 8.598105 samples/s, speed: 4402.229827 tokens/s, learning rate: 3.270e-06, loss_scalings: 20971.521484, pp_loss: 9.396545
[INFO] 2021-07-12 18:33:51,626 [run_pretraining.py:  512]:	********exe.run_328******* 
[INFO] 2021-07-12 18:33:52,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:52,550 [run_pretraining.py:  534]:	loss/total_loss, 9.390530586242676, 329
[INFO] 2021-07-12 18:33:52,550 [run_pretraining.py:  535]:	loss/mlm_loss, 9.390530586242676, 329
[INFO] 2021-07-12 18:33:52,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.279999873484485e-06, 329
[INFO] 2021-07-12 18:33:52,550 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 329
[INFO] 2021-07-12 18:33:52,550 [run_pretraining.py:  558]:	worker_index: 7, step: 329, cost: 9.390531, mlm loss: 9.390531, speed: 1.081919 steps/s, speed: 8.655355 samples/s, speed: 4431.541877 tokens/s, learning rate: 3.280e-06, loss_scalings: 20971.521484, pp_loss: 9.369415
[INFO] 2021-07-12 18:33:52,550 [run_pretraining.py:  512]:	********exe.run_329******* 
[INFO] 2021-07-12 18:33:53,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:53,481 [run_pretraining.py:  534]:	loss/total_loss, 9.287611961364746, 330
[INFO] 2021-07-12 18:33:53,481 [run_pretraining.py:  535]:	loss/mlm_loss, 9.287611961364746, 330
[INFO] 2021-07-12 18:33:53,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.2899999951041536e-06, 330
[INFO] 2021-07-12 18:33:53,481 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 330
[INFO] 2021-07-12 18:33:53,481 [run_pretraining.py:  558]:	worker_index: 7, step: 330, cost: 9.287612, mlm loss: 9.287612, speed: 1.075048 steps/s, speed: 8.600382 samples/s, speed: 4403.395404 tokens/s, learning rate: 3.290e-06, loss_scalings: 20971.521484, pp_loss: 9.514968
[INFO] 2021-07-12 18:33:53,481 [run_pretraining.py:  512]:	********exe.run_330******* 
[INFO] 2021-07-12 18:33:54,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:54,416 [run_pretraining.py:  534]:	loss/total_loss, 9.17235279083252, 331
[INFO] 2021-07-12 18:33:54,417 [run_pretraining.py:  535]:	loss/mlm_loss, 9.17235279083252, 331
[INFO] 2021-07-12 18:33:54,417 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.299999889350147e-06, 331
[INFO] 2021-07-12 18:33:54,417 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 331
[INFO] 2021-07-12 18:33:54,417 [run_pretraining.py:  558]:	worker_index: 7, step: 331, cost: 9.172353, mlm loss: 9.172353, speed: 1.069528 steps/s, speed: 8.556224 samples/s, speed: 4380.786912 tokens/s, learning rate: 3.300e-06, loss_scalings: 20971.521484, pp_loss: 9.388051
[INFO] 2021-07-12 18:33:54,417 [run_pretraining.py:  512]:	********exe.run_331******* 
[INFO] 2021-07-12 18:33:55,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:55,347 [run_pretraining.py:  534]:	loss/total_loss, 9.11203384399414, 332
[INFO] 2021-07-12 18:33:55,347 [run_pretraining.py:  535]:	loss/mlm_loss, 9.11203384399414, 332
[INFO] 2021-07-12 18:33:55,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3100000109698158e-06, 332
[INFO] 2021-07-12 18:33:55,348 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 332
[INFO] 2021-07-12 18:33:55,348 [run_pretraining.py:  558]:	worker_index: 7, step: 332, cost: 9.112034, mlm loss: 9.112034, speed: 1.075052 steps/s, speed: 8.600413 samples/s, speed: 4403.411205 tokens/s, learning rate: 3.310e-06, loss_scalings: 20971.521484, pp_loss: 9.288748
[INFO] 2021-07-12 18:33:55,348 [run_pretraining.py:  512]:	********exe.run_332******* 
[INFO] 2021-07-12 18:33:56,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:56,273 [run_pretraining.py:  534]:	loss/total_loss, 9.366304397583008, 333
[INFO] 2021-07-12 18:33:56,273 [run_pretraining.py:  535]:	loss/mlm_loss, 9.366304397583008, 333
[INFO] 2021-07-12 18:33:56,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.319999905215809e-06, 333
[INFO] 2021-07-12 18:33:56,273 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 333
[INFO] 2021-07-12 18:33:56,273 [run_pretraining.py:  558]:	worker_index: 7, step: 333, cost: 9.366304, mlm loss: 9.366304, speed: 1.081208 steps/s, speed: 8.649661 samples/s, speed: 4428.626567 tokens/s, learning rate: 3.320e-06, loss_scalings: 20971.521484, pp_loss: 9.342185
[INFO] 2021-07-12 18:33:56,273 [run_pretraining.py:  512]:	********exe.run_333******* 
[INFO] 2021-07-12 18:33:57,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:57,196 [run_pretraining.py:  534]:	loss/total_loss, 9.086969375610352, 334
[INFO] 2021-07-12 18:33:57,196 [run_pretraining.py:  535]:	loss/mlm_loss, 9.086969375610352, 334
[INFO] 2021-07-12 18:33:57,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.330000026835478e-06, 334
[INFO] 2021-07-12 18:33:57,197 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 334
[INFO] 2021-07-12 18:33:57,197 [run_pretraining.py:  558]:	worker_index: 7, step: 334, cost: 9.086969, mlm loss: 9.086969, speed: 1.083675 steps/s, speed: 8.669399 samples/s, speed: 4438.732286 tokens/s, learning rate: 3.330e-06, loss_scalings: 20971.521484, pp_loss: 9.244125
[INFO] 2021-07-12 18:33:57,197 [run_pretraining.py:  512]:	********exe.run_334******* 
[INFO] 2021-07-12 18:33:58,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:58,133 [run_pretraining.py:  534]:	loss/total_loss, 9.325328826904297, 335
[INFO] 2021-07-12 18:33:58,133 [run_pretraining.py:  535]:	loss/mlm_loss, 9.325328826904297, 335
[INFO] 2021-07-12 18:33:58,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.3399999210814713e-06, 335
[INFO] 2021-07-12 18:33:58,133 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 335
[INFO] 2021-07-12 18:33:58,134 [run_pretraining.py:  558]:	worker_index: 7, step: 335, cost: 9.325329, mlm loss: 9.325329, speed: 1.068109 steps/s, speed: 8.544868 samples/s, speed: 4374.972417 tokens/s, learning rate: 3.340e-06, loss_scalings: 20971.521484, pp_loss: 9.232573
[INFO] 2021-07-12 18:33:58,134 [run_pretraining.py:  512]:	********exe.run_335******* 
[INFO] 2021-07-12 18:33:59,055 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:59,056 [run_pretraining.py:  534]:	loss/total_loss, 9.300317764282227, 336
[INFO] 2021-07-12 18:33:59,056 [run_pretraining.py:  535]:	loss/mlm_loss, 9.300317764282227, 336
[INFO] 2021-07-12 18:33:59,056 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.35000004270114e-06, 336
[INFO] 2021-07-12 18:33:59,056 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 336
[INFO] 2021-07-12 18:33:59,056 [run_pretraining.py:  558]:	worker_index: 7, step: 336, cost: 9.300318, mlm loss: 9.300318, speed: 1.084494 steps/s, speed: 8.675953 samples/s, speed: 4442.088145 tokens/s, learning rate: 3.350e-06, loss_scalings: 20971.521484, pp_loss: 9.457893
[INFO] 2021-07-12 18:33:59,056 [run_pretraining.py:  512]:	********exe.run_336******* 
[INFO] 2021-07-12 18:33:59,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:33:59,976 [run_pretraining.py:  534]:	loss/total_loss, 9.003677368164062, 337
[INFO] 2021-07-12 18:33:59,977 [run_pretraining.py:  535]:	loss/mlm_loss, 9.003677368164062, 337
[INFO] 2021-07-12 18:33:59,977 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.359999709573458e-06, 337
[INFO] 2021-07-12 18:33:59,977 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 337
[INFO] 2021-07-12 18:33:59,977 [run_pretraining.py:  558]:	worker_index: 7, step: 337, cost: 9.003677, mlm loss: 9.003677, speed: 1.087214 steps/s, speed: 8.697712 samples/s, speed: 4453.228352 tokens/s, learning rate: 3.360e-06, loss_scalings: 20971.521484, pp_loss: 9.251808
[INFO] 2021-07-12 18:33:59,977 [run_pretraining.py:  512]:	********exe.run_337******* 
[INFO] 2021-07-12 18:34:00,901 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:00,902 [run_pretraining.py:  534]:	loss/total_loss, 9.571582794189453, 338
[INFO] 2021-07-12 18:34:00,902 [run_pretraining.py:  535]:	loss/mlm_loss, 9.571582794189453, 338
[INFO] 2021-07-12 18:34:00,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.370000058566802e-06, 338
[INFO] 2021-07-12 18:34:00,902 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 338
[INFO] 2021-07-12 18:34:00,902 [run_pretraining.py:  558]:	worker_index: 7, step: 338, cost: 9.571583, mlm loss: 9.571583, speed: 1.081744 steps/s, speed: 8.653956 samples/s, speed: 4430.825260 tokens/s, learning rate: 3.370e-06, loss_scalings: 20971.521484, pp_loss: 9.354933
[INFO] 2021-07-12 18:34:00,902 [run_pretraining.py:  512]:	********exe.run_338******* 
[INFO] 2021-07-12 18:34:01,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:01,826 [run_pretraining.py:  534]:	loss/total_loss, 9.38539981842041, 339
[INFO] 2021-07-12 18:34:01,827 [run_pretraining.py:  535]:	loss/mlm_loss, 9.38539981842041, 339
[INFO] 2021-07-12 18:34:01,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.37999972543912e-06, 339
[INFO] 2021-07-12 18:34:01,827 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 339
[INFO] 2021-07-12 18:34:01,827 [run_pretraining.py:  558]:	worker_index: 7, step: 339, cost: 9.385400, mlm loss: 9.385400, speed: 1.081969 steps/s, speed: 8.655748 samples/s, speed: 4431.743075 tokens/s, learning rate: 3.380e-06, loss_scalings: 20971.521484, pp_loss: 9.462896
[INFO] 2021-07-12 18:34:01,827 [run_pretraining.py:  512]:	********exe.run_339******* 
[INFO] 2021-07-12 18:34:02,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:02,757 [run_pretraining.py:  534]:	loss/total_loss, 9.215436935424805, 340
[INFO] 2021-07-12 18:34:02,757 [run_pretraining.py:  535]:	loss/mlm_loss, 9.215436935424805, 340
[INFO] 2021-07-12 18:34:02,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.389999847058789e-06, 340
[INFO] 2021-07-12 18:34:02,757 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 340
[INFO] 2021-07-12 18:34:02,757 [run_pretraining.py:  558]:	worker_index: 7, step: 340, cost: 9.215437, mlm loss: 9.215437, speed: 1.075789 steps/s, speed: 8.606313 samples/s, speed: 4406.432410 tokens/s, learning rate: 3.390e-06, loss_scalings: 20971.521484, pp_loss: 9.181870
[INFO] 2021-07-12 18:34:02,757 [run_pretraining.py:  512]:	********exe.run_340******* 
[INFO] 2021-07-12 18:34:03,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:03,677 [run_pretraining.py:  534]:	loss/total_loss, 9.418237686157227, 341
[INFO] 2021-07-12 18:34:03,677 [run_pretraining.py:  535]:	loss/mlm_loss, 9.418237686157227, 341
[INFO] 2021-07-12 18:34:03,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.400000196052133e-06, 341
[INFO] 2021-07-12 18:34:03,677 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 341
[INFO] 2021-07-12 18:34:03,677 [run_pretraining.py:  558]:	worker_index: 7, step: 341, cost: 9.418238, mlm loss: 9.418238, speed: 1.087456 steps/s, speed: 8.699651 samples/s, speed: 4454.221297 tokens/s, learning rate: 3.400e-06, loss_scalings: 20971.521484, pp_loss: 9.207489
[INFO] 2021-07-12 18:34:03,677 [run_pretraining.py:  512]:	********exe.run_341******* 
[INFO] 2021-07-12 18:34:04,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:04,598 [run_pretraining.py:  534]:	loss/total_loss, 9.194650650024414, 342
[INFO] 2021-07-12 18:34:04,599 [run_pretraining.py:  535]:	loss/mlm_loss, 9.194650650024414, 342
[INFO] 2021-07-12 18:34:04,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.409999862924451e-06, 342
[INFO] 2021-07-12 18:34:04,599 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 342
[INFO] 2021-07-12 18:34:04,599 [run_pretraining.py:  558]:	worker_index: 7, step: 342, cost: 9.194651, mlm loss: 9.194651, speed: 1.085872 steps/s, speed: 8.686973 samples/s, speed: 4447.730148 tokens/s, learning rate: 3.410e-06, loss_scalings: 20971.521484, pp_loss: 8.604877
[INFO] 2021-07-12 18:34:04,599 [run_pretraining.py:  512]:	********exe.run_342******* 
[INFO] 2021-07-12 18:34:30,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  534]:	loss/total_loss, 9.670398712158203, 343
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  535]:	loss/mlm_loss, 9.670398712158203, 343
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.41999998454412e-06, 343
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 343
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  558]:	worker_index: 7, step: 343, cost: 9.670399, mlm loss: 9.670399, speed: 0.038643 steps/s, speed: 0.309146 samples/s, speed: 158.282695 tokens/s, learning rate: 3.420e-06, loss_scalings: 20971.521484, pp_loss: 9.454732
[INFO] 2021-07-12 18:34:30,477 [run_pretraining.py:  512]:	********exe.run_343******* 
[INFO] 2021-07-12 18:34:31,391 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:31,392 [run_pretraining.py:  534]:	loss/total_loss, 9.252613067626953, 344
[INFO] 2021-07-12 18:34:31,392 [run_pretraining.py:  535]:	loss/mlm_loss, 9.252613067626953, 344
[INFO] 2021-07-12 18:34:31,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.429999878790113e-06, 344
[INFO] 2021-07-12 18:34:31,392 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 344
[INFO] 2021-07-12 18:34:31,392 [run_pretraining.py:  558]:	worker_index: 7, step: 344, cost: 9.252613, mlm loss: 9.252613, speed: 1.093853 steps/s, speed: 8.750824 samples/s, speed: 4480.422045 tokens/s, learning rate: 3.430e-06, loss_scalings: 20971.521484, pp_loss: 8.981386
[INFO] 2021-07-12 18:34:31,392 [run_pretraining.py:  512]:	********exe.run_344******* 
[INFO] 2021-07-12 18:34:32,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:32,315 [run_pretraining.py:  534]:	loss/total_loss, 9.262773513793945, 345
[INFO] 2021-07-12 18:34:32,315 [run_pretraining.py:  535]:	loss/mlm_loss, 9.262773513793945, 345
[INFO] 2021-07-12 18:34:32,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.440000000409782e-06, 345
[INFO] 2021-07-12 18:34:32,315 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 345
[INFO] 2021-07-12 18:34:32,315 [run_pretraining.py:  558]:	worker_index: 7, step: 345, cost: 9.262774, mlm loss: 9.262774, speed: 1.083813 steps/s, speed: 8.670503 samples/s, speed: 4439.297744 tokens/s, learning rate: 3.440e-06, loss_scalings: 20971.521484, pp_loss: 9.245207
[INFO] 2021-07-12 18:34:32,315 [run_pretraining.py:  512]:	********exe.run_345******* 
[INFO] 2021-07-12 18:34:33,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:33,234 [run_pretraining.py:  534]:	loss/total_loss, 9.268035888671875, 346
[INFO] 2021-07-12 18:34:33,234 [run_pretraining.py:  535]:	loss/mlm_loss, 9.268035888671875, 346
[INFO] 2021-07-12 18:34:33,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.4499998946557753e-06, 346
[INFO] 2021-07-12 18:34:33,234 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 346
[INFO] 2021-07-12 18:34:33,234 [run_pretraining.py:  558]:	worker_index: 7, step: 346, cost: 9.268036, mlm loss: 9.268036, speed: 1.089417 steps/s, speed: 8.715335 samples/s, speed: 4462.251528 tokens/s, learning rate: 3.450e-06, loss_scalings: 20971.521484, pp_loss: 8.677858
[INFO] 2021-07-12 18:34:33,234 [run_pretraining.py:  512]:	********exe.run_346******* 
[INFO] 2021-07-12 18:34:34,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:34,157 [run_pretraining.py:  534]:	loss/total_loss, 9.275318145751953, 347
[INFO] 2021-07-12 18:34:34,157 [run_pretraining.py:  535]:	loss/mlm_loss, 9.275318145751953, 347
[INFO] 2021-07-12 18:34:34,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.460000016275444e-06, 347
[INFO] 2021-07-12 18:34:34,158 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 347
[INFO] 2021-07-12 18:34:34,158 [run_pretraining.py:  558]:	worker_index: 7, step: 347, cost: 9.275318, mlm loss: 9.275318, speed: 1.083436 steps/s, speed: 8.667487 samples/s, speed: 4437.753112 tokens/s, learning rate: 3.460e-06, loss_scalings: 20971.521484, pp_loss: 9.139981
[INFO] 2021-07-12 18:34:34,158 [run_pretraining.py:  512]:	********exe.run_347******* 
[INFO] 2021-07-12 18:34:35,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:35,082 [run_pretraining.py:  534]:	loss/total_loss, 9.083240509033203, 348
[INFO] 2021-07-12 18:34:35,082 [run_pretraining.py:  535]:	loss/mlm_loss, 9.083240509033203, 348
[INFO] 2021-07-12 18:34:35,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.469999683147762e-06, 348
[INFO] 2021-07-12 18:34:35,082 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 348
[INFO] 2021-07-12 18:34:35,082 [run_pretraining.py:  558]:	worker_index: 7, step: 348, cost: 9.083241, mlm loss: 9.083241, speed: 1.082185 steps/s, speed: 8.657481 samples/s, speed: 4432.630390 tokens/s, learning rate: 3.470e-06, loss_scalings: 20971.521484, pp_loss: 9.236568
[INFO] 2021-07-12 18:34:35,082 [run_pretraining.py:  512]:	********exe.run_348******* 
[INFO] 2021-07-12 18:34:36,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:36,001 [run_pretraining.py:  534]:	loss/total_loss, 9.268232345581055, 349
[INFO] 2021-07-12 18:34:36,001 [run_pretraining.py:  535]:	loss/mlm_loss, 9.268232345581055, 349
[INFO] 2021-07-12 18:34:36,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.480000032141106e-06, 349
[INFO] 2021-07-12 18:34:36,001 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 349
[INFO] 2021-07-12 18:34:36,001 [run_pretraining.py:  558]:	worker_index: 7, step: 349, cost: 9.268232, mlm loss: 9.268232, speed: 1.089353 steps/s, speed: 8.714823 samples/s, speed: 4461.989606 tokens/s, learning rate: 3.480e-06, loss_scalings: 20971.521484, pp_loss: 9.393181
[INFO] 2021-07-12 18:34:36,001 [run_pretraining.py:  512]:	********exe.run_349******* 
[INFO] 2021-07-12 18:34:36,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:36,921 [run_pretraining.py:  534]:	loss/total_loss, 9.554508209228516, 350
[INFO] 2021-07-12 18:34:36,921 [run_pretraining.py:  535]:	loss/mlm_loss, 9.554508209228516, 350
[INFO] 2021-07-12 18:34:36,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.489999699013424e-06, 350
[INFO] 2021-07-12 18:34:36,921 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 350
[INFO] 2021-07-12 18:34:36,921 [run_pretraining.py:  558]:	worker_index: 7, step: 350, cost: 9.554508, mlm loss: 9.554508, speed: 1.087624 steps/s, speed: 8.700989 samples/s, speed: 4454.906226 tokens/s, learning rate: 3.490e-06, loss_scalings: 20971.521484, pp_loss: 9.371808
[INFO] 2021-07-12 18:34:36,921 [run_pretraining.py:  512]:	********exe.run_350******* 
[INFO] 2021-07-12 18:34:37,841 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:37,841 [run_pretraining.py:  534]:	loss/total_loss, 9.202194213867188, 351
[INFO] 2021-07-12 18:34:37,841 [run_pretraining.py:  535]:	loss/mlm_loss, 9.202194213867188, 351
[INFO] 2021-07-12 18:34:37,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.499999820633093e-06, 351
[INFO] 2021-07-12 18:34:37,841 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 351
[INFO] 2021-07-12 18:34:37,841 [run_pretraining.py:  558]:	worker_index: 7, step: 351, cost: 9.202194, mlm loss: 9.202194, speed: 1.087251 steps/s, speed: 8.698009 samples/s, speed: 4453.380729 tokens/s, learning rate: 3.500e-06, loss_scalings: 20971.521484, pp_loss: 8.480734
[INFO] 2021-07-12 18:34:37,842 [run_pretraining.py:  512]:	********exe.run_351******* 
[INFO] 2021-07-12 18:34:38,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:38,770 [run_pretraining.py:  534]:	loss/total_loss, 8.936386108398438, 352
[INFO] 2021-07-12 18:34:38,770 [run_pretraining.py:  535]:	loss/mlm_loss, 8.936386108398438, 352
[INFO] 2021-07-12 18:34:38,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.510000169626437e-06, 352
[INFO] 2021-07-12 18:34:38,770 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 352
[INFO] 2021-07-12 18:34:38,770 [run_pretraining.py:  558]:	worker_index: 7, step: 352, cost: 8.936386, mlm loss: 8.936386, speed: 1.077179 steps/s, speed: 8.617433 samples/s, speed: 4412.125781 tokens/s, learning rate: 3.510e-06, loss_scalings: 20971.521484, pp_loss: 8.183315
[INFO] 2021-07-12 18:34:38,771 [run_pretraining.py:  512]:	********exe.run_352******* 
[INFO] 2021-07-12 18:34:39,697 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:39,697 [run_pretraining.py:  534]:	loss/total_loss, 8.966707229614258, 353
[INFO] 2021-07-12 18:34:39,697 [run_pretraining.py:  535]:	loss/mlm_loss, 8.966707229614258, 353
[INFO] 2021-07-12 18:34:39,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.519999836498755e-06, 353
[INFO] 2021-07-12 18:34:39,698 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 353
[INFO] 2021-07-12 18:34:39,698 [run_pretraining.py:  558]:	worker_index: 7, step: 353, cost: 8.966707, mlm loss: 8.966707, speed: 1.079267 steps/s, speed: 8.634133 samples/s, speed: 4420.675845 tokens/s, learning rate: 3.520e-06, loss_scalings: 20971.521484, pp_loss: 9.207468
[INFO] 2021-07-12 18:34:39,698 [run_pretraining.py:  512]:	********exe.run_353******* 
[INFO] 2021-07-12 18:34:40,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:40,624 [run_pretraining.py:  534]:	loss/total_loss, 9.39974594116211, 354
[INFO] 2021-07-12 18:34:40,624 [run_pretraining.py:  535]:	loss/mlm_loss, 9.39974594116211, 354
[INFO] 2021-07-12 18:34:40,624 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.529999958118424e-06, 354
[INFO] 2021-07-12 18:34:40,624 [run_pretraining.py:  539]:	lr/loss_scaling, 20971.521484375, 354
[INFO] 2021-07-12 18:34:40,624 [run_pretraining.py:  558]:	worker_index: 7, step: 354, cost: 9.399746, mlm loss: 9.399746, speed: 1.079909 steps/s, speed: 8.639272 samples/s, speed: 4423.307347 tokens/s, learning rate: 3.530e-06, loss_scalings: 20971.521484, pp_loss: 9.308174
[INFO] 2021-07-12 18:34:40,624 [run_pretraining.py:  512]:	********exe.run_354******* 
[INFO] 2021-07-12 18:34:41,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:41,542 [run_pretraining.py:  534]:	loss/total_loss, 9.031102180480957, 355
[INFO] 2021-07-12 18:34:41,542 [run_pretraining.py:  535]:	loss/mlm_loss, 9.031102180480957, 355
[INFO] 2021-07-12 18:34:41,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.539999852364417e-06, 355
[INFO] 2021-07-12 18:34:41,542 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 355
[INFO] 2021-07-12 18:34:41,542 [run_pretraining.py:  558]:	worker_index: 7, step: 355, cost: 9.031102, mlm loss: 9.031102, speed: 1.089923 steps/s, speed: 8.719384 samples/s, speed: 4464.324806 tokens/s, learning rate: 3.540e-06, loss_scalings: 16777.216797, pp_loss: 9.357267
[INFO] 2021-07-12 18:34:41,543 [run_pretraining.py:  512]:	********exe.run_355******* 
[INFO] 2021-07-12 18:34:42,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:42,506 [run_pretraining.py:  534]:	loss/total_loss, 9.407630920410156, 356
[INFO] 2021-07-12 18:34:42,506 [run_pretraining.py:  535]:	loss/mlm_loss, 9.407630920410156, 356
[INFO] 2021-07-12 18:34:42,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.549999973984086e-06, 356
[INFO] 2021-07-12 18:34:42,507 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 356
[INFO] 2021-07-12 18:34:42,507 [run_pretraining.py:  558]:	worker_index: 7, step: 356, cost: 9.407631, mlm loss: 9.407631, speed: 1.037900 steps/s, speed: 8.303197 samples/s, speed: 4251.236947 tokens/s, learning rate: 3.550e-06, loss_scalings: 16777.216797, pp_loss: 8.948139
[INFO] 2021-07-12 18:34:42,507 [run_pretraining.py:  512]:	********exe.run_356******* 
[INFO] 2021-07-12 18:34:43,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:43,436 [run_pretraining.py:  534]:	loss/total_loss, 5.43988037109375, 357
[INFO] 2021-07-12 18:34:43,436 [run_pretraining.py:  535]:	loss/mlm_loss, 5.43988037109375, 357
[INFO] 2021-07-12 18:34:43,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5599998682300793e-06, 357
[INFO] 2021-07-12 18:34:43,436 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 357
[INFO] 2021-07-12 18:34:43,436 [run_pretraining.py:  558]:	worker_index: 7, step: 357, cost: 5.439880, mlm loss: 5.439880, speed: 1.076651 steps/s, speed: 8.613210 samples/s, speed: 4409.963715 tokens/s, learning rate: 3.560e-06, loss_scalings: 16777.216797, pp_loss: 8.341303
[INFO] 2021-07-12 18:34:43,436 [run_pretraining.py:  512]:	********exe.run_357******* 
[INFO] 2021-07-12 18:34:44,363 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:44,363 [run_pretraining.py:  534]:	loss/total_loss, 9.264392852783203, 358
[INFO] 2021-07-12 18:34:44,363 [run_pretraining.py:  535]:	loss/mlm_loss, 9.264392852783203, 358
[INFO] 2021-07-12 18:34:44,363 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.569999989849748e-06, 358
[INFO] 2021-07-12 18:34:44,363 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 358
[INFO] 2021-07-12 18:34:44,364 [run_pretraining.py:  558]:	worker_index: 7, step: 358, cost: 9.264393, mlm loss: 9.264393, speed: 1.079016 steps/s, speed: 8.632125 samples/s, speed: 4419.647769 tokens/s, learning rate: 3.570e-06, loss_scalings: 16777.216797, pp_loss: 8.194832
[INFO] 2021-07-12 18:34:44,364 [run_pretraining.py:  512]:	********exe.run_358******* 
[INFO] 2021-07-12 18:34:45,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:45,283 [run_pretraining.py:  534]:	loss/total_loss, 9.449613571166992, 359
[INFO] 2021-07-12 18:34:45,283 [run_pretraining.py:  535]:	loss/mlm_loss, 9.449613571166992, 359
[INFO] 2021-07-12 18:34:45,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5799998840957414e-06, 359
[INFO] 2021-07-12 18:34:45,284 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 359
[INFO] 2021-07-12 18:34:45,284 [run_pretraining.py:  558]:	worker_index: 7, step: 359, cost: 9.449614, mlm loss: 9.449614, speed: 1.087565 steps/s, speed: 8.700519 samples/s, speed: 4454.665957 tokens/s, learning rate: 3.580e-06, loss_scalings: 16777.216797, pp_loss: 8.348647
[INFO] 2021-07-12 18:34:45,284 [run_pretraining.py:  512]:	********exe.run_359******* 
[INFO] 2021-07-12 18:34:46,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:46,207 [run_pretraining.py:  534]:	loss/total_loss, 9.14891242980957, 360
[INFO] 2021-07-12 18:34:46,207 [run_pretraining.py:  535]:	loss/mlm_loss, 9.14891242980957, 360
[INFO] 2021-07-12 18:34:46,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.5900000057154102e-06, 360
[INFO] 2021-07-12 18:34:46,207 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 360
[INFO] 2021-07-12 18:34:46,208 [run_pretraining.py:  558]:	worker_index: 7, step: 360, cost: 9.148912, mlm loss: 9.148912, speed: 1.083203 steps/s, speed: 8.665626 samples/s, speed: 4436.800723 tokens/s, learning rate: 3.590e-06, loss_scalings: 16777.216797, pp_loss: 9.190697
[INFO] 2021-07-12 18:34:46,208 [run_pretraining.py:  512]:	********exe.run_360******* 
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  534]:	loss/total_loss, 9.147485733032227, 361
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  535]:	loss/mlm_loss, 9.147485733032227, 361
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.599999672587728e-06, 361
[INFO] 2021-07-12 18:34:47,126 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 361
[INFO] 2021-07-12 18:34:47,127 [run_pretraining.py:  558]:	worker_index: 7, step: 361, cost: 9.147486, mlm loss: 9.147486, speed: 1.088976 steps/s, speed: 8.711805 samples/s, speed: 4460.444200 tokens/s, learning rate: 3.600e-06, loss_scalings: 16777.216797, pp_loss: 9.212612
[INFO] 2021-07-12 18:34:47,127 [run_pretraining.py:  512]:	********exe.run_361******* 
[INFO] 2021-07-12 18:34:48,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:48,057 [run_pretraining.py:  534]:	loss/total_loss, 9.07883358001709, 362
[INFO] 2021-07-12 18:34:48,057 [run_pretraining.py:  535]:	loss/mlm_loss, 9.07883358001709, 362
[INFO] 2021-07-12 18:34:48,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6100000215810724e-06, 362
[INFO] 2021-07-12 18:34:48,057 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 362
[INFO] 2021-07-12 18:34:48,057 [run_pretraining.py:  558]:	worker_index: 7, step: 362, cost: 9.078834, mlm loss: 9.078834, speed: 1.075034 steps/s, speed: 8.600276 samples/s, speed: 4403.341230 tokens/s, learning rate: 3.610e-06, loss_scalings: 16777.216797, pp_loss: 9.147944
[INFO] 2021-07-12 18:34:48,057 [run_pretraining.py:  512]:	********exe.run_362******* 
[INFO] 2021-07-12 18:34:48,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:48,972 [run_pretraining.py:  534]:	loss/total_loss, 9.361971855163574, 363
[INFO] 2021-07-12 18:34:48,972 [run_pretraining.py:  535]:	loss/mlm_loss, 9.361971855163574, 363
[INFO] 2021-07-12 18:34:48,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.620000143200741e-06, 363
[INFO] 2021-07-12 18:34:48,972 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 363
[INFO] 2021-07-12 18:34:48,972 [run_pretraining.py:  558]:	worker_index: 7, step: 363, cost: 9.361972, mlm loss: 9.361972, speed: 1.093638 steps/s, speed: 8.749106 samples/s, speed: 4479.542359 tokens/s, learning rate: 3.620e-06, loss_scalings: 16777.216797, pp_loss: 9.267061
[INFO] 2021-07-12 18:34:48,972 [run_pretraining.py:  512]:	********exe.run_363******* 
[INFO] 2021-07-12 18:34:49,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:49,896 [run_pretraining.py:  534]:	loss/total_loss, 9.21682071685791, 364
[INFO] 2021-07-12 18:34:49,896 [run_pretraining.py:  535]:	loss/mlm_loss, 9.21682071685791, 364
[INFO] 2021-07-12 18:34:49,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.629999810073059e-06, 364
[INFO] 2021-07-12 18:34:49,896 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 364
[INFO] 2021-07-12 18:34:49,896 [run_pretraining.py:  558]:	worker_index: 7, step: 364, cost: 9.216821, mlm loss: 9.216821, speed: 1.083042 steps/s, speed: 8.664333 samples/s, speed: 4436.138533 tokens/s, learning rate: 3.630e-06, loss_scalings: 16777.216797, pp_loss: 9.187336
[INFO] 2021-07-12 18:34:49,896 [run_pretraining.py:  512]:	********exe.run_364******* 
[INFO] 2021-07-12 18:34:50,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:50,816 [run_pretraining.py:  534]:	loss/total_loss, 4.938871383666992, 365
[INFO] 2021-07-12 18:34:50,816 [run_pretraining.py:  535]:	loss/mlm_loss, 4.938871383666992, 365
[INFO] 2021-07-12 18:34:50,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6400001590664033e-06, 365
[INFO] 2021-07-12 18:34:50,816 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 365
[INFO] 2021-07-12 18:34:50,816 [run_pretraining.py:  558]:	worker_index: 7, step: 365, cost: 4.938871, mlm loss: 4.938871, speed: 1.087854 steps/s, speed: 8.702830 samples/s, speed: 4455.849069 tokens/s, learning rate: 3.640e-06, loss_scalings: 16777.216797, pp_loss: 8.159378
[INFO] 2021-07-12 18:34:50,816 [run_pretraining.py:  512]:	********exe.run_365******* 
[INFO] 2021-07-12 18:34:51,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:51,748 [run_pretraining.py:  534]:	loss/total_loss, 9.29775333404541, 366
[INFO] 2021-07-12 18:34:51,748 [run_pretraining.py:  535]:	loss/mlm_loss, 9.29775333404541, 366
[INFO] 2021-07-12 18:34:51,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.649999825938721e-06, 366
[INFO] 2021-07-12 18:34:51,748 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 366
[INFO] 2021-07-12 18:34:51,748 [run_pretraining.py:  558]:	worker_index: 7, step: 366, cost: 9.297753, mlm loss: 9.297753, speed: 1.073886 steps/s, speed: 8.591091 samples/s, speed: 4398.638814 tokens/s, learning rate: 3.650e-06, loss_scalings: 16777.216797, pp_loss: 9.255394
[INFO] 2021-07-12 18:34:51,748 [run_pretraining.py:  512]:	********exe.run_366******* 
[INFO] 2021-07-12 18:34:52,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:52,685 [run_pretraining.py:  534]:	loss/total_loss, 9.805840492248535, 367
[INFO] 2021-07-12 18:34:52,685 [run_pretraining.py:  535]:	loss/mlm_loss, 9.805840492248535, 367
[INFO] 2021-07-12 18:34:52,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.65999994755839e-06, 367
[INFO] 2021-07-12 18:34:52,685 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 367
[INFO] 2021-07-12 18:34:52,685 [run_pretraining.py:  558]:	worker_index: 7, step: 367, cost: 9.805840, mlm loss: 9.805840, speed: 1.068267 steps/s, speed: 8.546132 samples/s, speed: 4375.619814 tokens/s, learning rate: 3.660e-06, loss_scalings: 16777.216797, pp_loss: 9.358010
[INFO] 2021-07-12 18:34:52,685 [run_pretraining.py:  512]:	********exe.run_367******* 
[INFO] 2021-07-12 18:34:53,608 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:34:53,609 [run_pretraining.py:  534]:	loss/total_loss, 8.986156463623047, 368
[INFO] 2021-07-12 18:34:53,609 [run_pretraining.py:  535]:	loss/mlm_loss, 8.986156463623047, 368
[INFO] 2021-07-12 18:34:53,609 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6699998418043833e-06, 368
[INFO] 2021-07-12 18:34:53,609 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 368
[INFO] 2021-07-12 18:34:53,609 [run_pretraining.py:  558]:	worker_index: 7, step: 368, cost: 8.986156, mlm loss: 8.986156, speed: 1.082458 steps/s, speed: 8.659666 samples/s, speed: 4433.749188 tokens/s, learning rate: 3.670e-06, loss_scalings: 16777.216797, pp_loss: 9.155811
[INFO] 2021-07-12 18:34:53,609 [run_pretraining.py:  512]:	********exe.run_368******* 
[INFO] 2021-07-12 18:35:19,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:19,234 [run_pretraining.py:  534]:	loss/total_loss, 9.406429290771484, 369
[INFO] 2021-07-12 18:35:19,235 [run_pretraining.py:  535]:	loss/mlm_loss, 9.406429290771484, 369
[INFO] 2021-07-12 18:35:19,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.679999963424052e-06, 369
[INFO] 2021-07-12 18:35:19,235 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 369
[INFO] 2021-07-12 18:35:19,235 [run_pretraining.py:  558]:	worker_index: 7, step: 369, cost: 9.406429, mlm loss: 9.406429, speed: 0.039025 steps/s, speed: 0.312198 samples/s, speed: 159.845428 tokens/s, learning rate: 3.680e-06, loss_scalings: 16777.216797, pp_loss: 9.215910
[INFO] 2021-07-12 18:35:19,235 [run_pretraining.py:  512]:	********exe.run_369******* 
[INFO] 2021-07-12 18:35:20,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:20,168 [run_pretraining.py:  534]:	loss/total_loss, 9.039365768432617, 370
[INFO] 2021-07-12 18:35:20,168 [run_pretraining.py:  535]:	loss/mlm_loss, 9.039365768432617, 370
[INFO] 2021-07-12 18:35:20,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6899998576700455e-06, 370
[INFO] 2021-07-12 18:35:20,168 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 370
[INFO] 2021-07-12 18:35:20,168 [run_pretraining.py:  558]:	worker_index: 7, step: 370, cost: 9.039366, mlm loss: 9.039366, speed: 1.071898 steps/s, speed: 8.575180 samples/s, speed: 4390.492335 tokens/s, learning rate: 3.690e-06, loss_scalings: 16777.216797, pp_loss: 9.288270
[INFO] 2021-07-12 18:35:20,168 [run_pretraining.py:  512]:	********exe.run_370******* 
[INFO] 2021-07-12 18:35:21,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:21,087 [run_pretraining.py:  534]:	loss/total_loss, 9.420644760131836, 371
[INFO] 2021-07-12 18:35:21,087 [run_pretraining.py:  535]:	loss/mlm_loss, 9.420644760131836, 371
[INFO] 2021-07-12 18:35:21,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.6999999792897142e-06, 371
[INFO] 2021-07-12 18:35:21,087 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 371
[INFO] 2021-07-12 18:35:21,087 [run_pretraining.py:  558]:	worker_index: 7, step: 371, cost: 9.420645, mlm loss: 9.420645, speed: 1.089254 steps/s, speed: 8.714036 samples/s, speed: 4461.586354 tokens/s, learning rate: 3.700e-06, loss_scalings: 16777.216797, pp_loss: 8.681991
[INFO] 2021-07-12 18:35:21,087 [run_pretraining.py:  512]:	********exe.run_371******* 
[INFO] 2021-07-12 18:35:22,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:22,007 [run_pretraining.py:  534]:	loss/total_loss, 9.539443016052246, 372
[INFO] 2021-07-12 18:35:22,007 [run_pretraining.py:  535]:	loss/mlm_loss, 9.539443016052246, 372
[INFO] 2021-07-12 18:35:22,007 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.709999646162032e-06, 372
[INFO] 2021-07-12 18:35:22,007 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 372
[INFO] 2021-07-12 18:35:22,007 [run_pretraining.py:  558]:	worker_index: 7, step: 372, cost: 9.539443, mlm loss: 9.539443, speed: 1.087700 steps/s, speed: 8.701600 samples/s, speed: 4455.219307 tokens/s, learning rate: 3.710e-06, loss_scalings: 16777.216797, pp_loss: 9.377998
[INFO] 2021-07-12 18:35:22,007 [run_pretraining.py:  512]:	********exe.run_372******* 
[INFO] 2021-07-12 18:35:22,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:22,932 [run_pretraining.py:  534]:	loss/total_loss, 9.304256439208984, 373
[INFO] 2021-07-12 18:35:22,932 [run_pretraining.py:  535]:	loss/mlm_loss, 9.304256439208984, 373
[INFO] 2021-07-12 18:35:22,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7199999951553764e-06, 373
[INFO] 2021-07-12 18:35:22,932 [run_pretraining.py:  539]:	lr/loss_scaling, 16777.216796875, 373
[INFO] 2021-07-12 18:35:22,932 [run_pretraining.py:  558]:	worker_index: 7, step: 373, cost: 9.304256, mlm loss: 9.304256, speed: 1.081556 steps/s, speed: 8.652452 samples/s, speed: 4430.055184 tokens/s, learning rate: 3.720e-06, loss_scalings: 16777.216797, pp_loss: 9.017862
[INFO] 2021-07-12 18:35:22,932 [run_pretraining.py:  512]:	********exe.run_373******* 
[INFO] 2021-07-12 18:35:23,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:23,852 [run_pretraining.py:  534]:	loss/total_loss, 9.22368049621582, 374
[INFO] 2021-07-12 18:35:23,852 [run_pretraining.py:  535]:	loss/mlm_loss, 9.22368049621582, 374
[INFO] 2021-07-12 18:35:23,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.730000116775045e-06, 374
[INFO] 2021-07-12 18:35:23,852 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 374
[INFO] 2021-07-12 18:35:23,852 [run_pretraining.py:  558]:	worker_index: 7, step: 374, cost: 9.223680, mlm loss: 9.223680, speed: 1.087587 steps/s, speed: 8.700693 samples/s, speed: 4454.754899 tokens/s, learning rate: 3.730e-06, loss_scalings: 13421.773438, pp_loss: 8.191935
[INFO] 2021-07-12 18:35:23,853 [run_pretraining.py:  512]:	********exe.run_374******* 
[INFO] 2021-07-12 18:35:24,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:24,771 [run_pretraining.py:  534]:	loss/total_loss, 9.17812728881836, 375
[INFO] 2021-07-12 18:35:24,771 [run_pretraining.py:  535]:	loss/mlm_loss, 9.17812728881836, 375
[INFO] 2021-07-12 18:35:24,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.739999783647363e-06, 375
[INFO] 2021-07-12 18:35:24,771 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 375
[INFO] 2021-07-12 18:35:24,771 [run_pretraining.py:  558]:	worker_index: 7, step: 375, cost: 9.178127, mlm loss: 9.178127, speed: 1.088953 steps/s, speed: 8.711626 samples/s, speed: 4460.352714 tokens/s, learning rate: 3.740e-06, loss_scalings: 13421.773438, pp_loss: 9.313100
[INFO] 2021-07-12 18:35:24,772 [run_pretraining.py:  512]:	********exe.run_375******* 
[INFO] 2021-07-12 18:35:25,701 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:25,701 [run_pretraining.py:  534]:	loss/total_loss, 9.285602569580078, 376
[INFO] 2021-07-12 18:35:25,702 [run_pretraining.py:  535]:	loss/mlm_loss, 9.285602569580078, 376
[INFO] 2021-07-12 18:35:25,702 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7500001326407073e-06, 376
[INFO] 2021-07-12 18:35:25,702 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 376
[INFO] 2021-07-12 18:35:25,702 [run_pretraining.py:  558]:	worker_index: 7, step: 376, cost: 9.285603, mlm loss: 9.285603, speed: 1.075616 steps/s, speed: 8.604927 samples/s, speed: 4405.722760 tokens/s, learning rate: 3.750e-06, loss_scalings: 13421.773438, pp_loss: 8.257447
[INFO] 2021-07-12 18:35:25,702 [run_pretraining.py:  512]:	********exe.run_376******* 
[INFO] 2021-07-12 18:35:26,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  534]:	loss/total_loss, 9.556209564208984, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  535]:	loss/mlm_loss, 9.556209564208984, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.759999799513025e-06, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 377
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  558]:	worker_index: 7, step: 377, cost: 9.556210, mlm loss: 9.556210, speed: 1.090863 steps/s, speed: 8.726904 samples/s, speed: 4468.174982 tokens/s, learning rate: 3.760e-06, loss_scalings: 13421.773438, pp_loss: 9.251725
[INFO] 2021-07-12 18:35:26,619 [run_pretraining.py:  512]:	********exe.run_377******* 
[INFO] 2021-07-12 18:35:53,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:53,332 [run_pretraining.py:  534]:	loss/total_loss, 9.168379783630371, 378
[INFO] 2021-07-12 18:35:53,332 [run_pretraining.py:  535]:	loss/mlm_loss, 9.168379783630371, 378
[INFO] 2021-07-12 18:35:53,332 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.769999921132694e-06, 378
[INFO] 2021-07-12 18:35:53,332 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 378
[INFO] 2021-07-12 18:35:53,332 [run_pretraining.py:  558]:	worker_index: 7, step: 378, cost: 9.168380, mlm loss: 9.168380, speed: 0.037436 steps/s, speed: 0.299486 samples/s, speed: 153.336789 tokens/s, learning rate: 3.770e-06, loss_scalings: 13421.773438, pp_loss: 9.196921
[INFO] 2021-07-12 18:35:53,332 [run_pretraining.py:  512]:	********exe.run_378******* 
[INFO] 2021-07-12 18:35:54,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:54,252 [run_pretraining.py:  534]:	loss/total_loss, 9.506810188293457, 379
[INFO] 2021-07-12 18:35:54,252 [run_pretraining.py:  535]:	loss/mlm_loss, 9.506810188293457, 379
[INFO] 2021-07-12 18:35:54,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7799998153786873e-06, 379
[INFO] 2021-07-12 18:35:54,252 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 379
[INFO] 2021-07-12 18:35:54,252 [run_pretraining.py:  558]:	worker_index: 7, step: 379, cost: 9.506810, mlm loss: 9.506810, speed: 1.088078 steps/s, speed: 8.704627 samples/s, speed: 4456.769187 tokens/s, learning rate: 3.780e-06, loss_scalings: 13421.773438, pp_loss: 9.411842
[INFO] 2021-07-12 18:35:54,252 [run_pretraining.py:  512]:	********exe.run_379******* 
[INFO] 2021-07-12 18:35:55,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:55,176 [run_pretraining.py:  534]:	loss/total_loss, 9.163180351257324, 380
[INFO] 2021-07-12 18:35:55,176 [run_pretraining.py:  535]:	loss/mlm_loss, 9.163180351257324, 380
[INFO] 2021-07-12 18:35:55,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.789999936998356e-06, 380
[INFO] 2021-07-12 18:35:55,176 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 380
[INFO] 2021-07-12 18:35:55,176 [run_pretraining.py:  558]:	worker_index: 7, step: 380, cost: 9.163180, mlm loss: 9.163180, speed: 1.082854 steps/s, speed: 8.662834 samples/s, speed: 4435.371189 tokens/s, learning rate: 3.790e-06, loss_scalings: 13421.773438, pp_loss: 9.086934
[INFO] 2021-07-12 18:35:55,176 [run_pretraining.py:  512]:	********exe.run_380******* 
[INFO] 2021-07-12 18:35:56,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:56,224 [run_pretraining.py:  534]:	loss/total_loss, 9.648990631103516, 381
[INFO] 2021-07-12 18:35:56,229 [run_pretraining.py:  535]:	loss/mlm_loss, 9.648990631103516, 381
[INFO] 2021-07-12 18:35:56,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.7999998312443495e-06, 381
[INFO] 2021-07-12 18:35:56,240 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 381
[INFO] 2021-07-12 18:35:56,245 [run_pretraining.py:  558]:	worker_index: 7, step: 381, cost: 9.648991, mlm loss: 9.648991, speed: 0.954513 steps/s, speed: 7.636104 samples/s, speed: 3909.685394 tokens/s, learning rate: 3.800e-06, loss_scalings: 13421.773438, pp_loss: 8.242603
[INFO] 2021-07-12 18:35:56,250 [run_pretraining.py:  512]:	********exe.run_381******* 
[INFO] 2021-07-12 18:35:57,152 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:57,152 [run_pretraining.py:  534]:	loss/total_loss, 9.268436431884766, 382
[INFO] 2021-07-12 18:35:57,153 [run_pretraining.py:  535]:	loss/mlm_loss, 9.268436431884766, 382
[INFO] 2021-07-12 18:35:57,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.8099999528640183e-06, 382
[INFO] 2021-07-12 18:35:57,153 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 382
[INFO] 2021-07-12 18:35:57,153 [run_pretraining.py:  558]:	worker_index: 7, step: 382, cost: 9.268436, mlm loss: 9.268436, speed: 1.108669 steps/s, speed: 8.869356 samples/s, speed: 4541.110229 tokens/s, learning rate: 3.810e-06, loss_scalings: 13421.773438, pp_loss: 8.033154
[INFO] 2021-07-12 18:35:57,153 [run_pretraining.py:  512]:	********exe.run_382******* 
[INFO] 2021-07-12 18:35:58,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:58,060 [run_pretraining.py:  534]:	loss/total_loss, 9.155561447143555, 383
[INFO] 2021-07-12 18:35:58,061 [run_pretraining.py:  535]:	loss/mlm_loss, 9.155561447143555, 383
[INFO] 2021-07-12 18:35:58,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.819999619736336e-06, 383
[INFO] 2021-07-12 18:35:58,061 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 383
[INFO] 2021-07-12 18:35:58,061 [run_pretraining.py:  558]:	worker_index: 7, step: 383, cost: 9.155561, mlm loss: 9.155561, speed: 1.102106 steps/s, speed: 8.816844 samples/s, speed: 4514.224299 tokens/s, learning rate: 3.820e-06, loss_scalings: 13421.773438, pp_loss: 9.130678
[INFO] 2021-07-12 18:35:58,061 [run_pretraining.py:  512]:	********exe.run_383******* 
[INFO] 2021-07-12 18:35:58,966 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:58,967 [run_pretraining.py:  534]:	loss/total_loss, 9.449010848999023, 384
[INFO] 2021-07-12 18:35:58,967 [run_pretraining.py:  535]:	loss/mlm_loss, 9.449010848999023, 384
[INFO] 2021-07-12 18:35:58,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.82999996872968e-06, 384
[INFO] 2021-07-12 18:35:58,967 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 384
[INFO] 2021-07-12 18:35:58,967 [run_pretraining.py:  558]:	worker_index: 7, step: 384, cost: 9.449011, mlm loss: 9.449011, speed: 1.104128 steps/s, speed: 8.833024 samples/s, speed: 4522.508254 tokens/s, learning rate: 3.830e-06, loss_scalings: 13421.773438, pp_loss: 9.121281
[INFO] 2021-07-12 18:35:58,967 [run_pretraining.py:  512]:	********exe.run_384******* 
[INFO] 2021-07-12 18:35:59,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:35:59,875 [run_pretraining.py:  534]:	loss/total_loss, 8.994617462158203, 385
[INFO] 2021-07-12 18:35:59,875 [run_pretraining.py:  535]:	loss/mlm_loss, 8.994617462158203, 385
[INFO] 2021-07-12 18:35:59,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.839999862975674e-06, 385
[INFO] 2021-07-12 18:35:59,875 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 385
[INFO] 2021-07-12 18:35:59,875 [run_pretraining.py:  558]:	worker_index: 7, step: 385, cost: 8.994617, mlm loss: 8.994617, speed: 1.102177 steps/s, speed: 8.817417 samples/s, speed: 4514.517301 tokens/s, learning rate: 3.840e-06, loss_scalings: 13421.773438, pp_loss: 9.251518
[INFO] 2021-07-12 18:35:59,875 [run_pretraining.py:  512]:	********exe.run_385******* 
[INFO] 2021-07-12 18:36:25,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:25,759 [run_pretraining.py:  534]:	loss/total_loss, 9.160826683044434, 386
[INFO] 2021-07-12 18:36:25,759 [run_pretraining.py:  535]:	loss/mlm_loss, 9.160826683044434, 386
[INFO] 2021-07-12 18:36:25,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.849999757221667e-06, 386
[INFO] 2021-07-12 18:36:25,759 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 386
[INFO] 2021-07-12 18:36:25,759 [run_pretraining.py:  558]:	worker_index: 7, step: 386, cost: 9.160827, mlm loss: 9.160827, speed: 0.038635 steps/s, speed: 0.309078 samples/s, speed: 158.248103 tokens/s, learning rate: 3.850e-06, loss_scalings: 13421.773438, pp_loss: 9.163484
[INFO] 2021-07-12 18:36:25,759 [run_pretraining.py:  512]:	********exe.run_386******* 
[INFO] 2021-07-12 18:36:26,665 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:26,665 [run_pretraining.py:  534]:	loss/total_loss, 9.524308204650879, 387
[INFO] 2021-07-12 18:36:26,665 [run_pretraining.py:  535]:	loss/mlm_loss, 9.524308204650879, 387
[INFO] 2021-07-12 18:36:26,666 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.860000106215011e-06, 387
[INFO] 2021-07-12 18:36:26,666 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 387
[INFO] 2021-07-12 18:36:26,666 [run_pretraining.py:  558]:	worker_index: 7, step: 387, cost: 9.524308, mlm loss: 9.524308, speed: 1.103791 steps/s, speed: 8.830325 samples/s, speed: 4521.126475 tokens/s, learning rate: 3.860e-06, loss_scalings: 13421.773438, pp_loss: 9.391290
[INFO] 2021-07-12 18:36:26,666 [run_pretraining.py:  512]:	********exe.run_387******* 
[INFO] 2021-07-12 18:36:27,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:27,574 [run_pretraining.py:  534]:	loss/total_loss, 9.245068550109863, 388
[INFO] 2021-07-12 18:36:27,574 [run_pretraining.py:  535]:	loss/mlm_loss, 9.245068550109863, 388
[INFO] 2021-07-12 18:36:27,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.870000000461005e-06, 388
[INFO] 2021-07-12 18:36:27,574 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 388
[INFO] 2021-07-12 18:36:27,575 [run_pretraining.py:  558]:	worker_index: 7, step: 388, cost: 9.245069, mlm loss: 9.245069, speed: 1.101091 steps/s, speed: 8.808732 samples/s, speed: 4510.070603 tokens/s, learning rate: 3.870e-06, loss_scalings: 13421.773438, pp_loss: 8.288728
[INFO] 2021-07-12 18:36:27,575 [run_pretraining.py:  512]:	********exe.run_388******* 
[INFO] 2021-07-12 18:36:28,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:28,492 [run_pretraining.py:  534]:	loss/total_loss, 9.39598560333252, 389
[INFO] 2021-07-12 18:36:28,492 [run_pretraining.py:  535]:	loss/mlm_loss, 9.39598560333252, 389
[INFO] 2021-07-12 18:36:28,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.879999894706998e-06, 389
[INFO] 2021-07-12 18:36:28,492 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 389
[INFO] 2021-07-12 18:36:28,492 [run_pretraining.py:  558]:	worker_index: 7, step: 389, cost: 9.395986, mlm loss: 9.395986, speed: 1.090950 steps/s, speed: 8.727601 samples/s, speed: 4468.531773 tokens/s, learning rate: 3.880e-06, loss_scalings: 13421.773438, pp_loss: 8.873228
[INFO] 2021-07-12 18:36:28,492 [run_pretraining.py:  512]:	********exe.run_389******* 
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:29,405 [run_pretraining.py:  534]:	loss/total_loss, 9.466984748840332, 390
[INFO] 2021-07-12 18:36:29,406 [run_pretraining.py:  535]:	loss/mlm_loss, 9.466984748840332, 390
[INFO] 2021-07-12 18:36:29,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.889999788952991e-06, 390
[INFO] 2021-07-12 18:36:29,406 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 390
[INFO] 2021-07-12 18:36:29,406 [run_pretraining.py:  558]:	worker_index: 7, step: 390, cost: 9.466985, mlm loss: 9.466985, speed: 1.094985 steps/s, speed: 8.759878 samples/s, speed: 4485.057487 tokens/s, learning rate: 3.890e-06, loss_scalings: 13421.773438, pp_loss: 9.395379
[INFO] 2021-07-12 18:36:29,406 [run_pretraining.py:  512]:	********exe.run_390******* 
[INFO] 2021-07-12 18:36:30,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:30,317 [run_pretraining.py:  534]:	loss/total_loss, 9.007736206054688, 391
[INFO] 2021-07-12 18:36:30,317 [run_pretraining.py:  535]:	loss/mlm_loss, 9.007736206054688, 391
[INFO] 2021-07-12 18:36:30,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.900000137946336e-06, 391
[INFO] 2021-07-12 18:36:30,317 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 391
[INFO] 2021-07-12 18:36:30,317 [run_pretraining.py:  558]:	worker_index: 7, step: 391, cost: 9.007736, mlm loss: 9.007736, speed: 1.098432 steps/s, speed: 8.787460 samples/s, speed: 4499.179426 tokens/s, learning rate: 3.900e-06, loss_scalings: 13421.773438, pp_loss: 9.271606
[INFO] 2021-07-12 18:36:30,317 [run_pretraining.py:  512]:	********exe.run_391******* 
[INFO] 2021-07-12 18:36:31,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:31,229 [run_pretraining.py:  534]:	loss/total_loss, 9.37279224395752, 392
[INFO] 2021-07-12 18:36:31,229 [run_pretraining.py:  535]:	loss/mlm_loss, 9.37279224395752, 392
[INFO] 2021-07-12 18:36:31,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.909999577444978e-06, 392
[INFO] 2021-07-12 18:36:31,229 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 392
[INFO] 2021-07-12 18:36:31,229 [run_pretraining.py:  558]:	worker_index: 7, step: 392, cost: 9.372792, mlm loss: 9.372792, speed: 1.096542 steps/s, speed: 8.772336 samples/s, speed: 4491.436189 tokens/s, learning rate: 3.910e-06, loss_scalings: 13421.773438, pp_loss: 9.395067
[INFO] 2021-07-12 18:36:31,230 [run_pretraining.py:  512]:	********exe.run_392******* 
[INFO] 2021-07-12 18:36:32,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:32,143 [run_pretraining.py:  534]:	loss/total_loss, 9.30605697631836, 393
[INFO] 2021-07-12 18:36:32,143 [run_pretraining.py:  535]:	loss/mlm_loss, 9.30605697631836, 393
[INFO] 2021-07-12 18:36:32,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.919999926438322e-06, 393
[INFO] 2021-07-12 18:36:32,143 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 393
[INFO] 2021-07-12 18:36:32,143 [run_pretraining.py:  558]:	worker_index: 7, step: 393, cost: 9.306057, mlm loss: 9.306057, speed: 1.095418 steps/s, speed: 8.763342 samples/s, speed: 4486.830916 tokens/s, learning rate: 3.920e-06, loss_scalings: 13421.773438, pp_loss: 9.134264
[INFO] 2021-07-12 18:36:32,143 [run_pretraining.py:  512]:	********exe.run_393******* 
[INFO] 2021-07-12 18:36:33,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:33,052 [run_pretraining.py:  534]:	loss/total_loss, 9.436188697814941, 394
[INFO] 2021-07-12 18:36:33,052 [run_pretraining.py:  535]:	loss/mlm_loss, 9.436188697814941, 394
[INFO] 2021-07-12 18:36:33,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.929999820684316e-06, 394
[INFO] 2021-07-12 18:36:33,052 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 394
[INFO] 2021-07-12 18:36:33,052 [run_pretraining.py:  558]:	worker_index: 7, step: 394, cost: 9.436189, mlm loss: 9.436189, speed: 1.100925 steps/s, speed: 8.807400 samples/s, speed: 4509.388730 tokens/s, learning rate: 3.930e-06, loss_scalings: 13421.773438, pp_loss: 9.252904
[INFO] 2021-07-12 18:36:33,052 [run_pretraining.py:  512]:	********exe.run_394******* 
[INFO] 2021-07-12 18:36:33,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  534]:	loss/total_loss, 9.30029582977295, 395
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  535]:	loss/mlm_loss, 9.30029582977295, 395
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.939999714930309e-06, 395
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 395
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  558]:	worker_index: 7, step: 395, cost: 9.300296, mlm loss: 9.300296, speed: 1.100885 steps/s, speed: 8.807083 samples/s, speed: 4509.226579 tokens/s, learning rate: 3.940e-06, loss_scalings: 13421.773438, pp_loss: 9.155118
[INFO] 2021-07-12 18:36:33,961 [run_pretraining.py:  512]:	********exe.run_395******* 
[INFO] 2021-07-12 18:36:34,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:34,869 [run_pretraining.py:  534]:	loss/total_loss, 8.926714897155762, 396
[INFO] 2021-07-12 18:36:34,869 [run_pretraining.py:  535]:	loss/mlm_loss, 8.926714897155762, 396
[INFO] 2021-07-12 18:36:34,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.950000063923653e-06, 396
[INFO] 2021-07-12 18:36:34,869 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 396
[INFO] 2021-07-12 18:36:34,869 [run_pretraining.py:  558]:	worker_index: 7, step: 396, cost: 8.926715, mlm loss: 8.926715, speed: 1.102141 steps/s, speed: 8.817127 samples/s, speed: 4514.369016 tokens/s, learning rate: 3.950e-06, loss_scalings: 13421.773438, pp_loss: 9.201919
[INFO] 2021-07-12 18:36:34,869 [run_pretraining.py:  512]:	********exe.run_396******* 
[INFO] 2021-07-12 18:36:35,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:35,776 [run_pretraining.py:  534]:	loss/total_loss, 9.000275611877441, 397
[INFO] 2021-07-12 18:36:35,776 [run_pretraining.py:  535]:	loss/mlm_loss, 9.000275611877441, 397
[INFO] 2021-07-12 18:36:35,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9599999581696466e-06, 397
[INFO] 2021-07-12 18:36:35,777 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 397
[INFO] 2021-07-12 18:36:35,777 [run_pretraining.py:  558]:	worker_index: 7, step: 397, cost: 9.000276, mlm loss: 9.000276, speed: 1.102541 steps/s, speed: 8.820325 samples/s, speed: 4516.006627 tokens/s, learning rate: 3.960e-06, loss_scalings: 13421.773438, pp_loss: 9.139998
[INFO] 2021-07-12 18:36:35,777 [run_pretraining.py:  512]:	********exe.run_397******* 
[INFO] 2021-07-12 18:36:36,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:36,686 [run_pretraining.py:  534]:	loss/total_loss, 8.97409439086914, 398
[INFO] 2021-07-12 18:36:36,687 [run_pretraining.py:  535]:	loss/mlm_loss, 8.97409439086914, 398
[INFO] 2021-07-12 18:36:36,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.96999985241564e-06, 398
[INFO] 2021-07-12 18:36:36,687 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 398
[INFO] 2021-07-12 18:36:36,687 [run_pretraining.py:  558]:	worker_index: 7, step: 398, cost: 8.974094, mlm loss: 8.974094, speed: 1.099447 steps/s, speed: 8.795579 samples/s, speed: 4503.336684 tokens/s, learning rate: 3.970e-06, loss_scalings: 13421.773438, pp_loss: 9.043285
[INFO] 2021-07-12 18:36:36,687 [run_pretraining.py:  512]:	********exe.run_398******* 
[INFO] 2021-07-12 18:36:37,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  534]:	loss/total_loss, 8.861536979675293, 399
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  535]:	loss/mlm_loss, 8.861536979675293, 399
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.979999746661633e-06, 399
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 399
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  558]:	worker_index: 7, step: 399, cost: 8.861537, mlm loss: 8.861537, speed: 1.097001 steps/s, speed: 8.776005 samples/s, speed: 4493.314557 tokens/s, learning rate: 3.980e-06, loss_scalings: 13421.773438, pp_loss: 9.157417
[INFO] 2021-07-12 18:36:37,599 [run_pretraining.py:  512]:	********exe.run_399******* 
[INFO] 2021-07-12 18:36:38,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:38,511 [run_pretraining.py:  534]:	loss/total_loss, 9.536588668823242, 400
[INFO] 2021-07-12 18:36:38,511 [run_pretraining.py:  535]:	loss/mlm_loss, 9.536588668823242, 400
[INFO] 2021-07-12 18:36:38,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.9900000956549775e-06, 400
[INFO] 2021-07-12 18:36:38,511 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 400
[INFO] 2021-07-12 18:36:38,511 [run_pretraining.py:  558]:	worker_index: 7, step: 400, cost: 9.536589, mlm loss: 9.536589, speed: 1.097247 steps/s, speed: 8.777977 samples/s, speed: 4494.324285 tokens/s, learning rate: 3.990e-06, loss_scalings: 13421.773438, pp_loss: 8.750759
[INFO] 2021-07-12 18:36:38,511 [run_pretraining.py:  512]:	********exe.run_400******* 
[INFO] 2021-07-12 18:36:39,421 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:39,421 [run_pretraining.py:  534]:	loss/total_loss, 8.797285079956055, 401
[INFO] 2021-07-12 18:36:39,421 [run_pretraining.py:  535]:	loss/mlm_loss, 8.797285079956055, 401
[INFO] 2021-07-12 18:36:39,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 3.999999989900971e-06, 401
[INFO] 2021-07-12 18:36:39,421 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 401
[INFO] 2021-07-12 18:36:39,421 [run_pretraining.py:  558]:	worker_index: 7, step: 401, cost: 8.797285, mlm loss: 8.797285, speed: 1.099319 steps/s, speed: 8.794554 samples/s, speed: 4502.811444 tokens/s, learning rate: 4.000e-06, loss_scalings: 13421.773438, pp_loss: 9.089346
[INFO] 2021-07-12 18:36:39,421 [run_pretraining.py:  512]:	********exe.run_401******* 
[INFO] 2021-07-12 18:36:40,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:40,336 [run_pretraining.py:  534]:	loss/total_loss, 9.124776840209961, 402
[INFO] 2021-07-12 18:36:40,336 [run_pretraining.py:  535]:	loss/mlm_loss, 9.124776840209961, 402
[INFO] 2021-07-12 18:36:40,336 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.009999884146964e-06, 402
[INFO] 2021-07-12 18:36:40,336 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 402
[INFO] 2021-07-12 18:36:40,336 [run_pretraining.py:  558]:	worker_index: 7, step: 402, cost: 9.124777, mlm loss: 9.124777, speed: 1.093932 steps/s, speed: 8.751457 samples/s, speed: 4480.745735 tokens/s, learning rate: 4.010e-06, loss_scalings: 13421.773438, pp_loss: 9.136450
[INFO] 2021-07-12 18:36:40,336 [run_pretraining.py:  512]:	********exe.run_402******* 
[INFO] 2021-07-12 18:36:41,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:41,248 [run_pretraining.py:  534]:	loss/total_loss, 9.137557029724121, 403
[INFO] 2021-07-12 18:36:41,248 [run_pretraining.py:  535]:	loss/mlm_loss, 9.137557029724121, 403
[INFO] 2021-07-12 18:36:41,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0199997783929575e-06, 403
[INFO] 2021-07-12 18:36:41,248 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 403
[INFO] 2021-07-12 18:36:41,248 [run_pretraining.py:  558]:	worker_index: 7, step: 403, cost: 9.137557, mlm loss: 9.137557, speed: 1.097026 steps/s, speed: 8.776212 samples/s, speed: 4493.420328 tokens/s, learning rate: 4.020e-06, loss_scalings: 13421.773438, pp_loss: 9.164753
[INFO] 2021-07-12 18:36:41,248 [run_pretraining.py:  512]:	********exe.run_403******* 
[INFO] 2021-07-12 18:36:42,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:42,165 [run_pretraining.py:  534]:	loss/total_loss, 9.086689949035645, 404
[INFO] 2021-07-12 18:36:42,165 [run_pretraining.py:  535]:	loss/mlm_loss, 9.086689949035645, 404
[INFO] 2021-07-12 18:36:42,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.030000127386302e-06, 404
[INFO] 2021-07-12 18:36:42,166 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 404
[INFO] 2021-07-12 18:36:42,166 [run_pretraining.py:  558]:	worker_index: 7, step: 404, cost: 9.086690, mlm loss: 9.086690, speed: 1.091022 steps/s, speed: 8.728178 samples/s, speed: 4468.827011 tokens/s, learning rate: 4.030e-06, loss_scalings: 13421.773438, pp_loss: 9.378539
[INFO] 2021-07-12 18:36:42,166 [run_pretraining.py:  512]:	********exe.run_404******* 
[INFO] 2021-07-12 18:36:43,078 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:43,078 [run_pretraining.py:  534]:	loss/total_loss, 9.347262382507324, 405
[INFO] 2021-07-12 18:36:43,079 [run_pretraining.py:  535]:	loss/mlm_loss, 9.347262382507324, 405
[INFO] 2021-07-12 18:36:43,079 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.039999566884944e-06, 405
[INFO] 2021-07-12 18:36:43,079 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 405
[INFO] 2021-07-12 18:36:43,079 [run_pretraining.py:  558]:	worker_index: 7, step: 405, cost: 9.347262, mlm loss: 9.347262, speed: 1.095844 steps/s, speed: 8.766753 samples/s, speed: 4488.577602 tokens/s, learning rate: 4.040e-06, loss_scalings: 13421.773438, pp_loss: 9.100622
[INFO] 2021-07-12 18:36:43,079 [run_pretraining.py:  512]:	********exe.run_405******* 
[INFO] 2021-07-12 18:36:43,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:43,994 [run_pretraining.py:  534]:	loss/total_loss, 8.971110343933105, 406
[INFO] 2021-07-12 18:36:43,994 [run_pretraining.py:  535]:	loss/mlm_loss, 8.971110343933105, 406
[INFO] 2021-07-12 18:36:43,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.0499999158782884e-06, 406
[INFO] 2021-07-12 18:36:43,994 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 406
[INFO] 2021-07-12 18:36:43,994 [run_pretraining.py:  558]:	worker_index: 7, step: 406, cost: 8.971110, mlm loss: 8.971110, speed: 1.093201 steps/s, speed: 8.745610 samples/s, speed: 4477.752512 tokens/s, learning rate: 4.050e-06, loss_scalings: 13421.773438, pp_loss: 9.036084
[INFO] 2021-07-12 18:36:43,994 [run_pretraining.py:  512]:	********exe.run_406******* 
[INFO] 2021-07-12 18:36:44,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:44,898 [run_pretraining.py:  534]:	loss/total_loss, 8.933428764343262, 407
[INFO] 2021-07-12 18:36:44,898 [run_pretraining.py:  535]:	loss/mlm_loss, 8.933428764343262, 407
[INFO] 2021-07-12 18:36:44,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.060000264871633e-06, 407
[INFO] 2021-07-12 18:36:44,898 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 407
[INFO] 2021-07-12 18:36:44,898 [run_pretraining.py:  558]:	worker_index: 7, step: 407, cost: 8.933429, mlm loss: 8.933429, speed: 1.107318 steps/s, speed: 8.858545 samples/s, speed: 4535.575015 tokens/s, learning rate: 4.060e-06, loss_scalings: 13421.773438, pp_loss: 9.071514
[INFO] 2021-07-12 18:36:44,898 [run_pretraining.py:  512]:	********exe.run_407******* 
[INFO] 2021-07-12 18:36:45,805 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:45,805 [run_pretraining.py:  534]:	loss/total_loss, 8.975489616394043, 408
[INFO] 2021-07-12 18:36:45,805 [run_pretraining.py:  535]:	loss/mlm_loss, 8.975489616394043, 408
[INFO] 2021-07-12 18:36:45,805 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.069999704370275e-06, 408
[INFO] 2021-07-12 18:36:45,805 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 408
[INFO] 2021-07-12 18:36:45,805 [run_pretraining.py:  558]:	worker_index: 7, step: 408, cost: 8.975490, mlm loss: 8.975490, speed: 1.102642 steps/s, speed: 8.821137 samples/s, speed: 4516.422153 tokens/s, learning rate: 4.070e-06, loss_scalings: 13421.773438, pp_loss: 9.035400
[INFO] 2021-07-12 18:36:45,806 [run_pretraining.py:  512]:	********exe.run_408******* 
[INFO] 2021-07-12 18:36:46,709 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:46,710 [run_pretraining.py:  534]:	loss/total_loss, 9.389549255371094, 409
[INFO] 2021-07-12 18:36:46,710 [run_pretraining.py:  535]:	loss/mlm_loss, 9.389549255371094, 409
[INFO] 2021-07-12 18:36:46,710 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.080000053363619e-06, 409
[INFO] 2021-07-12 18:36:46,710 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 409
[INFO] 2021-07-12 18:36:46,710 [run_pretraining.py:  558]:	worker_index: 7, step: 409, cost: 9.389549, mlm loss: 9.389549, speed: 1.106452 steps/s, speed: 8.851614 samples/s, speed: 4532.026260 tokens/s, learning rate: 4.080e-06, loss_scalings: 13421.773438, pp_loss: 9.122231
[INFO] 2021-07-12 18:36:46,710 [run_pretraining.py:  512]:	********exe.run_409******* 
[INFO] 2021-07-12 18:36:47,661 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:47,662 [run_pretraining.py:  534]:	loss/total_loss, 9.25261116027832, 410
[INFO] 2021-07-12 18:36:47,662 [run_pretraining.py:  535]:	loss/mlm_loss, 9.25261116027832, 410
[INFO] 2021-07-12 18:36:47,662 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.089999947609613e-06, 410
[INFO] 2021-07-12 18:36:47,662 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 410
[INFO] 2021-07-12 18:36:47,662 [run_pretraining.py:  558]:	worker_index: 7, step: 410, cost: 9.252611, mlm loss: 9.252611, speed: 1.050747 steps/s, speed: 8.405975 samples/s, speed: 4303.859069 tokens/s, learning rate: 4.090e-06, loss_scalings: 13421.773438, pp_loss: 9.132618
[INFO] 2021-07-12 18:36:47,662 [run_pretraining.py:  512]:	********exe.run_410******* 
[INFO] 2021-07-12 18:36:48,705 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:48,705 [run_pretraining.py:  534]:	loss/total_loss, 9.293610572814941, 411
[INFO] 2021-07-12 18:36:48,706 [run_pretraining.py:  535]:	loss/mlm_loss, 9.293610572814941, 411
[INFO] 2021-07-12 18:36:48,706 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.099999841855606e-06, 411
[INFO] 2021-07-12 18:36:48,706 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 411
[INFO] 2021-07-12 18:36:48,706 [run_pretraining.py:  558]:	worker_index: 7, step: 411, cost: 9.293611, mlm loss: 9.293611, speed: 0.958860 steps/s, speed: 7.670878 samples/s, speed: 3927.489753 tokens/s, learning rate: 4.100e-06, loss_scalings: 13421.773438, pp_loss: 9.229941
[INFO] 2021-07-12 18:36:48,706 [run_pretraining.py:  512]:	********exe.run_411******* 
[INFO] 2021-07-12 18:36:49,753 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:49,754 [run_pretraining.py:  534]:	loss/total_loss, 9.086767196655273, 412
[INFO] 2021-07-12 18:36:49,754 [run_pretraining.py:  535]:	loss/mlm_loss, 9.086767196655273, 412
[INFO] 2021-07-12 18:36:49,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.109999736101599e-06, 412
[INFO] 2021-07-12 18:36:49,754 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 412
[INFO] 2021-07-12 18:36:49,754 [run_pretraining.py:  558]:	worker_index: 7, step: 412, cost: 9.086767, mlm loss: 9.086767, speed: 0.954392 steps/s, speed: 7.635140 samples/s, speed: 3909.191650 tokens/s, learning rate: 4.110e-06, loss_scalings: 13421.773438, pp_loss: 9.060020
[INFO] 2021-07-12 18:36:49,754 [run_pretraining.py:  512]:	********exe.run_412******* 
[INFO] 2021-07-12 18:36:50,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:50,810 [run_pretraining.py:  534]:	loss/total_loss, 9.222295761108398, 413
[INFO] 2021-07-12 18:36:50,810 [run_pretraining.py:  535]:	loss/mlm_loss, 9.222295761108398, 413
[INFO] 2021-07-12 18:36:50,810 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.120000085094944e-06, 413
[INFO] 2021-07-12 18:36:50,810 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 413
[INFO] 2021-07-12 18:36:50,810 [run_pretraining.py:  558]:	worker_index: 7, step: 413, cost: 9.222296, mlm loss: 9.222296, speed: 0.947542 steps/s, speed: 7.580334 samples/s, speed: 3881.131027 tokens/s, learning rate: 4.120e-06, loss_scalings: 13421.773438, pp_loss: 8.889437
[INFO] 2021-07-12 18:36:50,810 [run_pretraining.py:  512]:	********exe.run_413******* 
[INFO] 2021-07-12 18:36:51,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:51,865 [run_pretraining.py:  534]:	loss/total_loss, 9.379399299621582, 414
[INFO] 2021-07-12 18:36:51,865 [run_pretraining.py:  535]:	loss/mlm_loss, 9.379399299621582, 414
[INFO] 2021-07-12 18:36:51,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.129999979340937e-06, 414
[INFO] 2021-07-12 18:36:51,865 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 414
[INFO] 2021-07-12 18:36:51,865 [run_pretraining.py:  558]:	worker_index: 7, step: 414, cost: 9.379399, mlm loss: 9.379399, speed: 0.948295 steps/s, speed: 7.586363 samples/s, speed: 3884.218036 tokens/s, learning rate: 4.130e-06, loss_scalings: 13421.773438, pp_loss: 9.122268
[INFO] 2021-07-12 18:36:51,865 [run_pretraining.py:  512]:	********exe.run_414******* 
[INFO] 2021-07-12 18:36:52,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  534]:	loss/total_loss, 8.938145637512207, 415
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  535]:	loss/mlm_loss, 8.938145637512207, 415
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.13999987358693e-06, 415
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 415
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  558]:	worker_index: 7, step: 415, cost: 8.938146, mlm loss: 8.938146, speed: 0.949522 steps/s, speed: 7.596173 samples/s, speed: 3889.240731 tokens/s, learning rate: 4.140e-06, loss_scalings: 13421.773438, pp_loss: 8.979923
[INFO] 2021-07-12 18:36:52,919 [run_pretraining.py:  512]:	********exe.run_415******* 
[INFO] 2021-07-12 18:36:53,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:53,971 [run_pretraining.py:  534]:	loss/total_loss, 9.137149810791016, 416
[INFO] 2021-07-12 18:36:53,971 [run_pretraining.py:  535]:	loss/mlm_loss, 9.137149810791016, 416
[INFO] 2021-07-12 18:36:53,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.149999767832924e-06, 416
[INFO] 2021-07-12 18:36:53,971 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 416
[INFO] 2021-07-12 18:36:53,972 [run_pretraining.py:  558]:	worker_index: 7, step: 416, cost: 9.137150, mlm loss: 9.137150, speed: 0.950836 steps/s, speed: 7.606685 samples/s, speed: 3894.622497 tokens/s, learning rate: 4.150e-06, loss_scalings: 13421.773438, pp_loss: 9.152503
[INFO] 2021-07-12 18:36:53,972 [run_pretraining.py:  512]:	********exe.run_416******* 
[INFO] 2021-07-12 18:36:55,032 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:55,033 [run_pretraining.py:  534]:	loss/total_loss, 8.975240707397461, 417
[INFO] 2021-07-12 18:36:55,033 [run_pretraining.py:  535]:	loss/mlm_loss, 8.975240707397461, 417
[INFO] 2021-07-12 18:36:55,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.160000116826268e-06, 417
[INFO] 2021-07-12 18:36:55,033 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 417
[INFO] 2021-07-12 18:36:55,033 [run_pretraining.py:  558]:	worker_index: 7, step: 417, cost: 8.975241, mlm loss: 8.975241, speed: 0.942682 steps/s, speed: 7.541457 samples/s, speed: 3861.226114 tokens/s, learning rate: 4.160e-06, loss_scalings: 13421.773438, pp_loss: 9.061295
[INFO] 2021-07-12 18:36:55,033 [run_pretraining.py:  512]:	********exe.run_417******* 
[INFO] 2021-07-12 18:36:56,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:56,087 [run_pretraining.py:  534]:	loss/total_loss, 9.240859985351562, 418
[INFO] 2021-07-12 18:36:56,087 [run_pretraining.py:  535]:	loss/mlm_loss, 9.240859985351562, 418
[INFO] 2021-07-12 18:36:56,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.170000011072261e-06, 418
[INFO] 2021-07-12 18:36:56,087 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 418
[INFO] 2021-07-12 18:36:56,087 [run_pretraining.py:  558]:	worker_index: 7, step: 418, cost: 9.240860, mlm loss: 9.240860, speed: 0.949338 steps/s, speed: 7.594707 samples/s, speed: 3888.489843 tokens/s, learning rate: 4.170e-06, loss_scalings: 13421.773438, pp_loss: 8.094828
[INFO] 2021-07-12 18:36:56,087 [run_pretraining.py:  512]:	********exe.run_418******* 
[INFO] 2021-07-12 18:36:57,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:57,138 [run_pretraining.py:  534]:	loss/total_loss, 9.011298179626465, 419
[INFO] 2021-07-12 18:36:57,138 [run_pretraining.py:  535]:	loss/mlm_loss, 9.011298179626465, 419
[INFO] 2021-07-12 18:36:57,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.179999905318255e-06, 419
[INFO] 2021-07-12 18:36:57,138 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 419
[INFO] 2021-07-12 18:36:57,138 [run_pretraining.py:  558]:	worker_index: 7, step: 419, cost: 9.011298, mlm loss: 9.011298, speed: 0.951917 steps/s, speed: 7.615339 samples/s, speed: 3899.053504 tokens/s, learning rate: 4.180e-06, loss_scalings: 13421.773438, pp_loss: 8.900525
[INFO] 2021-07-12 18:36:57,138 [run_pretraining.py:  512]:	********exe.run_419******* 
[INFO] 2021-07-12 18:36:58,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:58,195 [run_pretraining.py:  534]:	loss/total_loss, 9.041662216186523, 420
[INFO] 2021-07-12 18:36:58,195 [run_pretraining.py:  535]:	loss/mlm_loss, 9.041662216186523, 420
[INFO] 2021-07-12 18:36:58,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.190000254311599e-06, 420
[INFO] 2021-07-12 18:36:58,195 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 420
[INFO] 2021-07-12 18:36:58,195 [run_pretraining.py:  558]:	worker_index: 7, step: 420, cost: 9.041662, mlm loss: 9.041662, speed: 0.946600 steps/s, speed: 7.572803 samples/s, speed: 3877.275222 tokens/s, learning rate: 4.190e-06, loss_scalings: 13421.773438, pp_loss: 9.167694
[INFO] 2021-07-12 18:36:58,195 [run_pretraining.py:  512]:	********exe.run_420******* 
[INFO] 2021-07-12 18:36:59,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:36:59,250 [run_pretraining.py:  534]:	loss/total_loss, 9.230232238769531, 421
[INFO] 2021-07-12 18:36:59,250 [run_pretraining.py:  535]:	loss/mlm_loss, 9.230232238769531, 421
[INFO] 2021-07-12 18:36:59,251 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.199999693810241e-06, 421
[INFO] 2021-07-12 18:36:59,251 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 421
[INFO] 2021-07-12 18:36:59,251 [run_pretraining.py:  558]:	worker_index: 7, step: 421, cost: 9.230232, mlm loss: 9.230232, speed: 0.948055 steps/s, speed: 7.584443 samples/s, speed: 3883.234715 tokens/s, learning rate: 4.200e-06, loss_scalings: 13421.773438, pp_loss: 9.154047
[INFO] 2021-07-12 18:36:59,251 [run_pretraining.py:  512]:	********exe.run_421******* 
[INFO] 2021-07-12 18:37:00,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:00,305 [run_pretraining.py:  534]:	loss/total_loss, 9.145866394042969, 422
[INFO] 2021-07-12 18:37:00,305 [run_pretraining.py:  535]:	loss/mlm_loss, 9.145866394042969, 422
[INFO] 2021-07-12 18:37:00,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2100000428035855e-06, 422
[INFO] 2021-07-12 18:37:00,305 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 422
[INFO] 2021-07-12 18:37:00,305 [run_pretraining.py:  558]:	worker_index: 7, step: 422, cost: 9.145866, mlm loss: 9.145866, speed: 0.948680 steps/s, speed: 7.589438 samples/s, speed: 3885.792386 tokens/s, learning rate: 4.210e-06, loss_scalings: 13421.773438, pp_loss: 8.925383
[INFO] 2021-07-12 18:37:00,306 [run_pretraining.py:  512]:	********exe.run_422******* 
[INFO] 2021-07-12 18:37:01,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:01,355 [run_pretraining.py:  534]:	loss/total_loss, 9.211624145507812, 423
[INFO] 2021-07-12 18:37:01,355 [run_pretraining.py:  535]:	loss/mlm_loss, 9.211624145507812, 423
[INFO] 2021-07-12 18:37:01,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.219999937049579e-06, 423
[INFO] 2021-07-12 18:37:01,355 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 423
[INFO] 2021-07-12 18:37:01,356 [run_pretraining.py:  558]:	worker_index: 7, step: 423, cost: 9.211624, mlm loss: 9.211624, speed: 0.952972 steps/s, speed: 7.623774 samples/s, speed: 3903.372213 tokens/s, learning rate: 4.220e-06, loss_scalings: 13421.773438, pp_loss: 9.186263
[INFO] 2021-07-12 18:37:01,356 [run_pretraining.py:  512]:	********exe.run_423******* 
[INFO] 2021-07-12 18:37:02,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:02,409 [run_pretraining.py:  534]:	loss/total_loss, 8.931655883789062, 424
[INFO] 2021-07-12 18:37:02,409 [run_pretraining.py:  535]:	loss/mlm_loss, 8.931655883789062, 424
[INFO] 2021-07-12 18:37:02,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.229999831295572e-06, 424
[INFO] 2021-07-12 18:37:02,409 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 424
[INFO] 2021-07-12 18:37:02,409 [run_pretraining.py:  558]:	worker_index: 7, step: 424, cost: 8.931656, mlm loss: 8.931656, speed: 0.949784 steps/s, speed: 7.598272 samples/s, speed: 3890.315189 tokens/s, learning rate: 4.230e-06, loss_scalings: 13421.773438, pp_loss: 9.136928
[INFO] 2021-07-12 18:37:02,409 [run_pretraining.py:  512]:	********exe.run_424******* 
[INFO] 2021-07-12 18:37:03,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:03,469 [run_pretraining.py:  534]:	loss/total_loss, 5.794633865356445, 425
[INFO] 2021-07-12 18:37:03,470 [run_pretraining.py:  535]:	loss/mlm_loss, 5.794633865356445, 425
[INFO] 2021-07-12 18:37:03,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2399997255415656e-06, 425
[INFO] 2021-07-12 18:37:03,470 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 425
[INFO] 2021-07-12 18:37:03,470 [run_pretraining.py:  558]:	worker_index: 7, step: 425, cost: 5.794634, mlm loss: 5.794634, speed: 0.943303 steps/s, speed: 7.546422 samples/s, speed: 3863.767900 tokens/s, learning rate: 4.240e-06, loss_scalings: 13421.773438, pp_loss: 8.082172
[INFO] 2021-07-12 18:37:03,470 [run_pretraining.py:  512]:	********exe.run_425******* 
[INFO] 2021-07-12 18:37:04,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:04,520 [run_pretraining.py:  534]:	loss/total_loss, 9.261961936950684, 426
[INFO] 2021-07-12 18:37:04,520 [run_pretraining.py:  535]:	loss/mlm_loss, 9.261961936950684, 426
[INFO] 2021-07-12 18:37:04,521 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.25000007453491e-06, 426
[INFO] 2021-07-12 18:37:04,521 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 426
[INFO] 2021-07-12 18:37:04,521 [run_pretraining.py:  558]:	worker_index: 7, step: 426, cost: 9.261962, mlm loss: 9.261962, speed: 0.952127 steps/s, speed: 7.617012 samples/s, speed: 3899.910284 tokens/s, learning rate: 4.250e-06, loss_scalings: 13421.773438, pp_loss: 8.856235
[INFO] 2021-07-12 18:37:04,521 [run_pretraining.py:  512]:	********exe.run_426******* 
[INFO] 2021-07-12 18:37:05,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:05,652 [run_pretraining.py:  534]:	loss/total_loss, 9.322198867797852, 427
[INFO] 2021-07-12 18:37:05,652 [run_pretraining.py:  535]:	loss/mlm_loss, 9.322198867797852, 427
[INFO] 2021-07-12 18:37:05,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.259999514033552e-06, 427
[INFO] 2021-07-12 18:37:05,652 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 427
[INFO] 2021-07-12 18:37:05,653 [run_pretraining.py:  558]:	worker_index: 7, step: 427, cost: 9.322199, mlm loss: 9.322199, speed: 0.884031 steps/s, speed: 7.072249 samples/s, speed: 3620.991283 tokens/s, learning rate: 4.260e-06, loss_scalings: 13421.773438, pp_loss: 9.368509
[INFO] 2021-07-12 18:37:05,653 [run_pretraining.py:  512]:	********exe.run_427******* 
[INFO] 2021-07-12 18:37:06,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  534]:	loss/total_loss, 9.128841400146484, 428
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  535]:	loss/mlm_loss, 9.128841400146484, 428
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.2699998630268965e-06, 428
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 428
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  558]:	worker_index: 7, step: 428, cost: 9.128841, mlm loss: 9.128841, speed: 0.913942 steps/s, speed: 7.311535 samples/s, speed: 3743.505836 tokens/s, learning rate: 4.270e-06, loss_scalings: 13421.773438, pp_loss: 8.968519
[INFO] 2021-07-12 18:37:06,747 [run_pretraining.py:  512]:	********exe.run_428******* 
[INFO] 2021-07-12 18:37:07,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:07,846 [run_pretraining.py:  534]:	loss/total_loss, 8.879488945007324, 429
[INFO] 2021-07-12 18:37:07,846 [run_pretraining.py:  535]:	loss/mlm_loss, 8.879488945007324, 429
[INFO] 2021-07-12 18:37:07,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.280000212020241e-06, 429
[INFO] 2021-07-12 18:37:07,846 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 429
[INFO] 2021-07-12 18:37:07,846 [run_pretraining.py:  558]:	worker_index: 7, step: 429, cost: 8.879489, mlm loss: 8.879489, speed: 0.910682 steps/s, speed: 7.285452 samples/s, speed: 3730.151488 tokens/s, learning rate: 4.280e-06, loss_scalings: 13421.773438, pp_loss: 8.829695
[INFO] 2021-07-12 18:37:07,846 [run_pretraining.py:  512]:	********exe.run_429******* 
[INFO] 2021-07-12 18:37:08,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:08,897 [run_pretraining.py:  534]:	loss/total_loss, 8.900491714477539, 430
[INFO] 2021-07-12 18:37:08,897 [run_pretraining.py:  535]:	loss/mlm_loss, 8.900491714477539, 430
[INFO] 2021-07-12 18:37:08,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.289999651518883e-06, 430
[INFO] 2021-07-12 18:37:08,898 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 430
[INFO] 2021-07-12 18:37:08,898 [run_pretraining.py:  558]:	worker_index: 7, step: 430, cost: 8.900492, mlm loss: 8.900492, speed: 0.951635 steps/s, speed: 7.613077 samples/s, speed: 3897.895502 tokens/s, learning rate: 4.290e-06, loss_scalings: 13421.773438, pp_loss: 8.978062
[INFO] 2021-07-12 18:37:08,898 [run_pretraining.py:  512]:	********exe.run_430******* 
[INFO] 2021-07-12 18:37:09,958 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:09,959 [run_pretraining.py:  534]:	loss/total_loss, 9.080714225769043, 431
[INFO] 2021-07-12 18:37:09,959 [run_pretraining.py:  535]:	loss/mlm_loss, 9.080714225769043, 431
[INFO] 2021-07-12 18:37:09,959 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.300000000512227e-06, 431
[INFO] 2021-07-12 18:37:09,959 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 431
[INFO] 2021-07-12 18:37:09,959 [run_pretraining.py:  558]:	worker_index: 7, step: 431, cost: 9.080714, mlm loss: 9.080714, speed: 0.942784 steps/s, speed: 7.542273 samples/s, speed: 3861.643581 tokens/s, learning rate: 4.300e-06, loss_scalings: 13421.773438, pp_loss: 9.094076
[INFO] 2021-07-12 18:37:09,959 [run_pretraining.py:  512]:	********exe.run_431******* 
[INFO] 2021-07-12 18:37:11,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:11,019 [run_pretraining.py:  534]:	loss/total_loss, 8.955906867980957, 432
[INFO] 2021-07-12 18:37:11,019 [run_pretraining.py:  535]:	loss/mlm_loss, 8.955906867980957, 432
[INFO] 2021-07-12 18:37:11,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.309999894758221e-06, 432
[INFO] 2021-07-12 18:37:11,019 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 432
[INFO] 2021-07-12 18:37:11,019 [run_pretraining.py:  558]:	worker_index: 7, step: 432, cost: 8.955907, mlm loss: 8.955907, speed: 0.943748 steps/s, speed: 7.549986 samples/s, speed: 3865.592719 tokens/s, learning rate: 4.310e-06, loss_scalings: 13421.773438, pp_loss: 9.279219
[INFO] 2021-07-12 18:37:11,019 [run_pretraining.py:  512]:	********exe.run_432******* 
[INFO] 2021-07-12 18:37:12,072 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:12,073 [run_pretraining.py:  534]:	loss/total_loss, 8.78916072845459, 433
[INFO] 2021-07-12 18:37:12,073 [run_pretraining.py:  535]:	loss/mlm_loss, 8.78916072845459, 433
[INFO] 2021-07-12 18:37:12,073 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.319999789004214e-06, 433
[INFO] 2021-07-12 18:37:12,073 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 433
[INFO] 2021-07-12 18:37:12,073 [run_pretraining.py:  558]:	worker_index: 7, step: 433, cost: 8.789161, mlm loss: 8.789161, speed: 0.949379 steps/s, speed: 7.595035 samples/s, speed: 3888.657953 tokens/s, learning rate: 4.320e-06, loss_scalings: 13421.773438, pp_loss: 9.064724
[INFO] 2021-07-12 18:37:12,073 [run_pretraining.py:  512]:	********exe.run_433******* 
[INFO] 2021-07-12 18:37:13,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:13,107 [run_pretraining.py:  534]:	loss/total_loss, 9.233013153076172, 434
[INFO] 2021-07-12 18:37:13,107 [run_pretraining.py:  535]:	loss/mlm_loss, 9.233013153076172, 434
[INFO] 2021-07-12 18:37:13,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.3299996832502075e-06, 434
[INFO] 2021-07-12 18:37:13,107 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 434
[INFO] 2021-07-12 18:37:13,107 [run_pretraining.py:  558]:	worker_index: 7, step: 434, cost: 9.233013, mlm loss: 9.233013, speed: 0.967767 steps/s, speed: 7.742134 samples/s, speed: 3963.972610 tokens/s, learning rate: 4.330e-06, loss_scalings: 13421.773438, pp_loss: 9.141966
[INFO] 2021-07-12 18:37:13,107 [run_pretraining.py:  512]:	********exe.run_434******* 
[INFO] 2021-07-12 18:37:14,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:14,166 [run_pretraining.py:  534]:	loss/total_loss, 8.676084518432617, 435
[INFO] 2021-07-12 18:37:14,166 [run_pretraining.py:  535]:	loss/mlm_loss, 8.676084518432617, 435
[INFO] 2021-07-12 18:37:14,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.340000032243552e-06, 435
[INFO] 2021-07-12 18:37:14,166 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 435
[INFO] 2021-07-12 18:37:14,166 [run_pretraining.py:  558]:	worker_index: 7, step: 435, cost: 8.676085, mlm loss: 8.676085, speed: 0.944846 steps/s, speed: 7.558772 samples/s, speed: 3870.091262 tokens/s, learning rate: 4.340e-06, loss_scalings: 13421.773438, pp_loss: 9.056217
[INFO] 2021-07-12 18:37:14,166 [run_pretraining.py:  512]:	********exe.run_435******* 
[INFO] 2021-07-12 18:37:15,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:15,219 [run_pretraining.py:  534]:	loss/total_loss, 9.409917831420898, 436
[INFO] 2021-07-12 18:37:15,219 [run_pretraining.py:  535]:	loss/mlm_loss, 9.409917831420898, 436
[INFO] 2021-07-12 18:37:15,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.349999926489545e-06, 436
[INFO] 2021-07-12 18:37:15,219 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 436
[INFO] 2021-07-12 18:37:15,219 [run_pretraining.py:  558]:	worker_index: 7, step: 436, cost: 9.409918, mlm loss: 9.409918, speed: 0.950493 steps/s, speed: 7.603947 samples/s, speed: 3893.220959 tokens/s, learning rate: 4.350e-06, loss_scalings: 13421.773438, pp_loss: 9.363286
[INFO] 2021-07-12 18:37:15,219 [run_pretraining.py:  512]:	********exe.run_436******* 
[INFO] 2021-07-12 18:37:16,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:16,268 [run_pretraining.py:  534]:	loss/total_loss, 8.842180252075195, 437
[INFO] 2021-07-12 18:37:16,269 [run_pretraining.py:  535]:	loss/mlm_loss, 8.842180252075195, 437
[INFO] 2021-07-12 18:37:16,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.359999820735538e-06, 437
[INFO] 2021-07-12 18:37:16,269 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 437
[INFO] 2021-07-12 18:37:16,269 [run_pretraining.py:  558]:	worker_index: 7, step: 437, cost: 8.842180, mlm loss: 8.842180, speed: 0.953018 steps/s, speed: 7.624146 samples/s, speed: 3903.562899 tokens/s, learning rate: 4.360e-06, loss_scalings: 13421.773438, pp_loss: 8.974291
[INFO] 2021-07-12 18:37:16,269 [run_pretraining.py:  512]:	********exe.run_437******* 
[INFO] 2021-07-12 18:37:17,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:17,323 [run_pretraining.py:  534]:	loss/total_loss, 9.123737335205078, 438
[INFO] 2021-07-12 18:37:17,323 [run_pretraining.py:  535]:	loss/mlm_loss, 9.123737335205078, 438
[INFO] 2021-07-12 18:37:17,323 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.369999714981532e-06, 438
[INFO] 2021-07-12 18:37:17,323 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 438
[INFO] 2021-07-12 18:37:17,323 [run_pretraining.py:  558]:	worker_index: 7, step: 438, cost: 9.123737, mlm loss: 9.123737, speed: 0.949185 steps/s, speed: 7.593478 samples/s, speed: 3887.860659 tokens/s, learning rate: 4.370e-06, loss_scalings: 13421.773438, pp_loss: 9.091358
[INFO] 2021-07-12 18:37:17,323 [run_pretraining.py:  512]:	********exe.run_438******* 
[INFO] 2021-07-12 18:37:18,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:18,380 [run_pretraining.py:  534]:	loss/total_loss, 8.956315994262695, 439
[INFO] 2021-07-12 18:37:18,380 [run_pretraining.py:  535]:	loss/mlm_loss, 8.956315994262695, 439
[INFO] 2021-07-12 18:37:18,380 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.380000063974876e-06, 439
[INFO] 2021-07-12 18:37:18,381 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 439
[INFO] 2021-07-12 18:37:18,381 [run_pretraining.py:  558]:	worker_index: 7, step: 439, cost: 8.956316, mlm loss: 8.956316, speed: 0.946095 steps/s, speed: 7.568758 samples/s, speed: 3875.204207 tokens/s, learning rate: 4.380e-06, loss_scalings: 13421.773438, pp_loss: 8.880255
[INFO] 2021-07-12 18:37:18,381 [run_pretraining.py:  512]:	********exe.run_439******* 
[INFO] 2021-07-12 18:37:19,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:19,431 [run_pretraining.py:  534]:	loss/total_loss, 8.804759979248047, 440
[INFO] 2021-07-12 18:37:19,431 [run_pretraining.py:  535]:	loss/mlm_loss, 8.804759979248047, 440
[INFO] 2021-07-12 18:37:19,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.389999958220869e-06, 440
[INFO] 2021-07-12 18:37:19,432 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 440
[INFO] 2021-07-12 18:37:19,432 [run_pretraining.py:  558]:	worker_index: 7, step: 440, cost: 8.804760, mlm loss: 8.804760, speed: 0.952079 steps/s, speed: 7.616635 samples/s, speed: 3899.717299 tokens/s, learning rate: 4.390e-06, loss_scalings: 13421.773438, pp_loss: 9.000813
[INFO] 2021-07-12 18:37:19,432 [run_pretraining.py:  512]:	********exe.run_440******* 
[INFO] 2021-07-12 18:37:20,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:20,491 [run_pretraining.py:  534]:	loss/total_loss, 8.867758750915527, 441
[INFO] 2021-07-12 18:37:20,491 [run_pretraining.py:  535]:	loss/mlm_loss, 8.867758750915527, 441
[INFO] 2021-07-12 18:37:20,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.399999852466863e-06, 441
[INFO] 2021-07-12 18:37:20,491 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 441
[INFO] 2021-07-12 18:37:20,491 [run_pretraining.py:  558]:	worker_index: 7, step: 441, cost: 8.867759, mlm loss: 8.867759, speed: 0.944355 steps/s, speed: 7.554837 samples/s, speed: 3868.076683 tokens/s, learning rate: 4.400e-06, loss_scalings: 13421.773438, pp_loss: 8.781867
[INFO] 2021-07-12 18:37:20,491 [run_pretraining.py:  512]:	********exe.run_441******* 
[INFO] 2021-07-12 18:37:21,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:21,539 [run_pretraining.py:  534]:	loss/total_loss, 8.766031265258789, 442
[INFO] 2021-07-12 18:37:21,539 [run_pretraining.py:  535]:	loss/mlm_loss, 8.766031265258789, 442
[INFO] 2021-07-12 18:37:21,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.410000201460207e-06, 442
[INFO] 2021-07-12 18:37:21,539 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 442
[INFO] 2021-07-12 18:37:21,539 [run_pretraining.py:  558]:	worker_index: 7, step: 442, cost: 8.766031, mlm loss: 8.766031, speed: 0.954963 steps/s, speed: 7.639701 samples/s, speed: 3911.527136 tokens/s, learning rate: 4.410e-06, loss_scalings: 13421.773438, pp_loss: 9.102114
[INFO] 2021-07-12 18:37:21,539 [run_pretraining.py:  512]:	********exe.run_442******* 
[INFO] 2021-07-12 18:37:22,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:22,625 [run_pretraining.py:  534]:	loss/total_loss, 9.347007751464844, 443
[INFO] 2021-07-12 18:37:22,625 [run_pretraining.py:  535]:	loss/mlm_loss, 9.347007751464844, 443
[INFO] 2021-07-12 18:37:22,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.419999640958849e-06, 443
[INFO] 2021-07-12 18:37:22,625 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 443
[INFO] 2021-07-12 18:37:22,625 [run_pretraining.py:  558]:	worker_index: 7, step: 443, cost: 9.347008, mlm loss: 9.347008, speed: 0.921120 steps/s, speed: 7.368961 samples/s, speed: 3772.908114 tokens/s, learning rate: 4.420e-06, loss_scalings: 13421.773438, pp_loss: 9.158766
[INFO] 2021-07-12 18:37:22,625 [run_pretraining.py:  512]:	********exe.run_443******* 
[INFO] 2021-07-12 18:37:23,687 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:23,688 [run_pretraining.py:  534]:	loss/total_loss, 8.783307075500488, 444
[INFO] 2021-07-12 18:37:23,688 [run_pretraining.py:  535]:	loss/mlm_loss, 8.783307075500488, 444
[INFO] 2021-07-12 18:37:23,688 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4299999899521936e-06, 444
[INFO] 2021-07-12 18:37:23,688 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 444
[INFO] 2021-07-12 18:37:23,688 [run_pretraining.py:  558]:	worker_index: 7, step: 444, cost: 8.783307, mlm loss: 8.783307, speed: 0.941341 steps/s, speed: 7.530725 samples/s, speed: 3855.731086 tokens/s, learning rate: 4.430e-06, loss_scalings: 13421.773438, pp_loss: 8.869108
[INFO] 2021-07-12 18:37:23,688 [run_pretraining.py:  512]:	********exe.run_444******* 
[INFO] 2021-07-12 18:37:24,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:24,745 [run_pretraining.py:  534]:	loss/total_loss, 8.938846588134766, 445
[INFO] 2021-07-12 18:37:24,745 [run_pretraining.py:  535]:	loss/mlm_loss, 8.938846588134766, 445
[INFO] 2021-07-12 18:37:24,746 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.439999884198187e-06, 445
[INFO] 2021-07-12 18:37:24,746 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 445
[INFO] 2021-07-12 18:37:24,746 [run_pretraining.py:  558]:	worker_index: 7, step: 445, cost: 8.938847, mlm loss: 8.938847, speed: 0.946282 steps/s, speed: 7.570259 samples/s, speed: 3875.972708 tokens/s, learning rate: 4.440e-06, loss_scalings: 13421.773438, pp_loss: 8.903975
[INFO] 2021-07-12 18:37:24,746 [run_pretraining.py:  512]:	********exe.run_445******* 
[INFO] 2021-07-12 18:37:25,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:25,797 [run_pretraining.py:  534]:	loss/total_loss, 8.519440650939941, 446
[INFO] 2021-07-12 18:37:25,797 [run_pretraining.py:  535]:	loss/mlm_loss, 8.519440650939941, 446
[INFO] 2021-07-12 18:37:25,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.44999977844418e-06, 446
[INFO] 2021-07-12 18:37:25,797 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 446
[INFO] 2021-07-12 18:37:25,797 [run_pretraining.py:  558]:	worker_index: 7, step: 446, cost: 8.519441, mlm loss: 8.519441, speed: 0.951378 steps/s, speed: 7.611020 samples/s, speed: 3896.842487 tokens/s, learning rate: 4.450e-06, loss_scalings: 13421.773438, pp_loss: 8.924768
[INFO] 2021-07-12 18:37:25,798 [run_pretraining.py:  512]:	********exe.run_446******* 
[INFO] 2021-07-12 18:37:26,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:26,852 [run_pretraining.py:  534]:	loss/total_loss, 9.12244701385498, 447
[INFO] 2021-07-12 18:37:26,853 [run_pretraining.py:  535]:	loss/mlm_loss, 9.12244701385498, 447
[INFO] 2021-07-12 18:37:26,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.459999672690174e-06, 447
[INFO] 2021-07-12 18:37:26,853 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 447
[INFO] 2021-07-12 18:37:26,853 [run_pretraining.py:  558]:	worker_index: 7, step: 447, cost: 9.122447, mlm loss: 9.122447, speed: 0.948167 steps/s, speed: 7.585336 samples/s, speed: 3883.692073 tokens/s, learning rate: 4.460e-06, loss_scalings: 13421.773438, pp_loss: 8.953706
[INFO] 2021-07-12 18:37:26,853 [run_pretraining.py:  512]:	********exe.run_447******* 
[INFO] 2021-07-12 18:37:27,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:27,902 [run_pretraining.py:  534]:	loss/total_loss, 9.172786712646484, 448
[INFO] 2021-07-12 18:37:27,902 [run_pretraining.py:  535]:	loss/mlm_loss, 9.172786712646484, 448
[INFO] 2021-07-12 18:37:27,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.470000021683518e-06, 448
[INFO] 2021-07-12 18:37:27,902 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 448
[INFO] 2021-07-12 18:37:27,903 [run_pretraining.py:  558]:	worker_index: 7, step: 448, cost: 9.172787, mlm loss: 9.172787, speed: 0.953226 steps/s, speed: 7.625810 samples/s, speed: 3904.414564 tokens/s, learning rate: 4.470e-06, loss_scalings: 13421.773438, pp_loss: 8.826445
[INFO] 2021-07-12 18:37:27,903 [run_pretraining.py:  512]:	********exe.run_448******* 
[INFO] 2021-07-12 18:37:28,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:28,957 [run_pretraining.py:  534]:	loss/total_loss, 8.63156795501709, 449
[INFO] 2021-07-12 18:37:28,957 [run_pretraining.py:  535]:	loss/mlm_loss, 8.63156795501709, 449
[INFO] 2021-07-12 18:37:28,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.479999915929511e-06, 449
[INFO] 2021-07-12 18:37:28,957 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 449
[INFO] 2021-07-12 18:37:28,958 [run_pretraining.py:  558]:	worker_index: 7, step: 449, cost: 8.631568, mlm loss: 8.631568, speed: 0.948413 steps/s, speed: 7.587305 samples/s, speed: 3884.700221 tokens/s, learning rate: 4.480e-06, loss_scalings: 13421.773438, pp_loss: 9.143629
[INFO] 2021-07-12 18:37:28,958 [run_pretraining.py:  512]:	********exe.run_449******* 
[INFO] 2021-07-12 18:37:30,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:30,003 [run_pretraining.py:  534]:	loss/total_loss, 8.653857231140137, 450
[INFO] 2021-07-12 18:37:30,003 [run_pretraining.py:  535]:	loss/mlm_loss, 8.653857231140137, 450
[INFO] 2021-07-12 18:37:30,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.4899998101755045e-06, 450
[INFO] 2021-07-12 18:37:30,003 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 450
[INFO] 2021-07-12 18:37:30,003 [run_pretraining.py:  558]:	worker_index: 7, step: 450, cost: 8.653857, mlm loss: 8.653857, speed: 0.957003 steps/s, speed: 7.656021 samples/s, speed: 3919.882554 tokens/s, learning rate: 4.490e-06, loss_scalings: 13421.773438, pp_loss: 8.963999
[INFO] 2021-07-12 18:37:30,003 [run_pretraining.py:  512]:	********exe.run_450******* 
[INFO] 2021-07-12 18:37:31,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:31,060 [run_pretraining.py:  534]:	loss/total_loss, 9.029306411743164, 451
[INFO] 2021-07-12 18:37:31,060 [run_pretraining.py:  535]:	loss/mlm_loss, 9.029306411743164, 451
[INFO] 2021-07-12 18:37:31,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.500000159168849e-06, 451
[INFO] 2021-07-12 18:37:31,060 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 451
[INFO] 2021-07-12 18:37:31,061 [run_pretraining.py:  558]:	worker_index: 7, step: 451, cost: 9.029306, mlm loss: 9.029306, speed: 0.946303 steps/s, speed: 7.570423 samples/s, speed: 3876.056659 tokens/s, learning rate: 4.500e-06, loss_scalings: 13421.773438, pp_loss: 9.078257
[INFO] 2021-07-12 18:37:31,061 [run_pretraining.py:  512]:	********exe.run_451******* 
[INFO] 2021-07-12 18:37:56,807 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:56,808 [run_pretraining.py:  534]:	loss/total_loss, 8.95931625366211, 452
[INFO] 2021-07-12 18:37:56,808 [run_pretraining.py:  535]:	loss/mlm_loss, 8.95931625366211, 452
[INFO] 2021-07-12 18:37:56,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.510000053414842e-06, 452
[INFO] 2021-07-12 18:37:56,808 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 452
[INFO] 2021-07-12 18:37:56,808 [run_pretraining.py:  558]:	worker_index: 7, step: 452, cost: 8.959316, mlm loss: 8.959316, speed: 0.038839 steps/s, speed: 0.310714 samples/s, speed: 159.085591 tokens/s, learning rate: 4.510e-06, loss_scalings: 13421.773438, pp_loss: 9.045230
[INFO] 2021-07-12 18:37:56,808 [run_pretraining.py:  512]:	********exe.run_452******* 
[INFO] 2021-07-12 18:37:57,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:57,724 [run_pretraining.py:  534]:	loss/total_loss, 8.810877799987793, 453
[INFO] 2021-07-12 18:37:57,724 [run_pretraining.py:  535]:	loss/mlm_loss, 8.810877799987793, 453
[INFO] 2021-07-12 18:37:57,724 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5199999476608355e-06, 453
[INFO] 2021-07-12 18:37:57,724 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 453
[INFO] 2021-07-12 18:37:57,724 [run_pretraining.py:  558]:	worker_index: 7, step: 453, cost: 8.810878, mlm loss: 8.810878, speed: 1.092370 steps/s, speed: 8.738959 samples/s, speed: 4474.347232 tokens/s, learning rate: 4.520e-06, loss_scalings: 13421.773438, pp_loss: 9.075561
[INFO] 2021-07-12 18:37:57,725 [run_pretraining.py:  512]:	********exe.run_453******* 
[INFO] 2021-07-12 18:37:58,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:58,635 [run_pretraining.py:  534]:	loss/total_loss, 9.044869422912598, 454
[INFO] 2021-07-12 18:37:58,635 [run_pretraining.py:  535]:	loss/mlm_loss, 9.044869422912598, 454
[INFO] 2021-07-12 18:37:58,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.529999841906829e-06, 454
[INFO] 2021-07-12 18:37:58,636 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 454
[INFO] 2021-07-12 18:37:58,636 [run_pretraining.py:  558]:	worker_index: 7, step: 454, cost: 9.044869, mlm loss: 9.044869, speed: 1.098258 steps/s, speed: 8.786065 samples/s, speed: 4498.465505 tokens/s, learning rate: 4.530e-06, loss_scalings: 13421.773438, pp_loss: 8.992621
[INFO] 2021-07-12 18:37:58,636 [run_pretraining.py:  512]:	********exe.run_454******* 
[INFO] 2021-07-12 18:37:59,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:37:59,539 [run_pretraining.py:  534]:	loss/total_loss, 9.151968955993652, 455
[INFO] 2021-07-12 18:37:59,540 [run_pretraining.py:  535]:	loss/mlm_loss, 9.151968955993652, 455
[INFO] 2021-07-12 18:37:59,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.540000190900173e-06, 455
[INFO] 2021-07-12 18:37:59,540 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 455
[INFO] 2021-07-12 18:37:59,540 [run_pretraining.py:  558]:	worker_index: 7, step: 455, cost: 9.151969, mlm loss: 9.151969, speed: 1.106870 steps/s, speed: 8.854956 samples/s, speed: 4533.737727 tokens/s, learning rate: 4.540e-06, loss_scalings: 13421.773438, pp_loss: 8.939701
[INFO] 2021-07-12 18:37:59,540 [run_pretraining.py:  512]:	********exe.run_455******* 
[INFO] 2021-07-12 18:38:00,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:00,449 [run_pretraining.py:  534]:	loss/total_loss, 9.129837036132812, 456
[INFO] 2021-07-12 18:38:00,449 [run_pretraining.py:  535]:	loss/mlm_loss, 9.129837036132812, 456
[INFO] 2021-07-12 18:38:00,449 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.5499996303988155e-06, 456
[INFO] 2021-07-12 18:38:00,449 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 456
[INFO] 2021-07-12 18:38:00,449 [run_pretraining.py:  558]:	worker_index: 7, step: 456, cost: 9.129837, mlm loss: 9.129837, speed: 1.100614 steps/s, speed: 8.804915 samples/s, speed: 4508.116688 tokens/s, learning rate: 4.550e-06, loss_scalings: 13421.773438, pp_loss: 9.062430
[INFO] 2021-07-12 18:38:00,449 [run_pretraining.py:  512]:	********exe.run_456******* 
[INFO] 2021-07-12 18:38:01,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:01,355 [run_pretraining.py:  534]:	loss/total_loss, 9.40687370300293, 457
[INFO] 2021-07-12 18:38:01,355 [run_pretraining.py:  535]:	loss/mlm_loss, 9.40687370300293, 457
[INFO] 2021-07-12 18:38:01,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.55999997939216e-06, 457
[INFO] 2021-07-12 18:38:01,355 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 457
[INFO] 2021-07-12 18:38:01,355 [run_pretraining.py:  558]:	worker_index: 7, step: 457, cost: 9.406874, mlm loss: 9.406874, speed: 1.104402 steps/s, speed: 8.835213 samples/s, speed: 4523.628816 tokens/s, learning rate: 4.560e-06, loss_scalings: 13421.773438, pp_loss: 9.224949
[INFO] 2021-07-12 18:38:01,355 [run_pretraining.py:  512]:	********exe.run_457******* 
[INFO] 2021-07-12 18:38:02,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:02,261 [run_pretraining.py:  534]:	loss/total_loss, 8.483593940734863, 458
[INFO] 2021-07-12 18:38:02,261 [run_pretraining.py:  535]:	loss/mlm_loss, 8.483593940734863, 458
[INFO] 2021-07-12 18:38:02,261 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.569999873638153e-06, 458
[INFO] 2021-07-12 18:38:02,261 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 458
[INFO] 2021-07-12 18:38:02,262 [run_pretraining.py:  558]:	worker_index: 7, step: 458, cost: 8.483594, mlm loss: 8.483594, speed: 1.104089 steps/s, speed: 8.832715 samples/s, speed: 4522.349919 tokens/s, learning rate: 4.570e-06, loss_scalings: 13421.773438, pp_loss: 9.147734
[INFO] 2021-07-12 18:38:02,262 [run_pretraining.py:  512]:	********exe.run_458******* 
[INFO] 2021-07-12 18:38:03,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:03,176 [run_pretraining.py:  534]:	loss/total_loss, 8.667398452758789, 459
[INFO] 2021-07-12 18:38:03,176 [run_pretraining.py:  535]:	loss/mlm_loss, 8.667398452758789, 459
[INFO] 2021-07-12 18:38:03,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.579999767884146e-06, 459
[INFO] 2021-07-12 18:38:03,176 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 459
[INFO] 2021-07-12 18:38:03,176 [run_pretraining.py:  558]:	worker_index: 7, step: 459, cost: 8.667398, mlm loss: 8.667398, speed: 1.093896 steps/s, speed: 8.751169 samples/s, speed: 4480.598492 tokens/s, learning rate: 4.580e-06, loss_scalings: 13421.773438, pp_loss: 9.082470
[INFO] 2021-07-12 18:38:03,176 [run_pretraining.py:  512]:	********exe.run_459******* 
[INFO] 2021-07-12 18:38:04,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  534]:	loss/total_loss, 9.142827033996582, 460
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  535]:	loss/mlm_loss, 9.142827033996582, 460
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.58999966213014e-06, 460
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 460
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  558]:	worker_index: 7, step: 460, cost: 9.142827, mlm loss: 9.142827, speed: 1.100967 steps/s, speed: 8.807733 samples/s, speed: 4509.559179 tokens/s, learning rate: 4.590e-06, loss_scalings: 13421.773438, pp_loss: 9.237358
[INFO] 2021-07-12 18:38:04,085 [run_pretraining.py:  512]:	********exe.run_460******* 
[INFO] 2021-07-12 18:38:04,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:04,988 [run_pretraining.py:  534]:	loss/total_loss, 9.00829792022705, 461
[INFO] 2021-07-12 18:38:04,988 [run_pretraining.py:  535]:	loss/mlm_loss, 9.00829792022705, 461
[INFO] 2021-07-12 18:38:04,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.600000011123484e-06, 461
[INFO] 2021-07-12 18:38:04,989 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 461
[INFO] 2021-07-12 18:38:04,989 [run_pretraining.py:  558]:	worker_index: 7, step: 461, cost: 9.008298, mlm loss: 9.008298, speed: 1.107820 steps/s, speed: 8.862560 samples/s, speed: 4537.630711 tokens/s, learning rate: 4.600e-06, loss_scalings: 13421.773438, pp_loss: 8.975285
[INFO] 2021-07-12 18:38:04,989 [run_pretraining.py:  512]:	********exe.run_461******* 
[INFO] 2021-07-12 18:38:05,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:05,898 [run_pretraining.py:  534]:	loss/total_loss, 9.4596529006958, 462
[INFO] 2021-07-12 18:38:05,899 [run_pretraining.py:  535]:	loss/mlm_loss, 9.4596529006958, 462
[INFO] 2021-07-12 18:38:05,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.609999905369477e-06, 462
[INFO] 2021-07-12 18:38:05,899 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 462
[INFO] 2021-07-12 18:38:05,899 [run_pretraining.py:  558]:	worker_index: 7, step: 462, cost: 9.459653, mlm loss: 9.459653, speed: 1.099508 steps/s, speed: 8.796066 samples/s, speed: 4503.585774 tokens/s, learning rate: 4.610e-06, loss_scalings: 13421.773438, pp_loss: 9.269262
[INFO] 2021-07-12 18:38:05,899 [run_pretraining.py:  512]:	********exe.run_462******* 
[INFO] 2021-07-12 18:38:06,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:06,811 [run_pretraining.py:  534]:	loss/total_loss, 9.196955680847168, 463
[INFO] 2021-07-12 18:38:06,811 [run_pretraining.py:  535]:	loss/mlm_loss, 9.196955680847168, 463
[INFO] 2021-07-12 18:38:06,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.619999799615471e-06, 463
[INFO] 2021-07-12 18:38:06,811 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 463
[INFO] 2021-07-12 18:38:06,811 [run_pretraining.py:  558]:	worker_index: 7, step: 463, cost: 9.196956, mlm loss: 9.196956, speed: 1.096543 steps/s, speed: 8.772343 samples/s, speed: 4491.439712 tokens/s, learning rate: 4.620e-06, loss_scalings: 13421.773438, pp_loss: 9.140714
[INFO] 2021-07-12 18:38:06,811 [run_pretraining.py:  512]:	********exe.run_463******* 
[INFO] 2021-07-12 18:38:07,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:07,720 [run_pretraining.py:  534]:	loss/total_loss, 8.886672973632812, 464
[INFO] 2021-07-12 18:38:07,720 [run_pretraining.py:  535]:	loss/mlm_loss, 8.886672973632812, 464
[INFO] 2021-07-12 18:38:07,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.630000148608815e-06, 464
[INFO] 2021-07-12 18:38:07,720 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 464
[INFO] 2021-07-12 18:38:07,721 [run_pretraining.py:  558]:	worker_index: 7, step: 464, cost: 8.886673, mlm loss: 8.886673, speed: 1.100657 steps/s, speed: 8.805253 samples/s, speed: 4508.289407 tokens/s, learning rate: 4.630e-06, loss_scalings: 13421.773438, pp_loss: 9.253244
[INFO] 2021-07-12 18:38:07,721 [run_pretraining.py:  512]:	********exe.run_464******* 
[INFO] 2021-07-12 18:38:08,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:08,629 [run_pretraining.py:  534]:	loss/total_loss, 9.128161430358887, 465
[INFO] 2021-07-12 18:38:08,629 [run_pretraining.py:  535]:	loss/mlm_loss, 9.128161430358887, 465
[INFO] 2021-07-12 18:38:08,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.640000042854808e-06, 465
[INFO] 2021-07-12 18:38:08,629 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 465
[INFO] 2021-07-12 18:38:08,629 [run_pretraining.py:  558]:	worker_index: 7, step: 465, cost: 9.128161, mlm loss: 9.128161, speed: 1.101042 steps/s, speed: 8.808334 samples/s, speed: 4509.866967 tokens/s, learning rate: 4.640e-06, loss_scalings: 13421.773438, pp_loss: 9.055675
[INFO] 2021-07-12 18:38:08,630 [run_pretraining.py:  512]:	********exe.run_465******* 
[INFO] 2021-07-12 18:38:09,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:09,540 [run_pretraining.py:  534]:	loss/total_loss, 9.063712120056152, 466
[INFO] 2021-07-12 18:38:09,540 [run_pretraining.py:  535]:	loss/mlm_loss, 9.063712120056152, 466
[INFO] 2021-07-12 18:38:09,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.649999937100802e-06, 466
[INFO] 2021-07-12 18:38:09,541 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 466
[INFO] 2021-07-12 18:38:09,541 [run_pretraining.py:  558]:	worker_index: 7, step: 466, cost: 9.063712, mlm loss: 9.063712, speed: 1.098210 steps/s, speed: 8.785684 samples/s, speed: 4498.269982 tokens/s, learning rate: 4.650e-06, loss_scalings: 13421.773438, pp_loss: 9.233523
[INFO] 2021-07-12 18:38:09,541 [run_pretraining.py:  512]:	********exe.run_466******* 
[INFO] 2021-07-12 18:38:10,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:10,447 [run_pretraining.py:  534]:	loss/total_loss, 9.095606803894043, 467
[INFO] 2021-07-12 18:38:10,447 [run_pretraining.py:  535]:	loss/mlm_loss, 9.095606803894043, 467
[INFO] 2021-07-12 18:38:10,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.659999831346795e-06, 467
[INFO] 2021-07-12 18:38:10,447 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 467
[INFO] 2021-07-12 18:38:10,447 [run_pretraining.py:  558]:	worker_index: 7, step: 467, cost: 9.095607, mlm loss: 9.095607, speed: 1.103638 steps/s, speed: 8.829105 samples/s, speed: 4520.501917 tokens/s, learning rate: 4.660e-06, loss_scalings: 13421.773438, pp_loss: 9.286056
[INFO] 2021-07-12 18:38:10,448 [run_pretraining.py:  512]:	********exe.run_467******* 
[INFO] 2021-07-12 18:38:11,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:11,359 [run_pretraining.py:  534]:	loss/total_loss, 9.212087631225586, 468
[INFO] 2021-07-12 18:38:11,359 [run_pretraining.py:  535]:	loss/mlm_loss, 9.212087631225586, 468
[INFO] 2021-07-12 18:38:11,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.670000180340139e-06, 468
[INFO] 2021-07-12 18:38:11,360 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 468
[INFO] 2021-07-12 18:38:11,360 [run_pretraining.py:  558]:	worker_index: 7, step: 468, cost: 9.212088, mlm loss: 9.212088, speed: 1.097125 steps/s, speed: 8.777004 samples/s, speed: 4493.825830 tokens/s, learning rate: 4.670e-06, loss_scalings: 13421.773438, pp_loss: 8.463196
[INFO] 2021-07-12 18:38:11,360 [run_pretraining.py:  512]:	********exe.run_468******* 
[INFO] 2021-07-12 18:38:12,269 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:12,270 [run_pretraining.py:  534]:	loss/total_loss, 9.44782829284668, 469
[INFO] 2021-07-12 18:38:12,270 [run_pretraining.py:  535]:	loss/mlm_loss, 9.44782829284668, 469
[INFO] 2021-07-12 18:38:12,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.679999619838782e-06, 469
[INFO] 2021-07-12 18:38:12,270 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 469
[INFO] 2021-07-12 18:38:12,270 [run_pretraining.py:  558]:	worker_index: 7, step: 469, cost: 9.447828, mlm loss: 9.447828, speed: 1.098786 steps/s, speed: 8.790284 samples/s, speed: 4500.625635 tokens/s, learning rate: 4.680e-06, loss_scalings: 13421.773438, pp_loss: 9.253613
[INFO] 2021-07-12 18:38:12,270 [run_pretraining.py:  512]:	********exe.run_469******* 
[INFO] 2021-07-12 18:38:13,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:13,181 [run_pretraining.py:  534]:	loss/total_loss, 9.035722732543945, 470
[INFO] 2021-07-12 18:38:13,181 [run_pretraining.py:  535]:	loss/mlm_loss, 9.035722732543945, 470
[INFO] 2021-07-12 18:38:13,181 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.689999968832126e-06, 470
[INFO] 2021-07-12 18:38:13,181 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 470
[INFO] 2021-07-12 18:38:13,181 [run_pretraining.py:  558]:	worker_index: 7, step: 470, cost: 9.035723, mlm loss: 9.035723, speed: 1.098957 steps/s, speed: 8.791653 samples/s, speed: 4501.326089 tokens/s, learning rate: 4.690e-06, loss_scalings: 13421.773438, pp_loss: 9.425982
[INFO] 2021-07-12 18:38:13,181 [run_pretraining.py:  512]:	********exe.run_470******* 
[INFO] 2021-07-12 18:38:14,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:14,086 [run_pretraining.py:  534]:	loss/total_loss, 9.038187026977539, 471
[INFO] 2021-07-12 18:38:14,086 [run_pretraining.py:  535]:	loss/mlm_loss, 9.038187026977539, 471
[INFO] 2021-07-12 18:38:14,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.699999863078119e-06, 471
[INFO] 2021-07-12 18:38:14,086 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 471
[INFO] 2021-07-12 18:38:14,086 [run_pretraining.py:  558]:	worker_index: 7, step: 471, cost: 9.038187, mlm loss: 9.038187, speed: 1.105823 steps/s, speed: 8.846585 samples/s, speed: 4529.451330 tokens/s, learning rate: 4.700e-06, loss_scalings: 13421.773438, pp_loss: 9.198651
[INFO] 2021-07-12 18:38:14,086 [run_pretraining.py:  512]:	********exe.run_471******* 
[INFO] 2021-07-12 18:38:15,004 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:15,004 [run_pretraining.py:  534]:	loss/total_loss, 8.739740371704102, 472
[INFO] 2021-07-12 18:38:15,004 [run_pretraining.py:  535]:	loss/mlm_loss, 8.739740371704102, 472
[INFO] 2021-07-12 18:38:15,004 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.709999757324113e-06, 472
[INFO] 2021-07-12 18:38:15,004 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 472
[INFO] 2021-07-12 18:38:15,004 [run_pretraining.py:  558]:	worker_index: 7, step: 472, cost: 8.739740, mlm loss: 8.739740, speed: 1.089479 steps/s, speed: 8.715829 samples/s, speed: 4462.504207 tokens/s, learning rate: 4.710e-06, loss_scalings: 13421.773438, pp_loss: 9.013796
[INFO] 2021-07-12 18:38:15,005 [run_pretraining.py:  512]:	********exe.run_472******* 
[INFO] 2021-07-12 18:38:15,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:15,949 [run_pretraining.py:  534]:	loss/total_loss, 8.734580039978027, 473
[INFO] 2021-07-12 18:38:15,949 [run_pretraining.py:  535]:	loss/mlm_loss, 8.734580039978027, 473
[INFO] 2021-07-12 18:38:15,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.720000106317457e-06, 473
[INFO] 2021-07-12 18:38:15,949 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 473
[INFO] 2021-07-12 18:38:15,949 [run_pretraining.py:  558]:	worker_index: 7, step: 473, cost: 8.734580, mlm loss: 8.734580, speed: 1.059563 steps/s, speed: 8.476505 samples/s, speed: 4339.970621 tokens/s, learning rate: 4.720e-06, loss_scalings: 13421.773438, pp_loss: 8.912859
[INFO] 2021-07-12 18:38:15,949 [run_pretraining.py:  512]:	********exe.run_473******* 
[INFO] 2021-07-12 18:38:16,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:16,853 [run_pretraining.py:  534]:	loss/total_loss, 9.591765403747559, 474
[INFO] 2021-07-12 18:38:16,853 [run_pretraining.py:  535]:	loss/mlm_loss, 9.591765403747559, 474
[INFO] 2021-07-12 18:38:16,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.73000000056345e-06, 474
[INFO] 2021-07-12 18:38:16,853 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 474
[INFO] 2021-07-12 18:38:16,853 [run_pretraining.py:  558]:	worker_index: 7, step: 474, cost: 9.591765, mlm loss: 9.591765, speed: 1.106371 steps/s, speed: 8.850972 samples/s, speed: 4531.697509 tokens/s, learning rate: 4.730e-06, loss_scalings: 13421.773438, pp_loss: 9.276744
[INFO] 2021-07-12 18:38:16,853 [run_pretraining.py:  512]:	********exe.run_474******* 
[INFO] 2021-07-12 18:38:17,759 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:17,759 [run_pretraining.py:  534]:	loss/total_loss, 9.708029747009277, 475
[INFO] 2021-07-12 18:38:17,760 [run_pretraining.py:  535]:	loss/mlm_loss, 9.708029747009277, 475
[INFO] 2021-07-12 18:38:17,760 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7399998948094435e-06, 475
[INFO] 2021-07-12 18:38:17,760 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 475
[INFO] 2021-07-12 18:38:17,760 [run_pretraining.py:  558]:	worker_index: 7, step: 475, cost: 9.708030, mlm loss: 9.708030, speed: 1.104050 steps/s, speed: 8.832403 samples/s, speed: 4522.190406 tokens/s, learning rate: 4.740e-06, loss_scalings: 13421.773438, pp_loss: 9.139967
[INFO] 2021-07-12 18:38:17,760 [run_pretraining.py:  512]:	********exe.run_475******* 
[INFO] 2021-07-12 18:38:18,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:18,676 [run_pretraining.py:  534]:	loss/total_loss, 9.182856559753418, 476
[INFO] 2021-07-12 18:38:18,676 [run_pretraining.py:  535]:	loss/mlm_loss, 9.182856559753418, 476
[INFO] 2021-07-12 18:38:18,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.749999789055437e-06, 476
[INFO] 2021-07-12 18:38:18,676 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 476
[INFO] 2021-07-12 18:38:18,676 [run_pretraining.py:  558]:	worker_index: 7, step: 476, cost: 9.182857, mlm loss: 9.182857, speed: 1.091667 steps/s, speed: 8.733335 samples/s, speed: 4471.467289 tokens/s, learning rate: 4.750e-06, loss_scalings: 13421.773438, pp_loss: 8.980177
[INFO] 2021-07-12 18:38:18,677 [run_pretraining.py:  512]:	********exe.run_476******* 
[INFO] 2021-07-12 18:38:19,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:19,588 [run_pretraining.py:  534]:	loss/total_loss, 8.87927532196045, 477
[INFO] 2021-07-12 18:38:19,589 [run_pretraining.py:  535]:	loss/mlm_loss, 8.87927532196045, 477
[INFO] 2021-07-12 18:38:19,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.760000138048781e-06, 477
[INFO] 2021-07-12 18:38:19,589 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 477
[INFO] 2021-07-12 18:38:19,589 [run_pretraining.py:  558]:	worker_index: 7, step: 477, cost: 8.879275, mlm loss: 8.879275, speed: 1.096905 steps/s, speed: 8.775241 samples/s, speed: 4492.923248 tokens/s, learning rate: 4.760e-06, loss_scalings: 13421.773438, pp_loss: 9.088934
[INFO] 2021-07-12 18:38:19,589 [run_pretraining.py:  512]:	********exe.run_477******* 
[INFO] 2021-07-12 18:38:20,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:20,504 [run_pretraining.py:  534]:	loss/total_loss, 8.833267211914062, 478
[INFO] 2021-07-12 18:38:20,504 [run_pretraining.py:  535]:	loss/mlm_loss, 8.833267211914062, 478
[INFO] 2021-07-12 18:38:20,504 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7699995775474235e-06, 478
[INFO] 2021-07-12 18:38:20,504 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 478
[INFO] 2021-07-12 18:38:20,504 [run_pretraining.py:  558]:	worker_index: 7, step: 478, cost: 8.833267, mlm loss: 8.833267, speed: 1.093332 steps/s, speed: 8.746654 samples/s, speed: 4478.287098 tokens/s, learning rate: 4.770e-06, loss_scalings: 13421.773438, pp_loss: 8.860376
[INFO] 2021-07-12 18:38:20,504 [run_pretraining.py:  512]:	********exe.run_478******* 
[INFO] 2021-07-12 18:38:21,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:21,424 [run_pretraining.py:  534]:	loss/total_loss, 9.022330284118652, 479
[INFO] 2021-07-12 18:38:21,424 [run_pretraining.py:  535]:	loss/mlm_loss, 9.022330284118652, 479
[INFO] 2021-07-12 18:38:21,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.779999926540768e-06, 479
[INFO] 2021-07-12 18:38:21,425 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 479
[INFO] 2021-07-12 18:38:21,425 [run_pretraining.py:  558]:	worker_index: 7, step: 479, cost: 9.022330, mlm loss: 9.022330, speed: 1.087004 steps/s, speed: 8.696035 samples/s, speed: 4452.369696 tokens/s, learning rate: 4.780e-06, loss_scalings: 13421.773438, pp_loss: 8.954913
[INFO] 2021-07-12 18:38:21,425 [run_pretraining.py:  512]:	********exe.run_479******* 
[INFO] 2021-07-12 18:38:22,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:22,334 [run_pretraining.py:  534]:	loss/total_loss, 9.136513710021973, 480
[INFO] 2021-07-12 18:38:22,334 [run_pretraining.py:  535]:	loss/mlm_loss, 9.136513710021973, 480
[INFO] 2021-07-12 18:38:22,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.789999820786761e-06, 480
[INFO] 2021-07-12 18:38:22,334 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 480
[INFO] 2021-07-12 18:38:22,334 [run_pretraining.py:  558]:	worker_index: 7, step: 480, cost: 9.136514, mlm loss: 9.136514, speed: 1.100010 steps/s, speed: 8.800080 samples/s, speed: 4505.640928 tokens/s, learning rate: 4.790e-06, loss_scalings: 13421.773438, pp_loss: 9.100287
[INFO] 2021-07-12 18:38:22,334 [run_pretraining.py:  512]:	********exe.run_480******* 
[INFO] 2021-07-12 18:38:23,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:23,242 [run_pretraining.py:  534]:	loss/total_loss, 9.120264053344727, 481
[INFO] 2021-07-12 18:38:23,242 [run_pretraining.py:  535]:	loss/mlm_loss, 9.120264053344727, 481
[INFO] 2021-07-12 18:38:23,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.7999997150327545e-06, 481
[INFO] 2021-07-12 18:38:23,242 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 481
[INFO] 2021-07-12 18:38:23,242 [run_pretraining.py:  558]:	worker_index: 7, step: 481, cost: 9.120264, mlm loss: 9.120264, speed: 1.102380 steps/s, speed: 8.819039 samples/s, speed: 4515.347880 tokens/s, learning rate: 4.800e-06, loss_scalings: 13421.773438, pp_loss: 9.168803
[INFO] 2021-07-12 18:38:23,242 [run_pretraining.py:  512]:	********exe.run_481******* 
[INFO] 2021-07-12 18:38:24,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:24,142 [run_pretraining.py:  534]:	loss/total_loss, 8.422966003417969, 482
[INFO] 2021-07-12 18:38:24,142 [run_pretraining.py:  535]:	loss/mlm_loss, 8.422966003417969, 482
[INFO] 2021-07-12 18:38:24,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.809999609278748e-06, 482
[INFO] 2021-07-12 18:38:24,142 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 482
[INFO] 2021-07-12 18:38:24,142 [run_pretraining.py:  558]:	worker_index: 7, step: 482, cost: 8.422966, mlm loss: 8.422966, speed: 1.111721 steps/s, speed: 8.893770 samples/s, speed: 4553.610071 tokens/s, learning rate: 4.810e-06, loss_scalings: 13421.773438, pp_loss: 8.911927
[INFO] 2021-07-12 18:38:24,142 [run_pretraining.py:  512]:	********exe.run_482******* 
[INFO] 2021-07-12 18:38:25,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:25,049 [run_pretraining.py:  534]:	loss/total_loss, 9.246358871459961, 483
[INFO] 2021-07-12 18:38:25,049 [run_pretraining.py:  535]:	loss/mlm_loss, 9.246358871459961, 483
[INFO] 2021-07-12 18:38:25,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.819999958272092e-06, 483
[INFO] 2021-07-12 18:38:25,049 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 483
[INFO] 2021-07-12 18:38:25,049 [run_pretraining.py:  558]:	worker_index: 7, step: 483, cost: 9.246359, mlm loss: 9.246359, speed: 1.103904 steps/s, speed: 8.831229 samples/s, speed: 4521.589354 tokens/s, learning rate: 4.820e-06, loss_scalings: 13421.773438, pp_loss: 9.015511
[INFO] 2021-07-12 18:38:25,049 [run_pretraining.py:  512]:	********exe.run_483******* 
[INFO] 2021-07-12 18:38:25,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:25,958 [run_pretraining.py:  534]:	loss/total_loss, 6.492319583892822, 484
[INFO] 2021-07-12 18:38:25,958 [run_pretraining.py:  535]:	loss/mlm_loss, 6.492319583892822, 484
[INFO] 2021-07-12 18:38:25,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.829999852518085e-06, 484
[INFO] 2021-07-12 18:38:25,958 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 484
[INFO] 2021-07-12 18:38:25,958 [run_pretraining.py:  558]:	worker_index: 7, step: 484, cost: 6.492320, mlm loss: 6.492320, speed: 1.100896 steps/s, speed: 8.807171 samples/s, speed: 4509.271554 tokens/s, learning rate: 4.830e-06, loss_scalings: 13421.773438, pp_loss: 8.284316
[INFO] 2021-07-12 18:38:25,958 [run_pretraining.py:  512]:	********exe.run_484******* 
[INFO] 2021-07-12 18:38:51,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  534]:	loss/total_loss, 8.557319641113281, 485
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  535]:	loss/mlm_loss, 8.557319641113281, 485
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.839999746764079e-06, 485
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 485
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  558]:	worker_index: 7, step: 485, cost: 8.557320, mlm loss: 8.557320, speed: 0.038694 steps/s, speed: 0.309556 samples/s, speed: 158.492580 tokens/s, learning rate: 4.840e-06, loss_scalings: 13421.773438, pp_loss: 8.004218
[INFO] 2021-07-12 18:38:51,802 [run_pretraining.py:  512]:	********exe.run_485******* 
[INFO] 2021-07-12 18:38:52,697 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  534]:	loss/total_loss, 8.973308563232422, 486
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  535]:	loss/mlm_loss, 8.973308563232422, 486
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.850000095757423e-06, 486
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 486
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  558]:	worker_index: 7, step: 486, cost: 8.973309, mlm loss: 8.973309, speed: 1.116845 steps/s, speed: 8.934763 samples/s, speed: 4574.598797 tokens/s, learning rate: 4.850e-06, loss_scalings: 13421.773438, pp_loss: 9.013618
[INFO] 2021-07-12 18:38:52,698 [run_pretraining.py:  512]:	********exe.run_486******* 
[INFO] 2021-07-12 18:39:19,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:19,139 [run_pretraining.py:  534]:	loss/total_loss, 9.033770561218262, 487
[INFO] 2021-07-12 18:39:19,139 [run_pretraining.py:  535]:	loss/mlm_loss, 9.033770561218262, 487
[INFO] 2021-07-12 18:39:19,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.859999990003416e-06, 487
[INFO] 2021-07-12 18:39:19,140 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 487
[INFO] 2021-07-12 18:39:19,140 [run_pretraining.py:  558]:	worker_index: 7, step: 487, cost: 9.033771, mlm loss: 9.033771, speed: 0.037820 steps/s, speed: 0.302562 samples/s, speed: 154.911817 tokens/s, learning rate: 4.860e-06, loss_scalings: 13421.773438, pp_loss: 8.915071
[INFO] 2021-07-12 18:39:19,140 [run_pretraining.py:  512]:	********exe.run_487******* 
[INFO] 2021-07-12 18:39:44,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  534]:	loss/total_loss, 8.799392700195312, 488
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  535]:	loss/mlm_loss, 8.799392700195312, 488
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.86999988424941e-06, 488
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 488
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  558]:	worker_index: 7, step: 488, cost: 8.799393, mlm loss: 8.799393, speed: 0.039449 steps/s, speed: 0.315594 samples/s, speed: 161.584151 tokens/s, learning rate: 4.870e-06, loss_scalings: 13421.773438, pp_loss: 8.963571
[INFO] 2021-07-12 18:39:44,489 [run_pretraining.py:  512]:	********exe.run_488******* 
[INFO] 2021-07-12 18:39:45,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:45,404 [run_pretraining.py:  534]:	loss/total_loss, 8.650259017944336, 489
[INFO] 2021-07-12 18:39:45,404 [run_pretraining.py:  535]:	loss/mlm_loss, 8.650259017944336, 489
[INFO] 2021-07-12 18:39:45,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.879999778495403e-06, 489
[INFO] 2021-07-12 18:39:45,404 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 489
[INFO] 2021-07-12 18:39:45,404 [run_pretraining.py:  558]:	worker_index: 7, step: 489, cost: 8.650259, mlm loss: 8.650259, speed: 1.094023 steps/s, speed: 8.752180 samples/s, speed: 4481.116225 tokens/s, learning rate: 4.880e-06, loss_scalings: 13421.773438, pp_loss: 8.734764
[INFO] 2021-07-12 18:39:45,404 [run_pretraining.py:  512]:	********exe.run_489******* 
[INFO] 2021-07-12 18:39:46,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:46,311 [run_pretraining.py:  534]:	loss/total_loss, 8.33222770690918, 490
[INFO] 2021-07-12 18:39:46,311 [run_pretraining.py:  535]:	loss/mlm_loss, 8.33222770690918, 490
[INFO] 2021-07-12 18:39:46,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.890000127488747e-06, 490
[INFO] 2021-07-12 18:39:46,311 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 490
[INFO] 2021-07-12 18:39:46,311 [run_pretraining.py:  558]:	worker_index: 7, step: 490, cost: 8.332228, mlm loss: 8.332228, speed: 1.103465 steps/s, speed: 8.827716 samples/s, speed: 4519.790726 tokens/s, learning rate: 4.890e-06, loss_scalings: 13421.773438, pp_loss: 8.710332
[INFO] 2021-07-12 18:39:46,311 [run_pretraining.py:  512]:	********exe.run_490******* 
[INFO] 2021-07-12 18:39:47,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:47,221 [run_pretraining.py:  534]:	loss/total_loss, 9.26357650756836, 491
[INFO] 2021-07-12 18:39:47,221 [run_pretraining.py:  535]:	loss/mlm_loss, 9.26357650756836, 491
[INFO] 2021-07-12 18:39:47,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.89999956698739e-06, 491
[INFO] 2021-07-12 18:39:47,221 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 491
[INFO] 2021-07-12 18:39:47,221 [run_pretraining.py:  558]:	worker_index: 7, step: 491, cost: 9.263577, mlm loss: 9.263577, speed: 1.099484 steps/s, speed: 8.795872 samples/s, speed: 4503.486607 tokens/s, learning rate: 4.900e-06, loss_scalings: 13421.773438, pp_loss: 8.837785
[INFO] 2021-07-12 18:39:47,221 [run_pretraining.py:  512]:	********exe.run_491******* 
[INFO] 2021-07-12 18:39:48,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:48,119 [run_pretraining.py:  534]:	loss/total_loss, 9.437694549560547, 492
[INFO] 2021-07-12 18:39:48,119 [run_pretraining.py:  535]:	loss/mlm_loss, 9.437694549560547, 492
[INFO] 2021-07-12 18:39:48,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.909999915980734e-06, 492
[INFO] 2021-07-12 18:39:48,119 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 492
[INFO] 2021-07-12 18:39:48,119 [run_pretraining.py:  558]:	worker_index: 7, step: 492, cost: 9.437695, mlm loss: 9.437695, speed: 1.113977 steps/s, speed: 8.911814 samples/s, speed: 4562.848722 tokens/s, learning rate: 4.910e-06, loss_scalings: 13421.773438, pp_loss: 8.981108
[INFO] 2021-07-12 18:39:48,120 [run_pretraining.py:  512]:	********exe.run_492******* 
[INFO] 2021-07-12 18:39:49,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:49,036 [run_pretraining.py:  534]:	loss/total_loss, 7.617962837219238, 493
[INFO] 2021-07-12 18:39:49,036 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617962837219238, 493
[INFO] 2021-07-12 18:39:49,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.919999810226727e-06, 493
[INFO] 2021-07-12 18:39:49,036 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 493
[INFO] 2021-07-12 18:39:49,037 [run_pretraining.py:  558]:	worker_index: 7, step: 493, cost: 7.617963, mlm loss: 7.617963, speed: 1.091198 steps/s, speed: 8.729588 samples/s, speed: 4469.548997 tokens/s, learning rate: 4.920e-06, loss_scalings: 13421.773438, pp_loss: 8.729748
[INFO] 2021-07-12 18:39:49,037 [run_pretraining.py:  512]:	********exe.run_493******* 
[INFO] 2021-07-12 18:39:49,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:49,941 [run_pretraining.py:  534]:	loss/total_loss, 9.023852348327637, 494
[INFO] 2021-07-12 18:39:49,941 [run_pretraining.py:  535]:	loss/mlm_loss, 9.023852348327637, 494
[INFO] 2021-07-12 18:39:49,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.929999704472721e-06, 494
[INFO] 2021-07-12 18:39:49,941 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 494
[INFO] 2021-07-12 18:39:49,941 [run_pretraining.py:  558]:	worker_index: 7, step: 494, cost: 9.023852, mlm loss: 9.023852, speed: 1.106335 steps/s, speed: 8.850682 samples/s, speed: 4531.549288 tokens/s, learning rate: 4.930e-06, loss_scalings: 13421.773438, pp_loss: 9.147938
[INFO] 2021-07-12 18:39:49,941 [run_pretraining.py:  512]:	********exe.run_494******* 
[INFO] 2021-07-12 18:39:50,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:50,845 [run_pretraining.py:  534]:	loss/total_loss, 9.055974960327148, 495
[INFO] 2021-07-12 18:39:50,845 [run_pretraining.py:  535]:	loss/mlm_loss, 9.055974960327148, 495
[INFO] 2021-07-12 18:39:50,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.940000053466065e-06, 495
[INFO] 2021-07-12 18:39:50,845 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 495
[INFO] 2021-07-12 18:39:50,845 [run_pretraining.py:  558]:	worker_index: 7, step: 495, cost: 9.055975, mlm loss: 9.055975, speed: 1.107189 steps/s, speed: 8.857514 samples/s, speed: 4535.047016 tokens/s, learning rate: 4.940e-06, loss_scalings: 13421.773438, pp_loss: 8.969555
[INFO] 2021-07-12 18:39:50,845 [run_pretraining.py:  512]:	********exe.run_495******* 
[INFO] 2021-07-12 18:39:51,749 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:51,749 [run_pretraining.py:  534]:	loss/total_loss, 9.030019760131836, 496
[INFO] 2021-07-12 18:39:51,749 [run_pretraining.py:  535]:	loss/mlm_loss, 9.030019760131836, 496
[INFO] 2021-07-12 18:39:51,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.949999947712058e-06, 496
[INFO] 2021-07-12 18:39:51,750 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 496
[INFO] 2021-07-12 18:39:51,750 [run_pretraining.py:  558]:	worker_index: 7, step: 496, cost: 9.030020, mlm loss: 9.030020, speed: 1.106020 steps/s, speed: 8.848162 samples/s, speed: 4530.258742 tokens/s, learning rate: 4.950e-06, loss_scalings: 13421.773438, pp_loss: 8.947226
[INFO] 2021-07-12 18:39:51,750 [run_pretraining.py:  512]:	********exe.run_496******* 
[INFO] 2021-07-12 18:39:52,660 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:52,660 [run_pretraining.py:  534]:	loss/total_loss, 8.900141716003418, 497
[INFO] 2021-07-12 18:39:52,661 [run_pretraining.py:  535]:	loss/mlm_loss, 8.900141716003418, 497
[INFO] 2021-07-12 18:39:52,661 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9599998419580515e-06, 497
[INFO] 2021-07-12 18:39:52,661 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 497
[INFO] 2021-07-12 18:39:52,661 [run_pretraining.py:  558]:	worker_index: 7, step: 497, cost: 8.900142, mlm loss: 8.900142, speed: 1.098378 steps/s, speed: 8.787027 samples/s, speed: 4498.957921 tokens/s, learning rate: 4.960e-06, loss_scalings: 13421.773438, pp_loss: 8.978302
[INFO] 2021-07-12 18:39:52,661 [run_pretraining.py:  512]:	********exe.run_497******* 
[INFO] 2021-07-12 18:39:53,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:53,571 [run_pretraining.py:  534]:	loss/total_loss, 9.093589782714844, 498
[INFO] 2021-07-12 18:39:53,571 [run_pretraining.py:  535]:	loss/mlm_loss, 9.093589782714844, 498
[INFO] 2021-07-12 18:39:53,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.969999736204045e-06, 498
[INFO] 2021-07-12 18:39:53,572 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 498
[INFO] 2021-07-12 18:39:53,572 [run_pretraining.py:  558]:	worker_index: 7, step: 498, cost: 9.093590, mlm loss: 9.093590, speed: 1.098671 steps/s, speed: 8.789368 samples/s, speed: 4500.156429 tokens/s, learning rate: 4.970e-06, loss_scalings: 13421.773438, pp_loss: 8.962155
[INFO] 2021-07-12 18:39:53,572 [run_pretraining.py:  512]:	********exe.run_498******* 
[INFO] 2021-07-12 18:39:54,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:54,484 [run_pretraining.py:  534]:	loss/total_loss, 9.235183715820312, 499
[INFO] 2021-07-12 18:39:54,484 [run_pretraining.py:  535]:	loss/mlm_loss, 9.235183715820312, 499
[INFO] 2021-07-12 18:39:54,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.980000085197389e-06, 499
[INFO] 2021-07-12 18:39:54,484 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 499
[INFO] 2021-07-12 18:39:54,484 [run_pretraining.py:  558]:	worker_index: 7, step: 499, cost: 9.235184, mlm loss: 9.235184, speed: 1.096490 steps/s, speed: 8.771919 samples/s, speed: 4491.222491 tokens/s, learning rate: 4.980e-06, loss_scalings: 13421.773438, pp_loss: 9.011793
[INFO] 2021-07-12 18:39:54,484 [run_pretraining.py:  512]:	********exe.run_499******* 
[INFO] 2021-07-12 18:39:55,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:55,396 [run_pretraining.py:  534]:	loss/total_loss, 8.735689163208008, 500
[INFO] 2021-07-12 18:39:55,396 [run_pretraining.py:  535]:	loss/mlm_loss, 8.735689163208008, 500
[INFO] 2021-07-12 18:39:55,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.9899999794433825e-06, 500
[INFO] 2021-07-12 18:39:55,397 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 500
[INFO] 2021-07-12 18:39:55,397 [run_pretraining.py:  558]:	worker_index: 7, step: 500, cost: 8.735689, mlm loss: 8.735689, speed: 1.096803 steps/s, speed: 8.774422 samples/s, speed: 4492.503812 tokens/s, learning rate: 4.990e-06, loss_scalings: 13421.773438, pp_loss: 9.053295
[INFO] 2021-07-12 18:39:55,397 [run_pretraining.py:  512]:	********exe.run_500******* 
[INFO] 2021-07-12 18:39:56,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:56,302 [run_pretraining.py:  534]:	loss/total_loss, 8.89736557006836, 501
[INFO] 2021-07-12 18:39:56,302 [run_pretraining.py:  535]:	loss/mlm_loss, 8.89736557006836, 501
[INFO] 2021-07-12 18:39:56,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 4.999999873689376e-06, 501
[INFO] 2021-07-12 18:39:56,302 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 501
[INFO] 2021-07-12 18:39:56,302 [run_pretraining.py:  558]:	worker_index: 7, step: 501, cost: 8.897366, mlm loss: 8.897366, speed: 1.105170 steps/s, speed: 8.841363 samples/s, speed: 4526.777936 tokens/s, learning rate: 5.000e-06, loss_scalings: 13421.773438, pp_loss: 8.756974
[INFO] 2021-07-12 18:39:56,302 [run_pretraining.py:  512]:	********exe.run_501******* 
[INFO] 2021-07-12 18:39:57,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:57,210 [run_pretraining.py:  534]:	loss/total_loss, 8.576141357421875, 502
[INFO] 2021-07-12 18:39:57,210 [run_pretraining.py:  535]:	loss/mlm_loss, 8.576141357421875, 502
[INFO] 2021-07-12 18:39:57,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.009999767935369e-06, 502
[INFO] 2021-07-12 18:39:57,211 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 502
[INFO] 2021-07-12 18:39:57,211 [run_pretraining.py:  558]:	worker_index: 7, step: 502, cost: 8.576141, mlm loss: 8.576141, speed: 1.101592 steps/s, speed: 8.812739 samples/s, speed: 4512.122201 tokens/s, learning rate: 5.010e-06, loss_scalings: 13421.773438, pp_loss: 9.043847
[INFO] 2021-07-12 18:39:57,211 [run_pretraining.py:  512]:	********exe.run_502******* 
[INFO] 2021-07-12 18:39:58,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:58,120 [run_pretraining.py:  534]:	loss/total_loss, 8.806058883666992, 503
[INFO] 2021-07-12 18:39:58,120 [run_pretraining.py:  535]:	loss/mlm_loss, 8.806058883666992, 503
[INFO] 2021-07-12 18:39:58,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.020000116928713e-06, 503
[INFO] 2021-07-12 18:39:58,120 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 503
[INFO] 2021-07-12 18:39:58,120 [run_pretraining.py:  558]:	worker_index: 7, step: 503, cost: 8.806059, mlm loss: 8.806059, speed: 1.100305 steps/s, speed: 8.802444 samples/s, speed: 4506.851275 tokens/s, learning rate: 5.020e-06, loss_scalings: 13421.773438, pp_loss: 9.005281
[INFO] 2021-07-12 18:39:58,120 [run_pretraining.py:  512]:	********exe.run_503******* 
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  534]:	loss/total_loss, 9.290974617004395, 504
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  535]:	loss/mlm_loss, 9.290974617004395, 504
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.029999556427356e-06, 504
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 504
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  558]:	worker_index: 7, step: 504, cost: 9.290975, mlm loss: 9.290975, speed: 1.100566 steps/s, speed: 8.804530 samples/s, speed: 4507.919142 tokens/s, learning rate: 5.030e-06, loss_scalings: 13421.773438, pp_loss: 8.105735
[INFO] 2021-07-12 18:39:59,029 [run_pretraining.py:  512]:	********exe.run_504******* 
[INFO] 2021-07-12 18:39:59,934 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:39:59,934 [run_pretraining.py:  534]:	loss/total_loss, 9.331613540649414, 505
[INFO] 2021-07-12 18:39:59,934 [run_pretraining.py:  535]:	loss/mlm_loss, 9.331613540649414, 505
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.0399999054207e-06, 505
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 505
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  558]:	worker_index: 7, step: 505, cost: 9.331614, mlm loss: 9.331614, speed: 1.105394 steps/s, speed: 8.843155 samples/s, speed: 4527.695365 tokens/s, learning rate: 5.040e-06, loss_scalings: 13421.773438, pp_loss: 9.064390
[INFO] 2021-07-12 18:39:59,935 [run_pretraining.py:  512]:	********exe.run_505******* 
[INFO] 2021-07-12 18:40:00,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:00,844 [run_pretraining.py:  534]:	loss/total_loss, 8.951129913330078, 506
[INFO] 2021-07-12 18:40:00,844 [run_pretraining.py:  535]:	loss/mlm_loss, 8.951129913330078, 506
[INFO] 2021-07-12 18:40:00,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.050000254414044e-06, 506
[INFO] 2021-07-12 18:40:00,844 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 506
[INFO] 2021-07-12 18:40:00,844 [run_pretraining.py:  558]:	worker_index: 7, step: 506, cost: 8.951130, mlm loss: 8.951130, speed: 1.100355 steps/s, speed: 8.802841 samples/s, speed: 4507.054639 tokens/s, learning rate: 5.050e-06, loss_scalings: 13421.773438, pp_loss: 8.959667
[INFO] 2021-07-12 18:40:00,844 [run_pretraining.py:  512]:	********exe.run_506******* 
[INFO] 2021-07-12 18:40:01,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:01,757 [run_pretraining.py:  534]:	loss/total_loss, 6.244751453399658, 507
[INFO] 2021-07-12 18:40:01,757 [run_pretraining.py:  535]:	loss/mlm_loss, 6.244751453399658, 507
[INFO] 2021-07-12 18:40:01,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.059999693912687e-06, 507
[INFO] 2021-07-12 18:40:01,758 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 507
[INFO] 2021-07-12 18:40:01,758 [run_pretraining.py:  558]:	worker_index: 7, step: 507, cost: 6.244751, mlm loss: 6.244751, speed: 1.095420 steps/s, speed: 8.763360 samples/s, speed: 4486.840291 tokens/s, learning rate: 5.060e-06, loss_scalings: 13421.773438, pp_loss: 8.205798
[INFO] 2021-07-12 18:40:01,758 [run_pretraining.py:  512]:	********exe.run_507******* 
[INFO] 2021-07-12 18:40:02,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:02,671 [run_pretraining.py:  534]:	loss/total_loss, 8.420499801635742, 508
[INFO] 2021-07-12 18:40:02,671 [run_pretraining.py:  535]:	loss/mlm_loss, 8.420499801635742, 508
[INFO] 2021-07-12 18:40:02,671 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.070000042906031e-06, 508
[INFO] 2021-07-12 18:40:02,671 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 508
[INFO] 2021-07-12 18:40:02,672 [run_pretraining.py:  558]:	worker_index: 7, step: 508, cost: 8.420500, mlm loss: 8.420500, speed: 1.095083 steps/s, speed: 8.760667 samples/s, speed: 4485.461481 tokens/s, learning rate: 5.070e-06, loss_scalings: 13421.773438, pp_loss: 8.798714
[INFO] 2021-07-12 18:40:02,672 [run_pretraining.py:  512]:	********exe.run_508******* 
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  534]:	loss/total_loss, 8.578448295593262, 509
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  535]:	loss/mlm_loss, 8.578448295593262, 509
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.079999937152024e-06, 509
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 509
[INFO] 2021-07-12 18:40:03,576 [run_pretraining.py:  558]:	worker_index: 7, step: 509, cost: 8.578448, mlm loss: 8.578448, speed: 1.105852 steps/s, speed: 8.846813 samples/s, speed: 4529.568363 tokens/s, learning rate: 5.080e-06, loss_scalings: 13421.773438, pp_loss: 9.014196
[INFO] 2021-07-12 18:40:03,577 [run_pretraining.py:  512]:	********exe.run_509******* 
[INFO] 2021-07-12 18:40:04,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:04,484 [run_pretraining.py:  534]:	loss/total_loss, 9.162109375, 510
[INFO] 2021-07-12 18:40:04,484 [run_pretraining.py:  535]:	loss/mlm_loss, 9.162109375, 510
[INFO] 2021-07-12 18:40:04,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.089999831398018e-06, 510
[INFO] 2021-07-12 18:40:04,484 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 510
[INFO] 2021-07-12 18:40:04,484 [run_pretraining.py:  558]:	worker_index: 7, step: 510, cost: 9.162109, mlm loss: 9.162109, speed: 1.102090 steps/s, speed: 8.816724 samples/s, speed: 4514.162619 tokens/s, learning rate: 5.090e-06, loss_scalings: 13421.773438, pp_loss: 9.017548
[INFO] 2021-07-12 18:40:04,485 [run_pretraining.py:  512]:	********exe.run_510******* 
[INFO] 2021-07-12 18:40:05,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:05,417 [run_pretraining.py:  534]:	loss/total_loss, 8.694976806640625, 511
[INFO] 2021-07-12 18:40:05,417 [run_pretraining.py:  535]:	loss/mlm_loss, 8.694976806640625, 511
[INFO] 2021-07-12 18:40:05,417 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.099999725644011e-06, 511
[INFO] 2021-07-12 18:40:05,417 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 511
[INFO] 2021-07-12 18:40:05,417 [run_pretraining.py:  558]:	worker_index: 7, step: 511, cost: 8.694977, mlm loss: 8.694977, speed: 1.072644 steps/s, speed: 8.581150 samples/s, speed: 4393.548642 tokens/s, learning rate: 5.100e-06, loss_scalings: 13421.773438, pp_loss: 8.825539
[INFO] 2021-07-12 18:40:05,417 [run_pretraining.py:  512]:	********exe.run_511******* 
[INFO] 2021-07-12 18:40:06,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  534]:	loss/total_loss, 9.101755142211914, 512
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  535]:	loss/mlm_loss, 9.101755142211914, 512
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.110000074637355e-06, 512
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 512
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  558]:	worker_index: 7, step: 512, cost: 9.101755, mlm loss: 9.101755, speed: 1.075266 steps/s, speed: 8.602128 samples/s, speed: 4404.289468 tokens/s, learning rate: 5.110e-06, loss_scalings: 13421.773438, pp_loss: 9.087664
[INFO] 2021-07-12 18:40:06,348 [run_pretraining.py:  512]:	********exe.run_512******* 
[INFO] 2021-07-12 18:40:07,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:07,257 [run_pretraining.py:  534]:	loss/total_loss, 8.505959510803223, 513
[INFO] 2021-07-12 18:40:07,257 [run_pretraining.py:  535]:	loss/mlm_loss, 8.505959510803223, 513
[INFO] 2021-07-12 18:40:07,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.119999514135998e-06, 513
[INFO] 2021-07-12 18:40:07,257 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 513
[INFO] 2021-07-12 18:40:07,257 [run_pretraining.py:  558]:	worker_index: 7, step: 513, cost: 8.505960, mlm loss: 8.505960, speed: 1.100974 steps/s, speed: 8.807791 samples/s, speed: 4509.588772 tokens/s, learning rate: 5.120e-06, loss_scalings: 13421.773438, pp_loss: 8.907419
[INFO] 2021-07-12 18:40:07,257 [run_pretraining.py:  512]:	********exe.run_513******* 
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  534]:	loss/total_loss, 6.053576469421387, 514
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  535]:	loss/mlm_loss, 6.053576469421387, 514
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.129999863129342e-06, 514
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 514
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  558]:	worker_index: 7, step: 514, cost: 6.053576, mlm loss: 6.053576, speed: 1.101533 steps/s, speed: 8.812264 samples/s, speed: 4511.879276 tokens/s, learning rate: 5.130e-06, loss_scalings: 13421.773438, pp_loss: 8.364587
[INFO] 2021-07-12 18:40:08,165 [run_pretraining.py:  512]:	********exe.run_514******* 
[INFO] 2021-07-12 18:40:09,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:09,066 [run_pretraining.py:  534]:	loss/total_loss, 8.862579345703125, 515
[INFO] 2021-07-12 18:40:09,066 [run_pretraining.py:  535]:	loss/mlm_loss, 8.862579345703125, 515
[INFO] 2021-07-12 18:40:09,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.139999757375335e-06, 515
[INFO] 2021-07-12 18:40:09,066 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 515
[INFO] 2021-07-12 18:40:09,066 [run_pretraining.py:  558]:	worker_index: 7, step: 515, cost: 8.862579, mlm loss: 8.862579, speed: 1.111182 steps/s, speed: 8.889453 samples/s, speed: 4551.399999 tokens/s, learning rate: 5.140e-06, loss_scalings: 13421.773438, pp_loss: 8.941374
[INFO] 2021-07-12 18:40:09,066 [run_pretraining.py:  512]:	********exe.run_515******* 
[INFO] 2021-07-12 18:40:09,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:09,981 [run_pretraining.py:  534]:	loss/total_loss, 9.230367660522461, 516
[INFO] 2021-07-12 18:40:09,981 [run_pretraining.py:  535]:	loss/mlm_loss, 9.230367660522461, 516
[INFO] 2021-07-12 18:40:09,981 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.149999651621329e-06, 516
[INFO] 2021-07-12 18:40:09,981 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 516
[INFO] 2021-07-12 18:40:09,981 [run_pretraining.py:  558]:	worker_index: 7, step: 516, cost: 9.230368, mlm loss: 9.230368, speed: 1.093759 steps/s, speed: 8.750069 samples/s, speed: 4480.035315 tokens/s, learning rate: 5.150e-06, loss_scalings: 13421.773438, pp_loss: 8.907364
[INFO] 2021-07-12 18:40:09,981 [run_pretraining.py:  512]:	********exe.run_516******* 
[INFO] 2021-07-12 18:40:10,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:10,888 [run_pretraining.py:  534]:	loss/total_loss, 8.808979988098145, 517
[INFO] 2021-07-12 18:40:10,888 [run_pretraining.py:  535]:	loss/mlm_loss, 8.808979988098145, 517
[INFO] 2021-07-12 18:40:10,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.160000000614673e-06, 517
[INFO] 2021-07-12 18:40:10,888 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 517
[INFO] 2021-07-12 18:40:10,888 [run_pretraining.py:  558]:	worker_index: 7, step: 517, cost: 8.808980, mlm loss: 8.808980, speed: 1.103445 steps/s, speed: 8.827561 samples/s, speed: 4519.711058 tokens/s, learning rate: 5.160e-06, loss_scalings: 13421.773438, pp_loss: 8.741429
[INFO] 2021-07-12 18:40:10,888 [run_pretraining.py:  512]:	********exe.run_517******* 
[INFO] 2021-07-12 18:40:11,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:11,788 [run_pretraining.py:  534]:	loss/total_loss, 8.911523818969727, 518
[INFO] 2021-07-12 18:40:11,788 [run_pretraining.py:  535]:	loss/mlm_loss, 8.911523818969727, 518
[INFO] 2021-07-12 18:40:11,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.169999894860666e-06, 518
[INFO] 2021-07-12 18:40:11,788 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 518
[INFO] 2021-07-12 18:40:11,788 [run_pretraining.py:  558]:	worker_index: 7, step: 518, cost: 8.911524, mlm loss: 8.911524, speed: 1.111683 steps/s, speed: 8.893461 samples/s, speed: 4553.451965 tokens/s, learning rate: 5.170e-06, loss_scalings: 13421.773438, pp_loss: 8.928392
[INFO] 2021-07-12 18:40:11,788 [run_pretraining.py:  512]:	********exe.run_518******* 
[INFO] 2021-07-12 18:40:12,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:12,686 [run_pretraining.py:  534]:	loss/total_loss, 8.865405082702637, 519
[INFO] 2021-07-12 18:40:12,686 [run_pretraining.py:  535]:	loss/mlm_loss, 8.865405082702637, 519
[INFO] 2021-07-12 18:40:12,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.17999978910666e-06, 519
[INFO] 2021-07-12 18:40:12,686 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 519
[INFO] 2021-07-12 18:40:12,686 [run_pretraining.py:  558]:	worker_index: 7, step: 519, cost: 8.865405, mlm loss: 8.865405, speed: 1.114480 steps/s, speed: 8.915837 samples/s, speed: 4564.908601 tokens/s, learning rate: 5.180e-06, loss_scalings: 13421.773438, pp_loss: 8.714795
[INFO] 2021-07-12 18:40:12,686 [run_pretraining.py:  512]:	********exe.run_519******* 
[INFO] 2021-07-12 18:40:13,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:13,597 [run_pretraining.py:  534]:	loss/total_loss, 9.198861122131348, 520
[INFO] 2021-07-12 18:40:13,597 [run_pretraining.py:  535]:	loss/mlm_loss, 9.198861122131348, 520
[INFO] 2021-07-12 18:40:13,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.189999683352653e-06, 520
[INFO] 2021-07-12 18:40:13,597 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 520
[INFO] 2021-07-12 18:40:13,597 [run_pretraining.py:  558]:	worker_index: 7, step: 520, cost: 9.198861, mlm loss: 9.198861, speed: 1.098401 steps/s, speed: 8.787204 samples/s, speed: 4499.048641 tokens/s, learning rate: 5.190e-06, loss_scalings: 13421.773438, pp_loss: 8.901477
[INFO] 2021-07-12 18:40:13,597 [run_pretraining.py:  512]:	********exe.run_520******* 
[INFO] 2021-07-12 18:40:14,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:14,502 [run_pretraining.py:  534]:	loss/total_loss, 8.90471076965332, 521
[INFO] 2021-07-12 18:40:14,502 [run_pretraining.py:  535]:	loss/mlm_loss, 8.90471076965332, 521
[INFO] 2021-07-12 18:40:14,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.200000032345997e-06, 521
[INFO] 2021-07-12 18:40:14,502 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 521
[INFO] 2021-07-12 18:40:14,502 [run_pretraining.py:  558]:	worker_index: 7, step: 521, cost: 8.904711, mlm loss: 8.904711, speed: 1.105272 steps/s, speed: 8.842174 samples/s, speed: 4527.193059 tokens/s, learning rate: 5.200e-06, loss_scalings: 13421.773438, pp_loss: 8.966869
[INFO] 2021-07-12 18:40:14,503 [run_pretraining.py:  512]:	********exe.run_521******* 
[INFO] 2021-07-12 18:40:15,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:15,446 [run_pretraining.py:  534]:	loss/total_loss, 8.978266716003418, 522
[INFO] 2021-07-12 18:40:15,447 [run_pretraining.py:  535]:	loss/mlm_loss, 8.978266716003418, 522
[INFO] 2021-07-12 18:40:15,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.2099999265919905e-06, 522
[INFO] 2021-07-12 18:40:15,447 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 522
[INFO] 2021-07-12 18:40:15,447 [run_pretraining.py:  558]:	worker_index: 7, step: 522, cost: 8.978267, mlm loss: 8.978267, speed: 1.059619 steps/s, speed: 8.476948 samples/s, speed: 4340.197580 tokens/s, learning rate: 5.210e-06, loss_scalings: 13421.773438, pp_loss: 8.871085
[INFO] 2021-07-12 18:40:15,447 [run_pretraining.py:  512]:	********exe.run_522******* 
[INFO] 2021-07-12 18:40:16,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:16,353 [run_pretraining.py:  534]:	loss/total_loss, 8.635680198669434, 523
[INFO] 2021-07-12 18:40:16,353 [run_pretraining.py:  535]:	loss/mlm_loss, 8.635680198669434, 523
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.219999820837984e-06, 523
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 523
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  558]:	worker_index: 7, step: 523, cost: 8.635680, mlm loss: 8.635680, speed: 1.103523 steps/s, speed: 8.828185 samples/s, speed: 4520.030936 tokens/s, learning rate: 5.220e-06, loss_scalings: 13421.773438, pp_loss: 8.873878
[INFO] 2021-07-12 18:40:16,354 [run_pretraining.py:  512]:	********exe.run_523******* 
[INFO] 2021-07-12 18:40:17,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:17,261 [run_pretraining.py:  534]:	loss/total_loss, 9.128801345825195, 524
[INFO] 2021-07-12 18:40:17,261 [run_pretraining.py:  535]:	loss/mlm_loss, 9.128801345825195, 524
[INFO] 2021-07-12 18:40:17,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.229999715083977e-06, 524
[INFO] 2021-07-12 18:40:17,262 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 524
[INFO] 2021-07-12 18:40:17,262 [run_pretraining.py:  558]:	worker_index: 7, step: 524, cost: 9.128801, mlm loss: 9.128801, speed: 1.102117 steps/s, speed: 8.816932 samples/s, speed: 4514.269374 tokens/s, learning rate: 5.230e-06, loss_scalings: 13421.773438, pp_loss: 8.915783
[INFO] 2021-07-12 18:40:17,262 [run_pretraining.py:  512]:	********exe.run_524******* 
[INFO] 2021-07-12 18:40:18,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  534]:	loss/total_loss, 9.161661148071289, 525
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  535]:	loss/mlm_loss, 9.161661148071289, 525
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.2400000640773214e-06, 525
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 525
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  558]:	worker_index: 7, step: 525, cost: 9.161661, mlm loss: 9.161661, speed: 1.103784 steps/s, speed: 8.830274 samples/s, speed: 4521.100300 tokens/s, learning rate: 5.240e-06, loss_scalings: 13421.773438, pp_loss: 8.830595
[INFO] 2021-07-12 18:40:18,168 [run_pretraining.py:  512]:	********exe.run_525******* 
[INFO] 2021-07-12 18:40:19,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:19,075 [run_pretraining.py:  534]:	loss/total_loss, 8.947343826293945, 526
[INFO] 2021-07-12 18:40:19,075 [run_pretraining.py:  535]:	loss/mlm_loss, 8.947343826293945, 526
[INFO] 2021-07-12 18:40:19,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.249999503575964e-06, 526
[INFO] 2021-07-12 18:40:19,075 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 526
[INFO] 2021-07-12 18:40:19,076 [run_pretraining.py:  558]:	worker_index: 7, step: 526, cost: 8.947344, mlm loss: 8.947344, speed: 1.103100 steps/s, speed: 8.824803 samples/s, speed: 4518.298904 tokens/s, learning rate: 5.250e-06, loss_scalings: 13421.773438, pp_loss: 8.778635
[INFO] 2021-07-12 18:40:19,076 [run_pretraining.py:  512]:	********exe.run_526******* 
[INFO] 2021-07-12 18:40:19,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:19,981 [run_pretraining.py:  534]:	loss/total_loss, 8.54688835144043, 527
[INFO] 2021-07-12 18:40:19,981 [run_pretraining.py:  535]:	loss/mlm_loss, 8.54688835144043, 527
[INFO] 2021-07-12 18:40:19,981 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.259999852569308e-06, 527
[INFO] 2021-07-12 18:40:19,981 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 527
[INFO] 2021-07-12 18:40:19,981 [run_pretraining.py:  558]:	worker_index: 7, step: 527, cost: 8.546888, mlm loss: 8.546888, speed: 1.104792 steps/s, speed: 8.838333 samples/s, speed: 4525.226667 tokens/s, learning rate: 5.260e-06, loss_scalings: 13421.773438, pp_loss: 8.927147
[INFO] 2021-07-12 18:40:19,981 [run_pretraining.py:  512]:	********exe.run_527******* 
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  534]:	loss/total_loss, 8.854509353637695, 528
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  535]:	loss/mlm_loss, 8.854509353637695, 528
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.270000201562652e-06, 528
[INFO] 2021-07-12 18:40:20,884 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 528
[INFO] 2021-07-12 18:40:20,885 [run_pretraining.py:  558]:	worker_index: 7, step: 528, cost: 8.854509, mlm loss: 8.854509, speed: 1.107898 steps/s, speed: 8.863185 samples/s, speed: 4537.950734 tokens/s, learning rate: 5.270e-06, loss_scalings: 13421.773438, pp_loss: 8.783875
[INFO] 2021-07-12 18:40:20,885 [run_pretraining.py:  512]:	********exe.run_528******* 
[INFO] 2021-07-12 18:40:21,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:21,794 [run_pretraining.py:  534]:	loss/total_loss, 8.89609146118164, 529
[INFO] 2021-07-12 18:40:21,794 [run_pretraining.py:  535]:	loss/mlm_loss, 8.89609146118164, 529
[INFO] 2021-07-12 18:40:21,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.279999641061295e-06, 529
[INFO] 2021-07-12 18:40:21,794 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 529
[INFO] 2021-07-12 18:40:21,794 [run_pretraining.py:  558]:	worker_index: 7, step: 529, cost: 8.896091, mlm loss: 8.896091, speed: 1.100243 steps/s, speed: 8.801943 samples/s, speed: 4506.594731 tokens/s, learning rate: 5.280e-06, loss_scalings: 13421.773438, pp_loss: 8.821039
[INFO] 2021-07-12 18:40:21,794 [run_pretraining.py:  512]:	********exe.run_529******* 
[INFO] 2021-07-12 18:40:22,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:22,704 [run_pretraining.py:  534]:	loss/total_loss, 8.904787063598633, 530
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  535]:	loss/mlm_loss, 8.904787063598633, 530
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.289999990054639e-06, 530
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 530
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  558]:	worker_index: 7, step: 530, cost: 8.904787, mlm loss: 8.904787, speed: 1.098854 steps/s, speed: 8.790833 samples/s, speed: 4500.906262 tokens/s, learning rate: 5.290e-06, loss_scalings: 13421.773438, pp_loss: 9.019043
[INFO] 2021-07-12 18:40:22,705 [run_pretraining.py:  512]:	********exe.run_530******* 
[INFO] 2021-07-12 18:40:23,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:23,618 [run_pretraining.py:  534]:	loss/total_loss, 8.834084510803223, 531
[INFO] 2021-07-12 18:40:23,618 [run_pretraining.py:  535]:	loss/mlm_loss, 8.834084510803223, 531
[INFO] 2021-07-12 18:40:23,618 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.299999884300632e-06, 531
[INFO] 2021-07-12 18:40:23,618 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 531
[INFO] 2021-07-12 18:40:23,618 [run_pretraining.py:  558]:	worker_index: 7, step: 531, cost: 8.834085, mlm loss: 8.834085, speed: 1.096029 steps/s, speed: 8.768231 samples/s, speed: 4489.334140 tokens/s, learning rate: 5.300e-06, loss_scalings: 13421.773438, pp_loss: 8.754829
[INFO] 2021-07-12 18:40:23,618 [run_pretraining.py:  512]:	********exe.run_531******* 
[INFO] 2021-07-12 18:40:24,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:24,521 [run_pretraining.py:  534]:	loss/total_loss, 9.146332740783691, 532
[INFO] 2021-07-12 18:40:24,521 [run_pretraining.py:  535]:	loss/mlm_loss, 9.146332740783691, 532
[INFO] 2021-07-12 18:40:24,521 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.309999778546626e-06, 532
[INFO] 2021-07-12 18:40:24,521 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 532
[INFO] 2021-07-12 18:40:24,521 [run_pretraining.py:  558]:	worker_index: 7, step: 532, cost: 9.146333, mlm loss: 9.146333, speed: 1.107961 steps/s, speed: 8.863686 samples/s, speed: 4538.207263 tokens/s, learning rate: 5.310e-06, loss_scalings: 13421.773438, pp_loss: 8.935061
[INFO] 2021-07-12 18:40:24,521 [run_pretraining.py:  512]:	********exe.run_532******* 
[INFO] 2021-07-12 18:40:25,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:25,432 [run_pretraining.py:  534]:	loss/total_loss, 8.546600341796875, 533
[INFO] 2021-07-12 18:40:25,432 [run_pretraining.py:  535]:	loss/mlm_loss, 8.546600341796875, 533
[INFO] 2021-07-12 18:40:25,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.319999672792619e-06, 533
[INFO] 2021-07-12 18:40:25,432 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 533
[INFO] 2021-07-12 18:40:25,432 [run_pretraining.py:  558]:	worker_index: 7, step: 533, cost: 8.546600, mlm loss: 8.546600, speed: 1.098498 steps/s, speed: 8.787985 samples/s, speed: 4499.448089 tokens/s, learning rate: 5.320e-06, loss_scalings: 13421.773438, pp_loss: 8.791268
[INFO] 2021-07-12 18:40:25,432 [run_pretraining.py:  512]:	********exe.run_533******* 
[INFO] 2021-07-12 18:40:26,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:26,359 [run_pretraining.py:  534]:	loss/total_loss, 9.320072174072266, 534
[INFO] 2021-07-12 18:40:26,359 [run_pretraining.py:  535]:	loss/mlm_loss, 9.320072174072266, 534
[INFO] 2021-07-12 18:40:26,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.330000021785963e-06, 534
[INFO] 2021-07-12 18:40:26,359 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 534
[INFO] 2021-07-12 18:40:26,359 [run_pretraining.py:  558]:	worker_index: 7, step: 534, cost: 9.320072, mlm loss: 9.320072, speed: 1.079534 steps/s, speed: 8.636273 samples/s, speed: 4421.771544 tokens/s, learning rate: 5.330e-06, loss_scalings: 13421.773438, pp_loss: 9.010469
[INFO] 2021-07-12 18:40:26,359 [run_pretraining.py:  512]:	********exe.run_534******* 
[INFO] 2021-07-12 18:40:27,259 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:27,259 [run_pretraining.py:  534]:	loss/total_loss, 8.824925422668457, 535
[INFO] 2021-07-12 18:40:27,259 [run_pretraining.py:  535]:	loss/mlm_loss, 8.824925422668457, 535
[INFO] 2021-07-12 18:40:27,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.339999916031957e-06, 535
[INFO] 2021-07-12 18:40:27,259 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 535
[INFO] 2021-07-12 18:40:27,259 [run_pretraining.py:  558]:	worker_index: 7, step: 535, cost: 8.824925, mlm loss: 8.824925, speed: 1.111393 steps/s, speed: 8.891142 samples/s, speed: 4552.264712 tokens/s, learning rate: 5.340e-06, loss_scalings: 13421.773438, pp_loss: 8.703151
[INFO] 2021-07-12 18:40:27,260 [run_pretraining.py:  512]:	********exe.run_535******* 
[INFO] 2021-07-12 18:40:28,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:28,166 [run_pretraining.py:  534]:	loss/total_loss, 9.070082664489746, 536
[INFO] 2021-07-12 18:40:28,166 [run_pretraining.py:  535]:	loss/mlm_loss, 9.070082664489746, 536
[INFO] 2021-07-12 18:40:28,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.34999981027795e-06, 536
[INFO] 2021-07-12 18:40:28,166 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 536
[INFO] 2021-07-12 18:40:28,166 [run_pretraining.py:  558]:	worker_index: 7, step: 536, cost: 9.070083, mlm loss: 9.070083, speed: 1.103694 steps/s, speed: 8.829551 samples/s, speed: 4520.730307 tokens/s, learning rate: 5.350e-06, loss_scalings: 13421.773438, pp_loss: 8.704323
[INFO] 2021-07-12 18:40:28,166 [run_pretraining.py:  512]:	********exe.run_536******* 
[INFO] 2021-07-12 18:40:29,067 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:29,068 [run_pretraining.py:  534]:	loss/total_loss, 8.94655990600586, 537
[INFO] 2021-07-12 18:40:29,068 [run_pretraining.py:  535]:	loss/mlm_loss, 8.94655990600586, 537
[INFO] 2021-07-12 18:40:29,068 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.359999704523943e-06, 537
[INFO] 2021-07-12 18:40:29,068 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 537
[INFO] 2021-07-12 18:40:29,068 [run_pretraining.py:  558]:	worker_index: 7, step: 537, cost: 8.946560, mlm loss: 8.946560, speed: 1.109304 steps/s, speed: 8.874434 samples/s, speed: 4543.710453 tokens/s, learning rate: 5.360e-06, loss_scalings: 13421.773438, pp_loss: 8.587816
[INFO] 2021-07-12 18:40:29,068 [run_pretraining.py:  512]:	********exe.run_537******* 
[INFO] 2021-07-12 18:40:30,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:30,025 [run_pretraining.py:  534]:	loss/total_loss, 8.706775665283203, 538
[INFO] 2021-07-12 18:40:30,025 [run_pretraining.py:  535]:	loss/mlm_loss, 8.706775665283203, 538
[INFO] 2021-07-12 18:40:30,025 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.370000053517288e-06, 538
[INFO] 2021-07-12 18:40:30,025 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 538
[INFO] 2021-07-12 18:40:30,025 [run_pretraining.py:  558]:	worker_index: 7, step: 538, cost: 8.706776, mlm loss: 8.706776, speed: 1.045452 steps/s, speed: 8.363613 samples/s, speed: 4282.170031 tokens/s, learning rate: 5.370e-06, loss_scalings: 13421.773438, pp_loss: 8.699857
[INFO] 2021-07-12 18:40:30,025 [run_pretraining.py:  512]:	********exe.run_538******* 
[INFO] 2021-07-12 18:40:30,986 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:30,987 [run_pretraining.py:  534]:	loss/total_loss, 8.326244354248047, 539
[INFO] 2021-07-12 18:40:30,987 [run_pretraining.py:  535]:	loss/mlm_loss, 8.326244354248047, 539
[INFO] 2021-07-12 18:40:30,987 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.379999947763281e-06, 539
[INFO] 2021-07-12 18:40:30,987 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 539
[INFO] 2021-07-12 18:40:30,987 [run_pretraining.py:  558]:	worker_index: 7, step: 539, cost: 8.326244, mlm loss: 8.326244, speed: 1.040829 steps/s, speed: 8.326635 samples/s, speed: 4263.237088 tokens/s, learning rate: 5.380e-06, loss_scalings: 13421.773438, pp_loss: 8.515265
[INFO] 2021-07-12 18:40:30,987 [run_pretraining.py:  512]:	********exe.run_539******* 
[INFO] 2021-07-12 18:40:31,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:31,892 [run_pretraining.py:  534]:	loss/total_loss, 8.536267280578613, 540
[INFO] 2021-07-12 18:40:31,892 [run_pretraining.py:  535]:	loss/mlm_loss, 8.536267280578613, 540
[INFO] 2021-07-12 18:40:31,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.389999842009274e-06, 540
[INFO] 2021-07-12 18:40:31,892 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 540
[INFO] 2021-07-12 18:40:31,892 [run_pretraining.py:  558]:	worker_index: 7, step: 540, cost: 8.536267, mlm loss: 8.536267, speed: 1.105577 steps/s, speed: 8.844619 samples/s, speed: 4528.444856 tokens/s, learning rate: 5.390e-06, loss_scalings: 13421.773438, pp_loss: 8.896571
[INFO] 2021-07-12 18:40:31,892 [run_pretraining.py:  512]:	********exe.run_540******* 
[INFO] 2021-07-12 18:40:32,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:32,790 [run_pretraining.py:  534]:	loss/total_loss, 8.797063827514648, 541
[INFO] 2021-07-12 18:40:32,790 [run_pretraining.py:  535]:	loss/mlm_loss, 8.797063827514648, 541
[INFO] 2021-07-12 18:40:32,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4000001910026185e-06, 541
[INFO] 2021-07-12 18:40:32,790 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 541
[INFO] 2021-07-12 18:40:32,790 [run_pretraining.py:  558]:	worker_index: 7, step: 541, cost: 8.797064, mlm loss: 8.797064, speed: 1.113915 steps/s, speed: 8.911317 samples/s, speed: 4562.594246 tokens/s, learning rate: 5.400e-06, loss_scalings: 13421.773438, pp_loss: 7.827075
[INFO] 2021-07-12 18:40:32,790 [run_pretraining.py:  512]:	********exe.run_541******* 
[INFO] 2021-07-12 18:40:33,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:33,701 [run_pretraining.py:  534]:	loss/total_loss, 8.672565460205078, 542
[INFO] 2021-07-12 18:40:33,701 [run_pretraining.py:  535]:	loss/mlm_loss, 8.672565460205078, 542
[INFO] 2021-07-12 18:40:33,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.409999630501261e-06, 542
[INFO] 2021-07-12 18:40:33,701 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 542
[INFO] 2021-07-12 18:40:33,701 [run_pretraining.py:  558]:	worker_index: 7, step: 542, cost: 8.672565, mlm loss: 8.672565, speed: 1.098905 steps/s, speed: 8.791238 samples/s, speed: 4501.113807 tokens/s, learning rate: 5.410e-06, loss_scalings: 13421.773438, pp_loss: 8.794343
[INFO] 2021-07-12 18:40:33,701 [run_pretraining.py:  512]:	********exe.run_542******* 
[INFO] 2021-07-12 18:40:34,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:34,616 [run_pretraining.py:  534]:	loss/total_loss, 8.608097076416016, 543
[INFO] 2021-07-12 18:40:34,616 [run_pretraining.py:  535]:	loss/mlm_loss, 8.608097076416016, 543
[INFO] 2021-07-12 18:40:34,616 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.419999979494605e-06, 543
[INFO] 2021-07-12 18:40:34,616 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 543
[INFO] 2021-07-12 18:40:34,616 [run_pretraining.py:  558]:	worker_index: 7, step: 543, cost: 8.608097, mlm loss: 8.608097, speed: 1.093159 steps/s, speed: 8.745271 samples/s, speed: 4477.578624 tokens/s, learning rate: 5.420e-06, loss_scalings: 13421.773438, pp_loss: 8.751490
[INFO] 2021-07-12 18:40:34,617 [run_pretraining.py:  512]:	********exe.run_543******* 
[INFO] 2021-07-12 18:40:35,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:35,592 [run_pretraining.py:  534]:	loss/total_loss, 8.859732627868652, 544
[INFO] 2021-07-12 18:40:35,592 [run_pretraining.py:  535]:	loss/mlm_loss, 8.859732627868652, 544
[INFO] 2021-07-12 18:40:35,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4299998737405986e-06, 544
[INFO] 2021-07-12 18:40:35,593 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 544
[INFO] 2021-07-12 18:40:35,593 [run_pretraining.py:  558]:	worker_index: 7, step: 544, cost: 8.859733, mlm loss: 8.859733, speed: 1.025055 steps/s, speed: 8.200443 samples/s, speed: 4198.626658 tokens/s, learning rate: 5.430e-06, loss_scalings: 13421.773438, pp_loss: 8.872900
[INFO] 2021-07-12 18:40:35,593 [run_pretraining.py:  512]:	********exe.run_544******* 
[INFO] 2021-07-12 18:40:36,662 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:36,663 [run_pretraining.py:  534]:	loss/total_loss, 8.995013236999512, 545
[INFO] 2021-07-12 18:40:36,663 [run_pretraining.py:  535]:	loss/mlm_loss, 8.995013236999512, 545
[INFO] 2021-07-12 18:40:36,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.439999767986592e-06, 545
[INFO] 2021-07-12 18:40:36,663 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 545
[INFO] 2021-07-12 18:40:36,663 [run_pretraining.py:  558]:	worker_index: 7, step: 545, cost: 8.995013, mlm loss: 8.995013, speed: 0.934952 steps/s, speed: 7.479614 samples/s, speed: 3829.562482 tokens/s, learning rate: 5.440e-06, loss_scalings: 13421.773438, pp_loss: 7.605836
[INFO] 2021-07-12 18:40:36,663 [run_pretraining.py:  512]:	********exe.run_545******* 
[INFO] 2021-07-12 18:40:37,723 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:37,724 [run_pretraining.py:  534]:	loss/total_loss, 9.124381065368652, 546
[INFO] 2021-07-12 18:40:37,724 [run_pretraining.py:  535]:	loss/mlm_loss, 9.124381065368652, 546
[INFO] 2021-07-12 18:40:37,724 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.449999662232585e-06, 546
[INFO] 2021-07-12 18:40:37,724 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 546
[INFO] 2021-07-12 18:40:37,724 [run_pretraining.py:  558]:	worker_index: 7, step: 546, cost: 9.124381, mlm loss: 9.124381, speed: 0.942931 steps/s, speed: 7.543451 samples/s, speed: 3862.246942 tokens/s, learning rate: 5.450e-06, loss_scalings: 13421.773438, pp_loss: 8.633258
[INFO] 2021-07-12 18:40:37,724 [run_pretraining.py:  512]:	********exe.run_546******* 
[INFO] 2021-07-12 18:40:38,778 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:38,778 [run_pretraining.py:  534]:	loss/total_loss, 9.252321243286133, 547
[INFO] 2021-07-12 18:40:38,778 [run_pretraining.py:  535]:	loss/mlm_loss, 9.252321243286133, 547
[INFO] 2021-07-12 18:40:38,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.4600000112259295e-06, 547
[INFO] 2021-07-12 18:40:38,778 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 547
[INFO] 2021-07-12 18:40:38,779 [run_pretraining.py:  558]:	worker_index: 7, step: 547, cost: 9.252321, mlm loss: 9.252321, speed: 0.948953 steps/s, speed: 7.591628 samples/s, speed: 3886.913307 tokens/s, learning rate: 5.460e-06, loss_scalings: 13421.773438, pp_loss: 8.611219
[INFO] 2021-07-12 18:40:38,779 [run_pretraining.py:  512]:	********exe.run_547******* 
[INFO] 2021-07-12 18:40:39,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:39,835 [run_pretraining.py:  534]:	loss/total_loss, 9.004408836364746, 548
[INFO] 2021-07-12 18:40:39,835 [run_pretraining.py:  535]:	loss/mlm_loss, 9.004408836364746, 548
[INFO] 2021-07-12 18:40:39,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.469999905471923e-06, 548
[INFO] 2021-07-12 18:40:39,835 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 548
[INFO] 2021-07-12 18:40:39,835 [run_pretraining.py:  558]:	worker_index: 7, step: 548, cost: 9.004409, mlm loss: 9.004409, speed: 0.946987 steps/s, speed: 7.575893 samples/s, speed: 3878.857084 tokens/s, learning rate: 5.470e-06, loss_scalings: 13421.773438, pp_loss: 8.954018
[INFO] 2021-07-12 18:40:39,835 [run_pretraining.py:  512]:	********exe.run_548******* 
[INFO] 2021-07-12 18:40:40,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:40,896 [run_pretraining.py:  534]:	loss/total_loss, 8.790369987487793, 549
[INFO] 2021-07-12 18:40:40,897 [run_pretraining.py:  535]:	loss/mlm_loss, 8.790369987487793, 549
[INFO] 2021-07-12 18:40:40,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.479999799717916e-06, 549
[INFO] 2021-07-12 18:40:40,897 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 549
[INFO] 2021-07-12 18:40:40,897 [run_pretraining.py:  558]:	worker_index: 7, step: 549, cost: 8.790370, mlm loss: 8.790370, speed: 0.942465 steps/s, speed: 7.539719 samples/s, speed: 3860.335934 tokens/s, learning rate: 5.480e-06, loss_scalings: 13421.773438, pp_loss: 8.886147
[INFO] 2021-07-12 18:40:40,897 [run_pretraining.py:  512]:	********exe.run_549******* 
[INFO] 2021-07-12 18:40:41,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:41,950 [run_pretraining.py:  534]:	loss/total_loss, 8.29092788696289, 550
[INFO] 2021-07-12 18:40:41,950 [run_pretraining.py:  535]:	loss/mlm_loss, 8.29092788696289, 550
[INFO] 2021-07-12 18:40:41,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.49000014871126e-06, 550
[INFO] 2021-07-12 18:40:41,950 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 550
[INFO] 2021-07-12 18:40:41,950 [run_pretraining.py:  558]:	worker_index: 7, step: 550, cost: 8.290928, mlm loss: 8.290928, speed: 0.950032 steps/s, speed: 7.600260 samples/s, speed: 3891.332949 tokens/s, learning rate: 5.490e-06, loss_scalings: 13421.773438, pp_loss: 8.698624
[INFO] 2021-07-12 18:40:41,950 [run_pretraining.py:  512]:	********exe.run_550******* 
[INFO] 2021-07-12 18:40:43,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:43,017 [run_pretraining.py:  534]:	loss/total_loss, 8.832414627075195, 551
[INFO] 2021-07-12 18:40:43,017 [run_pretraining.py:  535]:	loss/mlm_loss, 8.832414627075195, 551
[INFO] 2021-07-12 18:40:43,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.500000042957254e-06, 551
[INFO] 2021-07-12 18:40:43,018 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 551
[INFO] 2021-07-12 18:40:43,018 [run_pretraining.py:  558]:	worker_index: 7, step: 551, cost: 8.832415, mlm loss: 8.832415, speed: 0.937308 steps/s, speed: 7.498460 samples/s, speed: 3839.211607 tokens/s, learning rate: 5.500e-06, loss_scalings: 13421.773438, pp_loss: 8.868793
[INFO] 2021-07-12 18:40:43,018 [run_pretraining.py:  512]:	********exe.run_551******* 
[INFO] 2021-07-12 18:40:44,098 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:44,098 [run_pretraining.py:  534]:	loss/total_loss, 8.372220993041992, 552
[INFO] 2021-07-12 18:40:44,098 [run_pretraining.py:  535]:	loss/mlm_loss, 8.372220993041992, 552
[INFO] 2021-07-12 18:40:44,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.509999937203247e-06, 552
[INFO] 2021-07-12 18:40:44,098 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 552
[INFO] 2021-07-12 18:40:44,099 [run_pretraining.py:  558]:	worker_index: 7, step: 552, cost: 8.372221, mlm loss: 8.372221, speed: 0.925638 steps/s, speed: 7.405101 samples/s, speed: 3791.411876 tokens/s, learning rate: 5.510e-06, loss_scalings: 13421.773438, pp_loss: 8.932411
[INFO] 2021-07-12 18:40:44,099 [run_pretraining.py:  512]:	********exe.run_552******* 
[INFO] 2021-07-12 18:40:45,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:45,151 [run_pretraining.py:  534]:	loss/total_loss, 8.477092742919922, 553
[INFO] 2021-07-12 18:40:45,151 [run_pretraining.py:  535]:	loss/mlm_loss, 8.477092742919922, 553
[INFO] 2021-07-12 18:40:45,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.5199998314492404e-06, 553
[INFO] 2021-07-12 18:40:45,151 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 553
[INFO] 2021-07-12 18:40:45,151 [run_pretraining.py:  558]:	worker_index: 7, step: 553, cost: 8.477093, mlm loss: 8.477093, speed: 0.950865 steps/s, speed: 7.606923 samples/s, speed: 3894.744341 tokens/s, learning rate: 5.520e-06, loss_scalings: 13421.773438, pp_loss: 8.755977
[INFO] 2021-07-12 18:40:45,151 [run_pretraining.py:  512]:	********exe.run_553******* 
[INFO] 2021-07-12 18:40:46,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:46,205 [run_pretraining.py:  534]:	loss/total_loss, 8.785810470581055, 554
[INFO] 2021-07-12 18:40:46,205 [run_pretraining.py:  535]:	loss/mlm_loss, 8.785810470581055, 554
[INFO] 2021-07-12 18:40:46,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.530000180442585e-06, 554
[INFO] 2021-07-12 18:40:46,205 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 554
[INFO] 2021-07-12 18:40:46,205 [run_pretraining.py:  558]:	worker_index: 7, step: 554, cost: 8.785810, mlm loss: 8.785810, speed: 0.948979 steps/s, speed: 7.591829 samples/s, speed: 3887.016200 tokens/s, learning rate: 5.530e-06, loss_scalings: 13421.773438, pp_loss: 8.783396
[INFO] 2021-07-12 18:40:46,205 [run_pretraining.py:  512]:	********exe.run_554******* 
[INFO] 2021-07-12 18:40:47,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:47,271 [run_pretraining.py:  534]:	loss/total_loss, 8.172115325927734, 555
[INFO] 2021-07-12 18:40:47,271 [run_pretraining.py:  535]:	loss/mlm_loss, 8.172115325927734, 555
[INFO] 2021-07-12 18:40:47,271 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.539999619941227e-06, 555
[INFO] 2021-07-12 18:40:47,271 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 555
[INFO] 2021-07-12 18:40:47,271 [run_pretraining.py:  558]:	worker_index: 7, step: 555, cost: 8.172115, mlm loss: 8.172115, speed: 0.939004 steps/s, speed: 7.512034 samples/s, speed: 3846.161585 tokens/s, learning rate: 5.540e-06, loss_scalings: 13421.773438, pp_loss: 8.666326
[INFO] 2021-07-12 18:40:47,271 [run_pretraining.py:  512]:	********exe.run_555******* 
[INFO] 2021-07-12 18:40:48,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:48,329 [run_pretraining.py:  534]:	loss/total_loss, 9.06452751159668, 556
[INFO] 2021-07-12 18:40:48,329 [run_pretraining.py:  535]:	loss/mlm_loss, 9.06452751159668, 556
[INFO] 2021-07-12 18:40:48,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.549999968934571e-06, 556
[INFO] 2021-07-12 18:40:48,329 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 556
[INFO] 2021-07-12 18:40:48,329 [run_pretraining.py:  558]:	worker_index: 7, step: 556, cost: 9.064528, mlm loss: 9.064528, speed: 0.945500 steps/s, speed: 7.564001 samples/s, speed: 3872.768702 tokens/s, learning rate: 5.550e-06, loss_scalings: 13421.773438, pp_loss: 8.847292
[INFO] 2021-07-12 18:40:48,329 [run_pretraining.py:  512]:	********exe.run_556******* 
[INFO] 2021-07-12 18:40:49,404 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:49,405 [run_pretraining.py:  534]:	loss/total_loss, 9.323080062866211, 557
[INFO] 2021-07-12 18:40:49,405 [run_pretraining.py:  535]:	loss/mlm_loss, 9.323080062866211, 557
[INFO] 2021-07-12 18:40:49,405 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.559999863180565e-06, 557
[INFO] 2021-07-12 18:40:49,405 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 557
[INFO] 2021-07-12 18:40:49,405 [run_pretraining.py:  558]:	worker_index: 7, step: 557, cost: 9.323080, mlm loss: 9.323080, speed: 0.929927 steps/s, speed: 7.439415 samples/s, speed: 3808.980435 tokens/s, learning rate: 5.560e-06, loss_scalings: 13421.773438, pp_loss: 9.068577
[INFO] 2021-07-12 18:40:49,405 [run_pretraining.py:  512]:	********exe.run_557******* 
[INFO] 2021-07-12 18:40:50,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:50,485 [run_pretraining.py:  534]:	loss/total_loss, 8.91332721710205, 558
[INFO] 2021-07-12 18:40:50,485 [run_pretraining.py:  535]:	loss/mlm_loss, 8.91332721710205, 558
[INFO] 2021-07-12 18:40:50,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.569999757426558e-06, 558
[INFO] 2021-07-12 18:40:50,485 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 558
[INFO] 2021-07-12 18:40:50,485 [run_pretraining.py:  558]:	worker_index: 7, step: 558, cost: 8.913327, mlm loss: 8.913327, speed: 0.926451 steps/s, speed: 7.411605 samples/s, speed: 3794.741611 tokens/s, learning rate: 5.570e-06, loss_scalings: 13421.773438, pp_loss: 8.857303
[INFO] 2021-07-12 18:40:50,485 [run_pretraining.py:  512]:	********exe.run_558******* 
[INFO] 2021-07-12 18:40:51,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:51,541 [run_pretraining.py:  534]:	loss/total_loss, 8.88587474822998, 559
[INFO] 2021-07-12 18:40:51,541 [run_pretraining.py:  535]:	loss/mlm_loss, 8.88587474822998, 559
[INFO] 2021-07-12 18:40:51,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.579999651672551e-06, 559
[INFO] 2021-07-12 18:40:51,541 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 559
[INFO] 2021-07-12 18:40:51,541 [run_pretraining.py:  558]:	worker_index: 7, step: 559, cost: 8.885875, mlm loss: 8.885875, speed: 0.947519 steps/s, speed: 7.580156 samples/s, speed: 3881.039843 tokens/s, learning rate: 5.580e-06, loss_scalings: 13421.773438, pp_loss: 9.061173
[INFO] 2021-07-12 18:40:51,541 [run_pretraining.py:  512]:	********exe.run_559******* 
[INFO] 2021-07-12 18:40:52,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:52,600 [run_pretraining.py:  534]:	loss/total_loss, 9.2615385055542, 560
[INFO] 2021-07-12 18:40:52,600 [run_pretraining.py:  535]:	loss/mlm_loss, 9.2615385055542, 560
[INFO] 2021-07-12 18:40:52,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.590000000665896e-06, 560
[INFO] 2021-07-12 18:40:52,600 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 560
[INFO] 2021-07-12 18:40:52,600 [run_pretraining.py:  558]:	worker_index: 7, step: 560, cost: 9.261539, mlm loss: 9.261539, speed: 0.945159 steps/s, speed: 7.561274 samples/s, speed: 3871.372377 tokens/s, learning rate: 5.590e-06, loss_scalings: 13421.773438, pp_loss: 8.141517
[INFO] 2021-07-12 18:40:52,600 [run_pretraining.py:  512]:	********exe.run_560******* 
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  534]:	loss/total_loss, 8.735758781433105, 561
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  535]:	loss/mlm_loss, 8.735758781433105, 561
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.599999894911889e-06, 561
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 561
[INFO] 2021-07-12 18:40:53,660 [run_pretraining.py:  558]:	worker_index: 7, step: 561, cost: 8.735759, mlm loss: 8.735759, speed: 0.943547 steps/s, speed: 7.548372 samples/s, speed: 3864.766599 tokens/s, learning rate: 5.600e-06, loss_scalings: 13421.773438, pp_loss: 8.793221
[INFO] 2021-07-12 18:40:53,661 [run_pretraining.py:  512]:	********exe.run_561******* 
[INFO] 2021-07-12 18:40:54,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:54,721 [run_pretraining.py:  534]:	loss/total_loss, 8.840744018554688, 562
[INFO] 2021-07-12 18:40:54,721 [run_pretraining.py:  535]:	loss/mlm_loss, 8.840744018554688, 562
[INFO] 2021-07-12 18:40:54,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.609999789157882e-06, 562
[INFO] 2021-07-12 18:40:54,721 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 562
[INFO] 2021-07-12 18:40:54,721 [run_pretraining.py:  558]:	worker_index: 7, step: 562, cost: 8.840744, mlm loss: 8.840744, speed: 0.943555 steps/s, speed: 7.548444 samples/s, speed: 3864.803115 tokens/s, learning rate: 5.610e-06, loss_scalings: 13421.773438, pp_loss: 8.802521
[INFO] 2021-07-12 18:40:54,721 [run_pretraining.py:  512]:	********exe.run_562******* 
[INFO] 2021-07-12 18:40:55,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:55,777 [run_pretraining.py:  534]:	loss/total_loss, 8.5326566696167, 563
[INFO] 2021-07-12 18:40:55,777 [run_pretraining.py:  535]:	loss/mlm_loss, 8.5326566696167, 563
[INFO] 2021-07-12 18:40:55,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6200001381512266e-06, 563
[INFO] 2021-07-12 18:40:55,777 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 563
[INFO] 2021-07-12 18:40:55,777 [run_pretraining.py:  558]:	worker_index: 7, step: 563, cost: 8.532657, mlm loss: 8.532657, speed: 0.947335 steps/s, speed: 7.578682 samples/s, speed: 3880.285107 tokens/s, learning rate: 5.620e-06, loss_scalings: 13421.773438, pp_loss: 7.972575
[INFO] 2021-07-12 18:40:55,777 [run_pretraining.py:  512]:	********exe.run_563******* 
[INFO] 2021-07-12 18:40:56,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:56,826 [run_pretraining.py:  534]:	loss/total_loss, 9.554004669189453, 564
[INFO] 2021-07-12 18:40:56,826 [run_pretraining.py:  535]:	loss/mlm_loss, 9.554004669189453, 564
[INFO] 2021-07-12 18:40:56,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.629999577649869e-06, 564
[INFO] 2021-07-12 18:40:56,826 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 564
[INFO] 2021-07-12 18:40:56,826 [run_pretraining.py:  558]:	worker_index: 7, step: 564, cost: 9.554005, mlm loss: 9.554005, speed: 0.953704 steps/s, speed: 7.629630 samples/s, speed: 3906.370362 tokens/s, learning rate: 5.630e-06, loss_scalings: 13421.773438, pp_loss: 8.979507
[INFO] 2021-07-12 18:40:56,826 [run_pretraining.py:  512]:	********exe.run_564******* 
[INFO] 2021-07-12 18:40:57,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:57,882 [run_pretraining.py:  534]:	loss/total_loss, 8.628923416137695, 565
[INFO] 2021-07-12 18:40:57,882 [run_pretraining.py:  535]:	loss/mlm_loss, 8.628923416137695, 565
[INFO] 2021-07-12 18:40:57,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.639999926643213e-06, 565
[INFO] 2021-07-12 18:40:57,882 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 565
[INFO] 2021-07-12 18:40:57,882 [run_pretraining.py:  558]:	worker_index: 7, step: 565, cost: 8.628923, mlm loss: 8.628923, speed: 0.947555 steps/s, speed: 7.580442 samples/s, speed: 3881.186266 tokens/s, learning rate: 5.640e-06, loss_scalings: 13421.773438, pp_loss: 8.674191
[INFO] 2021-07-12 18:40:57,882 [run_pretraining.py:  512]:	********exe.run_565******* 
[INFO] 2021-07-12 18:40:58,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:40:58,940 [run_pretraining.py:  534]:	loss/total_loss, 9.088594436645508, 566
[INFO] 2021-07-12 18:40:58,940 [run_pretraining.py:  535]:	loss/mlm_loss, 9.088594436645508, 566
[INFO] 2021-07-12 18:40:58,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.649999820889207e-06, 566
[INFO] 2021-07-12 18:40:58,940 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 566
[INFO] 2021-07-12 18:40:58,940 [run_pretraining.py:  558]:	worker_index: 7, step: 566, cost: 9.088594, mlm loss: 9.088594, speed: 0.945816 steps/s, speed: 7.566527 samples/s, speed: 3874.062074 tokens/s, learning rate: 5.650e-06, loss_scalings: 13421.773438, pp_loss: 8.936481
[INFO] 2021-07-12 18:40:58,940 [run_pretraining.py:  512]:	********exe.run_566******* 
[INFO] 2021-07-12 18:41:00,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:00,006 [run_pretraining.py:  534]:	loss/total_loss, 8.842456817626953, 567
[INFO] 2021-07-12 18:41:00,006 [run_pretraining.py:  535]:	loss/mlm_loss, 8.842456817626953, 567
[INFO] 2021-07-12 18:41:00,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6599997151352e-06, 567
[INFO] 2021-07-12 18:41:00,006 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 567
[INFO] 2021-07-12 18:41:00,006 [run_pretraining.py:  558]:	worker_index: 7, step: 567, cost: 8.842457, mlm loss: 8.842457, speed: 0.938817 steps/s, speed: 7.510533 samples/s, speed: 3845.392809 tokens/s, learning rate: 5.660e-06, loss_scalings: 13421.773438, pp_loss: 8.722716
[INFO] 2021-07-12 18:41:00,006 [run_pretraining.py:  512]:	********exe.run_567******* 
[INFO] 2021-07-12 18:41:01,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:01,053 [run_pretraining.py:  534]:	loss/total_loss, 9.209497451782227, 568
[INFO] 2021-07-12 18:41:01,053 [run_pretraining.py:  535]:	loss/mlm_loss, 9.209497451782227, 568
[INFO] 2021-07-12 18:41:01,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.669999609381193e-06, 568
[INFO] 2021-07-12 18:41:01,053 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 568
[INFO] 2021-07-12 18:41:01,054 [run_pretraining.py:  558]:	worker_index: 7, step: 568, cost: 9.209497, mlm loss: 9.209497, speed: 0.955352 steps/s, speed: 7.642816 samples/s, speed: 3913.121924 tokens/s, learning rate: 5.670e-06, loss_scalings: 13421.773438, pp_loss: 9.025461
[INFO] 2021-07-12 18:41:01,054 [run_pretraining.py:  512]:	********exe.run_568******* 
[INFO] 2021-07-12 18:41:01,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:01,968 [run_pretraining.py:  534]:	loss/total_loss, 9.097627639770508, 569
[INFO] 2021-07-12 18:41:01,969 [run_pretraining.py:  535]:	loss/mlm_loss, 9.097627639770508, 569
[INFO] 2021-07-12 18:41:01,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.6799999583745375e-06, 569
[INFO] 2021-07-12 18:41:01,969 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 569
[INFO] 2021-07-12 18:41:01,969 [run_pretraining.py:  558]:	worker_index: 7, step: 569, cost: 9.097628, mlm loss: 9.097628, speed: 1.093279 steps/s, speed: 8.746235 samples/s, speed: 4478.072314 tokens/s, learning rate: 5.680e-06, loss_scalings: 13421.773438, pp_loss: 8.922367
[INFO] 2021-07-12 18:41:01,969 [run_pretraining.py:  512]:	********exe.run_569******* 
[INFO] 2021-07-12 18:41:02,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:02,885 [run_pretraining.py:  534]:	loss/total_loss, 9.134437561035156, 570
[INFO] 2021-07-12 18:41:02,885 [run_pretraining.py:  535]:	loss/mlm_loss, 9.134437561035156, 570
[INFO] 2021-07-12 18:41:02,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.689999852620531e-06, 570
[INFO] 2021-07-12 18:41:02,885 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 570
[INFO] 2021-07-12 18:41:02,885 [run_pretraining.py:  558]:	worker_index: 7, step: 570, cost: 9.134438, mlm loss: 9.134438, speed: 1.092238 steps/s, speed: 8.737901 samples/s, speed: 4473.805431 tokens/s, learning rate: 5.690e-06, loss_scalings: 13421.773438, pp_loss: 8.776044
[INFO] 2021-07-12 18:41:02,885 [run_pretraining.py:  512]:	********exe.run_570******* 
[INFO] 2021-07-12 18:41:03,795 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:03,796 [run_pretraining.py:  534]:	loss/total_loss, 9.010995864868164, 571
[INFO] 2021-07-12 18:41:03,796 [run_pretraining.py:  535]:	loss/mlm_loss, 9.010995864868164, 571
[INFO] 2021-07-12 18:41:03,796 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.699999746866524e-06, 571
[INFO] 2021-07-12 18:41:03,796 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 571
[INFO] 2021-07-12 18:41:03,796 [run_pretraining.py:  558]:	worker_index: 7, step: 571, cost: 9.010996, mlm loss: 9.010996, speed: 1.098327 steps/s, speed: 8.786620 samples/s, speed: 4498.749397 tokens/s, learning rate: 5.700e-06, loss_scalings: 13421.773438, pp_loss: 8.710106
[INFO] 2021-07-12 18:41:03,796 [run_pretraining.py:  512]:	********exe.run_571******* 
[INFO] 2021-07-12 18:41:04,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:04,821 [run_pretraining.py:  534]:	loss/total_loss, 8.508912086486816, 572
[INFO] 2021-07-12 18:41:04,821 [run_pretraining.py:  535]:	loss/mlm_loss, 8.508912086486816, 572
[INFO] 2021-07-12 18:41:04,821 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7100000958598685e-06, 572
[INFO] 2021-07-12 18:41:04,821 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 572
[INFO] 2021-07-12 18:41:04,821 [run_pretraining.py:  558]:	worker_index: 7, step: 572, cost: 8.508912, mlm loss: 8.508912, speed: 0.975961 steps/s, speed: 7.807685 samples/s, speed: 3997.534723 tokens/s, learning rate: 5.710e-06, loss_scalings: 13421.773438, pp_loss: 8.534190
[INFO] 2021-07-12 18:41:04,822 [run_pretraining.py:  512]:	********exe.run_572******* 
[INFO] 2021-07-12 18:41:05,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:05,885 [run_pretraining.py:  534]:	loss/total_loss, 8.528324127197266, 573
[INFO] 2021-07-12 18:41:05,885 [run_pretraining.py:  535]:	loss/mlm_loss, 8.528324127197266, 573
[INFO] 2021-07-12 18:41:05,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.719999990105862e-06, 573
[INFO] 2021-07-12 18:41:05,885 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 573
[INFO] 2021-07-12 18:41:05,885 [run_pretraining.py:  558]:	worker_index: 7, step: 573, cost: 8.528324, mlm loss: 8.528324, speed: 0.940843 steps/s, speed: 7.526743 samples/s, speed: 3853.692526 tokens/s, learning rate: 5.720e-06, loss_scalings: 13421.773438, pp_loss: 8.681491
[INFO] 2021-07-12 18:41:05,885 [run_pretraining.py:  512]:	********exe.run_573******* 
[INFO] 2021-07-12 18:41:06,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:06,937 [run_pretraining.py:  534]:	loss/total_loss, 8.9871244430542, 574
[INFO] 2021-07-12 18:41:06,937 [run_pretraining.py:  535]:	loss/mlm_loss, 8.9871244430542, 574
[INFO] 2021-07-12 18:41:06,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.729999884351855e-06, 574
[INFO] 2021-07-12 18:41:06,937 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 574
[INFO] 2021-07-12 18:41:06,937 [run_pretraining.py:  558]:	worker_index: 7, step: 574, cost: 8.987124, mlm loss: 8.987124, speed: 0.950850 steps/s, speed: 7.606797 samples/s, speed: 3894.679887 tokens/s, learning rate: 5.730e-06, loss_scalings: 13421.773438, pp_loss: 8.719409
[INFO] 2021-07-12 18:41:06,937 [run_pretraining.py:  512]:	********exe.run_574******* 
[INFO] 2021-07-12 18:41:07,916 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:07,916 [run_pretraining.py:  534]:	loss/total_loss, 8.43093490600586, 575
[INFO] 2021-07-12 18:41:07,916 [run_pretraining.py:  535]:	loss/mlm_loss, 8.43093490600586, 575
[INFO] 2021-07-12 18:41:07,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7399997785978485e-06, 575
[INFO] 2021-07-12 18:41:07,917 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 575
[INFO] 2021-07-12 18:41:07,917 [run_pretraining.py:  558]:	worker_index: 7, step: 575, cost: 8.430935, mlm loss: 8.430935, speed: 1.021711 steps/s, speed: 8.173689 samples/s, speed: 4184.928779 tokens/s, learning rate: 5.740e-06, loss_scalings: 13421.773438, pp_loss: 8.435286
[INFO] 2021-07-12 18:41:07,917 [run_pretraining.py:  512]:	********exe.run_575******* 
[INFO] 2021-07-12 18:41:08,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:08,831 [run_pretraining.py:  534]:	loss/total_loss, 7.985699653625488, 576
[INFO] 2021-07-12 18:41:08,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.985699653625488, 576
[INFO] 2021-07-12 18:41:08,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.750000127591193e-06, 576
[INFO] 2021-07-12 18:41:08,831 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 576
[INFO] 2021-07-12 18:41:08,831 [run_pretraining.py:  558]:	worker_index: 7, step: 576, cost: 7.985700, mlm loss: 7.985700, speed: 1.094110 steps/s, speed: 8.752883 samples/s, speed: 4481.476254 tokens/s, learning rate: 5.750e-06, loss_scalings: 13421.773438, pp_loss: 8.479194
[INFO] 2021-07-12 18:41:08,831 [run_pretraining.py:  512]:	********exe.run_576******* 
[INFO] 2021-07-12 18:41:09,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:09,743 [run_pretraining.py:  534]:	loss/total_loss, 8.99557113647461, 577
[INFO] 2021-07-12 18:41:09,744 [run_pretraining.py:  535]:	loss/mlm_loss, 8.99557113647461, 577
[INFO] 2021-07-12 18:41:09,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.759999567089835e-06, 577
[INFO] 2021-07-12 18:41:09,744 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 577
[INFO] 2021-07-12 18:41:09,744 [run_pretraining.py:  558]:	worker_index: 7, step: 577, cost: 8.995571, mlm loss: 8.995571, speed: 1.096731 steps/s, speed: 8.773846 samples/s, speed: 4492.208961 tokens/s, learning rate: 5.760e-06, loss_scalings: 13421.773438, pp_loss: 8.528591
[INFO] 2021-07-12 18:41:09,744 [run_pretraining.py:  512]:	********exe.run_577******* 
[INFO] 2021-07-12 18:41:10,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:10,673 [run_pretraining.py:  534]:	loss/total_loss, 9.07514762878418, 578
[INFO] 2021-07-12 18:41:10,673 [run_pretraining.py:  535]:	loss/mlm_loss, 9.07514762878418, 578
[INFO] 2021-07-12 18:41:10,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.769999916083179e-06, 578
[INFO] 2021-07-12 18:41:10,674 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 578
[INFO] 2021-07-12 18:41:10,674 [run_pretraining.py:  558]:	worker_index: 7, step: 578, cost: 9.075148, mlm loss: 9.075148, speed: 1.076185 steps/s, speed: 8.609480 samples/s, speed: 4408.053710 tokens/s, learning rate: 5.770e-06, loss_scalings: 13421.773438, pp_loss: 8.630881
[INFO] 2021-07-12 18:41:10,674 [run_pretraining.py:  512]:	********exe.run_578******* 
[INFO] 2021-07-12 18:41:11,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:11,590 [run_pretraining.py:  534]:	loss/total_loss, 8.769623756408691, 579
[INFO] 2021-07-12 18:41:11,590 [run_pretraining.py:  535]:	loss/mlm_loss, 8.769623756408691, 579
[INFO] 2021-07-12 18:41:11,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.779999810329173e-06, 579
[INFO] 2021-07-12 18:41:11,590 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 579
[INFO] 2021-07-12 18:41:11,590 [run_pretraining.py:  558]:	worker_index: 7, step: 579, cost: 8.769624, mlm loss: 8.769624, speed: 1.091906 steps/s, speed: 8.735244 samples/s, speed: 4472.445099 tokens/s, learning rate: 5.780e-06, loss_scalings: 13421.773438, pp_loss: 8.854365
[INFO] 2021-07-12 18:41:11,590 [run_pretraining.py:  512]:	********exe.run_579******* 
[INFO] 2021-07-12 18:41:12,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:12,505 [run_pretraining.py:  534]:	loss/total_loss, 8.963665008544922, 580
[INFO] 2021-07-12 18:41:12,505 [run_pretraining.py:  535]:	loss/mlm_loss, 8.963665008544922, 580
[INFO] 2021-07-12 18:41:12,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.789999704575166e-06, 580
[INFO] 2021-07-12 18:41:12,505 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 580
[INFO] 2021-07-12 18:41:12,505 [run_pretraining.py:  558]:	worker_index: 7, step: 580, cost: 8.963665, mlm loss: 8.963665, speed: 1.093389 steps/s, speed: 8.747115 samples/s, speed: 4478.522917 tokens/s, learning rate: 5.790e-06, loss_scalings: 13421.773438, pp_loss: 8.801369
[INFO] 2021-07-12 18:41:12,505 [run_pretraining.py:  512]:	********exe.run_580******* 
[INFO] 2021-07-12 18:41:13,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:13,426 [run_pretraining.py:  534]:	loss/total_loss, 8.801006317138672, 581
[INFO] 2021-07-12 18:41:13,426 [run_pretraining.py:  535]:	loss/mlm_loss, 8.801006317138672, 581
[INFO] 2021-07-12 18:41:13,427 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.7999995988211595e-06, 581
[INFO] 2021-07-12 18:41:13,427 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 581
[INFO] 2021-07-12 18:41:13,427 [run_pretraining.py:  558]:	worker_index: 7, step: 581, cost: 8.801006, mlm loss: 8.801006, speed: 1.086113 steps/s, speed: 8.688903 samples/s, speed: 4448.718338 tokens/s, learning rate: 5.800e-06, loss_scalings: 13421.773438, pp_loss: 8.813925
[INFO] 2021-07-12 18:41:13,427 [run_pretraining.py:  512]:	********exe.run_581******* 
[INFO] 2021-07-12 18:41:14,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:14,344 [run_pretraining.py:  534]:	loss/total_loss, 9.215595245361328, 582
[INFO] 2021-07-12 18:41:14,344 [run_pretraining.py:  535]:	loss/mlm_loss, 9.215595245361328, 582
[INFO] 2021-07-12 18:41:14,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.809999947814504e-06, 582
[INFO] 2021-07-12 18:41:14,344 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 582
[INFO] 2021-07-12 18:41:14,344 [run_pretraining.py:  558]:	worker_index: 7, step: 582, cost: 9.215595, mlm loss: 9.215595, speed: 1.090732 steps/s, speed: 8.725858 samples/s, speed: 4467.639322 tokens/s, learning rate: 5.810e-06, loss_scalings: 13421.773438, pp_loss: 8.893408
[INFO] 2021-07-12 18:41:14,344 [run_pretraining.py:  512]:	********exe.run_582******* 
[INFO] 2021-07-12 18:41:15,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:15,260 [run_pretraining.py:  534]:	loss/total_loss, 9.313095092773438, 583
[INFO] 2021-07-12 18:41:15,260 [run_pretraining.py:  535]:	loss/mlm_loss, 9.313095092773438, 583
[INFO] 2021-07-12 18:41:15,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.819999842060497e-06, 583
[INFO] 2021-07-12 18:41:15,261 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 583
[INFO] 2021-07-12 18:41:15,261 [run_pretraining.py:  558]:	worker_index: 7, step: 583, cost: 9.313095, mlm loss: 9.313095, speed: 1.091941 steps/s, speed: 8.735524 samples/s, speed: 4472.588314 tokens/s, learning rate: 5.820e-06, loss_scalings: 13421.773438, pp_loss: 8.967595
[INFO] 2021-07-12 18:41:15,261 [run_pretraining.py:  512]:	********exe.run_583******* 
[INFO] 2021-07-12 18:41:16,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:16,177 [run_pretraining.py:  534]:	loss/total_loss, 8.81120777130127, 584
[INFO] 2021-07-12 18:41:16,178 [run_pretraining.py:  535]:	loss/mlm_loss, 8.81120777130127, 584
[INFO] 2021-07-12 18:41:16,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.82999973630649e-06, 584
[INFO] 2021-07-12 18:41:16,178 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 584
[INFO] 2021-07-12 18:41:16,178 [run_pretraining.py:  558]:	worker_index: 7, step: 584, cost: 8.811208, mlm loss: 8.811208, speed: 1.091132 steps/s, speed: 8.729054 samples/s, speed: 4469.275754 tokens/s, learning rate: 5.830e-06, loss_scalings: 13421.773438, pp_loss: 8.825193
[INFO] 2021-07-12 18:41:16,178 [run_pretraining.py:  512]:	********exe.run_584******* 
[INFO] 2021-07-12 18:41:17,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:17,088 [run_pretraining.py:  534]:	loss/total_loss, 8.845282554626465, 585
[INFO] 2021-07-12 18:41:17,088 [run_pretraining.py:  535]:	loss/mlm_loss, 8.845282554626465, 585
[INFO] 2021-07-12 18:41:17,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.840000085299835e-06, 585
[INFO] 2021-07-12 18:41:17,088 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 585
[INFO] 2021-07-12 18:41:17,088 [run_pretraining.py:  558]:	worker_index: 7, step: 585, cost: 8.845283, mlm loss: 8.845283, speed: 1.099396 steps/s, speed: 8.795167 samples/s, speed: 4503.125393 tokens/s, learning rate: 5.840e-06, loss_scalings: 13421.773438, pp_loss: 8.585496
[INFO] 2021-07-12 18:41:17,088 [run_pretraining.py:  512]:	********exe.run_585******* 
[INFO] 2021-07-12 18:41:17,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  534]:	loss/total_loss, 8.436124801635742, 586
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  535]:	loss/mlm_loss, 8.436124801635742, 586
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.849999979545828e-06, 586
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 586
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  558]:	worker_index: 7, step: 586, cost: 8.436125, mlm loss: 8.436125, speed: 1.102056 steps/s, speed: 8.816448 samples/s, speed: 4514.021473 tokens/s, learning rate: 5.850e-06, loss_scalings: 13421.773438, pp_loss: 8.480145
[INFO] 2021-07-12 18:41:17,996 [run_pretraining.py:  512]:	********exe.run_586******* 
[INFO] 2021-07-12 18:41:18,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:18,908 [run_pretraining.py:  534]:	loss/total_loss, 8.782194137573242, 587
[INFO] 2021-07-12 18:41:18,908 [run_pretraining.py:  535]:	loss/mlm_loss, 8.782194137573242, 587
[INFO] 2021-07-12 18:41:18,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.859999873791821e-06, 587
[INFO] 2021-07-12 18:41:18,908 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 587
[INFO] 2021-07-12 18:41:18,908 [run_pretraining.py:  558]:	worker_index: 7, step: 587, cost: 8.782194, mlm loss: 8.782194, speed: 1.097261 steps/s, speed: 8.778085 samples/s, speed: 4494.379546 tokens/s, learning rate: 5.860e-06, loss_scalings: 13421.773438, pp_loss: 8.875446
[INFO] 2021-07-12 18:41:18,908 [run_pretraining.py:  512]:	********exe.run_587******* 
[INFO] 2021-07-12 18:41:19,810 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:19,810 [run_pretraining.py:  534]:	loss/total_loss, 9.067370414733887, 588
[INFO] 2021-07-12 18:41:19,810 [run_pretraining.py:  535]:	loss/mlm_loss, 9.067370414733887, 588
[INFO] 2021-07-12 18:41:19,810 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.869999768037815e-06, 588
[INFO] 2021-07-12 18:41:19,811 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 588
[INFO] 2021-07-12 18:41:19,811 [run_pretraining.py:  558]:	worker_index: 7, step: 588, cost: 9.067370, mlm loss: 9.067370, speed: 1.108723 steps/s, speed: 8.869785 samples/s, speed: 4541.329902 tokens/s, learning rate: 5.870e-06, loss_scalings: 13421.773438, pp_loss: 8.871984
[INFO] 2021-07-12 18:41:19,811 [run_pretraining.py:  512]:	********exe.run_588******* 
[INFO] 2021-07-12 18:41:20,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  534]:	loss/total_loss, 8.806805610656738, 589
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  535]:	loss/mlm_loss, 8.806805610656738, 589
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.880000117031159e-06, 589
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 589
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  558]:	worker_index: 7, step: 589, cost: 8.806806, mlm loss: 8.806806, speed: 1.109995 steps/s, speed: 8.879958 samples/s, speed: 4546.538646 tokens/s, learning rate: 5.880e-06, loss_scalings: 13421.773438, pp_loss: 8.531586
[INFO] 2021-07-12 18:41:20,712 [run_pretraining.py:  512]:	********exe.run_589******* 
[INFO] 2021-07-12 18:41:21,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:21,677 [run_pretraining.py:  534]:	loss/total_loss, 8.82717514038086, 590
[INFO] 2021-07-12 18:41:21,677 [run_pretraining.py:  535]:	loss/mlm_loss, 8.82717514038086, 590
[INFO] 2021-07-12 18:41:21,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.889999556529801e-06, 590
[INFO] 2021-07-12 18:41:21,678 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 590
[INFO] 2021-07-12 18:41:21,678 [run_pretraining.py:  558]:	worker_index: 7, step: 590, cost: 8.827175, mlm loss: 8.827175, speed: 1.036405 steps/s, speed: 8.291240 samples/s, speed: 4245.114790 tokens/s, learning rate: 5.890e-06, loss_scalings: 13421.773438, pp_loss: 8.841483
[INFO] 2021-07-12 18:41:21,678 [run_pretraining.py:  512]:	********exe.run_590******* 
[INFO] 2021-07-12 18:41:22,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:22,587 [run_pretraining.py:  534]:	loss/total_loss, 8.518433570861816, 591
[INFO] 2021-07-12 18:41:22,587 [run_pretraining.py:  535]:	loss/mlm_loss, 8.518433570861816, 591
[INFO] 2021-07-12 18:41:22,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.8999999055231456e-06, 591
[INFO] 2021-07-12 18:41:22,587 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 591
[INFO] 2021-07-12 18:41:22,587 [run_pretraining.py:  558]:	worker_index: 7, step: 591, cost: 8.518434, mlm loss: 8.518434, speed: 1.100197 steps/s, speed: 8.801573 samples/s, speed: 4506.405593 tokens/s, learning rate: 5.900e-06, loss_scalings: 13421.773438, pp_loss: 8.419230
[INFO] 2021-07-12 18:41:22,587 [run_pretraining.py:  512]:	********exe.run_591******* 
[INFO] 2021-07-12 18:41:23,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:23,497 [run_pretraining.py:  534]:	loss/total_loss, 9.110441207885742, 592
[INFO] 2021-07-12 18:41:23,497 [run_pretraining.py:  535]:	loss/mlm_loss, 9.110441207885742, 592
[INFO] 2021-07-12 18:41:23,497 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.909999799769139e-06, 592
[INFO] 2021-07-12 18:41:23,497 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 592
[INFO] 2021-07-12 18:41:23,497 [run_pretraining.py:  558]:	worker_index: 7, step: 592, cost: 9.110441, mlm loss: 9.110441, speed: 1.099561 steps/s, speed: 8.796490 samples/s, speed: 4503.803012 tokens/s, learning rate: 5.910e-06, loss_scalings: 13421.773438, pp_loss: 9.042507
[INFO] 2021-07-12 18:41:23,497 [run_pretraining.py:  512]:	********exe.run_592******* 
[INFO] 2021-07-12 18:41:24,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:24,413 [run_pretraining.py:  534]:	loss/total_loss, 8.663519859313965, 593
[INFO] 2021-07-12 18:41:24,413 [run_pretraining.py:  535]:	loss/mlm_loss, 8.663519859313965, 593
[INFO] 2021-07-12 18:41:24,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.919999694015132e-06, 593
[INFO] 2021-07-12 18:41:24,413 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 593
[INFO] 2021-07-12 18:41:24,413 [run_pretraining.py:  558]:	worker_index: 7, step: 593, cost: 8.663520, mlm loss: 8.663520, speed: 1.093112 steps/s, speed: 8.744895 samples/s, speed: 4477.386079 tokens/s, learning rate: 5.920e-06, loss_scalings: 13421.773438, pp_loss: 7.981713
[INFO] 2021-07-12 18:41:24,413 [run_pretraining.py:  512]:	********exe.run_593******* 
[INFO] 2021-07-12 18:41:25,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:25,371 [run_pretraining.py:  534]:	loss/total_loss, 8.829614639282227, 594
[INFO] 2021-07-12 18:41:25,371 [run_pretraining.py:  535]:	loss/mlm_loss, 8.829614639282227, 594
[INFO] 2021-07-12 18:41:25,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9300000430084765e-06, 594
[INFO] 2021-07-12 18:41:25,371 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 594
[INFO] 2021-07-12 18:41:25,371 [run_pretraining.py:  558]:	worker_index: 7, step: 594, cost: 8.829615, mlm loss: 8.829615, speed: 1.044436 steps/s, speed: 8.355489 samples/s, speed: 4278.010333 tokens/s, learning rate: 5.930e-06, loss_scalings: 13421.773438, pp_loss: 8.599947
[INFO] 2021-07-12 18:41:25,371 [run_pretraining.py:  512]:	********exe.run_594******* 
[INFO] 2021-07-12 18:41:26,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:26,301 [run_pretraining.py:  534]:	loss/total_loss, 8.3168306350708, 595
[INFO] 2021-07-12 18:41:26,301 [run_pretraining.py:  535]:	loss/mlm_loss, 8.3168306350708, 595
[INFO] 2021-07-12 18:41:26,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.93999993725447e-06, 595
[INFO] 2021-07-12 18:41:26,301 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 595
[INFO] 2021-07-12 18:41:26,301 [run_pretraining.py:  558]:	worker_index: 7, step: 595, cost: 8.316831, mlm loss: 8.316831, speed: 1.075581 steps/s, speed: 8.604647 samples/s, speed: 4405.579276 tokens/s, learning rate: 5.940e-06, loss_scalings: 13421.773438, pp_loss: 8.482622
[INFO] 2021-07-12 18:41:26,301 [run_pretraining.py:  512]:	********exe.run_595******* 
[INFO] 2021-07-12 18:41:27,238 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:27,238 [run_pretraining.py:  534]:	loss/total_loss, 8.688657760620117, 596
[INFO] 2021-07-12 18:41:27,238 [run_pretraining.py:  535]:	loss/mlm_loss, 8.688657760620117, 596
[INFO] 2021-07-12 18:41:27,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.949999831500463e-06, 596
[INFO] 2021-07-12 18:41:27,238 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 596
[INFO] 2021-07-12 18:41:27,239 [run_pretraining.py:  558]:	worker_index: 7, step: 596, cost: 8.688658, mlm loss: 8.688658, speed: 1.067771 steps/s, speed: 8.542164 samples/s, speed: 4373.588007 tokens/s, learning rate: 5.950e-06, loss_scalings: 13421.773438, pp_loss: 8.434301
[INFO] 2021-07-12 18:41:27,239 [run_pretraining.py:  512]:	********exe.run_596******* 
[INFO] 2021-07-12 18:41:28,149 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:28,149 [run_pretraining.py:  534]:	loss/total_loss, 8.82748794555664, 597
[INFO] 2021-07-12 18:41:28,149 [run_pretraining.py:  535]:	loss/mlm_loss, 8.82748794555664, 597
[INFO] 2021-07-12 18:41:28,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9599997257464565e-06, 597
[INFO] 2021-07-12 18:41:28,149 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 597
[INFO] 2021-07-12 18:41:28,150 [run_pretraining.py:  558]:	worker_index: 7, step: 597, cost: 8.827488, mlm loss: 8.827488, speed: 1.098461 steps/s, speed: 8.787690 samples/s, speed: 4499.297257 tokens/s, learning rate: 5.960e-06, loss_scalings: 13421.773438, pp_loss: 8.722401
[INFO] 2021-07-12 18:41:28,150 [run_pretraining.py:  512]:	********exe.run_597******* 
[INFO] 2021-07-12 18:41:29,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:29,060 [run_pretraining.py:  534]:	loss/total_loss, 8.389389991760254, 598
[INFO] 2021-07-12 18:41:29,061 [run_pretraining.py:  535]:	loss/mlm_loss, 8.389389991760254, 598
[INFO] 2021-07-12 18:41:29,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.970000074739801e-06, 598
[INFO] 2021-07-12 18:41:29,061 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 598
[INFO] 2021-07-12 18:41:29,061 [run_pretraining.py:  558]:	worker_index: 7, step: 598, cost: 8.389390, mlm loss: 8.389390, speed: 1.098187 steps/s, speed: 8.785497 samples/s, speed: 4498.174582 tokens/s, learning rate: 5.970e-06, loss_scalings: 13421.773438, pp_loss: 8.651925
[INFO] 2021-07-12 18:41:29,061 [run_pretraining.py:  512]:	********exe.run_598******* 
[INFO] 2021-07-12 18:41:29,969 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:29,970 [run_pretraining.py:  534]:	loss/total_loss, 8.781949996948242, 599
[INFO] 2021-07-12 18:41:29,970 [run_pretraining.py:  535]:	loss/mlm_loss, 8.781949996948242, 599
[INFO] 2021-07-12 18:41:29,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.979999968985794e-06, 599
[INFO] 2021-07-12 18:41:29,970 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 599
[INFO] 2021-07-12 18:41:29,970 [run_pretraining.py:  558]:	worker_index: 7, step: 599, cost: 8.781950, mlm loss: 8.781950, speed: 1.100320 steps/s, speed: 8.802562 samples/s, speed: 4506.911573 tokens/s, learning rate: 5.980e-06, loss_scalings: 13421.773438, pp_loss: 8.894523
[INFO] 2021-07-12 18:41:29,970 [run_pretraining.py:  512]:	********exe.run_599******* 
[INFO] 2021-07-12 18:41:30,892 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:30,892 [run_pretraining.py:  534]:	loss/total_loss, 8.326163291931152, 600
[INFO] 2021-07-12 18:41:30,892 [run_pretraining.py:  535]:	loss/mlm_loss, 8.326163291931152, 600
[INFO] 2021-07-12 18:41:30,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.9899998632317875e-06, 600
[INFO] 2021-07-12 18:41:30,892 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 600
[INFO] 2021-07-12 18:41:30,892 [run_pretraining.py:  558]:	worker_index: 7, step: 600, cost: 8.326163, mlm loss: 8.326163, speed: 1.085256 steps/s, speed: 8.682050 samples/s, speed: 4445.209832 tokens/s, learning rate: 5.990e-06, loss_scalings: 13421.773438, pp_loss: 8.632858
[INFO] 2021-07-12 18:41:30,892 [run_pretraining.py:  512]:	********exe.run_600******* 
[INFO] 2021-07-12 18:41:31,804 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:31,805 [run_pretraining.py:  534]:	loss/total_loss, 8.76852035522461, 601
[INFO] 2021-07-12 18:41:31,805 [run_pretraining.py:  535]:	loss/mlm_loss, 8.76852035522461, 601
[INFO] 2021-07-12 18:41:31,805 [run_pretraining.py:  536]:	lr/scheduled_lr, 5.999999757477781e-06, 601
[INFO] 2021-07-12 18:41:31,805 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 601
[INFO] 2021-07-12 18:41:31,805 [run_pretraining.py:  558]:	worker_index: 7, step: 601, cost: 8.768520, mlm loss: 8.768520, speed: 1.096718 steps/s, speed: 8.773740 samples/s, speed: 4492.154929 tokens/s, learning rate: 6.000e-06, loss_scalings: 13421.773438, pp_loss: 8.522797
[INFO] 2021-07-12 18:41:31,805 [run_pretraining.py:  512]:	********exe.run_601******* 
[INFO] 2021-07-12 18:41:32,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  534]:	loss/total_loss, 9.158001899719238, 602
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  535]:	loss/mlm_loss, 9.158001899719238, 602
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.010000106471125e-06, 602
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 602
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  558]:	worker_index: 7, step: 602, cost: 9.158002, mlm loss: 9.158002, speed: 1.096075 steps/s, speed: 8.768600 samples/s, speed: 4489.523021 tokens/s, learning rate: 6.010e-06, loss_scalings: 13421.773438, pp_loss: 8.741481
[INFO] 2021-07-12 18:41:32,718 [run_pretraining.py:  512]:	********exe.run_602******* 
[INFO] 2021-07-12 18:41:33,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:33,632 [run_pretraining.py:  534]:	loss/total_loss, 8.64958667755127, 603
[INFO] 2021-07-12 18:41:33,633 [run_pretraining.py:  535]:	loss/mlm_loss, 8.64958667755127, 603
[INFO] 2021-07-12 18:41:33,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.0199995459697675e-06, 603
[INFO] 2021-07-12 18:41:33,633 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 603
[INFO] 2021-07-12 18:41:33,633 [run_pretraining.py:  558]:	worker_index: 7, step: 603, cost: 8.649587, mlm loss: 8.649587, speed: 1.093755 steps/s, speed: 8.750039 samples/s, speed: 4480.020127 tokens/s, learning rate: 6.020e-06, loss_scalings: 13421.773438, pp_loss: 8.989614
[INFO] 2021-07-12 18:41:33,633 [run_pretraining.py:  512]:	********exe.run_603******* 
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  534]:	loss/total_loss, 8.213449478149414, 604
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  535]:	loss/mlm_loss, 8.213449478149414, 604
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.029999894963112e-06, 604
[INFO] 2021-07-12 18:41:34,551 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 604
[INFO] 2021-07-12 18:41:34,552 [run_pretraining.py:  558]:	worker_index: 7, step: 604, cost: 8.213449, mlm loss: 8.213449, speed: 1.089170 steps/s, speed: 8.713359 samples/s, speed: 4461.239939 tokens/s, learning rate: 6.030e-06, loss_scalings: 13421.773438, pp_loss: 8.688942
[INFO] 2021-07-12 18:41:34,552 [run_pretraining.py:  512]:	********exe.run_604******* 
[INFO] 2021-07-12 18:41:35,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:35,459 [run_pretraining.py:  534]:	loss/total_loss, 8.722707748413086, 605
[INFO] 2021-07-12 18:41:35,459 [run_pretraining.py:  535]:	loss/mlm_loss, 8.722707748413086, 605
[INFO] 2021-07-12 18:41:35,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.040000243956456e-06, 605
[INFO] 2021-07-12 18:41:35,459 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 605
[INFO] 2021-07-12 18:41:35,459 [run_pretraining.py:  558]:	worker_index: 7, step: 605, cost: 8.722708, mlm loss: 8.722708, speed: 1.102983 steps/s, speed: 8.823860 samples/s, speed: 4517.816501 tokens/s, learning rate: 6.040e-06, loss_scalings: 13421.773438, pp_loss: 8.778929
[INFO] 2021-07-12 18:41:35,459 [run_pretraining.py:  512]:	********exe.run_605******* 
[INFO] 2021-07-12 18:41:36,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:36,374 [run_pretraining.py:  534]:	loss/total_loss, 8.601950645446777, 606
[INFO] 2021-07-12 18:41:36,374 [run_pretraining.py:  535]:	loss/mlm_loss, 8.601950645446777, 606
[INFO] 2021-07-12 18:41:36,374 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.049999683455098e-06, 606
[INFO] 2021-07-12 18:41:36,374 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 606
[INFO] 2021-07-12 18:41:36,374 [run_pretraining.py:  558]:	worker_index: 7, step: 606, cost: 8.601951, mlm loss: 8.601951, speed: 1.092947 steps/s, speed: 8.743578 samples/s, speed: 4476.711719 tokens/s, learning rate: 6.050e-06, loss_scalings: 13421.773438, pp_loss: 8.612702
[INFO] 2021-07-12 18:41:36,375 [run_pretraining.py:  512]:	********exe.run_606******* 
[INFO] 2021-07-12 18:41:37,289 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:37,289 [run_pretraining.py:  534]:	loss/total_loss, 8.53030776977539, 607
[INFO] 2021-07-12 18:41:37,290 [run_pretraining.py:  535]:	loss/mlm_loss, 8.53030776977539, 607
[INFO] 2021-07-12 18:41:37,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.060000032448443e-06, 607
[INFO] 2021-07-12 18:41:37,290 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 607
[INFO] 2021-07-12 18:41:37,290 [run_pretraining.py:  558]:	worker_index: 7, step: 607, cost: 8.530308, mlm loss: 8.530308, speed: 1.093282 steps/s, speed: 8.746258 samples/s, speed: 4478.083987 tokens/s, learning rate: 6.060e-06, loss_scalings: 13421.773438, pp_loss: 8.560417
[INFO] 2021-07-12 18:41:37,290 [run_pretraining.py:  512]:	********exe.run_607******* 
[INFO] 2021-07-12 18:41:38,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:38,203 [run_pretraining.py:  534]:	loss/total_loss, 8.761001586914062, 608
[INFO] 2021-07-12 18:41:38,203 [run_pretraining.py:  535]:	loss/mlm_loss, 8.761001586914062, 608
[INFO] 2021-07-12 18:41:38,203 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.069999926694436e-06, 608
[INFO] 2021-07-12 18:41:38,203 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 608
[INFO] 2021-07-12 18:41:38,203 [run_pretraining.py:  558]:	worker_index: 7, step: 608, cost: 8.761002, mlm loss: 8.761002, speed: 1.095409 steps/s, speed: 8.763271 samples/s, speed: 4486.794590 tokens/s, learning rate: 6.070e-06, loss_scalings: 13421.773438, pp_loss: 8.720797
[INFO] 2021-07-12 18:41:38,203 [run_pretraining.py:  512]:	********exe.run_608******* 
[INFO] 2021-07-12 18:41:39,120 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:39,121 [run_pretraining.py:  534]:	loss/total_loss, 8.99807071685791, 609
[INFO] 2021-07-12 18:41:39,121 [run_pretraining.py:  535]:	loss/mlm_loss, 8.99807071685791, 609
[INFO] 2021-07-12 18:41:39,121 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.079999820940429e-06, 609
[INFO] 2021-07-12 18:41:39,121 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 609
[INFO] 2021-07-12 18:41:39,121 [run_pretraining.py:  558]:	worker_index: 7, step: 609, cost: 8.998071, mlm loss: 8.998071, speed: 1.090325 steps/s, speed: 8.722596 samples/s, speed: 4465.969259 tokens/s, learning rate: 6.080e-06, loss_scalings: 13421.773438, pp_loss: 8.709620
[INFO] 2021-07-12 18:41:39,121 [run_pretraining.py:  512]:	********exe.run_609******* 
[INFO] 2021-07-12 18:41:40,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:40,045 [run_pretraining.py:  534]:	loss/total_loss, 8.561625480651855, 610
[INFO] 2021-07-12 18:41:40,046 [run_pretraining.py:  535]:	loss/mlm_loss, 8.561625480651855, 610
[INFO] 2021-07-12 18:41:40,046 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.089999715186423e-06, 610
[INFO] 2021-07-12 18:41:40,046 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 610
[INFO] 2021-07-12 18:41:40,046 [run_pretraining.py:  558]:	worker_index: 7, step: 610, cost: 8.561625, mlm loss: 8.561625, speed: 1.082228 steps/s, speed: 8.657827 samples/s, speed: 4432.807667 tokens/s, learning rate: 6.090e-06, loss_scalings: 13421.773438, pp_loss: 8.620710
[INFO] 2021-07-12 18:41:40,046 [run_pretraining.py:  512]:	********exe.run_610******* 
[INFO] 2021-07-12 18:41:40,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:40,964 [run_pretraining.py:  534]:	loss/total_loss, 8.801700592041016, 611
[INFO] 2021-07-12 18:41:40,964 [run_pretraining.py:  535]:	loss/mlm_loss, 8.801700592041016, 611
[INFO] 2021-07-12 18:41:40,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.100000064179767e-06, 611
[INFO] 2021-07-12 18:41:40,964 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 611
[INFO] 2021-07-12 18:41:40,964 [run_pretraining.py:  558]:	worker_index: 7, step: 611, cost: 8.801701, mlm loss: 8.801701, speed: 1.090022 steps/s, speed: 8.720180 samples/s, speed: 4464.732035 tokens/s, learning rate: 6.100e-06, loss_scalings: 13421.773438, pp_loss: 8.794608
[INFO] 2021-07-12 18:41:40,964 [run_pretraining.py:  512]:	********exe.run_611******* 
[INFO] 2021-07-12 18:41:41,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:41,880 [run_pretraining.py:  534]:	loss/total_loss, 8.710155487060547, 612
[INFO] 2021-07-12 18:41:41,880 [run_pretraining.py:  535]:	loss/mlm_loss, 8.710155487060547, 612
[INFO] 2021-07-12 18:41:41,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.109999503678409e-06, 612
[INFO] 2021-07-12 18:41:41,880 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 612
[INFO] 2021-07-12 18:41:41,881 [run_pretraining.py:  558]:	worker_index: 7, step: 612, cost: 8.710155, mlm loss: 8.710155, speed: 1.091690 steps/s, speed: 8.733523 samples/s, speed: 4471.563886 tokens/s, learning rate: 6.110e-06, loss_scalings: 13421.773438, pp_loss: 8.831215
[INFO] 2021-07-12 18:41:41,881 [run_pretraining.py:  512]:	********exe.run_612******* 
[INFO] 2021-07-12 18:41:42,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:42,796 [run_pretraining.py:  534]:	loss/total_loss, 8.554637908935547, 613
[INFO] 2021-07-12 18:41:42,797 [run_pretraining.py:  535]:	loss/mlm_loss, 8.554637908935547, 613
[INFO] 2021-07-12 18:41:42,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.119999852671754e-06, 613
[INFO] 2021-07-12 18:41:42,797 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 613
[INFO] 2021-07-12 18:41:42,797 [run_pretraining.py:  558]:	worker_index: 7, step: 613, cost: 8.554638, mlm loss: 8.554638, speed: 1.092200 steps/s, speed: 8.737601 samples/s, speed: 4473.651654 tokens/s, learning rate: 6.120e-06, loss_scalings: 13421.773438, pp_loss: 8.481033
[INFO] 2021-07-12 18:41:42,797 [run_pretraining.py:  512]:	********exe.run_613******* 
[INFO] 2021-07-12 18:41:43,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:43,711 [run_pretraining.py:  534]:	loss/total_loss, 8.428175926208496, 614
[INFO] 2021-07-12 18:41:43,711 [run_pretraining.py:  535]:	loss/mlm_loss, 8.428175926208496, 614
[INFO] 2021-07-12 18:41:43,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.129999746917747e-06, 614
[INFO] 2021-07-12 18:41:43,711 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 614
[INFO] 2021-07-12 18:41:43,711 [run_pretraining.py:  558]:	worker_index: 7, step: 614, cost: 8.428176, mlm loss: 8.428176, speed: 1.094600 steps/s, speed: 8.756801 samples/s, speed: 4483.482023 tokens/s, learning rate: 6.130e-06, loss_scalings: 13421.773438, pp_loss: 8.731707
[INFO] 2021-07-12 18:41:43,711 [run_pretraining.py:  512]:	********exe.run_614******* 
[INFO] 2021-07-12 18:41:44,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:41:44,629 [run_pretraining.py:  534]:	loss/total_loss, 8.888362884521484, 615
[INFO] 2021-07-12 18:41:44,629 [run_pretraining.py:  535]:	loss/mlm_loss, 8.888362884521484, 615
[INFO] 2021-07-12 18:41:44,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.13999964116374e-06, 615
[INFO] 2021-07-12 18:41:44,629 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 615
[INFO] 2021-07-12 18:41:44,629 [run_pretraining.py:  558]:	worker_index: 7, step: 615, cost: 8.888363, mlm loss: 8.888363, speed: 1.090129 steps/s, speed: 8.721034 samples/s, speed: 4465.169511 tokens/s, learning rate: 6.140e-06, loss_scalings: 13421.773438, pp_loss: 8.561579
[INFO] 2021-07-12 18:41:44,629 [run_pretraining.py:  512]:	********exe.run_615******* 
[INFO] 2021-07-12 18:42:10,734 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:10,734 [run_pretraining.py:  534]:	loss/total_loss, 8.352603912353516, 616
[INFO] 2021-07-12 18:42:10,734 [run_pretraining.py:  535]:	loss/mlm_loss, 8.352603912353516, 616
[INFO] 2021-07-12 18:42:10,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.1499999901570845e-06, 616
[INFO] 2021-07-12 18:42:10,734 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 616
[INFO] 2021-07-12 18:42:10,735 [run_pretraining.py:  558]:	worker_index: 7, step: 616, cost: 8.352604, mlm loss: 8.352604, speed: 0.038307 steps/s, speed: 0.306455 samples/s, speed: 156.905183 tokens/s, learning rate: 6.150e-06, loss_scalings: 13421.773438, pp_loss: 8.107716
[INFO] 2021-07-12 18:42:10,735 [run_pretraining.py:  512]:	********exe.run_616******* 
[INFO] 2021-07-12 18:42:11,651 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  534]:	loss/total_loss, 8.606801986694336, 617
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  535]:	loss/mlm_loss, 8.606801986694336, 617
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.159999884403078e-06, 617
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 617
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  558]:	worker_index: 7, step: 617, cost: 8.606802, mlm loss: 8.606802, speed: 1.090575 steps/s, speed: 8.724597 samples/s, speed: 4466.993447 tokens/s, learning rate: 6.160e-06, loss_scalings: 13421.773438, pp_loss: 8.627394
[INFO] 2021-07-12 18:42:11,652 [run_pretraining.py:  512]:	********exe.run_617******* 
[INFO] 2021-07-12 18:42:12,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:12,567 [run_pretraining.py:  534]:	loss/total_loss, 8.648411750793457, 618
[INFO] 2021-07-12 18:42:12,568 [run_pretraining.py:  535]:	loss/mlm_loss, 8.648411750793457, 618
[INFO] 2021-07-12 18:42:12,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.169999778649071e-06, 618
[INFO] 2021-07-12 18:42:12,568 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 618
[INFO] 2021-07-12 18:42:12,568 [run_pretraining.py:  558]:	worker_index: 7, step: 618, cost: 8.648412, mlm loss: 8.648412, speed: 1.092980 steps/s, speed: 8.743837 samples/s, speed: 4476.844708 tokens/s, learning rate: 6.170e-06, loss_scalings: 13421.773438, pp_loss: 8.723398
[INFO] 2021-07-12 18:42:12,568 [run_pretraining.py:  512]:	********exe.run_618******* 
[INFO] 2021-07-12 18:42:13,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:13,483 [run_pretraining.py:  534]:	loss/total_loss, 8.539306640625, 619
[INFO] 2021-07-12 18:42:13,483 [run_pretraining.py:  535]:	loss/mlm_loss, 8.539306640625, 619
[INFO] 2021-07-12 18:42:13,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.179999672895065e-06, 619
[INFO] 2021-07-12 18:42:13,483 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 619
[INFO] 2021-07-12 18:42:13,483 [run_pretraining.py:  558]:	worker_index: 7, step: 619, cost: 8.539307, mlm loss: 8.539307, speed: 1.093294 steps/s, speed: 8.746354 samples/s, speed: 4478.133012 tokens/s, learning rate: 6.180e-06, loss_scalings: 13421.773438, pp_loss: 8.619358
[INFO] 2021-07-12 18:42:13,483 [run_pretraining.py:  512]:	********exe.run_619******* 
[INFO] 2021-07-12 18:42:14,392 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:14,393 [run_pretraining.py:  534]:	loss/total_loss, 8.793421745300293, 620
[INFO] 2021-07-12 18:42:14,393 [run_pretraining.py:  535]:	loss/mlm_loss, 8.793421745300293, 620
[INFO] 2021-07-12 18:42:14,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.190000021888409e-06, 620
[INFO] 2021-07-12 18:42:14,393 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 620
[INFO] 2021-07-12 18:42:14,393 [run_pretraining.py:  558]:	worker_index: 7, step: 620, cost: 8.793422, mlm loss: 8.793422, speed: 1.099642 steps/s, speed: 8.797136 samples/s, speed: 4504.133632 tokens/s, learning rate: 6.190e-06, loss_scalings: 13421.773438, pp_loss: 8.719068
[INFO] 2021-07-12 18:42:14,393 [run_pretraining.py:  512]:	********exe.run_620******* 
[INFO] 2021-07-12 18:42:15,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:15,306 [run_pretraining.py:  534]:	loss/total_loss, 8.227327346801758, 621
[INFO] 2021-07-12 18:42:15,306 [run_pretraining.py:  535]:	loss/mlm_loss, 8.227327346801758, 621
[INFO] 2021-07-12 18:42:15,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.199999916134402e-06, 621
[INFO] 2021-07-12 18:42:15,306 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 621
[INFO] 2021-07-12 18:42:15,306 [run_pretraining.py:  558]:	worker_index: 7, step: 621, cost: 8.227327, mlm loss: 8.227327, speed: 1.095915 steps/s, speed: 8.767317 samples/s, speed: 4488.866112 tokens/s, learning rate: 6.200e-06, loss_scalings: 13421.773438, pp_loss: 8.630905
[INFO] 2021-07-12 18:42:15,306 [run_pretraining.py:  512]:	********exe.run_621******* 
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  534]:	loss/total_loss, 8.387238502502441, 622
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  535]:	loss/mlm_loss, 8.387238502502441, 622
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2099998103803955e-06, 622
[INFO] 2021-07-12 18:42:16,216 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 622
[INFO] 2021-07-12 18:42:16,217 [run_pretraining.py:  558]:	worker_index: 7, step: 622, cost: 8.387239, mlm loss: 8.387239, speed: 1.099381 steps/s, speed: 8.795045 samples/s, speed: 4503.062836 tokens/s, learning rate: 6.210e-06, loss_scalings: 13421.773438, pp_loss: 8.617512
[INFO] 2021-07-12 18:42:16,217 [run_pretraining.py:  512]:	********exe.run_622******* 
[INFO] 2021-07-12 18:42:17,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:17,138 [run_pretraining.py:  534]:	loss/total_loss, 8.743988990783691, 623
[INFO] 2021-07-12 18:42:17,138 [run_pretraining.py:  535]:	loss/mlm_loss, 8.743988990783691, 623
[INFO] 2021-07-12 18:42:17,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.219999704626389e-06, 623
[INFO] 2021-07-12 18:42:17,138 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 623
[INFO] 2021-07-12 18:42:17,138 [run_pretraining.py:  558]:	worker_index: 7, step: 623, cost: 8.743989, mlm loss: 8.743989, speed: 1.085788 steps/s, speed: 8.686307 samples/s, speed: 4447.389335 tokens/s, learning rate: 6.220e-06, loss_scalings: 13421.773438, pp_loss: 8.523029
[INFO] 2021-07-12 18:42:17,138 [run_pretraining.py:  512]:	********exe.run_623******* 
[INFO] 2021-07-12 18:42:18,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:18,050 [run_pretraining.py:  534]:	loss/total_loss, 8.718271255493164, 624
[INFO] 2021-07-12 18:42:18,050 [run_pretraining.py:  535]:	loss/mlm_loss, 8.718271255493164, 624
[INFO] 2021-07-12 18:42:18,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.230000053619733e-06, 624
[INFO] 2021-07-12 18:42:18,050 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 624
[INFO] 2021-07-12 18:42:18,050 [run_pretraining.py:  558]:	worker_index: 7, step: 624, cost: 8.718271, mlm loss: 8.718271, speed: 1.097266 steps/s, speed: 8.778124 samples/s, speed: 4494.399534 tokens/s, learning rate: 6.230e-06, loss_scalings: 13421.773438, pp_loss: 8.889206
[INFO] 2021-07-12 18:42:18,050 [run_pretraining.py:  512]:	********exe.run_624******* 
[INFO] 2021-07-12 18:42:18,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:18,967 [run_pretraining.py:  534]:	loss/total_loss, 8.350395202636719, 625
[INFO] 2021-07-12 18:42:18,967 [run_pretraining.py:  535]:	loss/mlm_loss, 8.350395202636719, 625
[INFO] 2021-07-12 18:42:18,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2399994931183755e-06, 625
[INFO] 2021-07-12 18:42:18,968 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 625
[INFO] 2021-07-12 18:42:18,968 [run_pretraining.py:  558]:	worker_index: 7, step: 625, cost: 8.350395, mlm loss: 8.350395, speed: 1.090702 steps/s, speed: 8.725620 samples/s, speed: 4467.517335 tokens/s, learning rate: 6.240e-06, loss_scalings: 13421.773438, pp_loss: 8.614035
[INFO] 2021-07-12 18:42:18,968 [run_pretraining.py:  512]:	********exe.run_625******* 
[INFO] 2021-07-12 18:42:19,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:19,875 [run_pretraining.py:  534]:	loss/total_loss, 7.780525207519531, 626
[INFO] 2021-07-12 18:42:19,875 [run_pretraining.py:  535]:	loss/mlm_loss, 7.780525207519531, 626
[INFO] 2021-07-12 18:42:19,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.24999984211172e-06, 626
[INFO] 2021-07-12 18:42:19,875 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 626
[INFO] 2021-07-12 18:42:19,875 [run_pretraining.py:  558]:	worker_index: 7, step: 626, cost: 7.780525, mlm loss: 7.780525, speed: 1.102366 steps/s, speed: 8.818930 samples/s, speed: 4515.292103 tokens/s, learning rate: 6.250e-06, loss_scalings: 13421.773438, pp_loss: 8.430895
[INFO] 2021-07-12 18:42:19,876 [run_pretraining.py:  512]:	********exe.run_626******* 
[INFO] 2021-07-12 18:42:20,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:20,789 [run_pretraining.py:  534]:	loss/total_loss, 8.756315231323242, 627
[INFO] 2021-07-12 18:42:20,789 [run_pretraining.py:  535]:	loss/mlm_loss, 8.756315231323242, 627
[INFO] 2021-07-12 18:42:20,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.260000191105064e-06, 627
[INFO] 2021-07-12 18:42:20,790 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 627
[INFO] 2021-07-12 18:42:20,790 [run_pretraining.py:  558]:	worker_index: 7, step: 627, cost: 8.756315, mlm loss: 8.756315, speed: 1.094562 steps/s, speed: 8.756492 samples/s, speed: 4483.324069 tokens/s, learning rate: 6.260e-06, loss_scalings: 13421.773438, pp_loss: 8.590654
[INFO] 2021-07-12 18:42:20,790 [run_pretraining.py:  512]:	********exe.run_627******* 
[INFO] 2021-07-12 18:42:21,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:21,705 [run_pretraining.py:  534]:	loss/total_loss, 8.63354778289795, 628
[INFO] 2021-07-12 18:42:21,705 [run_pretraining.py:  535]:	loss/mlm_loss, 8.63354778289795, 628
[INFO] 2021-07-12 18:42:21,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.270000085351057e-06, 628
[INFO] 2021-07-12 18:42:21,705 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 628
[INFO] 2021-07-12 18:42:21,705 [run_pretraining.py:  558]:	worker_index: 7, step: 628, cost: 8.633548, mlm loss: 8.633548, speed: 1.093374 steps/s, speed: 8.746990 samples/s, speed: 4478.458706 tokens/s, learning rate: 6.270e-06, loss_scalings: 13421.773438, pp_loss: 8.719928
[INFO] 2021-07-12 18:42:21,705 [run_pretraining.py:  512]:	********exe.run_628******* 
[INFO] 2021-07-12 18:42:22,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:22,624 [run_pretraining.py:  534]:	loss/total_loss, 8.752639770507812, 629
[INFO] 2021-07-12 18:42:22,624 [run_pretraining.py:  535]:	loss/mlm_loss, 8.752639770507812, 629
[INFO] 2021-07-12 18:42:22,624 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.2799995248497e-06, 629
[INFO] 2021-07-12 18:42:22,625 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 629
[INFO] 2021-07-12 18:42:22,625 [run_pretraining.py:  558]:	worker_index: 7, step: 629, cost: 8.752640, mlm loss: 8.752640, speed: 1.088098 steps/s, speed: 8.704781 samples/s, speed: 4456.847808 tokens/s, learning rate: 6.280e-06, loss_scalings: 13421.773438, pp_loss: 8.634691
[INFO] 2021-07-12 18:42:22,625 [run_pretraining.py:  512]:	********exe.run_629******* 
[INFO] 2021-07-12 18:42:23,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:23,538 [run_pretraining.py:  534]:	loss/total_loss, 8.82075309753418, 630
[INFO] 2021-07-12 18:42:23,538 [run_pretraining.py:  535]:	loss/mlm_loss, 8.82075309753418, 630
[INFO] 2021-07-12 18:42:23,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.289999873843044e-06, 630
[INFO] 2021-07-12 18:42:23,538 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 630
[INFO] 2021-07-12 18:42:23,538 [run_pretraining.py:  558]:	worker_index: 7, step: 630, cost: 8.820753, mlm loss: 8.820753, speed: 1.095119 steps/s, speed: 8.760951 samples/s, speed: 4485.606702 tokens/s, learning rate: 6.290e-06, loss_scalings: 13421.773438, pp_loss: 8.626381
[INFO] 2021-07-12 18:42:23,538 [run_pretraining.py:  512]:	********exe.run_630******* 
[INFO] 2021-07-12 18:42:24,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:24,456 [run_pretraining.py:  534]:	loss/total_loss, 8.8087158203125, 631
[INFO] 2021-07-12 18:42:24,456 [run_pretraining.py:  535]:	loss/mlm_loss, 8.8087158203125, 631
[INFO] 2021-07-12 18:42:24,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.299999768089037e-06, 631
[INFO] 2021-07-12 18:42:24,456 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 631
[INFO] 2021-07-12 18:42:24,456 [run_pretraining.py:  558]:	worker_index: 7, step: 631, cost: 8.808716, mlm loss: 8.808716, speed: 1.090615 steps/s, speed: 8.724916 samples/s, speed: 4467.157221 tokens/s, learning rate: 6.300e-06, loss_scalings: 13421.773438, pp_loss: 8.726446
[INFO] 2021-07-12 18:42:24,456 [run_pretraining.py:  512]:	********exe.run_631******* 
[INFO] 2021-07-12 18:42:25,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:25,376 [run_pretraining.py:  534]:	loss/total_loss, 8.34510612487793, 632
[INFO] 2021-07-12 18:42:25,376 [run_pretraining.py:  535]:	loss/mlm_loss, 8.34510612487793, 632
[INFO] 2021-07-12 18:42:25,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.310000117082382e-06, 632
[INFO] 2021-07-12 18:42:25,376 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 632
[INFO] 2021-07-12 18:42:25,376 [run_pretraining.py:  558]:	worker_index: 7, step: 632, cost: 8.345106, mlm loss: 8.345106, speed: 1.087333 steps/s, speed: 8.698663 samples/s, speed: 4453.715532 tokens/s, learning rate: 6.310e-06, loss_scalings: 13421.773438, pp_loss: 7.723489
[INFO] 2021-07-12 18:42:25,376 [run_pretraining.py:  512]:	********exe.run_632******* 
[INFO] 2021-07-12 18:42:26,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:26,303 [run_pretraining.py:  534]:	loss/total_loss, 8.137773513793945, 633
[INFO] 2021-07-12 18:42:26,303 [run_pretraining.py:  535]:	loss/mlm_loss, 8.137773513793945, 633
[INFO] 2021-07-12 18:42:26,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.319999556581024e-06, 633
[INFO] 2021-07-12 18:42:26,303 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 633
[INFO] 2021-07-12 18:42:26,303 [run_pretraining.py:  558]:	worker_index: 7, step: 633, cost: 8.137774, mlm loss: 8.137774, speed: 1.079835 steps/s, speed: 8.638676 samples/s, speed: 4423.002151 tokens/s, learning rate: 6.320e-06, loss_scalings: 13421.773438, pp_loss: 7.766597
[INFO] 2021-07-12 18:42:26,303 [run_pretraining.py:  512]:	********exe.run_633******* 
[INFO] 2021-07-12 18:42:27,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:27,222 [run_pretraining.py:  534]:	loss/total_loss, 8.371377944946289, 634
[INFO] 2021-07-12 18:42:27,222 [run_pretraining.py:  535]:	loss/mlm_loss, 8.371377944946289, 634
[INFO] 2021-07-12 18:42:27,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.329999905574368e-06, 634
[INFO] 2021-07-12 18:42:27,222 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 634
[INFO] 2021-07-12 18:42:27,222 [run_pretraining.py:  558]:	worker_index: 7, step: 634, cost: 8.371378, mlm loss: 8.371378, speed: 1.088584 steps/s, speed: 8.708671 samples/s, speed: 4458.839687 tokens/s, learning rate: 6.330e-06, loss_scalings: 13421.773438, pp_loss: 8.217110
[INFO] 2021-07-12 18:42:27,222 [run_pretraining.py:  512]:	********exe.run_634******* 
[INFO] 2021-07-12 18:42:28,143 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:28,144 [run_pretraining.py:  534]:	loss/total_loss, 8.547249794006348, 635
[INFO] 2021-07-12 18:42:28,144 [run_pretraining.py:  535]:	loss/mlm_loss, 8.547249794006348, 635
[INFO] 2021-07-12 18:42:28,144 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.339999799820362e-06, 635
[INFO] 2021-07-12 18:42:28,144 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 635
[INFO] 2021-07-12 18:42:28,144 [run_pretraining.py:  558]:	worker_index: 7, step: 635, cost: 8.547250, mlm loss: 8.547250, speed: 1.085829 steps/s, speed: 8.686629 samples/s, speed: 4447.553978 tokens/s, learning rate: 6.340e-06, loss_scalings: 13421.773438, pp_loss: 8.528879
[INFO] 2021-07-12 18:42:28,144 [run_pretraining.py:  512]:	********exe.run_635******* 
[INFO] 2021-07-12 18:42:29,092 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:29,093 [run_pretraining.py:  534]:	loss/total_loss, 8.43482780456543, 636
[INFO] 2021-07-12 18:42:29,093 [run_pretraining.py:  535]:	loss/mlm_loss, 8.43482780456543, 636
[INFO] 2021-07-12 18:42:29,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.350000148813706e-06, 636
[INFO] 2021-07-12 18:42:29,093 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 636
[INFO] 2021-07-12 18:42:29,093 [run_pretraining.py:  558]:	worker_index: 7, step: 636, cost: 8.434828, mlm loss: 8.434828, speed: 1.054423 steps/s, speed: 8.435386 samples/s, speed: 4318.917855 tokens/s, learning rate: 6.350e-06, loss_scalings: 13421.773438, pp_loss: 8.443003
[INFO] 2021-07-12 18:42:29,093 [run_pretraining.py:  512]:	********exe.run_636******* 
[INFO] 2021-07-12 18:42:30,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:30,013 [run_pretraining.py:  534]:	loss/total_loss, 8.917102813720703, 637
[INFO] 2021-07-12 18:42:30,013 [run_pretraining.py:  535]:	loss/mlm_loss, 8.917102813720703, 637
[INFO] 2021-07-12 18:42:30,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.360000043059699e-06, 637
[INFO] 2021-07-12 18:42:30,013 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 637
[INFO] 2021-07-12 18:42:30,013 [run_pretraining.py:  558]:	worker_index: 7, step: 637, cost: 8.917103, mlm loss: 8.917103, speed: 1.087263 steps/s, speed: 8.698104 samples/s, speed: 4453.429214 tokens/s, learning rate: 6.360e-06, loss_scalings: 13421.773438, pp_loss: 8.747162
[INFO] 2021-07-12 18:42:30,013 [run_pretraining.py:  512]:	********exe.run_637******* 
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  534]:	loss/total_loss, 8.382975578308105, 638
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  535]:	loss/mlm_loss, 8.382975578308105, 638
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.369999482558342e-06, 638
[INFO] 2021-07-12 18:42:30,938 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 638
[INFO] 2021-07-12 18:42:30,939 [run_pretraining.py:  558]:	worker_index: 7, step: 638, cost: 8.382976, mlm loss: 8.382976, speed: 1.081528 steps/s, speed: 8.652222 samples/s, speed: 4429.937525 tokens/s, learning rate: 6.370e-06, loss_scalings: 13421.773438, pp_loss: 8.661111
[INFO] 2021-07-12 18:42:30,939 [run_pretraining.py:  512]:	********exe.run_638******* 
[INFO] 2021-07-12 18:42:31,848 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:31,849 [run_pretraining.py:  534]:	loss/total_loss, 8.238531112670898, 639
[INFO] 2021-07-12 18:42:31,849 [run_pretraining.py:  535]:	loss/mlm_loss, 8.238531112670898, 639
[INFO] 2021-07-12 18:42:31,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.379999831551686e-06, 639
[INFO] 2021-07-12 18:42:31,849 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 639
[INFO] 2021-07-12 18:42:31,849 [run_pretraining.py:  558]:	worker_index: 7, step: 639, cost: 8.238531, mlm loss: 8.238531, speed: 1.098906 steps/s, speed: 8.791247 samples/s, speed: 4501.118524 tokens/s, learning rate: 6.380e-06, loss_scalings: 13421.773438, pp_loss: 8.701460
[INFO] 2021-07-12 18:42:31,849 [run_pretraining.py:  512]:	********exe.run_639******* 
[INFO] 2021-07-12 18:42:32,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:32,840 [run_pretraining.py:  534]:	loss/total_loss, 8.845211029052734, 640
[INFO] 2021-07-12 18:42:32,841 [run_pretraining.py:  535]:	loss/mlm_loss, 8.845211029052734, 640
[INFO] 2021-07-12 18:42:32,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.39000018054503e-06, 640
[INFO] 2021-07-12 18:42:32,841 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 640
[INFO] 2021-07-12 18:42:32,841 [run_pretraining.py:  558]:	worker_index: 7, step: 640, cost: 8.845211, mlm loss: 8.845211, speed: 1.009135 steps/s, speed: 8.073080 samples/s, speed: 4133.416833 tokens/s, learning rate: 6.390e-06, loss_scalings: 13421.773438, pp_loss: 8.534777
[INFO] 2021-07-12 18:42:32,841 [run_pretraining.py:  512]:	********exe.run_640******* 
[INFO] 2021-07-12 18:42:33,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:33,745 [run_pretraining.py:  534]:	loss/total_loss, 8.46548843383789, 641
[INFO] 2021-07-12 18:42:33,745 [run_pretraining.py:  535]:	loss/mlm_loss, 8.46548843383789, 641
[INFO] 2021-07-12 18:42:33,746 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.4000000747910235e-06, 641
[INFO] 2021-07-12 18:42:33,746 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 641
[INFO] 2021-07-12 18:42:33,746 [run_pretraining.py:  558]:	worker_index: 7, step: 641, cost: 8.465488, mlm loss: 8.465488, speed: 1.105797 steps/s, speed: 8.846375 samples/s, speed: 4529.343855 tokens/s, learning rate: 6.400e-06, loss_scalings: 13421.773438, pp_loss: 8.675287
[INFO] 2021-07-12 18:42:33,746 [run_pretraining.py:  512]:	********exe.run_641******* 
[INFO] 2021-07-12 18:42:34,650 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:34,650 [run_pretraining.py:  534]:	loss/total_loss, 8.979328155517578, 642
[INFO] 2021-07-12 18:42:34,650 [run_pretraining.py:  535]:	loss/mlm_loss, 8.979328155517578, 642
[INFO] 2021-07-12 18:42:34,650 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.409999514289666e-06, 642
[INFO] 2021-07-12 18:42:34,650 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 642
[INFO] 2021-07-12 18:42:34,650 [run_pretraining.py:  558]:	worker_index: 7, step: 642, cost: 8.979328, mlm loss: 8.979328, speed: 1.106119 steps/s, speed: 8.848950 samples/s, speed: 4530.662556 tokens/s, learning rate: 6.410e-06, loss_scalings: 13421.773438, pp_loss: 8.572321
[INFO] 2021-07-12 18:42:34,651 [run_pretraining.py:  512]:	********exe.run_642******* 
[INFO] 2021-07-12 18:42:35,563 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:35,564 [run_pretraining.py:  534]:	loss/total_loss, 8.289629936218262, 643
[INFO] 2021-07-12 18:42:35,564 [run_pretraining.py:  535]:	loss/mlm_loss, 8.289629936218262, 643
[INFO] 2021-07-12 18:42:35,564 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.41999986328301e-06, 643
[INFO] 2021-07-12 18:42:35,564 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 643
[INFO] 2021-07-12 18:42:35,564 [run_pretraining.py:  558]:	worker_index: 7, step: 643, cost: 8.289630, mlm loss: 8.289630, speed: 1.095432 steps/s, speed: 8.763456 samples/s, speed: 4486.889508 tokens/s, learning rate: 6.420e-06, loss_scalings: 13421.773438, pp_loss: 8.580868
[INFO] 2021-07-12 18:42:35,564 [run_pretraining.py:  512]:	********exe.run_643******* 
[INFO] 2021-07-12 18:42:36,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:36,470 [run_pretraining.py:  534]:	loss/total_loss, 8.975157737731934, 644
[INFO] 2021-07-12 18:42:36,470 [run_pretraining.py:  535]:	loss/mlm_loss, 8.975157737731934, 644
[INFO] 2021-07-12 18:42:36,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.4299997575290035e-06, 644
[INFO] 2021-07-12 18:42:36,470 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 644
[INFO] 2021-07-12 18:42:36,470 [run_pretraining.py:  558]:	worker_index: 7, step: 644, cost: 8.975158, mlm loss: 8.975158, speed: 1.104368 steps/s, speed: 8.834940 samples/s, speed: 4523.489460 tokens/s, learning rate: 6.430e-06, loss_scalings: 13421.773438, pp_loss: 8.767690
[INFO] 2021-07-12 18:42:36,470 [run_pretraining.py:  512]:	********exe.run_644******* 
[INFO] 2021-07-12 18:42:37,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:37,534 [run_pretraining.py:  534]:	loss/total_loss, 8.641352653503418, 645
[INFO] 2021-07-12 18:42:37,535 [run_pretraining.py:  535]:	loss/mlm_loss, 8.641352653503418, 645
[INFO] 2021-07-12 18:42:37,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.440000106522348e-06, 645
[INFO] 2021-07-12 18:42:37,535 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 645
[INFO] 2021-07-12 18:42:37,535 [run_pretraining.py:  558]:	worker_index: 7, step: 645, cost: 8.641353, mlm loss: 8.641353, speed: 0.939790 steps/s, speed: 7.518318 samples/s, speed: 3849.378624 tokens/s, learning rate: 6.440e-06, loss_scalings: 13421.773438, pp_loss: 8.591782
[INFO] 2021-07-12 18:42:37,535 [run_pretraining.py:  512]:	********exe.run_645******* 
[INFO] 2021-07-12 18:42:38,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:38,610 [run_pretraining.py:  534]:	loss/total_loss, 8.591205596923828, 646
[INFO] 2021-07-12 18:42:38,610 [run_pretraining.py:  535]:	loss/mlm_loss, 8.591205596923828, 646
[INFO] 2021-07-12 18:42:38,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.44999954602099e-06, 646
[INFO] 2021-07-12 18:42:38,610 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 646
[INFO] 2021-07-12 18:42:38,610 [run_pretraining.py:  558]:	worker_index: 7, step: 646, cost: 8.591206, mlm loss: 8.591206, speed: 0.930457 steps/s, speed: 7.443656 samples/s, speed: 3811.152027 tokens/s, learning rate: 6.450e-06, loss_scalings: 13421.773438, pp_loss: 8.702755
[INFO] 2021-07-12 18:42:38,610 [run_pretraining.py:  512]:	********exe.run_646******* 
[INFO] 2021-07-12 18:42:39,723 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:39,723 [run_pretraining.py:  534]:	loss/total_loss, 8.586991310119629, 647
[INFO] 2021-07-12 18:42:39,724 [run_pretraining.py:  535]:	loss/mlm_loss, 8.586991310119629, 647
[INFO] 2021-07-12 18:42:39,724 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.459999440266984e-06, 647
[INFO] 2021-07-12 18:42:39,724 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 647
[INFO] 2021-07-12 18:42:39,724 [run_pretraining.py:  558]:	worker_index: 7, step: 647, cost: 8.586991, mlm loss: 8.586991, speed: 0.898564 steps/s, speed: 7.188508 samples/s, speed: 3680.516164 tokens/s, learning rate: 6.460e-06, loss_scalings: 13421.773438, pp_loss: 8.722850
[INFO] 2021-07-12 18:42:39,724 [run_pretraining.py:  512]:	********exe.run_647******* 
[INFO] 2021-07-12 18:42:40,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:40,787 [run_pretraining.py:  534]:	loss/total_loss, 8.836701393127441, 648
[INFO] 2021-07-12 18:42:40,787 [run_pretraining.py:  535]:	loss/mlm_loss, 8.836701393127441, 648
[INFO] 2021-07-12 18:42:40,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.469999789260328e-06, 648
[INFO] 2021-07-12 18:42:40,787 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 648
[INFO] 2021-07-12 18:42:40,787 [run_pretraining.py:  558]:	worker_index: 7, step: 648, cost: 8.836701, mlm loss: 8.836701, speed: 0.941043 steps/s, speed: 7.528341 samples/s, speed: 3854.510459 tokens/s, learning rate: 6.470e-06, loss_scalings: 13421.773438, pp_loss: 8.657557
[INFO] 2021-07-12 18:42:40,787 [run_pretraining.py:  512]:	********exe.run_648******* 
[INFO] 2021-07-12 18:42:41,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:41,831 [run_pretraining.py:  534]:	loss/total_loss, 8.340003967285156, 649
[INFO] 2021-07-12 18:42:41,831 [run_pretraining.py:  535]:	loss/mlm_loss, 8.340003967285156, 649
[INFO] 2021-07-12 18:42:41,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.480000138253672e-06, 649
[INFO] 2021-07-12 18:42:41,831 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 649
[INFO] 2021-07-12 18:42:41,831 [run_pretraining.py:  558]:	worker_index: 7, step: 649, cost: 8.340004, mlm loss: 8.340004, speed: 0.958407 steps/s, speed: 7.667255 samples/s, speed: 3925.634746 tokens/s, learning rate: 6.480e-06, loss_scalings: 13421.773438, pp_loss: 8.535008
[INFO] 2021-07-12 18:42:41,831 [run_pretraining.py:  512]:	********exe.run_649******* 
[INFO] 2021-07-12 18:42:42,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:42,777 [run_pretraining.py:  534]:	loss/total_loss, 8.435891151428223, 650
[INFO] 2021-07-12 18:42:42,777 [run_pretraining.py:  535]:	loss/mlm_loss, 8.435891151428223, 650
[INFO] 2021-07-12 18:42:42,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.490000032499665e-06, 650
[INFO] 2021-07-12 18:42:42,777 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 650
[INFO] 2021-07-12 18:42:42,777 [run_pretraining.py:  558]:	worker_index: 7, step: 650, cost: 8.435891, mlm loss: 8.435891, speed: 1.058087 steps/s, speed: 8.464697 samples/s, speed: 4333.924947 tokens/s, learning rate: 6.490e-06, loss_scalings: 13421.773438, pp_loss: 8.534630
[INFO] 2021-07-12 18:42:42,777 [run_pretraining.py:  512]:	********exe.run_650******* 
[INFO] 2021-07-12 18:42:43,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:43,672 [run_pretraining.py:  534]:	loss/total_loss, 8.571144104003906, 651
[INFO] 2021-07-12 18:42:43,672 [run_pretraining.py:  535]:	loss/mlm_loss, 8.571144104003906, 651
[INFO] 2021-07-12 18:42:43,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.499999471998308e-06, 651
[INFO] 2021-07-12 18:42:43,672 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 651
[INFO] 2021-07-12 18:42:43,673 [run_pretraining.py:  558]:	worker_index: 7, step: 651, cost: 8.571144, mlm loss: 8.571144, speed: 1.117249 steps/s, speed: 8.937991 samples/s, speed: 4576.251149 tokens/s, learning rate: 6.500e-06, loss_scalings: 13421.773438, pp_loss: 8.473198
[INFO] 2021-07-12 18:42:43,673 [run_pretraining.py:  512]:	********exe.run_651******* 
[INFO] 2021-07-12 18:42:44,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:44,583 [run_pretraining.py:  534]:	loss/total_loss, 8.695501327514648, 652
[INFO] 2021-07-12 18:42:44,583 [run_pretraining.py:  535]:	loss/mlm_loss, 8.695501327514648, 652
[INFO] 2021-07-12 18:42:44,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.509999820991652e-06, 652
[INFO] 2021-07-12 18:42:44,584 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 652
[INFO] 2021-07-12 18:42:44,584 [run_pretraining.py:  558]:	worker_index: 7, step: 652, cost: 8.695501, mlm loss: 8.695501, speed: 1.098336 steps/s, speed: 8.786684 samples/s, speed: 4498.782382 tokens/s, learning rate: 6.510e-06, loss_scalings: 13421.773438, pp_loss: 8.644388
[INFO] 2021-07-12 18:42:44,584 [run_pretraining.py:  512]:	********exe.run_652******* 
[INFO] 2021-07-12 18:42:45,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:45,496 [run_pretraining.py:  534]:	loss/total_loss, 8.456892013549805, 653
[INFO] 2021-07-12 18:42:45,496 [run_pretraining.py:  535]:	loss/mlm_loss, 8.456892013549805, 653
[INFO] 2021-07-12 18:42:45,496 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.5199997152376454e-06, 653
[INFO] 2021-07-12 18:42:45,497 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 653
[INFO] 2021-07-12 18:42:45,497 [run_pretraining.py:  558]:	worker_index: 7, step: 653, cost: 8.456892, mlm loss: 8.456892, speed: 1.096202 steps/s, speed: 8.769619 samples/s, speed: 4490.045166 tokens/s, learning rate: 6.520e-06, loss_scalings: 13421.773438, pp_loss: 8.343949
[INFO] 2021-07-12 18:42:45,497 [run_pretraining.py:  512]:	********exe.run_653******* 
[INFO] 2021-07-12 18:42:46,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:46,403 [run_pretraining.py:  534]:	loss/total_loss, 8.863725662231445, 654
[INFO] 2021-07-12 18:42:46,403 [run_pretraining.py:  535]:	loss/mlm_loss, 8.863725662231445, 654
[INFO] 2021-07-12 18:42:46,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.53000006423099e-06, 654
[INFO] 2021-07-12 18:42:46,403 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 654
[INFO] 2021-07-12 18:42:46,403 [run_pretraining.py:  558]:	worker_index: 7, step: 654, cost: 8.863726, mlm loss: 8.863726, speed: 1.104169 steps/s, speed: 8.833354 samples/s, speed: 4522.677315 tokens/s, learning rate: 6.530e-06, loss_scalings: 13421.773438, pp_loss: 8.557661
[INFO] 2021-07-12 18:42:46,403 [run_pretraining.py:  512]:	********exe.run_654******* 
[INFO] 2021-07-12 18:42:47,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:47,311 [run_pretraining.py:  534]:	loss/total_loss, 8.502591133117676, 655
[INFO] 2021-07-12 18:42:47,312 [run_pretraining.py:  535]:	loss/mlm_loss, 8.502591133117676, 655
[INFO] 2021-07-12 18:42:47,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.539999503729632e-06, 655
[INFO] 2021-07-12 18:42:47,312 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 655
[INFO] 2021-07-12 18:42:47,312 [run_pretraining.py:  558]:	worker_index: 7, step: 655, cost: 8.502591, mlm loss: 8.502591, speed: 1.101063 steps/s, speed: 8.808505 samples/s, speed: 4509.954576 tokens/s, learning rate: 6.540e-06, loss_scalings: 13421.773438, pp_loss: 8.120148
[INFO] 2021-07-12 18:42:47,312 [run_pretraining.py:  512]:	********exe.run_655******* 
[INFO] 2021-07-12 18:42:48,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:48,216 [run_pretraining.py:  534]:	loss/total_loss, 8.662511825561523, 656
[INFO] 2021-07-12 18:42:48,216 [run_pretraining.py:  535]:	loss/mlm_loss, 8.662511825561523, 656
[INFO] 2021-07-12 18:42:48,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.549999852722976e-06, 656
[INFO] 2021-07-12 18:42:48,216 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 656
[INFO] 2021-07-12 18:42:48,217 [run_pretraining.py:  558]:	worker_index: 7, step: 656, cost: 8.662512, mlm loss: 8.662512, speed: 1.106154 steps/s, speed: 8.849233 samples/s, speed: 4530.807134 tokens/s, learning rate: 6.550e-06, loss_scalings: 13421.773438, pp_loss: 8.641905
[INFO] 2021-07-12 18:42:48,217 [run_pretraining.py:  512]:	********exe.run_656******* 
[INFO] 2021-07-12 18:42:49,114 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:49,115 [run_pretraining.py:  534]:	loss/total_loss, 8.386882781982422, 657
[INFO] 2021-07-12 18:42:49,115 [run_pretraining.py:  535]:	loss/mlm_loss, 8.386882781982422, 657
[INFO] 2021-07-12 18:42:49,115 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.55999974696897e-06, 657
[INFO] 2021-07-12 18:42:49,115 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 657
[INFO] 2021-07-12 18:42:49,115 [run_pretraining.py:  558]:	worker_index: 7, step: 657, cost: 8.386883, mlm loss: 8.386883, speed: 1.113411 steps/s, speed: 8.907286 samples/s, speed: 4560.530402 tokens/s, learning rate: 6.560e-06, loss_scalings: 13421.773438, pp_loss: 8.037739
[INFO] 2021-07-12 18:42:49,115 [run_pretraining.py:  512]:	********exe.run_657******* 
[INFO] 2021-07-12 18:42:50,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:50,018 [run_pretraining.py:  534]:	loss/total_loss, 8.263814926147461, 658
[INFO] 2021-07-12 18:42:50,019 [run_pretraining.py:  535]:	loss/mlm_loss, 8.263814926147461, 658
[INFO] 2021-07-12 18:42:50,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.570000095962314e-06, 658
[INFO] 2021-07-12 18:42:50,019 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 658
[INFO] 2021-07-12 18:42:50,019 [run_pretraining.py:  558]:	worker_index: 7, step: 658, cost: 8.263815, mlm loss: 8.263815, speed: 1.107644 steps/s, speed: 8.861153 samples/s, speed: 4536.910526 tokens/s, learning rate: 6.570e-06, loss_scalings: 13421.773438, pp_loss: 8.527611
[INFO] 2021-07-12 18:42:50,019 [run_pretraining.py:  512]:	********exe.run_658******* 
[INFO] 2021-07-12 18:42:50,929 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:50,930 [run_pretraining.py:  534]:	loss/total_loss, 8.80659294128418, 659
[INFO] 2021-07-12 18:42:50,930 [run_pretraining.py:  535]:	loss/mlm_loss, 8.80659294128418, 659
[INFO] 2021-07-12 18:42:50,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.579999990208307e-06, 659
[INFO] 2021-07-12 18:42:50,930 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 659
[INFO] 2021-07-12 18:42:50,930 [run_pretraining.py:  558]:	worker_index: 7, step: 659, cost: 8.806593, mlm loss: 8.806593, speed: 1.097935 steps/s, speed: 8.783480 samples/s, speed: 4497.141933 tokens/s, learning rate: 6.580e-06, loss_scalings: 13421.773438, pp_loss: 8.688324
[INFO] 2021-07-12 18:42:50,930 [run_pretraining.py:  512]:	********exe.run_659******* 
[INFO] 2021-07-12 18:42:51,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:51,836 [run_pretraining.py:  534]:	loss/total_loss, 8.304285049438477, 660
[INFO] 2021-07-12 18:42:51,836 [run_pretraining.py:  535]:	loss/mlm_loss, 8.304285049438477, 660
[INFO] 2021-07-12 18:42:51,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.58999942970695e-06, 660
[INFO] 2021-07-12 18:42:51,836 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 660
[INFO] 2021-07-12 18:42:51,837 [run_pretraining.py:  558]:	worker_index: 7, step: 660, cost: 8.304285, mlm loss: 8.304285, speed: 1.104062 steps/s, speed: 8.832496 samples/s, speed: 4522.238021 tokens/s, learning rate: 6.590e-06, loss_scalings: 13421.773438, pp_loss: 8.600140
[INFO] 2021-07-12 18:42:51,837 [run_pretraining.py:  512]:	********exe.run_660******* 
[INFO] 2021-07-12 18:42:52,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:52,744 [run_pretraining.py:  534]:	loss/total_loss, 8.321566581726074, 661
[INFO] 2021-07-12 18:42:52,744 [run_pretraining.py:  535]:	loss/mlm_loss, 8.321566581726074, 661
[INFO] 2021-07-12 18:42:52,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.599999778700294e-06, 661
[INFO] 2021-07-12 18:42:52,744 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 661
[INFO] 2021-07-12 18:42:52,744 [run_pretraining.py:  558]:	worker_index: 7, step: 661, cost: 8.321567, mlm loss: 8.321567, speed: 1.102853 steps/s, speed: 8.822821 samples/s, speed: 4517.284314 tokens/s, learning rate: 6.600e-06, loss_scalings: 13421.773438, pp_loss: 8.314121
[INFO] 2021-07-12 18:42:52,744 [run_pretraining.py:  512]:	********exe.run_661******* 
[INFO] 2021-07-12 18:42:53,649 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:53,650 [run_pretraining.py:  534]:	loss/total_loss, 10.270868301391602, 662
[INFO] 2021-07-12 18:42:53,650 [run_pretraining.py:  535]:	loss/mlm_loss, 10.270868301391602, 662
[INFO] 2021-07-12 18:42:53,650 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.610000127693638e-06, 662
[INFO] 2021-07-12 18:42:53,650 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 662
[INFO] 2021-07-12 18:42:53,650 [run_pretraining.py:  558]:	worker_index: 7, step: 662, cost: 10.270868, mlm loss: 10.270868, speed: 1.104358 steps/s, speed: 8.834864 samples/s, speed: 4523.450156 tokens/s, learning rate: 6.610e-06, loss_scalings: 13421.773438, pp_loss: 9.147522
[INFO] 2021-07-12 18:42:53,650 [run_pretraining.py:  512]:	********exe.run_662******* 
[INFO] 2021-07-12 18:42:54,551 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:54,551 [run_pretraining.py:  534]:	loss/total_loss, 8.530850410461426, 663
[INFO] 2021-07-12 18:42:54,551 [run_pretraining.py:  535]:	loss/mlm_loss, 8.530850410461426, 663
[INFO] 2021-07-12 18:42:54,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.6200000219396316e-06, 663
[INFO] 2021-07-12 18:42:54,552 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 663
[INFO] 2021-07-12 18:42:54,552 [run_pretraining.py:  558]:	worker_index: 7, step: 663, cost: 8.530850, mlm loss: 8.530850, speed: 1.110013 steps/s, speed: 8.880106 samples/s, speed: 4546.614449 tokens/s, learning rate: 6.620e-06, loss_scalings: 13421.773438, pp_loss: 8.486245
[INFO] 2021-07-12 18:42:54,552 [run_pretraining.py:  512]:	********exe.run_663******* 
[INFO] 2021-07-12 18:42:55,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:55,453 [run_pretraining.py:  534]:	loss/total_loss, 8.382230758666992, 664
[INFO] 2021-07-12 18:42:55,453 [run_pretraining.py:  535]:	loss/mlm_loss, 8.382230758666992, 664
[INFO] 2021-07-12 18:42:55,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.629999461438274e-06, 664
[INFO] 2021-07-12 18:42:55,453 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 664
[INFO] 2021-07-12 18:42:55,454 [run_pretraining.py:  558]:	worker_index: 7, step: 664, cost: 8.382231, mlm loss: 8.382231, speed: 1.109633 steps/s, speed: 8.877062 samples/s, speed: 4545.055570 tokens/s, learning rate: 6.630e-06, loss_scalings: 13421.773438, pp_loss: 8.507223
[INFO] 2021-07-12 18:42:55,454 [run_pretraining.py:  512]:	********exe.run_664******* 
[INFO] 2021-07-12 18:42:56,371 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:42:56,371 [run_pretraining.py:  534]:	loss/total_loss, 8.626855850219727, 665
[INFO] 2021-07-12 18:42:56,371 [run_pretraining.py:  535]:	loss/mlm_loss, 8.626855850219727, 665
[INFO] 2021-07-12 18:42:56,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.639999810431618e-06, 665
[INFO] 2021-07-12 18:42:56,371 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 665
[INFO] 2021-07-12 18:42:56,372 [run_pretraining.py:  558]:	worker_index: 7, step: 665, cost: 8.626856, mlm loss: 8.626856, speed: 1.090051 steps/s, speed: 8.720404 samples/s, speed: 4464.846907 tokens/s, learning rate: 6.640e-06, loss_scalings: 13421.773438, pp_loss: 8.618026
[INFO] 2021-07-12 18:42:56,372 [run_pretraining.py:  512]:	********exe.run_665******* 
[INFO] 2021-07-12 18:43:19,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:19,355 [run_pretraining.py:  534]:	loss/total_loss, 8.569082260131836, 666
[INFO] 2021-07-12 18:43:19,355 [run_pretraining.py:  535]:	loss/mlm_loss, 8.569082260131836, 666
[INFO] 2021-07-12 18:43:19,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.649999704677612e-06, 666
[INFO] 2021-07-12 18:43:19,355 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 666
[INFO] 2021-07-12 18:43:19,355 [run_pretraining.py:  558]:	worker_index: 7, step: 666, cost: 8.569082, mlm loss: 8.569082, speed: 0.043511 steps/s, speed: 0.348088 samples/s, speed: 178.221281 tokens/s, learning rate: 6.650e-06, loss_scalings: 13421.773438, pp_loss: 8.085997
[INFO] 2021-07-12 18:43:19,355 [run_pretraining.py:  512]:	********exe.run_666******* 
[INFO] 2021-07-12 18:43:20,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:20,316 [run_pretraining.py:  534]:	loss/total_loss, 7.788302421569824, 667
[INFO] 2021-07-12 18:43:20,316 [run_pretraining.py:  535]:	loss/mlm_loss, 7.788302421569824, 667
[INFO] 2021-07-12 18:43:20,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.660000053670956e-06, 667
[INFO] 2021-07-12 18:43:20,316 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 667
[INFO] 2021-07-12 18:43:20,317 [run_pretraining.py:  558]:	worker_index: 7, step: 667, cost: 7.788302, mlm loss: 7.788302, speed: 1.040550 steps/s, speed: 8.324400 samples/s, speed: 4262.092709 tokens/s, learning rate: 6.660e-06, loss_scalings: 13421.773438, pp_loss: 8.289117
[INFO] 2021-07-12 18:43:20,317 [run_pretraining.py:  512]:	********exe.run_667******* 
[INFO] 2021-07-12 18:43:21,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:21,258 [run_pretraining.py:  534]:	loss/total_loss, 8.438848495483398, 668
[INFO] 2021-07-12 18:43:21,258 [run_pretraining.py:  535]:	loss/mlm_loss, 8.438848495483398, 668
[INFO] 2021-07-12 18:43:21,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.669999493169598e-06, 668
[INFO] 2021-07-12 18:43:21,258 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 668
[INFO] 2021-07-12 18:43:21,258 [run_pretraining.py:  558]:	worker_index: 7, step: 668, cost: 8.438848, mlm loss: 8.438848, speed: 1.062523 steps/s, speed: 8.500186 samples/s, speed: 4352.095072 tokens/s, learning rate: 6.670e-06, loss_scalings: 13421.773438, pp_loss: 8.421534
[INFO] 2021-07-12 18:43:21,258 [run_pretraining.py:  512]:	********exe.run_668******* 
[INFO] 2021-07-12 18:43:22,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:22,199 [run_pretraining.py:  534]:	loss/total_loss, 8.219581604003906, 669
[INFO] 2021-07-12 18:43:22,199 [run_pretraining.py:  535]:	loss/mlm_loss, 8.219581604003906, 669
[INFO] 2021-07-12 18:43:22,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.6799998421629425e-06, 669
[INFO] 2021-07-12 18:43:22,199 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 669
[INFO] 2021-07-12 18:43:22,200 [run_pretraining.py:  558]:	worker_index: 7, step: 669, cost: 8.219582, mlm loss: 8.219582, speed: 1.063265 steps/s, speed: 8.506122 samples/s, speed: 4355.134569 tokens/s, learning rate: 6.680e-06, loss_scalings: 13421.773438, pp_loss: 8.506701
[INFO] 2021-07-12 18:43:22,200 [run_pretraining.py:  512]:	********exe.run_669******* 
[INFO] 2021-07-12 18:43:23,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:23,264 [run_pretraining.py:  534]:	loss/total_loss, 8.866989135742188, 670
[INFO] 2021-07-12 18:43:23,264 [run_pretraining.py:  535]:	loss/mlm_loss, 8.866989135742188, 670
[INFO] 2021-07-12 18:43:23,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.689999736408936e-06, 670
[INFO] 2021-07-12 18:43:23,264 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 670
[INFO] 2021-07-12 18:43:23,264 [run_pretraining.py:  558]:	worker_index: 7, step: 670, cost: 8.866989, mlm loss: 8.866989, speed: 0.940033 steps/s, speed: 7.520260 samples/s, speed: 3850.373349 tokens/s, learning rate: 6.690e-06, loss_scalings: 13421.773438, pp_loss: 8.597157
[INFO] 2021-07-12 18:43:23,264 [run_pretraining.py:  512]:	********exe.run_670******* 
[INFO] 2021-07-12 18:43:49,170 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:49,171 [run_pretraining.py:  534]:	loss/total_loss, 8.135515213012695, 671
[INFO] 2021-07-12 18:43:49,171 [run_pretraining.py:  535]:	loss/mlm_loss, 8.135515213012695, 671
[INFO] 2021-07-12 18:43:49,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.70000008540228e-06, 671
[INFO] 2021-07-12 18:43:49,171 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 671
[INFO] 2021-07-12 18:43:49,171 [run_pretraining.py:  558]:	worker_index: 7, step: 671, cost: 8.135515, mlm loss: 8.135515, speed: 0.038601 steps/s, speed: 0.308806 samples/s, speed: 158.108623 tokens/s, learning rate: 6.700e-06, loss_scalings: 13421.773438, pp_loss: 8.312584
[INFO] 2021-07-12 18:43:49,171 [run_pretraining.py:  512]:	********exe.run_671******* 
[INFO] 2021-07-12 18:43:50,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:50,216 [run_pretraining.py:  534]:	loss/total_loss, 8.475749969482422, 672
[INFO] 2021-07-12 18:43:50,217 [run_pretraining.py:  535]:	loss/mlm_loss, 8.475749969482422, 672
[INFO] 2021-07-12 18:43:50,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.7099999796482734e-06, 672
[INFO] 2021-07-12 18:43:50,217 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 672
[INFO] 2021-07-12 18:43:50,217 [run_pretraining.py:  558]:	worker_index: 7, step: 672, cost: 8.475750, mlm loss: 8.475750, speed: 0.956673 steps/s, speed: 7.653387 samples/s, speed: 3918.534280 tokens/s, learning rate: 6.710e-06, loss_scalings: 13421.773438, pp_loss: 8.679374
[INFO] 2021-07-12 18:43:50,217 [run_pretraining.py:  512]:	********exe.run_672******* 
[INFO] 2021-07-12 18:43:51,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:51,254 [run_pretraining.py:  534]:	loss/total_loss, 8.281569480895996, 673
[INFO] 2021-07-12 18:43:51,254 [run_pretraining.py:  535]:	loss/mlm_loss, 8.281569480895996, 673
[INFO] 2021-07-12 18:43:51,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.719999419146916e-06, 673
[INFO] 2021-07-12 18:43:51,254 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 673
[INFO] 2021-07-12 18:43:51,254 [run_pretraining.py:  558]:	worker_index: 7, step: 673, cost: 8.281569, mlm loss: 8.281569, speed: 0.964766 steps/s, speed: 7.718127 samples/s, speed: 3951.680831 tokens/s, learning rate: 6.720e-06, loss_scalings: 13421.773438, pp_loss: 8.425878
[INFO] 2021-07-12 18:43:51,254 [run_pretraining.py:  512]:	********exe.run_673******* 
[INFO] 2021-07-12 18:43:52,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:52,345 [run_pretraining.py:  534]:	loss/total_loss, 8.359513282775879, 674
[INFO] 2021-07-12 18:43:52,346 [run_pretraining.py:  535]:	loss/mlm_loss, 8.359513282775879, 674
[INFO] 2021-07-12 18:43:52,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.72999976814026e-06, 674
[INFO] 2021-07-12 18:43:52,346 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 674
[INFO] 2021-07-12 18:43:52,346 [run_pretraining.py:  558]:	worker_index: 7, step: 674, cost: 8.359513, mlm loss: 8.359513, speed: 0.916405 steps/s, speed: 7.331241 samples/s, speed: 3753.595588 tokens/s, learning rate: 6.730e-06, loss_scalings: 13421.773438, pp_loss: 8.430107
[INFO] 2021-07-12 18:43:52,346 [run_pretraining.py:  512]:	********exe.run_674******* 
[INFO] 2021-07-12 18:43:53,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:53,388 [run_pretraining.py:  534]:	loss/total_loss, 8.301629066467285, 675
[INFO] 2021-07-12 18:43:53,389 [run_pretraining.py:  535]:	loss/mlm_loss, 8.301629066467285, 675
[INFO] 2021-07-12 18:43:53,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.740000117133604e-06, 675
[INFO] 2021-07-12 18:43:53,389 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 675
[INFO] 2021-07-12 18:43:53,389 [run_pretraining.py:  558]:	worker_index: 7, step: 675, cost: 8.301629, mlm loss: 8.301629, speed: 0.959358 steps/s, speed: 7.674863 samples/s, speed: 3929.529860 tokens/s, learning rate: 6.740e-06, loss_scalings: 13421.773438, pp_loss: 8.697788
[INFO] 2021-07-12 18:43:53,389 [run_pretraining.py:  512]:	********exe.run_675******* 
[INFO] 2021-07-12 18:43:54,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:54,436 [run_pretraining.py:  534]:	loss/total_loss, 6.528844356536865, 676
[INFO] 2021-07-12 18:43:54,436 [run_pretraining.py:  535]:	loss/mlm_loss, 6.528844356536865, 676
[INFO] 2021-07-12 18:43:54,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.750000011379598e-06, 676
[INFO] 2021-07-12 18:43:54,436 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 676
[INFO] 2021-07-12 18:43:54,436 [run_pretraining.py:  558]:	worker_index: 7, step: 676, cost: 6.528844, mlm loss: 6.528844, speed: 0.955355 steps/s, speed: 7.642841 samples/s, speed: 3913.134402 tokens/s, learning rate: 6.750e-06, loss_scalings: 13421.773438, pp_loss: 8.126637
[INFO] 2021-07-12 18:43:54,436 [run_pretraining.py:  512]:	********exe.run_676******* 
[INFO] 2021-07-12 18:43:55,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:55,369 [run_pretraining.py:  534]:	loss/total_loss, 8.328812599182129, 677
[INFO] 2021-07-12 18:43:55,369 [run_pretraining.py:  535]:	loss/mlm_loss, 8.328812599182129, 677
[INFO] 2021-07-12 18:43:55,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.75999945087824e-06, 677
[INFO] 2021-07-12 18:43:55,369 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 677
[INFO] 2021-07-12 18:43:55,369 [run_pretraining.py:  558]:	worker_index: 7, step: 677, cost: 8.328813, mlm loss: 8.328813, speed: 1.072565 steps/s, speed: 8.580518 samples/s, speed: 4393.225070 tokens/s, learning rate: 6.760e-06, loss_scalings: 13421.773438, pp_loss: 8.380561
[INFO] 2021-07-12 18:43:55,369 [run_pretraining.py:  512]:	********exe.run_677******* 
[INFO] 2021-07-12 18:43:56,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:56,288 [run_pretraining.py:  534]:	loss/total_loss, 8.150530815124512, 678
[INFO] 2021-07-12 18:43:56,288 [run_pretraining.py:  535]:	loss/mlm_loss, 8.150530815124512, 678
[INFO] 2021-07-12 18:43:56,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.769999799871584e-06, 678
[INFO] 2021-07-12 18:43:56,288 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 678
[INFO] 2021-07-12 18:43:56,288 [run_pretraining.py:  558]:	worker_index: 7, step: 678, cost: 8.150531, mlm loss: 8.150531, speed: 1.088954 steps/s, speed: 8.711629 samples/s, speed: 4460.353872 tokens/s, learning rate: 6.770e-06, loss_scalings: 13421.773438, pp_loss: 8.399893
[INFO] 2021-07-12 18:43:56,288 [run_pretraining.py:  512]:	********exe.run_678******* 
[INFO] 2021-07-12 18:43:57,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  534]:	loss/total_loss, 8.522939682006836, 679
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  535]:	loss/mlm_loss, 8.522939682006836, 679
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.779999694117578e-06, 679
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 679
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  558]:	worker_index: 7, step: 679, cost: 8.522940, mlm loss: 8.522940, speed: 1.086392 steps/s, speed: 8.691136 samples/s, speed: 4449.861409 tokens/s, learning rate: 6.780e-06, loss_scalings: 13421.773438, pp_loss: 8.564897
[INFO] 2021-07-12 18:43:57,209 [run_pretraining.py:  512]:	********exe.run_679******* 
[INFO] 2021-07-12 18:43:58,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:58,128 [run_pretraining.py:  534]:	loss/total_loss, 9.00904369354248, 680
[INFO] 2021-07-12 18:43:58,128 [run_pretraining.py:  535]:	loss/mlm_loss, 9.00904369354248, 680
[INFO] 2021-07-12 18:43:58,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.790000043110922e-06, 680
[INFO] 2021-07-12 18:43:58,129 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 680
[INFO] 2021-07-12 18:43:58,129 [run_pretraining.py:  558]:	worker_index: 7, step: 680, cost: 9.009044, mlm loss: 9.009044, speed: 1.088437 steps/s, speed: 8.707494 samples/s, speed: 4458.236846 tokens/s, learning rate: 6.790e-06, loss_scalings: 13421.773438, pp_loss: 8.501191
[INFO] 2021-07-12 18:43:58,129 [run_pretraining.py:  512]:	********exe.run_680******* 
[INFO] 2021-07-12 18:43:59,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:59,050 [run_pretraining.py:  534]:	loss/total_loss, 8.306831359863281, 681
[INFO] 2021-07-12 18:43:59,050 [run_pretraining.py:  535]:	loss/mlm_loss, 8.306831359863281, 681
[INFO] 2021-07-12 18:43:59,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.800000392104266e-06, 681
[INFO] 2021-07-12 18:43:59,050 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 681
[INFO] 2021-07-12 18:43:59,050 [run_pretraining.py:  558]:	worker_index: 7, step: 681, cost: 8.306831, mlm loss: 8.306831, speed: 1.086133 steps/s, speed: 8.689065 samples/s, speed: 4448.801283 tokens/s, learning rate: 6.800e-06, loss_scalings: 13421.773438, pp_loss: 8.489081
[INFO] 2021-07-12 18:43:59,050 [run_pretraining.py:  512]:	********exe.run_681******* 
[INFO] 2021-07-12 18:43:59,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:43:59,970 [run_pretraining.py:  534]:	loss/total_loss, 8.609797477722168, 682
[INFO] 2021-07-12 18:43:59,970 [run_pretraining.py:  535]:	loss/mlm_loss, 8.609797477722168, 682
[INFO] 2021-07-12 18:43:59,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.809999831602909e-06, 682
[INFO] 2021-07-12 18:43:59,970 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 682
[INFO] 2021-07-12 18:43:59,970 [run_pretraining.py:  558]:	worker_index: 7, step: 682, cost: 8.609797, mlm loss: 8.609797, speed: 1.087310 steps/s, speed: 8.698483 samples/s, speed: 4453.623168 tokens/s, learning rate: 6.810e-06, loss_scalings: 13421.773438, pp_loss: 8.547771
[INFO] 2021-07-12 18:43:59,970 [run_pretraining.py:  512]:	********exe.run_682******* 
[INFO] 2021-07-12 18:44:00,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:00,895 [run_pretraining.py:  534]:	loss/total_loss, 8.656131744384766, 683
[INFO] 2021-07-12 18:44:00,895 [run_pretraining.py:  535]:	loss/mlm_loss, 8.656131744384766, 683
[INFO] 2021-07-12 18:44:00,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.819999725848902e-06, 683
[INFO] 2021-07-12 18:44:00,895 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 683
[INFO] 2021-07-12 18:44:00,895 [run_pretraining.py:  558]:	worker_index: 7, step: 683, cost: 8.656132, mlm loss: 8.656132, speed: 1.082273 steps/s, speed: 8.658185 samples/s, speed: 4432.990677 tokens/s, learning rate: 6.820e-06, loss_scalings: 13421.773438, pp_loss: 8.460516
[INFO] 2021-07-12 18:44:00,895 [run_pretraining.py:  512]:	********exe.run_683******* 
[INFO] 2021-07-12 18:44:01,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:01,825 [run_pretraining.py:  534]:	loss/total_loss, 8.128896713256836, 684
[INFO] 2021-07-12 18:44:01,826 [run_pretraining.py:  535]:	loss/mlm_loss, 8.128896713256836, 684
[INFO] 2021-07-12 18:44:01,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.830000074842246e-06, 684
[INFO] 2021-07-12 18:44:01,826 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 684
[INFO] 2021-07-12 18:44:01,826 [run_pretraining.py:  558]:	worker_index: 7, step: 684, cost: 8.128897, mlm loss: 8.128897, speed: 1.075117 steps/s, speed: 8.600933 samples/s, speed: 4403.677582 tokens/s, learning rate: 6.830e-06, loss_scalings: 13421.773438, pp_loss: 8.179327
[INFO] 2021-07-12 18:44:01,826 [run_pretraining.py:  512]:	********exe.run_684******* 
[INFO] 2021-07-12 18:44:02,747 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:02,748 [run_pretraining.py:  534]:	loss/total_loss, 8.606345176696777, 685
[INFO] 2021-07-12 18:44:02,748 [run_pretraining.py:  535]:	loss/mlm_loss, 8.606345176696777, 685
[INFO] 2021-07-12 18:44:02,748 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.83999996908824e-06, 685
[INFO] 2021-07-12 18:44:02,748 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 685
[INFO] 2021-07-12 18:44:02,748 [run_pretraining.py:  558]:	worker_index: 7, step: 685, cost: 8.606345, mlm loss: 8.606345, speed: 1.084971 steps/s, speed: 8.679764 samples/s, speed: 4444.039260 tokens/s, learning rate: 6.840e-06, loss_scalings: 13421.773438, pp_loss: 8.776323
[INFO] 2021-07-12 18:44:02,748 [run_pretraining.py:  512]:	********exe.run_685******* 
[INFO] 2021-07-12 18:44:03,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:03,676 [run_pretraining.py:  534]:	loss/total_loss, 8.495031356811523, 686
[INFO] 2021-07-12 18:44:03,676 [run_pretraining.py:  535]:	loss/mlm_loss, 8.495031356811523, 686
[INFO] 2021-07-12 18:44:03,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.849999408586882e-06, 686
[INFO] 2021-07-12 18:44:03,677 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 686
[INFO] 2021-07-12 18:44:03,677 [run_pretraining.py:  558]:	worker_index: 7, step: 686, cost: 8.495031, mlm loss: 8.495031, speed: 1.077851 steps/s, speed: 8.622810 samples/s, speed: 4414.878713 tokens/s, learning rate: 6.850e-06, loss_scalings: 13421.773438, pp_loss: 8.505841
[INFO] 2021-07-12 18:44:03,677 [run_pretraining.py:  512]:	********exe.run_686******* 
[INFO] 2021-07-12 18:44:04,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  534]:	loss/total_loss, 7.873421669006348, 687
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  535]:	loss/mlm_loss, 7.873421669006348, 687
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.859999757580226e-06, 687
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 687
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  558]:	worker_index: 7, step: 687, cost: 7.873422, mlm loss: 7.873422, speed: 1.084800 steps/s, speed: 8.678402 samples/s, speed: 4443.341580 tokens/s, learning rate: 6.860e-06, loss_scalings: 13421.773438, pp_loss: 8.400857
[INFO] 2021-07-12 18:44:04,599 [run_pretraining.py:  512]:	********exe.run_687******* 
[INFO] 2021-07-12 18:44:05,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:05,519 [run_pretraining.py:  534]:	loss/total_loss, 8.48951530456543, 688
[INFO] 2021-07-12 18:44:05,519 [run_pretraining.py:  535]:	loss/mlm_loss, 8.48951530456543, 688
[INFO] 2021-07-12 18:44:05,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.8700001065735705e-06, 688
[INFO] 2021-07-12 18:44:05,520 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 688
[INFO] 2021-07-12 18:44:05,520 [run_pretraining.py:  558]:	worker_index: 7, step: 688, cost: 8.489515, mlm loss: 8.489515, speed: 1.087173 steps/s, speed: 8.697385 samples/s, speed: 4453.060980 tokens/s, learning rate: 6.870e-06, loss_scalings: 13421.773438, pp_loss: 8.276443
[INFO] 2021-07-12 18:44:05,520 [run_pretraining.py:  512]:	********exe.run_688******* 
[INFO] 2021-07-12 18:44:06,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:06,443 [run_pretraining.py:  534]:	loss/total_loss, 8.495800971984863, 689
[INFO] 2021-07-12 18:44:06,444 [run_pretraining.py:  535]:	loss/mlm_loss, 8.495800971984863, 689
[INFO] 2021-07-12 18:44:06,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.880000000819564e-06, 689
[INFO] 2021-07-12 18:44:06,444 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 689
[INFO] 2021-07-12 18:44:06,444 [run_pretraining.py:  558]:	worker_index: 7, step: 689, cost: 8.495801, mlm loss: 8.495801, speed: 1.082754 steps/s, speed: 8.662034 samples/s, speed: 4434.961284 tokens/s, learning rate: 6.880e-06, loss_scalings: 13421.773438, pp_loss: 8.551199
[INFO] 2021-07-12 18:44:06,444 [run_pretraining.py:  512]:	********exe.run_689******* 
[INFO] 2021-07-12 18:44:07,363 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:07,364 [run_pretraining.py:  534]:	loss/total_loss, 8.587162017822266, 690
[INFO] 2021-07-12 18:44:07,364 [run_pretraining.py:  535]:	loss/mlm_loss, 8.587162017822266, 690
[INFO] 2021-07-12 18:44:07,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.889999440318206e-06, 690
[INFO] 2021-07-12 18:44:07,364 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 690
[INFO] 2021-07-12 18:44:07,364 [run_pretraining.py:  558]:	worker_index: 7, step: 690, cost: 8.587162, mlm loss: 8.587162, speed: 1.087133 steps/s, speed: 8.697062 samples/s, speed: 4452.895929 tokens/s, learning rate: 6.890e-06, loss_scalings: 13421.773438, pp_loss: 8.392347
[INFO] 2021-07-12 18:44:07,364 [run_pretraining.py:  512]:	********exe.run_690******* 
[INFO] 2021-07-12 18:44:08,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:08,287 [run_pretraining.py:  534]:	loss/total_loss, 8.256547927856445, 691
[INFO] 2021-07-12 18:44:08,287 [run_pretraining.py:  535]:	loss/mlm_loss, 8.256547927856445, 691
[INFO] 2021-07-12 18:44:08,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.8999997893115506e-06, 691
[INFO] 2021-07-12 18:44:08,287 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 691
[INFO] 2021-07-12 18:44:08,287 [run_pretraining.py:  558]:	worker_index: 7, step: 691, cost: 8.256548, mlm loss: 8.256548, speed: 1.084503 steps/s, speed: 8.676021 samples/s, speed: 4442.122602 tokens/s, learning rate: 6.900e-06, loss_scalings: 13421.773438, pp_loss: 8.484320
[INFO] 2021-07-12 18:44:08,287 [run_pretraining.py:  512]:	********exe.run_691******* 
[INFO] 2021-07-12 18:44:09,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:09,222 [run_pretraining.py:  534]:	loss/total_loss, 8.166887283325195, 692
[INFO] 2021-07-12 18:44:09,222 [run_pretraining.py:  535]:	loss/mlm_loss, 8.166887283325195, 692
[INFO] 2021-07-12 18:44:09,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.909999683557544e-06, 692
[INFO] 2021-07-12 18:44:09,222 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 692
[INFO] 2021-07-12 18:44:09,222 [run_pretraining.py:  558]:	worker_index: 7, step: 692, cost: 8.166887, mlm loss: 8.166887, speed: 1.070402 steps/s, speed: 8.563216 samples/s, speed: 4384.366726 tokens/s, learning rate: 6.910e-06, loss_scalings: 13421.773438, pp_loss: 8.423063
[INFO] 2021-07-12 18:44:09,222 [run_pretraining.py:  512]:	********exe.run_692******* 
[INFO] 2021-07-12 18:44:10,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:10,142 [run_pretraining.py:  534]:	loss/total_loss, 8.707062721252441, 693
[INFO] 2021-07-12 18:44:10,142 [run_pretraining.py:  535]:	loss/mlm_loss, 8.707062721252441, 693
[INFO] 2021-07-12 18:44:10,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.920000032550888e-06, 693
[INFO] 2021-07-12 18:44:10,142 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 693
[INFO] 2021-07-12 18:44:10,142 [run_pretraining.py:  558]:	worker_index: 7, step: 693, cost: 8.707063, mlm loss: 8.707063, speed: 1.087570 steps/s, speed: 8.700560 samples/s, speed: 4454.686748 tokens/s, learning rate: 6.920e-06, loss_scalings: 13421.773438, pp_loss: 8.565073
[INFO] 2021-07-12 18:44:10,142 [run_pretraining.py:  512]:	********exe.run_693******* 
[INFO] 2021-07-12 18:44:11,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:11,052 [run_pretraining.py:  534]:	loss/total_loss, 8.997493743896484, 694
[INFO] 2021-07-12 18:44:11,053 [run_pretraining.py:  535]:	loss/mlm_loss, 8.997493743896484, 694
[INFO] 2021-07-12 18:44:11,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.930000381544232e-06, 694
[INFO] 2021-07-12 18:44:11,053 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 694
[INFO] 2021-07-12 18:44:11,053 [run_pretraining.py:  558]:	worker_index: 7, step: 694, cost: 8.997494, mlm loss: 8.997494, speed: 1.098807 steps/s, speed: 8.790453 samples/s, speed: 4500.711706 tokens/s, learning rate: 6.930e-06, loss_scalings: 13421.773438, pp_loss: 8.679008
[INFO] 2021-07-12 18:44:11,053 [run_pretraining.py:  512]:	********exe.run_694******* 
[INFO] 2021-07-12 18:44:11,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:11,957 [run_pretraining.py:  534]:	loss/total_loss, 4.030670166015625, 695
[INFO] 2021-07-12 18:44:11,957 [run_pretraining.py:  535]:	loss/mlm_loss, 4.030670166015625, 695
[INFO] 2021-07-12 18:44:11,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.939999366295524e-06, 695
[INFO] 2021-07-12 18:44:11,957 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 695
[INFO] 2021-07-12 18:44:11,957 [run_pretraining.py:  558]:	worker_index: 7, step: 695, cost: 4.030670, mlm loss: 4.030670, speed: 1.106250 steps/s, speed: 8.850003 samples/s, speed: 4531.201485 tokens/s, learning rate: 6.940e-06, loss_scalings: 13421.773438, pp_loss: 7.229010
[INFO] 2021-07-12 18:44:11,958 [run_pretraining.py:  512]:	********exe.run_695******* 
[INFO] 2021-07-12 18:44:12,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:12,881 [run_pretraining.py:  534]:	loss/total_loss, 8.39649772644043, 696
[INFO] 2021-07-12 18:44:12,881 [run_pretraining.py:  535]:	loss/mlm_loss, 8.39649772644043, 696
[INFO] 2021-07-12 18:44:12,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.949999715288868e-06, 696
[INFO] 2021-07-12 18:44:12,881 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 696
[INFO] 2021-07-12 18:44:12,881 [run_pretraining.py:  558]:	worker_index: 7, step: 696, cost: 8.396498, mlm loss: 8.396498, speed: 1.083426 steps/s, speed: 8.667406 samples/s, speed: 4437.711845 tokens/s, learning rate: 6.950e-06, loss_scalings: 13421.773438, pp_loss: 8.639084
[INFO] 2021-07-12 18:44:12,881 [run_pretraining.py:  512]:	********exe.run_696******* 
[INFO] 2021-07-12 18:44:13,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  534]:	loss/total_loss, 8.407833099365234, 697
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  535]:	loss/mlm_loss, 8.407833099365234, 697
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.960000064282212e-06, 697
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 697
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  558]:	worker_index: 7, step: 697, cost: 8.407833, mlm loss: 8.407833, speed: 1.095923 steps/s, speed: 8.767388 samples/s, speed: 4488.902472 tokens/s, learning rate: 6.960e-06, loss_scalings: 13421.773438, pp_loss: 8.293482
[INFO] 2021-07-12 18:44:13,794 [run_pretraining.py:  512]:	********exe.run_697******* 
[INFO] 2021-07-12 18:44:14,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  534]:	loss/total_loss, 8.560319900512695, 698
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  535]:	loss/mlm_loss, 8.560319900512695, 698
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.969999958528206e-06, 698
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 698
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  558]:	worker_index: 7, step: 698, cost: 8.560320, mlm loss: 8.560320, speed: 1.095159 steps/s, speed: 8.761271 samples/s, speed: 4485.770673 tokens/s, learning rate: 6.970e-06, loss_scalings: 13421.773438, pp_loss: 8.473734
[INFO] 2021-07-12 18:44:14,708 [run_pretraining.py:  512]:	********exe.run_698******* 
[INFO] 2021-07-12 18:44:15,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:15,622 [run_pretraining.py:  534]:	loss/total_loss, 8.455066680908203, 699
[INFO] 2021-07-12 18:44:15,622 [run_pretraining.py:  535]:	loss/mlm_loss, 8.455066680908203, 699
[INFO] 2021-07-12 18:44:15,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.979999398026848e-06, 699
[INFO] 2021-07-12 18:44:15,622 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 699
[INFO] 2021-07-12 18:44:15,622 [run_pretraining.py:  558]:	worker_index: 7, step: 699, cost: 8.455067, mlm loss: 8.455067, speed: 1.094641 steps/s, speed: 8.757125 samples/s, speed: 4483.648179 tokens/s, learning rate: 6.980e-06, loss_scalings: 13421.773438, pp_loss: 8.442673
[INFO] 2021-07-12 18:44:15,622 [run_pretraining.py:  512]:	********exe.run_699******* 
[INFO] 2021-07-12 18:44:16,558 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:16,559 [run_pretraining.py:  534]:	loss/total_loss, 8.896465301513672, 700
[INFO] 2021-07-12 18:44:16,559 [run_pretraining.py:  535]:	loss/mlm_loss, 8.896465301513672, 700
[INFO] 2021-07-12 18:44:16,559 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.9899997470201924e-06, 700
[INFO] 2021-07-12 18:44:16,559 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 700
[INFO] 2021-07-12 18:44:16,559 [run_pretraining.py:  558]:	worker_index: 7, step: 700, cost: 8.896465, mlm loss: 8.896465, speed: 1.068327 steps/s, speed: 8.546614 samples/s, speed: 4375.866121 tokens/s, learning rate: 6.990e-06, loss_scalings: 13421.773438, pp_loss: 8.432936
[INFO] 2021-07-12 18:44:16,559 [run_pretraining.py:  512]:	********exe.run_700******* 
[INFO] 2021-07-12 18:44:17,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:17,474 [run_pretraining.py:  534]:	loss/total_loss, 8.637896537780762, 701
[INFO] 2021-07-12 18:44:17,474 [run_pretraining.py:  535]:	loss/mlm_loss, 8.637896537780762, 701
[INFO] 2021-07-12 18:44:17,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 6.999999641266186e-06, 701
[INFO] 2021-07-12 18:44:17,474 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 701
[INFO] 2021-07-12 18:44:17,474 [run_pretraining.py:  558]:	worker_index: 7, step: 701, cost: 8.637897, mlm loss: 8.637897, speed: 1.093117 steps/s, speed: 8.744936 samples/s, speed: 4477.407083 tokens/s, learning rate: 7.000e-06, loss_scalings: 13421.773438, pp_loss: 8.415063
[INFO] 2021-07-12 18:44:17,474 [run_pretraining.py:  512]:	********exe.run_701******* 
[INFO] 2021-07-12 18:44:18,387 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:18,388 [run_pretraining.py:  534]:	loss/total_loss, 8.342491149902344, 702
[INFO] 2021-07-12 18:44:18,388 [run_pretraining.py:  535]:	loss/mlm_loss, 8.342491149902344, 702
[INFO] 2021-07-12 18:44:18,388 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.00999999025953e-06, 702
[INFO] 2021-07-12 18:44:18,388 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 702
[INFO] 2021-07-12 18:44:18,388 [run_pretraining.py:  558]:	worker_index: 7, step: 702, cost: 8.342491, mlm loss: 8.342491, speed: 1.094825 steps/s, speed: 8.758600 samples/s, speed: 4484.403055 tokens/s, learning rate: 7.010e-06, loss_scalings: 13421.773438, pp_loss: 8.437963
[INFO] 2021-07-12 18:44:18,388 [run_pretraining.py:  512]:	********exe.run_702******* 
[INFO] 2021-07-12 18:44:19,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:19,303 [run_pretraining.py:  534]:	loss/total_loss, 8.617268562316895, 703
[INFO] 2021-07-12 18:44:19,303 [run_pretraining.py:  535]:	loss/mlm_loss, 8.617268562316895, 703
[INFO] 2021-07-12 18:44:19,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.020000339252874e-06, 703
[INFO] 2021-07-12 18:44:19,303 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 703
[INFO] 2021-07-12 18:44:19,303 [run_pretraining.py:  558]:	worker_index: 7, step: 703, cost: 8.617269, mlm loss: 8.617269, speed: 1.094110 steps/s, speed: 8.752879 samples/s, speed: 4481.473916 tokens/s, learning rate: 7.020e-06, loss_scalings: 13421.773438, pp_loss: 8.763833
[INFO] 2021-07-12 18:44:19,303 [run_pretraining.py:  512]:	********exe.run_703******* 
[INFO] 2021-07-12 18:44:20,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:20,218 [run_pretraining.py:  534]:	loss/total_loss, 8.949753761291504, 704
[INFO] 2021-07-12 18:44:20,218 [run_pretraining.py:  535]:	loss/mlm_loss, 8.949753761291504, 704
[INFO] 2021-07-12 18:44:20,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.029999778751517e-06, 704
[INFO] 2021-07-12 18:44:20,218 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 704
[INFO] 2021-07-12 18:44:20,218 [run_pretraining.py:  558]:	worker_index: 7, step: 704, cost: 8.949754, mlm loss: 8.949754, speed: 1.093803 steps/s, speed: 8.750425 samples/s, speed: 4480.217572 tokens/s, learning rate: 7.030e-06, loss_scalings: 13421.773438, pp_loss: 8.505965
[INFO] 2021-07-12 18:44:20,218 [run_pretraining.py:  512]:	********exe.run_704******* 
[INFO] 2021-07-12 18:44:21,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:21,138 [run_pretraining.py:  534]:	loss/total_loss, 8.52234935760498, 705
[INFO] 2021-07-12 18:44:21,138 [run_pretraining.py:  535]:	loss/mlm_loss, 8.52234935760498, 705
[INFO] 2021-07-12 18:44:21,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.03999967299751e-06, 705
[INFO] 2021-07-12 18:44:21,138 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 705
[INFO] 2021-07-12 18:44:21,138 [run_pretraining.py:  558]:	worker_index: 7, step: 705, cost: 8.522349, mlm loss: 8.522349, speed: 1.087533 steps/s, speed: 8.700260 samples/s, speed: 4454.533127 tokens/s, learning rate: 7.040e-06, loss_scalings: 13421.773438, pp_loss: 8.468461
[INFO] 2021-07-12 18:44:21,138 [run_pretraining.py:  512]:	********exe.run_705******* 
[INFO] 2021-07-12 18:44:22,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:22,053 [run_pretraining.py:  534]:	loss/total_loss, 8.294319152832031, 706
[INFO] 2021-07-12 18:44:22,053 [run_pretraining.py:  535]:	loss/mlm_loss, 8.294319152832031, 706
[INFO] 2021-07-12 18:44:22,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.050000021990854e-06, 706
[INFO] 2021-07-12 18:44:22,053 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 706
[INFO] 2021-07-12 18:44:22,053 [run_pretraining.py:  558]:	worker_index: 7, step: 706, cost: 8.294319, mlm loss: 8.294319, speed: 1.093153 steps/s, speed: 8.745225 samples/s, speed: 4477.555284 tokens/s, learning rate: 7.050e-06, loss_scalings: 13421.773438, pp_loss: 7.512659
[INFO] 2021-07-12 18:44:22,054 [run_pretraining.py:  512]:	********exe.run_706******* 
[INFO] 2021-07-12 18:44:23,029 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:23,030 [run_pretraining.py:  534]:	loss/total_loss, 7.978679656982422, 707
[INFO] 2021-07-12 18:44:23,030 [run_pretraining.py:  535]:	loss/mlm_loss, 7.978679656982422, 707
[INFO] 2021-07-12 18:44:23,030 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.059999916236848e-06, 707
[INFO] 2021-07-12 18:44:23,030 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 707
[INFO] 2021-07-12 18:44:23,030 [run_pretraining.py:  558]:	worker_index: 7, step: 707, cost: 7.978680, mlm loss: 7.978680, speed: 1.024731 steps/s, speed: 8.197850 samples/s, speed: 4197.299290 tokens/s, learning rate: 7.060e-06, loss_scalings: 13421.773438, pp_loss: 8.254210
[INFO] 2021-07-12 18:44:23,030 [run_pretraining.py:  512]:	********exe.run_707******* 
[INFO] 2021-07-12 18:44:23,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:23,942 [run_pretraining.py:  534]:	loss/total_loss, 8.320892333984375, 708
[INFO] 2021-07-12 18:44:23,942 [run_pretraining.py:  535]:	loss/mlm_loss, 8.320892333984375, 708
[INFO] 2021-07-12 18:44:23,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.06999935573549e-06, 708
[INFO] 2021-07-12 18:44:23,942 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 708
[INFO] 2021-07-12 18:44:23,942 [run_pretraining.py:  558]:	worker_index: 7, step: 708, cost: 8.320892, mlm loss: 8.320892, speed: 1.096948 steps/s, speed: 8.775583 samples/s, speed: 4493.098330 tokens/s, learning rate: 7.070e-06, loss_scalings: 13421.773438, pp_loss: 8.338839
[INFO] 2021-07-12 18:44:23,942 [run_pretraining.py:  512]:	********exe.run_708******* 
[INFO] 2021-07-12 18:44:24,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:24,857 [run_pretraining.py:  534]:	loss/total_loss, 8.730545997619629, 709
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  535]:	loss/mlm_loss, 8.730545997619629, 709
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.079999704728834e-06, 709
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 709
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  558]:	worker_index: 7, step: 709, cost: 8.730546, mlm loss: 8.730546, speed: 1.093086 steps/s, speed: 8.744690 samples/s, speed: 4477.281062 tokens/s, learning rate: 7.080e-06, loss_scalings: 13421.773438, pp_loss: 8.527135
[INFO] 2021-07-12 18:44:24,858 [run_pretraining.py:  512]:	********exe.run_709******* 
[INFO] 2021-07-12 18:44:25,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:25,772 [run_pretraining.py:  534]:	loss/total_loss, 8.025123596191406, 710
[INFO] 2021-07-12 18:44:25,773 [run_pretraining.py:  535]:	loss/mlm_loss, 8.025123596191406, 710
[INFO] 2021-07-12 18:44:25,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.0900000537221786e-06, 710
[INFO] 2021-07-12 18:44:25,773 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 710
[INFO] 2021-07-12 18:44:25,773 [run_pretraining.py:  558]:	worker_index: 7, step: 710, cost: 8.025124, mlm loss: 8.025124, speed: 1.093683 steps/s, speed: 8.749462 samples/s, speed: 4479.724577 tokens/s, learning rate: 7.090e-06, loss_scalings: 13421.773438, pp_loss: 8.472056
[INFO] 2021-07-12 18:44:25,773 [run_pretraining.py:  512]:	********exe.run_710******* 
[INFO] 2021-07-12 18:44:26,695 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:26,695 [run_pretraining.py:  534]:	loss/total_loss, 8.425349235534668, 711
[INFO] 2021-07-12 18:44:26,695 [run_pretraining.py:  535]:	loss/mlm_loss, 8.425349235534668, 711
[INFO] 2021-07-12 18:44:26,696 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.099999947968172e-06, 711
[INFO] 2021-07-12 18:44:26,696 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 711
[INFO] 2021-07-12 18:44:26,696 [run_pretraining.py:  558]:	worker_index: 7, step: 711, cost: 8.425349, mlm loss: 8.425349, speed: 1.084311 steps/s, speed: 8.674491 samples/s, speed: 4441.339409 tokens/s, learning rate: 7.100e-06, loss_scalings: 13421.773438, pp_loss: 8.464482
[INFO] 2021-07-12 18:44:26,696 [run_pretraining.py:  512]:	********exe.run_711******* 
[INFO] 2021-07-12 18:44:27,613 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:27,613 [run_pretraining.py:  534]:	loss/total_loss, 8.861318588256836, 712
[INFO] 2021-07-12 18:44:27,613 [run_pretraining.py:  535]:	loss/mlm_loss, 8.861318588256836, 712
[INFO] 2021-07-12 18:44:27,614 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.109999387466814e-06, 712
[INFO] 2021-07-12 18:44:27,614 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 712
[INFO] 2021-07-12 18:44:27,614 [run_pretraining.py:  558]:	worker_index: 7, step: 712, cost: 8.861319, mlm loss: 8.861319, speed: 1.090153 steps/s, speed: 8.721220 samples/s, speed: 4465.264677 tokens/s, learning rate: 7.110e-06, loss_scalings: 13421.773438, pp_loss: 8.780208
[INFO] 2021-07-12 18:44:27,614 [run_pretraining.py:  512]:	********exe.run_712******* 
[INFO] 2021-07-12 18:44:28,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:28,573 [run_pretraining.py:  534]:	loss/total_loss, 8.27361011505127, 713
[INFO] 2021-07-12 18:44:28,573 [run_pretraining.py:  535]:	loss/mlm_loss, 8.27361011505127, 713
[INFO] 2021-07-12 18:44:28,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.119999736460159e-06, 713
[INFO] 2021-07-12 18:44:28,573 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 713
[INFO] 2021-07-12 18:44:28,573 [run_pretraining.py:  558]:	worker_index: 7, step: 713, cost: 8.273610, mlm loss: 8.273610, speed: 1.043117 steps/s, speed: 8.344937 samples/s, speed: 4272.607672 tokens/s, learning rate: 7.120e-06, loss_scalings: 13421.773438, pp_loss: 8.349682
[INFO] 2021-07-12 18:44:28,573 [run_pretraining.py:  512]:	********exe.run_713******* 
[INFO] 2021-07-12 18:44:29,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  534]:	loss/total_loss, 8.412202835083008, 714
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  535]:	loss/mlm_loss, 8.412202835083008, 714
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.129999630706152e-06, 714
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 714
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  558]:	worker_index: 7, step: 714, cost: 8.412203, mlm loss: 8.412203, speed: 0.932266 steps/s, speed: 7.458125 samples/s, speed: 3818.559939 tokens/s, learning rate: 7.130e-06, loss_scalings: 13421.773438, pp_loss: 8.641939
[INFO] 2021-07-12 18:44:29,646 [run_pretraining.py:  512]:	********exe.run_714******* 
[INFO] 2021-07-12 18:44:30,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:30,724 [run_pretraining.py:  534]:	loss/total_loss, 8.119877815246582, 715
[INFO] 2021-07-12 18:44:30,724 [run_pretraining.py:  535]:	loss/mlm_loss, 8.119877815246582, 715
[INFO] 2021-07-12 18:44:30,724 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.139999979699496e-06, 715
[INFO] 2021-07-12 18:44:30,724 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 715
[INFO] 2021-07-12 18:44:30,724 [run_pretraining.py:  558]:	worker_index: 7, step: 715, cost: 8.119878, mlm loss: 8.119878, speed: 0.928101 steps/s, speed: 7.424807 samples/s, speed: 3801.501092 tokens/s, learning rate: 7.140e-06, loss_scalings: 13421.773438, pp_loss: 8.807588
[INFO] 2021-07-12 18:44:30,724 [run_pretraining.py:  512]:	********exe.run_715******* 
[INFO] 2021-07-12 18:44:31,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  534]:	loss/total_loss, 8.177780151367188, 716
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  535]:	loss/mlm_loss, 8.177780151367188, 716
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.15000032869284e-06, 716
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 716
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  558]:	worker_index: 7, step: 716, cost: 8.177780, mlm loss: 8.177780, speed: 0.940766 steps/s, speed: 7.526130 samples/s, speed: 3853.378760 tokens/s, learning rate: 7.150e-06, loss_scalings: 13421.773438, pp_loss: 8.249879
[INFO] 2021-07-12 18:44:31,788 [run_pretraining.py:  512]:	********exe.run_716******* 
[INFO] 2021-07-12 18:44:32,855 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:32,856 [run_pretraining.py:  534]:	loss/total_loss, 8.305715560913086, 717
[INFO] 2021-07-12 18:44:32,856 [run_pretraining.py:  535]:	loss/mlm_loss, 8.305715560913086, 717
[INFO] 2021-07-12 18:44:32,856 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.159999768191483e-06, 717
[INFO] 2021-07-12 18:44:32,856 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 717
[INFO] 2021-07-12 18:44:32,856 [run_pretraining.py:  558]:	worker_index: 7, step: 717, cost: 8.305716, mlm loss: 8.305716, speed: 0.936607 steps/s, speed: 7.492856 samples/s, speed: 3836.342179 tokens/s, learning rate: 7.160e-06, loss_scalings: 13421.773438, pp_loss: 8.434763
[INFO] 2021-07-12 18:44:32,856 [run_pretraining.py:  512]:	********exe.run_717******* 
[INFO] 2021-07-12 18:44:33,921 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:33,922 [run_pretraining.py:  534]:	loss/total_loss, 8.414737701416016, 718
[INFO] 2021-07-12 18:44:33,922 [run_pretraining.py:  535]:	loss/mlm_loss, 8.414737701416016, 718
[INFO] 2021-07-12 18:44:33,922 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.169999662437476e-06, 718
[INFO] 2021-07-12 18:44:33,922 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 718
[INFO] 2021-07-12 18:44:33,922 [run_pretraining.py:  558]:	worker_index: 7, step: 718, cost: 8.414738, mlm loss: 8.414738, speed: 0.938638 steps/s, speed: 7.509106 samples/s, speed: 3844.662197 tokens/s, learning rate: 7.170e-06, loss_scalings: 13421.773438, pp_loss: 7.423949
[INFO] 2021-07-12 18:44:33,922 [run_pretraining.py:  512]:	********exe.run_718******* 
[INFO] 2021-07-12 18:44:34,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:34,992 [run_pretraining.py:  534]:	loss/total_loss, 8.093780517578125, 719
[INFO] 2021-07-12 18:44:34,992 [run_pretraining.py:  535]:	loss/mlm_loss, 8.093780517578125, 719
[INFO] 2021-07-12 18:44:34,992 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.1800000114308205e-06, 719
[INFO] 2021-07-12 18:44:34,992 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 719
[INFO] 2021-07-12 18:44:34,992 [run_pretraining.py:  558]:	worker_index: 7, step: 719, cost: 8.093781, mlm loss: 8.093781, speed: 0.935220 steps/s, speed: 7.481764 samples/s, speed: 3830.663150 tokens/s, learning rate: 7.180e-06, loss_scalings: 13421.773438, pp_loss: 8.373986
[INFO] 2021-07-12 18:44:34,992 [run_pretraining.py:  512]:	********exe.run_719******* 
[INFO] 2021-07-12 18:44:36,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:36,063 [run_pretraining.py:  534]:	loss/total_loss, 8.170994758605957, 720
[INFO] 2021-07-12 18:44:36,063 [run_pretraining.py:  535]:	loss/mlm_loss, 8.170994758605957, 720
[INFO] 2021-07-12 18:44:36,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.189999905676814e-06, 720
[INFO] 2021-07-12 18:44:36,063 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 720
[INFO] 2021-07-12 18:44:36,063 [run_pretraining.py:  558]:	worker_index: 7, step: 720, cost: 8.170995, mlm loss: 8.170995, speed: 0.934107 steps/s, speed: 7.472855 samples/s, speed: 3826.101512 tokens/s, learning rate: 7.190e-06, loss_scalings: 13421.773438, pp_loss: 8.332500
[INFO] 2021-07-12 18:44:36,064 [run_pretraining.py:  512]:	********exe.run_720******* 
[INFO] 2021-07-12 18:44:37,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:37,132 [run_pretraining.py:  534]:	loss/total_loss, 7.843422889709473, 721
[INFO] 2021-07-12 18:44:37,132 [run_pretraining.py:  535]:	loss/mlm_loss, 7.843422889709473, 721
[INFO] 2021-07-12 18:44:37,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.199999345175456e-06, 721
[INFO] 2021-07-12 18:44:37,132 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 721
[INFO] 2021-07-12 18:44:37,132 [run_pretraining.py:  558]:	worker_index: 7, step: 721, cost: 7.843423, mlm loss: 7.843423, speed: 0.936581 steps/s, speed: 7.492647 samples/s, speed: 3836.235098 tokens/s, learning rate: 7.200e-06, loss_scalings: 13421.773438, pp_loss: 8.275011
[INFO] 2021-07-12 18:44:37,132 [run_pretraining.py:  512]:	********exe.run_721******* 
[INFO] 2021-07-12 18:44:38,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:38,213 [run_pretraining.py:  534]:	loss/total_loss, 8.94544792175293, 722
[INFO] 2021-07-12 18:44:38,213 [run_pretraining.py:  535]:	loss/mlm_loss, 8.94544792175293, 722
[INFO] 2021-07-12 18:44:38,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.2099996941688005e-06, 722
[INFO] 2021-07-12 18:44:38,214 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 722
[INFO] 2021-07-12 18:44:38,214 [run_pretraining.py:  558]:	worker_index: 7, step: 722, cost: 8.945448, mlm loss: 8.945448, speed: 0.924921 steps/s, speed: 7.399371 samples/s, speed: 3788.478084 tokens/s, learning rate: 7.210e-06, loss_scalings: 13421.773438, pp_loss: 8.475161
[INFO] 2021-07-12 18:44:38,214 [run_pretraining.py:  512]:	********exe.run_722******* 
[INFO] 2021-07-12 18:44:39,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:39,328 [run_pretraining.py:  534]:	loss/total_loss, 8.200303077697754, 723
[INFO] 2021-07-12 18:44:39,328 [run_pretraining.py:  535]:	loss/mlm_loss, 8.200303077697754, 723
[INFO] 2021-07-12 18:44:39,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.220000043162145e-06, 723
[INFO] 2021-07-12 18:44:39,329 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 723
[INFO] 2021-07-12 18:44:39,329 [run_pretraining.py:  558]:	worker_index: 7, step: 723, cost: 8.200303, mlm loss: 8.200303, speed: 0.897330 steps/s, speed: 7.178641 samples/s, speed: 3675.464140 tokens/s, learning rate: 7.220e-06, loss_scalings: 13421.773438, pp_loss: 8.269202
[INFO] 2021-07-12 18:44:39,329 [run_pretraining.py:  512]:	********exe.run_723******* 
[INFO] 2021-07-12 18:44:40,391 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:40,392 [run_pretraining.py:  534]:	loss/total_loss, 7.796330451965332, 724
[INFO] 2021-07-12 18:44:40,392 [run_pretraining.py:  535]:	loss/mlm_loss, 7.796330451965332, 724
[INFO] 2021-07-12 18:44:40,392 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.229999937408138e-06, 724
[INFO] 2021-07-12 18:44:40,392 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 724
[INFO] 2021-07-12 18:44:40,392 [run_pretraining.py:  558]:	worker_index: 7, step: 724, cost: 7.796330, mlm loss: 7.796330, speed: 0.940937 steps/s, speed: 7.527495 samples/s, speed: 3854.077240 tokens/s, learning rate: 7.230e-06, loss_scalings: 13421.773438, pp_loss: 8.189260
[INFO] 2021-07-12 18:44:40,392 [run_pretraining.py:  512]:	********exe.run_724******* 
[INFO] 2021-07-12 18:44:41,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:41,463 [run_pretraining.py:  534]:	loss/total_loss, 8.625572204589844, 725
[INFO] 2021-07-12 18:44:41,464 [run_pretraining.py:  535]:	loss/mlm_loss, 8.625572204589844, 725
[INFO] 2021-07-12 18:44:41,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.240000286401482e-06, 725
[INFO] 2021-07-12 18:44:41,464 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 725
[INFO] 2021-07-12 18:44:41,464 [run_pretraining.py:  558]:	worker_index: 7, step: 725, cost: 8.625572, mlm loss: 8.625572, speed: 0.933760 steps/s, speed: 7.470081 samples/s, speed: 3824.681580 tokens/s, learning rate: 7.240e-06, loss_scalings: 13421.773438, pp_loss: 8.483527
[INFO] 2021-07-12 18:44:41,464 [run_pretraining.py:  512]:	********exe.run_725******* 
[INFO] 2021-07-12 18:44:42,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:42,524 [run_pretraining.py:  534]:	loss/total_loss, 7.832401275634766, 726
[INFO] 2021-07-12 18:44:42,525 [run_pretraining.py:  535]:	loss/mlm_loss, 7.832401275634766, 726
[INFO] 2021-07-12 18:44:42,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.249999725900125e-06, 726
[INFO] 2021-07-12 18:44:42,525 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 726
[INFO] 2021-07-12 18:44:42,525 [run_pretraining.py:  558]:	worker_index: 7, step: 726, cost: 7.832401, mlm loss: 7.832401, speed: 0.943034 steps/s, speed: 7.544272 samples/s, speed: 3862.667236 tokens/s, learning rate: 7.250e-06, loss_scalings: 13421.773438, pp_loss: 8.418414
[INFO] 2021-07-12 18:44:42,525 [run_pretraining.py:  512]:	********exe.run_726******* 
[INFO] 2021-07-12 18:44:43,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:43,588 [run_pretraining.py:  534]:	loss/total_loss, 8.443658828735352, 727
[INFO] 2021-07-12 18:44:43,588 [run_pretraining.py:  535]:	loss/mlm_loss, 8.443658828735352, 727
[INFO] 2021-07-12 18:44:43,588 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.259999620146118e-06, 727
[INFO] 2021-07-12 18:44:43,588 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 727
[INFO] 2021-07-12 18:44:43,588 [run_pretraining.py:  558]:	worker_index: 7, step: 727, cost: 8.443659, mlm loss: 8.443659, speed: 0.941125 steps/s, speed: 7.528996 samples/s, speed: 3854.846033 tokens/s, learning rate: 7.260e-06, loss_scalings: 13421.773438, pp_loss: 8.371883
[INFO] 2021-07-12 18:44:43,588 [run_pretraining.py:  512]:	********exe.run_727******* 
[INFO] 2021-07-12 18:44:44,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:44,633 [run_pretraining.py:  534]:	loss/total_loss, 9.27392292022705, 728
[INFO] 2021-07-12 18:44:44,633 [run_pretraining.py:  535]:	loss/mlm_loss, 9.27392292022705, 728
[INFO] 2021-07-12 18:44:44,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.269999969139462e-06, 728
[INFO] 2021-07-12 18:44:44,633 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 728
[INFO] 2021-07-12 18:44:44,633 [run_pretraining.py:  558]:	worker_index: 7, step: 728, cost: 9.273923, mlm loss: 9.273923, speed: 0.957537 steps/s, speed: 7.660296 samples/s, speed: 3922.071450 tokens/s, learning rate: 7.270e-06, loss_scalings: 13421.773438, pp_loss: 8.623002
[INFO] 2021-07-12 18:44:44,633 [run_pretraining.py:  512]:	********exe.run_728******* 
[INFO] 2021-07-12 18:44:45,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:45,694 [run_pretraining.py:  534]:	loss/total_loss, 8.413797378540039, 729
[INFO] 2021-07-12 18:44:45,694 [run_pretraining.py:  535]:	loss/mlm_loss, 8.413797378540039, 729
[INFO] 2021-07-12 18:44:45,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.2800003181328066e-06, 729
[INFO] 2021-07-12 18:44:45,694 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 729
[INFO] 2021-07-12 18:44:45,694 [run_pretraining.py:  558]:	worker_index: 7, step: 729, cost: 8.413797, mlm loss: 8.413797, speed: 0.942800 steps/s, speed: 7.542403 samples/s, speed: 3861.710419 tokens/s, learning rate: 7.280e-06, loss_scalings: 13421.773438, pp_loss: 8.387876
[INFO] 2021-07-12 18:44:45,694 [run_pretraining.py:  512]:	********exe.run_729******* 
[INFO] 2021-07-12 18:44:46,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:46,757 [run_pretraining.py:  534]:	loss/total_loss, 8.625617980957031, 730
[INFO] 2021-07-12 18:44:46,757 [run_pretraining.py:  535]:	loss/mlm_loss, 8.625617980957031, 730
[INFO] 2021-07-12 18:44:46,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.289999757631449e-06, 730
[INFO] 2021-07-12 18:44:46,757 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 730
[INFO] 2021-07-12 18:44:46,757 [run_pretraining.py:  558]:	worker_index: 7, step: 730, cost: 8.625618, mlm loss: 8.625618, speed: 0.941566 steps/s, speed: 7.532532 samples/s, speed: 3856.656371 tokens/s, learning rate: 7.290e-06, loss_scalings: 13421.773438, pp_loss: 7.543566
[INFO] 2021-07-12 18:44:46,757 [run_pretraining.py:  512]:	********exe.run_730******* 
[INFO] 2021-07-12 18:44:47,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:47,825 [run_pretraining.py:  534]:	loss/total_loss, 8.335506439208984, 731
[INFO] 2021-07-12 18:44:47,825 [run_pretraining.py:  535]:	loss/mlm_loss, 8.335506439208984, 731
[INFO] 2021-07-12 18:44:47,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.299999651877442e-06, 731
[INFO] 2021-07-12 18:44:47,826 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 731
[INFO] 2021-07-12 18:44:47,826 [run_pretraining.py:  558]:	worker_index: 7, step: 731, cost: 8.335506, mlm loss: 8.335506, speed: 0.936281 steps/s, speed: 7.490248 samples/s, speed: 3835.007092 tokens/s, learning rate: 7.300e-06, loss_scalings: 13421.773438, pp_loss: 8.403591
[INFO] 2021-07-12 18:44:47,826 [run_pretraining.py:  512]:	********exe.run_731******* 
[INFO] 2021-07-12 18:44:48,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:48,892 [run_pretraining.py:  534]:	loss/total_loss, 8.116233825683594, 732
[INFO] 2021-07-12 18:44:48,892 [run_pretraining.py:  535]:	loss/mlm_loss, 8.116233825683594, 732
[INFO] 2021-07-12 18:44:48,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.310000000870787e-06, 732
[INFO] 2021-07-12 18:44:48,892 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 732
[INFO] 2021-07-12 18:44:48,892 [run_pretraining.py:  558]:	worker_index: 7, step: 732, cost: 8.116234, mlm loss: 8.116234, speed: 0.938494 steps/s, speed: 7.507950 samples/s, speed: 3844.070339 tokens/s, learning rate: 7.310e-06, loss_scalings: 13421.773438, pp_loss: 8.294420
[INFO] 2021-07-12 18:44:48,892 [run_pretraining.py:  512]:	********exe.run_732******* 
[INFO] 2021-07-12 18:44:49,962 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  534]:	loss/total_loss, 8.416546821594238, 733
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  535]:	loss/mlm_loss, 8.416546821594238, 733
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.31999989511678e-06, 733
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 733
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  558]:	worker_index: 7, step: 733, cost: 8.416547, mlm loss: 8.416547, speed: 0.933994 steps/s, speed: 7.471954 samples/s, speed: 3825.640579 tokens/s, learning rate: 7.320e-06, loss_scalings: 13421.773438, pp_loss: 8.282640
[INFO] 2021-07-12 18:44:49,963 [run_pretraining.py:  512]:	********exe.run_733******* 
[INFO] 2021-07-12 18:44:51,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:51,035 [run_pretraining.py:  534]:	loss/total_loss, 7.861357688903809, 734
[INFO] 2021-07-12 18:44:51,035 [run_pretraining.py:  535]:	loss/mlm_loss, 7.861357688903809, 734
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.329999334615422e-06, 734
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 734
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  558]:	worker_index: 7, step: 734, cost: 7.861358, mlm loss: 7.861358, speed: 0.933009 steps/s, speed: 7.464069 samples/s, speed: 3821.603432 tokens/s, learning rate: 7.330e-06, loss_scalings: 13421.773438, pp_loss: 8.295774
[INFO] 2021-07-12 18:44:51,036 [run_pretraining.py:  512]:	********exe.run_734******* 
[INFO] 2021-07-12 18:44:52,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:52,077 [run_pretraining.py:  534]:	loss/total_loss, 8.366908073425293, 735
[INFO] 2021-07-12 18:44:52,077 [run_pretraining.py:  535]:	loss/mlm_loss, 8.366908073425293, 735
[INFO] 2021-07-12 18:44:52,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.339999683608767e-06, 735
[INFO] 2021-07-12 18:44:52,077 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 735
[INFO] 2021-07-12 18:44:52,078 [run_pretraining.py:  558]:	worker_index: 7, step: 735, cost: 8.366908, mlm loss: 8.366908, speed: 0.960385 steps/s, speed: 7.683079 samples/s, speed: 3933.736232 tokens/s, learning rate: 7.340e-06, loss_scalings: 13421.773438, pp_loss: 8.110080
[INFO] 2021-07-12 18:44:52,078 [run_pretraining.py:  512]:	********exe.run_735******* 
[INFO] 2021-07-12 18:44:52,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:52,989 [run_pretraining.py:  534]:	loss/total_loss, 8.444221496582031, 736
[INFO] 2021-07-12 18:44:52,989 [run_pretraining.py:  535]:	loss/mlm_loss, 8.444221496582031, 736
[INFO] 2021-07-12 18:44:52,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.350000032602111e-06, 736
[INFO] 2021-07-12 18:44:52,989 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 736
[INFO] 2021-07-12 18:44:52,989 [run_pretraining.py:  558]:	worker_index: 7, step: 736, cost: 8.444221, mlm loss: 8.444221, speed: 1.097541 steps/s, speed: 8.780325 samples/s, speed: 4495.526207 tokens/s, learning rate: 7.350e-06, loss_scalings: 13421.773438, pp_loss: 8.220551
[INFO] 2021-07-12 18:44:52,989 [run_pretraining.py:  512]:	********exe.run_736******* 
[INFO] 2021-07-12 18:44:53,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:53,905 [run_pretraining.py:  534]:	loss/total_loss, 6.812921524047852, 737
[INFO] 2021-07-12 18:44:53,905 [run_pretraining.py:  535]:	loss/mlm_loss, 6.812921524047852, 737
[INFO] 2021-07-12 18:44:53,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.359999926848104e-06, 737
[INFO] 2021-07-12 18:44:53,905 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 737
[INFO] 2021-07-12 18:44:53,905 [run_pretraining.py:  558]:	worker_index: 7, step: 737, cost: 6.812922, mlm loss: 6.812922, speed: 1.092965 steps/s, speed: 8.743721 samples/s, speed: 4476.785212 tokens/s, learning rate: 7.360e-06, loss_scalings: 13421.773438, pp_loss: 7.875243
[INFO] 2021-07-12 18:44:53,905 [run_pretraining.py:  512]:	********exe.run_737******* 
[INFO] 2021-07-12 18:44:54,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:54,817 [run_pretraining.py:  534]:	loss/total_loss, 8.43488883972168, 738
[INFO] 2021-07-12 18:44:54,817 [run_pretraining.py:  535]:	loss/mlm_loss, 8.43488883972168, 738
[INFO] 2021-07-12 18:44:54,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.3700002758414485e-06, 738
[INFO] 2021-07-12 18:44:54,818 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 738
[INFO] 2021-07-12 18:44:54,818 [run_pretraining.py:  558]:	worker_index: 7, step: 738, cost: 8.434889, mlm loss: 8.434889, speed: 1.096314 steps/s, speed: 8.770513 samples/s, speed: 4490.502876 tokens/s, learning rate: 7.370e-06, loss_scalings: 13421.773438, pp_loss: 8.400959
[INFO] 2021-07-12 18:44:54,818 [run_pretraining.py:  512]:	********exe.run_738******* 
[INFO] 2021-07-12 18:44:55,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:55,729 [run_pretraining.py:  534]:	loss/total_loss, 8.265027046203613, 739
[INFO] 2021-07-12 18:44:55,729 [run_pretraining.py:  535]:	loss/mlm_loss, 8.265027046203613, 739
[INFO] 2021-07-12 18:44:55,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.379999715340091e-06, 739
[INFO] 2021-07-12 18:44:55,729 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 739
[INFO] 2021-07-12 18:44:55,729 [run_pretraining.py:  558]:	worker_index: 7, step: 739, cost: 8.265027, mlm loss: 8.265027, speed: 1.098260 steps/s, speed: 8.786077 samples/s, speed: 4498.471394 tokens/s, learning rate: 7.380e-06, loss_scalings: 13421.773438, pp_loss: 8.311384
[INFO] 2021-07-12 18:44:55,729 [run_pretraining.py:  512]:	********exe.run_739******* 
[INFO] 2021-07-12 18:44:56,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:56,645 [run_pretraining.py:  534]:	loss/total_loss, 8.227892875671387, 740
[INFO] 2021-07-12 18:44:56,645 [run_pretraining.py:  535]:	loss/mlm_loss, 8.227892875671387, 740
[INFO] 2021-07-12 18:44:56,645 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.389999609586084e-06, 740
[INFO] 2021-07-12 18:44:56,645 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 740
[INFO] 2021-07-12 18:44:56,645 [run_pretraining.py:  558]:	worker_index: 7, step: 740, cost: 8.227893, mlm loss: 8.227893, speed: 1.092165 steps/s, speed: 8.737321 samples/s, speed: 4473.508370 tokens/s, learning rate: 7.390e-06, loss_scalings: 13421.773438, pp_loss: 8.260592
[INFO] 2021-07-12 18:44:56,645 [run_pretraining.py:  512]:	********exe.run_740******* 
[INFO] 2021-07-12 18:44:57,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:57,562 [run_pretraining.py:  534]:	loss/total_loss, 8.464085578918457, 741
[INFO] 2021-07-12 18:44:57,562 [run_pretraining.py:  535]:	loss/mlm_loss, 8.464085578918457, 741
[INFO] 2021-07-12 18:44:57,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.3999999585794285e-06, 741
[INFO] 2021-07-12 18:44:57,562 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 741
[INFO] 2021-07-12 18:44:57,562 [run_pretraining.py:  558]:	worker_index: 7, step: 741, cost: 8.464086, mlm loss: 8.464086, speed: 1.091323 steps/s, speed: 8.730583 samples/s, speed: 4470.058365 tokens/s, learning rate: 7.400e-06, loss_scalings: 13421.773438, pp_loss: 8.114160
[INFO] 2021-07-12 18:44:57,562 [run_pretraining.py:  512]:	********exe.run_741******* 
[INFO] 2021-07-12 18:44:58,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:58,474 [run_pretraining.py:  534]:	loss/total_loss, 8.444250106811523, 742
[INFO] 2021-07-12 18:44:58,474 [run_pretraining.py:  535]:	loss/mlm_loss, 8.444250106811523, 742
[INFO] 2021-07-12 18:44:58,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.409999852825422e-06, 742
[INFO] 2021-07-12 18:44:58,475 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 742
[INFO] 2021-07-12 18:44:58,475 [run_pretraining.py:  558]:	worker_index: 7, step: 742, cost: 8.444250, mlm loss: 8.444250, speed: 1.096588 steps/s, speed: 8.772701 samples/s, speed: 4491.622898 tokens/s, learning rate: 7.410e-06, loss_scalings: 13421.773438, pp_loss: 8.368675
[INFO] 2021-07-12 18:44:58,475 [run_pretraining.py:  512]:	********exe.run_742******* 
[INFO] 2021-07-12 18:44:59,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:44:59,390 [run_pretraining.py:  534]:	loss/total_loss, 8.438239097595215, 743
[INFO] 2021-07-12 18:44:59,390 [run_pretraining.py:  535]:	loss/mlm_loss, 8.438239097595215, 743
[INFO] 2021-07-12 18:44:59,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.419999292324064e-06, 743
[INFO] 2021-07-12 18:44:59,390 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 743
[INFO] 2021-07-12 18:44:59,390 [run_pretraining.py:  558]:	worker_index: 7, step: 743, cost: 8.438239, mlm loss: 8.438239, speed: 1.093280 steps/s, speed: 8.746242 samples/s, speed: 4478.075816 tokens/s, learning rate: 7.420e-06, loss_scalings: 13421.773438, pp_loss: 8.458437
[INFO] 2021-07-12 18:44:59,390 [run_pretraining.py:  512]:	********exe.run_743******* 
[INFO] 2021-07-12 18:45:00,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:00,301 [run_pretraining.py:  534]:	loss/total_loss, 7.683335304260254, 744
[INFO] 2021-07-12 18:45:00,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.683335304260254, 744
[INFO] 2021-07-12 18:45:00,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.4299996413174085e-06, 744
[INFO] 2021-07-12 18:45:00,301 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 744
[INFO] 2021-07-12 18:45:00,301 [run_pretraining.py:  558]:	worker_index: 7, step: 744, cost: 7.683335, mlm loss: 7.683335, speed: 1.098433 steps/s, speed: 8.787462 samples/s, speed: 4499.180604 tokens/s, learning rate: 7.430e-06, loss_scalings: 13421.773438, pp_loss: 8.489653
[INFO] 2021-07-12 18:45:00,301 [run_pretraining.py:  512]:	********exe.run_744******* 
[INFO] 2021-07-12 18:45:01,217 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:01,217 [run_pretraining.py:  534]:	loss/total_loss, 8.173669815063477, 745
[INFO] 2021-07-12 18:45:01,218 [run_pretraining.py:  535]:	loss/mlm_loss, 8.173669815063477, 745
[INFO] 2021-07-12 18:45:01,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.439999990310753e-06, 745
[INFO] 2021-07-12 18:45:01,218 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 745
[INFO] 2021-07-12 18:45:01,218 [run_pretraining.py:  558]:	worker_index: 7, step: 745, cost: 8.173670, mlm loss: 8.173670, speed: 1.091660 steps/s, speed: 8.733282 samples/s, speed: 4471.440521 tokens/s, learning rate: 7.440e-06, loss_scalings: 13421.773438, pp_loss: 8.332100
[INFO] 2021-07-12 18:45:01,218 [run_pretraining.py:  512]:	********exe.run_745******* 
[INFO] 2021-07-12 18:45:02,136 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:02,136 [run_pretraining.py:  534]:	loss/total_loss, 7.9990339279174805, 746
[INFO] 2021-07-12 18:45:02,136 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9990339279174805, 746
[INFO] 2021-07-12 18:45:02,137 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.449999884556746e-06, 746
[INFO] 2021-07-12 18:45:02,137 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 746
[INFO] 2021-07-12 18:45:02,137 [run_pretraining.py:  558]:	worker_index: 7, step: 746, cost: 7.999034, mlm loss: 7.999034, speed: 1.088936 steps/s, speed: 8.711491 samples/s, speed: 4460.283234 tokens/s, learning rate: 7.450e-06, loss_scalings: 13421.773438, pp_loss: 8.217449
[INFO] 2021-07-12 18:45:02,137 [run_pretraining.py:  512]:	********exe.run_746******* 
[INFO] 2021-07-12 18:45:03,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:03,050 [run_pretraining.py:  534]:	loss/total_loss, 8.362531661987305, 747
[INFO] 2021-07-12 18:45:03,050 [run_pretraining.py:  535]:	loss/mlm_loss, 8.362531661987305, 747
[INFO] 2021-07-12 18:45:03,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.46000023355009e-06, 747
[INFO] 2021-07-12 18:45:03,051 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 747
[INFO] 2021-07-12 18:45:03,051 [run_pretraining.py:  558]:	worker_index: 7, step: 747, cost: 8.362532, mlm loss: 8.362532, speed: 1.094881 steps/s, speed: 8.759048 samples/s, speed: 4484.632495 tokens/s, learning rate: 7.460e-06, loss_scalings: 13421.773438, pp_loss: 7.396095
[INFO] 2021-07-12 18:45:03,051 [run_pretraining.py:  512]:	********exe.run_747******* 
[INFO] 2021-07-12 18:45:03,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:03,969 [run_pretraining.py:  534]:	loss/total_loss, 8.183537483215332, 748
[INFO] 2021-07-12 18:45:03,969 [run_pretraining.py:  535]:	loss/mlm_loss, 8.183537483215332, 748
[INFO] 2021-07-12 18:45:03,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.469999673048733e-06, 748
[INFO] 2021-07-12 18:45:03,969 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 748
[INFO] 2021-07-12 18:45:03,969 [run_pretraining.py:  558]:	worker_index: 7, step: 748, cost: 8.183537, mlm loss: 8.183537, speed: 1.089668 steps/s, speed: 8.717341 samples/s, speed: 4463.278650 tokens/s, learning rate: 7.470e-06, loss_scalings: 13421.773438, pp_loss: 7.772099
[INFO] 2021-07-12 18:45:03,969 [run_pretraining.py:  512]:	********exe.run_748******* 
[INFO] 2021-07-12 18:45:04,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:04,892 [run_pretraining.py:  534]:	loss/total_loss, 8.26007080078125, 749
[INFO] 2021-07-12 18:45:04,892 [run_pretraining.py:  535]:	loss/mlm_loss, 8.26007080078125, 749
[INFO] 2021-07-12 18:45:04,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.479999567294726e-06, 749
[INFO] 2021-07-12 18:45:04,892 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 749
[INFO] 2021-07-12 18:45:04,892 [run_pretraining.py:  558]:	worker_index: 7, step: 749, cost: 8.260071, mlm loss: 8.260071, speed: 1.084111 steps/s, speed: 8.672888 samples/s, speed: 4440.518615 tokens/s, learning rate: 7.480e-06, loss_scalings: 13421.773438, pp_loss: 7.681467
[INFO] 2021-07-12 18:45:04,892 [run_pretraining.py:  512]:	********exe.run_749******* 
[INFO] 2021-07-12 18:45:05,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:05,802 [run_pretraining.py:  534]:	loss/total_loss, 8.03880786895752, 750
[INFO] 2021-07-12 18:45:05,802 [run_pretraining.py:  535]:	loss/mlm_loss, 8.03880786895752, 750
[INFO] 2021-07-12 18:45:05,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.48999991628807e-06, 750
[INFO] 2021-07-12 18:45:05,802 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 750
[INFO] 2021-07-12 18:45:05,802 [run_pretraining.py:  558]:	worker_index: 7, step: 750, cost: 8.038808, mlm loss: 8.038808, speed: 1.099408 steps/s, speed: 8.795266 samples/s, speed: 4503.176148 tokens/s, learning rate: 7.490e-06, loss_scalings: 13421.773438, pp_loss: 8.310744
[INFO] 2021-07-12 18:45:05,802 [run_pretraining.py:  512]:	********exe.run_750******* 
[INFO] 2021-07-12 18:45:06,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:06,708 [run_pretraining.py:  534]:	loss/total_loss, 8.119115829467773, 751
[INFO] 2021-07-12 18:45:06,708 [run_pretraining.py:  535]:	loss/mlm_loss, 8.119115829467773, 751
[INFO] 2021-07-12 18:45:06,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.500000265281415e-06, 751
[INFO] 2021-07-12 18:45:06,708 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 751
[INFO] 2021-07-12 18:45:06,708 [run_pretraining.py:  558]:	worker_index: 7, step: 751, cost: 8.119116, mlm loss: 8.119116, speed: 1.105020 steps/s, speed: 8.840164 samples/s, speed: 4526.163740 tokens/s, learning rate: 7.500e-06, loss_scalings: 13421.773438, pp_loss: 7.311020
[INFO] 2021-07-12 18:45:06,708 [run_pretraining.py:  512]:	********exe.run_751******* 
[INFO] 2021-07-12 18:45:07,615 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:07,615 [run_pretraining.py:  534]:	loss/total_loss, 8.336127281188965, 752
[INFO] 2021-07-12 18:45:07,615 [run_pretraining.py:  535]:	loss/mlm_loss, 8.336127281188965, 752
[INFO] 2021-07-12 18:45:07,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.509999704780057e-06, 752
[INFO] 2021-07-12 18:45:07,615 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 752
[INFO] 2021-07-12 18:45:07,616 [run_pretraining.py:  558]:	worker_index: 7, step: 752, cost: 8.336127, mlm loss: 8.336127, speed: 1.102599 steps/s, speed: 8.820794 samples/s, speed: 4516.246435 tokens/s, learning rate: 7.510e-06, loss_scalings: 13421.773438, pp_loss: 8.358403
[INFO] 2021-07-12 18:45:07,616 [run_pretraining.py:  512]:	********exe.run_752******* 
[INFO] 2021-07-12 18:45:08,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:08,530 [run_pretraining.py:  534]:	loss/total_loss, 8.23192310333252, 753
[INFO] 2021-07-12 18:45:08,530 [run_pretraining.py:  535]:	loss/mlm_loss, 8.23192310333252, 753
[INFO] 2021-07-12 18:45:08,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.51999959902605e-06, 753
[INFO] 2021-07-12 18:45:08,531 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 753
[INFO] 2021-07-12 18:45:08,531 [run_pretraining.py:  558]:	worker_index: 7, step: 753, cost: 8.231923, mlm loss: 8.231923, speed: 1.093515 steps/s, speed: 8.748121 samples/s, speed: 4479.037835 tokens/s, learning rate: 7.520e-06, loss_scalings: 13421.773438, pp_loss: 8.225770
[INFO] 2021-07-12 18:45:08,531 [run_pretraining.py:  512]:	********exe.run_753******* 
[INFO] 2021-07-12 18:45:09,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:09,432 [run_pretraining.py:  534]:	loss/total_loss, 8.046183586120605, 754
[INFO] 2021-07-12 18:45:09,432 [run_pretraining.py:  535]:	loss/mlm_loss, 8.046183586120605, 754
[INFO] 2021-07-12 18:45:09,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.529999948019395e-06, 754
[INFO] 2021-07-12 18:45:09,432 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 754
[INFO] 2021-07-12 18:45:09,432 [run_pretraining.py:  558]:	worker_index: 7, step: 754, cost: 8.046184, mlm loss: 8.046184, speed: 1.110004 steps/s, speed: 8.880033 samples/s, speed: 4546.577149 tokens/s, learning rate: 7.530e-06, loss_scalings: 13421.773438, pp_loss: 8.560131
[INFO] 2021-07-12 18:45:09,432 [run_pretraining.py:  512]:	********exe.run_754******* 
[INFO] 2021-07-12 18:45:10,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:10,331 [run_pretraining.py:  534]:	loss/total_loss, 8.177214622497559, 755
[INFO] 2021-07-12 18:45:10,331 [run_pretraining.py:  535]:	loss/mlm_loss, 8.177214622497559, 755
[INFO] 2021-07-12 18:45:10,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.539999842265388e-06, 755
[INFO] 2021-07-12 18:45:10,331 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 755
[INFO] 2021-07-12 18:45:10,331 [run_pretraining.py:  558]:	worker_index: 7, step: 755, cost: 8.177215, mlm loss: 8.177215, speed: 1.113222 steps/s, speed: 8.905773 samples/s, speed: 4559.755731 tokens/s, learning rate: 7.540e-06, loss_scalings: 13421.773438, pp_loss: 8.249276
[INFO] 2021-07-12 18:45:10,331 [run_pretraining.py:  512]:	********exe.run_755******* 
[INFO] 2021-07-12 18:45:11,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:11,235 [run_pretraining.py:  534]:	loss/total_loss, 8.62908935546875, 756
[INFO] 2021-07-12 18:45:11,235 [run_pretraining.py:  535]:	loss/mlm_loss, 8.62908935546875, 756
[INFO] 2021-07-12 18:45:11,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.5499992817640305e-06, 756
[INFO] 2021-07-12 18:45:11,235 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 756
[INFO] 2021-07-12 18:45:11,235 [run_pretraining.py:  558]:	worker_index: 7, step: 756, cost: 8.629089, mlm loss: 8.629089, speed: 1.107004 steps/s, speed: 8.856032 samples/s, speed: 4534.288159 tokens/s, learning rate: 7.550e-06, loss_scalings: 13421.773438, pp_loss: 8.324786
[INFO] 2021-07-12 18:45:11,235 [run_pretraining.py:  512]:	********exe.run_756******* 
[INFO] 2021-07-12 18:45:12,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:12,142 [run_pretraining.py:  534]:	loss/total_loss, 9.04011058807373, 757
[INFO] 2021-07-12 18:45:12,142 [run_pretraining.py:  535]:	loss/mlm_loss, 9.04011058807373, 757
[INFO] 2021-07-12 18:45:12,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.559999630757375e-06, 757
[INFO] 2021-07-12 18:45:12,143 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 757
[INFO] 2021-07-12 18:45:12,143 [run_pretraining.py:  558]:	worker_index: 7, step: 757, cost: 9.040111, mlm loss: 9.040111, speed: 1.102731 steps/s, speed: 8.821851 samples/s, speed: 4516.787878 tokens/s, learning rate: 7.560e-06, loss_scalings: 13421.773438, pp_loss: 7.538978
[INFO] 2021-07-12 18:45:12,143 [run_pretraining.py:  512]:	********exe.run_757******* 
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  534]:	loss/total_loss, 7.78095006942749, 758
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  535]:	loss/mlm_loss, 7.78095006942749, 758
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.569999979750719e-06, 758
[INFO] 2021-07-12 18:45:13,043 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 758
[INFO] 2021-07-12 18:45:13,044 [run_pretraining.py:  558]:	worker_index: 7, step: 758, cost: 7.780950, mlm loss: 7.780950, speed: 1.110885 steps/s, speed: 8.887078 samples/s, speed: 4550.183686 tokens/s, learning rate: 7.570e-06, loss_scalings: 13421.773438, pp_loss: 8.201011
[INFO] 2021-07-12 18:45:13,044 [run_pretraining.py:  512]:	********exe.run_758******* 
[INFO] 2021-07-12 18:45:13,951 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:13,951 [run_pretraining.py:  534]:	loss/total_loss, 8.40636157989502, 759
[INFO] 2021-07-12 18:45:13,952 [run_pretraining.py:  535]:	loss/mlm_loss, 8.40636157989502, 759
[INFO] 2021-07-12 18:45:13,952 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.579999873996712e-06, 759
[INFO] 2021-07-12 18:45:13,952 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 759
[INFO] 2021-07-12 18:45:13,952 [run_pretraining.py:  558]:	worker_index: 7, step: 759, cost: 8.406362, mlm loss: 8.406362, speed: 1.101816 steps/s, speed: 8.814531 samples/s, speed: 4513.039627 tokens/s, learning rate: 7.580e-06, loss_scalings: 13421.773438, pp_loss: 8.218486
[INFO] 2021-07-12 18:45:13,952 [run_pretraining.py:  512]:	********exe.run_759******* 
[INFO] 2021-07-12 18:45:14,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:14,854 [run_pretraining.py:  534]:	loss/total_loss, 8.425849914550781, 760
[INFO] 2021-07-12 18:45:14,854 [run_pretraining.py:  535]:	loss/mlm_loss, 8.425849914550781, 760
[INFO] 2021-07-12 18:45:14,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.5900002229900565e-06, 760
[INFO] 2021-07-12 18:45:14,854 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 760
[INFO] 2021-07-12 18:45:14,854 [run_pretraining.py:  558]:	worker_index: 7, step: 760, cost: 8.425850, mlm loss: 8.425850, speed: 1.108924 steps/s, speed: 8.871391 samples/s, speed: 4542.152363 tokens/s, learning rate: 7.590e-06, loss_scalings: 13421.773438, pp_loss: 8.535360
[INFO] 2021-07-12 18:45:14,854 [run_pretraining.py:  512]:	********exe.run_760******* 
[INFO] 2021-07-12 18:45:15,759 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:15,760 [run_pretraining.py:  534]:	loss/total_loss, 9.011079788208008, 761
[INFO] 2021-07-12 18:45:15,760 [run_pretraining.py:  535]:	loss/mlm_loss, 9.011079788208008, 761
[INFO] 2021-07-12 18:45:15,760 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.599999662488699e-06, 761
[INFO] 2021-07-12 18:45:15,760 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 761
[INFO] 2021-07-12 18:45:15,760 [run_pretraining.py:  558]:	worker_index: 7, step: 761, cost: 9.011080, mlm loss: 9.011080, speed: 1.104819 steps/s, speed: 8.838550 samples/s, speed: 4525.337522 tokens/s, learning rate: 7.600e-06, loss_scalings: 13421.773438, pp_loss: 8.499920
[INFO] 2021-07-12 18:45:15,760 [run_pretraining.py:  512]:	********exe.run_761******* 
[INFO] 2021-07-12 18:45:16,661 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:16,662 [run_pretraining.py:  534]:	loss/total_loss, 8.377303123474121, 762
[INFO] 2021-07-12 18:45:16,662 [run_pretraining.py:  535]:	loss/mlm_loss, 8.377303123474121, 762
[INFO] 2021-07-12 18:45:16,662 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.609999556734692e-06, 762
[INFO] 2021-07-12 18:45:16,662 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 762
[INFO] 2021-07-12 18:45:16,662 [run_pretraining.py:  558]:	worker_index: 7, step: 762, cost: 8.377303, mlm loss: 8.377303, speed: 1.109357 steps/s, speed: 8.874859 samples/s, speed: 4543.927974 tokens/s, learning rate: 7.610e-06, loss_scalings: 13421.773438, pp_loss: 8.277437
[INFO] 2021-07-12 18:45:16,662 [run_pretraining.py:  512]:	********exe.run_762******* 
[INFO] 2021-07-12 18:45:17,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:17,566 [run_pretraining.py:  534]:	loss/total_loss, 8.558670997619629, 763
[INFO] 2021-07-12 18:45:17,566 [run_pretraining.py:  535]:	loss/mlm_loss, 8.558670997619629, 763
[INFO] 2021-07-12 18:45:17,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.6199999057280365e-06, 763
[INFO] 2021-07-12 18:45:17,566 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 763
[INFO] 2021-07-12 18:45:17,566 [run_pretraining.py:  558]:	worker_index: 7, step: 763, cost: 8.558671, mlm loss: 8.558671, speed: 1.107125 steps/s, speed: 8.856997 samples/s, speed: 4534.782464 tokens/s, learning rate: 7.620e-06, loss_scalings: 13421.773438, pp_loss: 8.195026
[INFO] 2021-07-12 18:45:17,566 [run_pretraining.py:  512]:	********exe.run_763******* 
[INFO] 2021-07-12 18:45:18,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:18,476 [run_pretraining.py:  534]:	loss/total_loss, 8.231882095336914, 764
[INFO] 2021-07-12 18:45:18,476 [run_pretraining.py:  535]:	loss/mlm_loss, 8.231882095336914, 764
[INFO] 2021-07-12 18:45:18,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.63000025472138e-06, 764
[INFO] 2021-07-12 18:45:18,476 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 764
[INFO] 2021-07-12 18:45:18,476 [run_pretraining.py:  558]:	worker_index: 7, step: 764, cost: 8.231882, mlm loss: 8.231882, speed: 1.099224 steps/s, speed: 8.793795 samples/s, speed: 4502.423199 tokens/s, learning rate: 7.630e-06, loss_scalings: 13421.773438, pp_loss: 8.311107
[INFO] 2021-07-12 18:45:18,476 [run_pretraining.py:  512]:	********exe.run_764******* 
[INFO] 2021-07-12 18:45:19,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:19,384 [run_pretraining.py:  534]:	loss/total_loss, 8.072371482849121, 765
[INFO] 2021-07-12 18:45:19,384 [run_pretraining.py:  535]:	loss/mlm_loss, 8.072371482849121, 765
[INFO] 2021-07-12 18:45:19,384 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.639999239472672e-06, 765
[INFO] 2021-07-12 18:45:19,384 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 765
[INFO] 2021-07-12 18:45:19,384 [run_pretraining.py:  558]:	worker_index: 7, step: 765, cost: 8.072371, mlm loss: 8.072371, speed: 1.102358 steps/s, speed: 8.818867 samples/s, speed: 4515.260062 tokens/s, learning rate: 7.640e-06, loss_scalings: 13421.773438, pp_loss: 8.378516
[INFO] 2021-07-12 18:45:19,384 [run_pretraining.py:  512]:	********exe.run_765******* 
[INFO] 2021-07-12 18:45:20,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:20,303 [run_pretraining.py:  534]:	loss/total_loss, 8.219756126403809, 766
[INFO] 2021-07-12 18:45:20,303 [run_pretraining.py:  535]:	loss/mlm_loss, 8.219756126403809, 766
[INFO] 2021-07-12 18:45:20,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.650000043213367e-06, 766
[INFO] 2021-07-12 18:45:20,303 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 766
[INFO] 2021-07-12 18:45:20,304 [run_pretraining.py:  558]:	worker_index: 7, step: 766, cost: 8.219756, mlm loss: 8.219756, speed: 1.088455 steps/s, speed: 8.707641 samples/s, speed: 4458.312047 tokens/s, learning rate: 7.650e-06, loss_scalings: 13421.773438, pp_loss: 8.298385
[INFO] 2021-07-12 18:45:20,304 [run_pretraining.py:  512]:	********exe.run_766******* 
[INFO] 2021-07-12 18:45:21,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:21,214 [run_pretraining.py:  534]:	loss/total_loss, 8.503801345825195, 767
[INFO] 2021-07-12 18:45:21,214 [run_pretraining.py:  535]:	loss/mlm_loss, 8.503801345825195, 767
[INFO] 2021-07-12 18:45:21,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.65999993745936e-06, 767
[INFO] 2021-07-12 18:45:21,214 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 767
[INFO] 2021-07-12 18:45:21,214 [run_pretraining.py:  558]:	worker_index: 7, step: 767, cost: 8.503801, mlm loss: 8.503801, speed: 1.098929 steps/s, speed: 8.791431 samples/s, speed: 4501.212870 tokens/s, learning rate: 7.660e-06, loss_scalings: 13421.773438, pp_loss: 8.424503
[INFO] 2021-07-12 18:45:21,214 [run_pretraining.py:  512]:	********exe.run_767******* 
[INFO] 2021-07-12 18:45:22,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:22,126 [run_pretraining.py:  534]:	loss/total_loss, 8.547309875488281, 768
[INFO] 2021-07-12 18:45:22,126 [run_pretraining.py:  535]:	loss/mlm_loss, 8.547309875488281, 768
[INFO] 2021-07-12 18:45:22,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.669999831705354e-06, 768
[INFO] 2021-07-12 18:45:22,126 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 768
[INFO] 2021-07-12 18:45:22,126 [run_pretraining.py:  558]:	worker_index: 7, step: 768, cost: 8.547310, mlm loss: 8.547310, speed: 1.097163 steps/s, speed: 8.777307 samples/s, speed: 4493.980997 tokens/s, learning rate: 7.670e-06, loss_scalings: 13421.773438, pp_loss: 8.347761
[INFO] 2021-07-12 18:45:22,126 [run_pretraining.py:  512]:	********exe.run_768******* 
[INFO] 2021-07-12 18:45:23,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:23,039 [run_pretraining.py:  534]:	loss/total_loss, 8.465777397155762, 769
[INFO] 2021-07-12 18:45:23,039 [run_pretraining.py:  535]:	loss/mlm_loss, 8.465777397155762, 769
[INFO] 2021-07-12 18:45:23,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.679999725951348e-06, 769
[INFO] 2021-07-12 18:45:23,039 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 769
[INFO] 2021-07-12 18:45:23,039 [run_pretraining.py:  558]:	worker_index: 7, step: 769, cost: 8.465777, mlm loss: 8.465777, speed: 1.095901 steps/s, speed: 8.767204 samples/s, speed: 4488.808642 tokens/s, learning rate: 7.680e-06, loss_scalings: 13421.773438, pp_loss: 8.317870
[INFO] 2021-07-12 18:45:23,039 [run_pretraining.py:  512]:	********exe.run_769******* 
[INFO] 2021-07-12 18:45:23,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:23,948 [run_pretraining.py:  534]:	loss/total_loss, 8.157848358154297, 770
[INFO] 2021-07-12 18:45:23,948 [run_pretraining.py:  535]:	loss/mlm_loss, 8.157848358154297, 770
[INFO] 2021-07-12 18:45:23,948 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.68999962019734e-06, 770
[INFO] 2021-07-12 18:45:23,948 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 770
[INFO] 2021-07-12 18:45:23,949 [run_pretraining.py:  558]:	worker_index: 7, step: 770, cost: 8.157848, mlm loss: 8.157848, speed: 1.100694 steps/s, speed: 8.805549 samples/s, speed: 4508.440843 tokens/s, learning rate: 7.690e-06, loss_scalings: 13421.773438, pp_loss: 8.186612
[INFO] 2021-07-12 18:45:23,949 [run_pretraining.py:  512]:	********exe.run_770******* 
[INFO] 2021-07-12 18:45:24,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:24,868 [run_pretraining.py:  534]:	loss/total_loss, 8.019804954528809, 771
[INFO] 2021-07-12 18:45:24,868 [run_pretraining.py:  535]:	loss/mlm_loss, 8.019804954528809, 771
[INFO] 2021-07-12 18:45:24,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.699999514443334e-06, 771
[INFO] 2021-07-12 18:45:24,868 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 771
[INFO] 2021-07-12 18:45:24,868 [run_pretraining.py:  558]:	worker_index: 7, step: 771, cost: 8.019805, mlm loss: 8.019805, speed: 1.088129 steps/s, speed: 8.705032 samples/s, speed: 4456.976151 tokens/s, learning rate: 7.700e-06, loss_scalings: 13421.773438, pp_loss: 8.219749
[INFO] 2021-07-12 18:45:24,868 [run_pretraining.py:  512]:	********exe.run_771******* 
[INFO] 2021-07-12 18:45:25,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:25,797 [run_pretraining.py:  534]:	loss/total_loss, 6.285604953765869, 772
[INFO] 2021-07-12 18:45:25,797 [run_pretraining.py:  535]:	loss/mlm_loss, 6.285604953765869, 772
[INFO] 2021-07-12 18:45:25,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.71000031818403e-06, 772
[INFO] 2021-07-12 18:45:25,797 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 772
[INFO] 2021-07-12 18:45:25,797 [run_pretraining.py:  558]:	worker_index: 7, step: 772, cost: 6.285605, mlm loss: 6.285605, speed: 1.077354 steps/s, speed: 8.618830 samples/s, speed: 4412.840896 tokens/s, learning rate: 7.710e-06, loss_scalings: 13421.773438, pp_loss: 7.796764
[INFO] 2021-07-12 18:45:25,797 [run_pretraining.py:  512]:	********exe.run_772******* 
[INFO] 2021-07-12 18:45:26,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:26,857 [run_pretraining.py:  534]:	loss/total_loss, 6.542896270751953, 773
[INFO] 2021-07-12 18:45:26,857 [run_pretraining.py:  535]:	loss/mlm_loss, 6.542896270751953, 773
[INFO] 2021-07-12 18:45:26,857 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.720000212430023e-06, 773
[INFO] 2021-07-12 18:45:26,857 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 773
[INFO] 2021-07-12 18:45:26,857 [run_pretraining.py:  558]:	worker_index: 7, step: 773, cost: 6.542896, mlm loss: 6.542896, speed: 0.944011 steps/s, speed: 7.552086 samples/s, speed: 3866.668074 tokens/s, learning rate: 7.720e-06, loss_scalings: 13421.773438, pp_loss: 8.066460
[INFO] 2021-07-12 18:45:26,857 [run_pretraining.py:  512]:	********exe.run_773******* 
[INFO] 2021-07-12 18:45:27,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:27,914 [run_pretraining.py:  534]:	loss/total_loss, 8.645181655883789, 774
[INFO] 2021-07-12 18:45:27,914 [run_pretraining.py:  535]:	loss/mlm_loss, 8.645181655883789, 774
[INFO] 2021-07-12 18:45:27,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.729999197181314e-06, 774
[INFO] 2021-07-12 18:45:27,914 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 774
[INFO] 2021-07-12 18:45:27,914 [run_pretraining.py:  558]:	worker_index: 7, step: 774, cost: 8.645182, mlm loss: 8.645182, speed: 0.946333 steps/s, speed: 7.570664 samples/s, speed: 3876.179967 tokens/s, learning rate: 7.730e-06, loss_scalings: 13421.773438, pp_loss: 8.493870
[INFO] 2021-07-12 18:45:27,914 [run_pretraining.py:  512]:	********exe.run_774******* 
[INFO] 2021-07-12 18:45:28,975 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:28,975 [run_pretraining.py:  534]:	loss/total_loss, 9.001611709594727, 775
[INFO] 2021-07-12 18:45:28,976 [run_pretraining.py:  535]:	loss/mlm_loss, 9.001611709594727, 775
[INFO] 2021-07-12 18:45:28,976 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.74000000092201e-06, 775
[INFO] 2021-07-12 18:45:28,976 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 775
[INFO] 2021-07-12 18:45:28,976 [run_pretraining.py:  558]:	worker_index: 7, step: 775, cost: 9.001612, mlm loss: 9.001612, speed: 0.942702 steps/s, speed: 7.541617 samples/s, speed: 3861.307691 tokens/s, learning rate: 7.740e-06, loss_scalings: 13421.773438, pp_loss: 8.637613
[INFO] 2021-07-12 18:45:28,976 [run_pretraining.py:  512]:	********exe.run_775******* 
[INFO] 2021-07-12 18:45:30,045 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:30,045 [run_pretraining.py:  534]:	loss/total_loss, 8.553692817687988, 776
[INFO] 2021-07-12 18:45:30,045 [run_pretraining.py:  535]:	loss/mlm_loss, 8.553692817687988, 776
[INFO] 2021-07-12 18:45:30,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.749999895168003e-06, 776
[INFO] 2021-07-12 18:45:30,045 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 776
[INFO] 2021-07-12 18:45:30,045 [run_pretraining.py:  558]:	worker_index: 7, step: 776, cost: 8.553693, mlm loss: 8.553693, speed: 0.935499 steps/s, speed: 7.483992 samples/s, speed: 3831.803764 tokens/s, learning rate: 7.750e-06, loss_scalings: 13421.773438, pp_loss: 8.390144
[INFO] 2021-07-12 18:45:30,045 [run_pretraining.py:  512]:	********exe.run_776******* 
[INFO] 2021-07-12 18:45:31,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:31,129 [run_pretraining.py:  534]:	loss/total_loss, 8.387683868408203, 777
[INFO] 2021-07-12 18:45:31,129 [run_pretraining.py:  535]:	loss/mlm_loss, 8.387683868408203, 777
[INFO] 2021-07-12 18:45:31,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.759999789413996e-06, 777
[INFO] 2021-07-12 18:45:31,129 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 777
[INFO] 2021-07-12 18:45:31,129 [run_pretraining.py:  558]:	worker_index: 7, step: 777, cost: 8.387684, mlm loss: 8.387684, speed: 0.923248 steps/s, speed: 7.385985 samples/s, speed: 3781.624113 tokens/s, learning rate: 7.760e-06, loss_scalings: 13421.773438, pp_loss: 7.436119
[INFO] 2021-07-12 18:45:31,129 [run_pretraining.py:  512]:	********exe.run_777******* 
[INFO] 2021-07-12 18:45:32,185 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:32,185 [run_pretraining.py:  534]:	loss/total_loss, 8.596055030822754, 778
[INFO] 2021-07-12 18:45:32,186 [run_pretraining.py:  535]:	loss/mlm_loss, 8.596055030822754, 778
[INFO] 2021-07-12 18:45:32,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.76999968365999e-06, 778
[INFO] 2021-07-12 18:45:32,186 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 778
[INFO] 2021-07-12 18:45:32,186 [run_pretraining.py:  558]:	worker_index: 7, step: 778, cost: 8.596055, mlm loss: 8.596055, speed: 0.947026 steps/s, speed: 7.576207 samples/s, speed: 3879.018232 tokens/s, learning rate: 7.770e-06, loss_scalings: 13421.773438, pp_loss: 8.509357
[INFO] 2021-07-12 18:45:32,186 [run_pretraining.py:  512]:	********exe.run_778******* 
[INFO] 2021-07-12 18:45:33,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:33,252 [run_pretraining.py:  534]:	loss/total_loss, 7.636863708496094, 779
[INFO] 2021-07-12 18:45:33,252 [run_pretraining.py:  535]:	loss/mlm_loss, 7.636863708496094, 779
[INFO] 2021-07-12 18:45:33,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.779999577905983e-06, 779
[INFO] 2021-07-12 18:45:33,252 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 779
[INFO] 2021-07-12 18:45:33,252 [run_pretraining.py:  558]:	worker_index: 7, step: 779, cost: 7.636864, mlm loss: 7.636864, speed: 0.938073 steps/s, speed: 7.504583 samples/s, speed: 3842.346556 tokens/s, learning rate: 7.780e-06, loss_scalings: 13421.773438, pp_loss: 7.952051
[INFO] 2021-07-12 18:45:33,253 [run_pretraining.py:  512]:	********exe.run_779******* 
[INFO] 2021-07-12 18:45:34,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:34,313 [run_pretraining.py:  534]:	loss/total_loss, 8.039812088012695, 780
[INFO] 2021-07-12 18:45:34,314 [run_pretraining.py:  535]:	loss/mlm_loss, 8.039812088012695, 780
[INFO] 2021-07-12 18:45:34,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.789999472151976e-06, 780
[INFO] 2021-07-12 18:45:34,314 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 780
[INFO] 2021-07-12 18:45:34,314 [run_pretraining.py:  558]:	worker_index: 7, step: 780, cost: 8.039812, mlm loss: 8.039812, speed: 0.942851 steps/s, speed: 7.542812 samples/s, speed: 3861.919628 tokens/s, learning rate: 7.790e-06, loss_scalings: 13421.773438, pp_loss: 8.117662
[INFO] 2021-07-12 18:45:34,314 [run_pretraining.py:  512]:	********exe.run_780******* 
[INFO] 2021-07-12 18:45:35,383 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:35,384 [run_pretraining.py:  534]:	loss/total_loss, 8.195650100708008, 781
[INFO] 2021-07-12 18:45:35,384 [run_pretraining.py:  535]:	loss/mlm_loss, 8.195650100708008, 781
[INFO] 2021-07-12 18:45:35,384 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.800000275892671e-06, 781
[INFO] 2021-07-12 18:45:35,384 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 781
[INFO] 2021-07-12 18:45:35,384 [run_pretraining.py:  558]:	worker_index: 7, step: 781, cost: 8.195650, mlm loss: 8.195650, speed: 0.934901 steps/s, speed: 7.479204 samples/s, speed: 3829.352497 tokens/s, learning rate: 7.800e-06, loss_scalings: 13421.773438, pp_loss: 8.181488
[INFO] 2021-07-12 18:45:35,384 [run_pretraining.py:  512]:	********exe.run_781******* 
[INFO] 2021-07-12 18:45:36,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:36,442 [run_pretraining.py:  534]:	loss/total_loss, 7.782174110412598, 782
[INFO] 2021-07-12 18:45:36,442 [run_pretraining.py:  535]:	loss/mlm_loss, 7.782174110412598, 782
[INFO] 2021-07-12 18:45:36,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.810000170138665e-06, 782
[INFO] 2021-07-12 18:45:36,442 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 782
[INFO] 2021-07-12 18:45:36,442 [run_pretraining.py:  558]:	worker_index: 7, step: 782, cost: 7.782174, mlm loss: 7.782174, speed: 0.945479 steps/s, speed: 7.563833 samples/s, speed: 3872.682275 tokens/s, learning rate: 7.810e-06, loss_scalings: 13421.773438, pp_loss: 7.965373
[INFO] 2021-07-12 18:45:36,442 [run_pretraining.py:  512]:	********exe.run_782******* 
[INFO] 2021-07-12 18:45:37,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:37,506 [run_pretraining.py:  534]:	loss/total_loss, 8.198341369628906, 783
[INFO] 2021-07-12 18:45:37,506 [run_pretraining.py:  535]:	loss/mlm_loss, 8.198341369628906, 783
[INFO] 2021-07-12 18:45:37,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.819999154889956e-06, 783
[INFO] 2021-07-12 18:45:37,506 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 783
[INFO] 2021-07-12 18:45:37,507 [run_pretraining.py:  558]:	worker_index: 7, step: 783, cost: 8.198341, mlm loss: 8.198341, speed: 0.940276 steps/s, speed: 7.522208 samples/s, speed: 3851.370315 tokens/s, learning rate: 7.820e-06, loss_scalings: 13421.773438, pp_loss: 8.249424
[INFO] 2021-07-12 18:45:37,507 [run_pretraining.py:  512]:	********exe.run_783******* 
[INFO] 2021-07-12 18:45:38,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:38,561 [run_pretraining.py:  534]:	loss/total_loss, 8.291372299194336, 784
[INFO] 2021-07-12 18:45:38,561 [run_pretraining.py:  535]:	loss/mlm_loss, 8.291372299194336, 784
[INFO] 2021-07-12 18:45:38,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.829999958630651e-06, 784
[INFO] 2021-07-12 18:45:38,561 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 784
[INFO] 2021-07-12 18:45:38,561 [run_pretraining.py:  558]:	worker_index: 7, step: 784, cost: 8.291372, mlm loss: 8.291372, speed: 0.948511 steps/s, speed: 7.588089 samples/s, speed: 3885.101694 tokens/s, learning rate: 7.830e-06, loss_scalings: 13421.773438, pp_loss: 8.376200
[INFO] 2021-07-12 18:45:38,562 [run_pretraining.py:  512]:	********exe.run_784******* 
[INFO] 2021-07-12 18:45:39,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:39,628 [run_pretraining.py:  534]:	loss/total_loss, 8.371624946594238, 785
[INFO] 2021-07-12 18:45:39,628 [run_pretraining.py:  535]:	loss/mlm_loss, 8.371624946594238, 785
[INFO] 2021-07-12 18:45:39,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.839999852876645e-06, 785
[INFO] 2021-07-12 18:45:39,628 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 785
[INFO] 2021-07-12 18:45:39,628 [run_pretraining.py:  558]:	worker_index: 7, step: 785, cost: 8.371625, mlm loss: 8.371625, speed: 0.937785 steps/s, speed: 7.502278 samples/s, speed: 3841.166164 tokens/s, learning rate: 7.840e-06, loss_scalings: 13421.773438, pp_loss: 8.403366
[INFO] 2021-07-12 18:45:39,629 [run_pretraining.py:  512]:	********exe.run_785******* 
[INFO] 2021-07-12 18:45:40,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:40,648 [run_pretraining.py:  534]:	loss/total_loss, 7.954625129699707, 786
[INFO] 2021-07-12 18:45:40,648 [run_pretraining.py:  535]:	loss/mlm_loss, 7.954625129699707, 786
[INFO] 2021-07-12 18:45:40,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.849999747122638e-06, 786
[INFO] 2021-07-12 18:45:40,648 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 786
[INFO] 2021-07-12 18:45:40,648 [run_pretraining.py:  558]:	worker_index: 7, step: 786, cost: 7.954625, mlm loss: 7.954625, speed: 0.981512 steps/s, speed: 7.852098 samples/s, speed: 4020.274032 tokens/s, learning rate: 7.850e-06, loss_scalings: 13421.773438, pp_loss: 8.310431
[INFO] 2021-07-12 18:45:40,648 [run_pretraining.py:  512]:	********exe.run_786******* 
[INFO] 2021-07-12 18:45:41,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:41,563 [run_pretraining.py:  534]:	loss/total_loss, 8.212098121643066, 787
[INFO] 2021-07-12 18:45:41,563 [run_pretraining.py:  535]:	loss/mlm_loss, 8.212098121643066, 787
[INFO] 2021-07-12 18:45:41,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.859999641368631e-06, 787
[INFO] 2021-07-12 18:45:41,563 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 787
[INFO] 2021-07-12 18:45:41,563 [run_pretraining.py:  558]:	worker_index: 7, step: 787, cost: 8.212098, mlm loss: 8.212098, speed: 1.093519 steps/s, speed: 8.748150 samples/s, speed: 4479.053016 tokens/s, learning rate: 7.860e-06, loss_scalings: 13421.773438, pp_loss: 7.814436
[INFO] 2021-07-12 18:45:41,563 [run_pretraining.py:  512]:	********exe.run_787******* 
[INFO] 2021-07-12 18:45:42,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:42,481 [run_pretraining.py:  534]:	loss/total_loss, 8.219890594482422, 788
[INFO] 2021-07-12 18:45:42,481 [run_pretraining.py:  535]:	loss/mlm_loss, 8.219890594482422, 788
[INFO] 2021-07-12 18:45:42,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.869999535614625e-06, 788
[INFO] 2021-07-12 18:45:42,481 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 788
[INFO] 2021-07-12 18:45:42,482 [run_pretraining.py:  558]:	worker_index: 7, step: 788, cost: 8.219891, mlm loss: 8.219891, speed: 1.089578 steps/s, speed: 8.716628 samples/s, speed: 4462.913422 tokens/s, learning rate: 7.870e-06, loss_scalings: 13421.773438, pp_loss: 8.190912
[INFO] 2021-07-12 18:45:42,482 [run_pretraining.py:  512]:	********exe.run_788******* 
[INFO] 2021-07-12 18:45:43,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:45:43,398 [run_pretraining.py:  534]:	loss/total_loss, 8.47634506225586, 789
[INFO] 2021-07-12 18:45:43,398 [run_pretraining.py:  535]:	loss/mlm_loss, 8.47634506225586, 789
[INFO] 2021-07-12 18:45:43,398 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.879999429860618e-06, 789
[INFO] 2021-07-12 18:45:43,398 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 789
[INFO] 2021-07-12 18:45:43,398 [run_pretraining.py:  558]:	worker_index: 7, step: 789, cost: 8.476345, mlm loss: 8.476345, speed: 1.091657 steps/s, speed: 8.733257 samples/s, speed: 4471.427720 tokens/s, learning rate: 7.880e-06, loss_scalings: 13421.773438, pp_loss: 8.263601
[INFO] 2021-07-12 18:45:43,398 [run_pretraining.py:  512]:	********exe.run_789******* 
[INFO] 2021-07-12 18:46:08,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:08,296 [run_pretraining.py:  534]:	loss/total_loss, 8.22861099243164, 790
[INFO] 2021-07-12 18:46:08,296 [run_pretraining.py:  535]:	loss/mlm_loss, 8.22861099243164, 790
[INFO] 2021-07-12 18:46:08,296 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.890000233601313e-06, 790
[INFO] 2021-07-12 18:46:08,296 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 790
[INFO] 2021-07-12 18:46:08,296 [run_pretraining.py:  558]:	worker_index: 7, step: 790, cost: 8.228611, mlm loss: 8.228611, speed: 0.040165 steps/s, speed: 0.321320 samples/s, speed: 164.515891 tokens/s, learning rate: 7.890e-06, loss_scalings: 13421.773438, pp_loss: 8.145264
[INFO] 2021-07-12 18:46:08,296 [run_pretraining.py:  512]:	********exe.run_790******* 
[INFO] 2021-07-12 18:46:09,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:09,213 [run_pretraining.py:  534]:	loss/total_loss, 8.253425598144531, 791
[INFO] 2021-07-12 18:46:09,213 [run_pretraining.py:  535]:	loss/mlm_loss, 8.253425598144531, 791
[INFO] 2021-07-12 18:46:09,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.900000127847306e-06, 791
[INFO] 2021-07-12 18:46:09,213 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 791
[INFO] 2021-07-12 18:46:09,213 [run_pretraining.py:  558]:	worker_index: 7, step: 791, cost: 8.253426, mlm loss: 8.253426, speed: 1.091237 steps/s, speed: 8.729892 samples/s, speed: 4469.704819 tokens/s, learning rate: 7.900e-06, loss_scalings: 13421.773438, pp_loss: 8.302786
[INFO] 2021-07-12 18:46:09,213 [run_pretraining.py:  512]:	********exe.run_791******* 
[INFO] 2021-07-12 18:46:10,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  534]:	loss/total_loss, 8.01427936553955, 792
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  535]:	loss/mlm_loss, 8.01427936553955, 792
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.9100000220933e-06, 792
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 792
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  558]:	worker_index: 7, step: 792, cost: 8.014279, mlm loss: 8.014279, speed: 1.078412 steps/s, speed: 8.627293 samples/s, speed: 4417.173934 tokens/s, learning rate: 7.910e-06, loss_scalings: 13421.773438, pp_loss: 8.115988
[INFO] 2021-07-12 18:46:10,141 [run_pretraining.py:  512]:	********exe.run_792******* 
[INFO] 2021-07-12 18:46:11,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:11,050 [run_pretraining.py:  534]:	loss/total_loss, 8.195441246032715, 793
[INFO] 2021-07-12 18:46:11,050 [run_pretraining.py:  535]:	loss/mlm_loss, 8.195441246032715, 793
[INFO] 2021-07-12 18:46:11,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.919999916339293e-06, 793
[INFO] 2021-07-12 18:46:11,050 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 793
[INFO] 2021-07-12 18:46:11,050 [run_pretraining.py:  558]:	worker_index: 7, step: 793, cost: 8.195441, mlm loss: 8.195441, speed: 1.101087 steps/s, speed: 8.808699 samples/s, speed: 4510.054028 tokens/s, learning rate: 7.920e-06, loss_scalings: 13421.773438, pp_loss: 8.257884
[INFO] 2021-07-12 18:46:11,050 [run_pretraining.py:  512]:	********exe.run_793******* 
[INFO] 2021-07-12 18:46:36,804 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:36,805 [run_pretraining.py:  534]:	loss/total_loss, 8.305191040039062, 794
[INFO] 2021-07-12 18:46:36,805 [run_pretraining.py:  535]:	loss/mlm_loss, 8.305191040039062, 794
[INFO] 2021-07-12 18:46:36,805 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.929999810585286e-06, 794
[INFO] 2021-07-12 18:46:36,805 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 794
[INFO] 2021-07-12 18:46:36,805 [run_pretraining.py:  558]:	worker_index: 7, step: 794, cost: 8.305191, mlm loss: 8.305191, speed: 0.038828 steps/s, speed: 0.310626 samples/s, speed: 159.040500 tokens/s, learning rate: 7.930e-06, loss_scalings: 13421.773438, pp_loss: 8.520265
[INFO] 2021-07-12 18:46:36,805 [run_pretraining.py:  512]:	********exe.run_794******* 
[INFO] 2021-07-12 18:46:37,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:37,720 [run_pretraining.py:  534]:	loss/total_loss, 8.298121452331543, 795
[INFO] 2021-07-12 18:46:37,720 [run_pretraining.py:  535]:	loss/mlm_loss, 8.298121452331543, 795
[INFO] 2021-07-12 18:46:37,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.93999970483128e-06, 795
[INFO] 2021-07-12 18:46:37,720 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 795
[INFO] 2021-07-12 18:46:37,720 [run_pretraining.py:  558]:	worker_index: 7, step: 795, cost: 8.298121, mlm loss: 8.298121, speed: 1.093652 steps/s, speed: 8.749218 samples/s, speed: 4479.599593 tokens/s, learning rate: 7.940e-06, loss_scalings: 13421.773438, pp_loss: 8.307275
[INFO] 2021-07-12 18:46:37,720 [run_pretraining.py:  512]:	********exe.run_795******* 
[INFO] 2021-07-12 18:46:38,664 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:38,665 [run_pretraining.py:  534]:	loss/total_loss, 7.802268028259277, 796
[INFO] 2021-07-12 18:46:38,665 [run_pretraining.py:  535]:	loss/mlm_loss, 7.802268028259277, 796
[INFO] 2021-07-12 18:46:38,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.949999599077273e-06, 796
[INFO] 2021-07-12 18:46:38,665 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 796
[INFO] 2021-07-12 18:46:38,665 [run_pretraining.py:  558]:	worker_index: 7, step: 796, cost: 7.802268, mlm loss: 7.802268, speed: 1.058942 steps/s, speed: 8.471534 samples/s, speed: 4337.425268 tokens/s, learning rate: 7.950e-06, loss_scalings: 13421.773438, pp_loss: 8.338636
[INFO] 2021-07-12 18:46:38,665 [run_pretraining.py:  512]:	********exe.run_796******* 
[INFO] 2021-07-12 18:46:39,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:39,751 [run_pretraining.py:  534]:	loss/total_loss, 8.52047061920166, 797
[INFO] 2021-07-12 18:46:39,751 [run_pretraining.py:  535]:	loss/mlm_loss, 8.52047061920166, 797
[INFO] 2021-07-12 18:46:39,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.959999493323267e-06, 797
[INFO] 2021-07-12 18:46:39,751 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 797
[INFO] 2021-07-12 18:46:39,751 [run_pretraining.py:  558]:	worker_index: 7, step: 797, cost: 8.520471, mlm loss: 8.520471, speed: 0.921203 steps/s, speed: 7.369626 samples/s, speed: 3773.248690 tokens/s, learning rate: 7.960e-06, loss_scalings: 13421.773438, pp_loss: 8.156118
[INFO] 2021-07-12 18:46:39,751 [run_pretraining.py:  512]:	********exe.run_797******* 
[INFO] 2021-07-12 18:46:40,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:40,809 [run_pretraining.py:  534]:	loss/total_loss, 8.278952598571777, 798
[INFO] 2021-07-12 18:46:40,809 [run_pretraining.py:  535]:	loss/mlm_loss, 8.278952598571777, 798
[INFO] 2021-07-12 18:46:40,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.970000297063962e-06, 798
[INFO] 2021-07-12 18:46:40,809 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 798
[INFO] 2021-07-12 18:46:40,809 [run_pretraining.py:  558]:	worker_index: 7, step: 798, cost: 8.278953, mlm loss: 8.278953, speed: 0.946150 steps/s, speed: 7.569200 samples/s, speed: 3875.430617 tokens/s, learning rate: 7.970e-06, loss_scalings: 13421.773438, pp_loss: 8.259241
[INFO] 2021-07-12 18:46:40,809 [run_pretraining.py:  512]:	********exe.run_798******* 
[INFO] 2021-07-12 18:46:41,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:41,879 [run_pretraining.py:  534]:	loss/total_loss, 8.696722030639648, 799
[INFO] 2021-07-12 18:46:41,879 [run_pretraining.py:  535]:	loss/mlm_loss, 8.696722030639648, 799
[INFO] 2021-07-12 18:46:41,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.980000191309955e-06, 799
[INFO] 2021-07-12 18:46:41,879 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 799
[INFO] 2021-07-12 18:46:41,879 [run_pretraining.py:  558]:	worker_index: 7, step: 799, cost: 8.696722, mlm loss: 8.696722, speed: 0.934765 steps/s, speed: 7.478121 samples/s, speed: 3828.797767 tokens/s, learning rate: 7.980e-06, loss_scalings: 13421.773438, pp_loss: 8.431503
[INFO] 2021-07-12 18:46:41,879 [run_pretraining.py:  512]:	********exe.run_799******* 
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  534]:	loss/total_loss, 8.218585014343262, 800
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  535]:	loss/mlm_loss, 8.218585014343262, 800
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.989999176061247e-06, 800
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 800
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  558]:	worker_index: 7, step: 800, cost: 8.218585, mlm loss: 8.218585, speed: 1.072550 steps/s, speed: 8.580399 samples/s, speed: 4393.164405 tokens/s, learning rate: 7.990e-06, loss_scalings: 13421.773438, pp_loss: 8.259798
[INFO] 2021-07-12 18:46:42,812 [run_pretraining.py:  512]:	********exe.run_800******* 
[INFO] 2021-07-12 18:46:43,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:43,725 [run_pretraining.py:  534]:	loss/total_loss, 8.279420852661133, 801
[INFO] 2021-07-12 18:46:43,726 [run_pretraining.py:  535]:	loss/mlm_loss, 8.279420852661133, 801
[INFO] 2021-07-12 18:46:43,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 7.999999979801942e-06, 801
[INFO] 2021-07-12 18:46:43,726 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 801
[INFO] 2021-07-12 18:46:43,726 [run_pretraining.py:  558]:	worker_index: 7, step: 801, cost: 8.279421, mlm loss: 8.279421, speed: 1.095649 steps/s, speed: 8.765189 samples/s, speed: 4487.776771 tokens/s, learning rate: 8.000e-06, loss_scalings: 13421.773438, pp_loss: 8.352123
[INFO] 2021-07-12 18:46:43,726 [run_pretraining.py:  512]:	********exe.run_801******* 
[INFO] 2021-07-12 18:46:44,649 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:44,649 [run_pretraining.py:  534]:	loss/total_loss, 8.374996185302734, 802
[INFO] 2021-07-12 18:46:44,649 [run_pretraining.py:  535]:	loss/mlm_loss, 8.374996185302734, 802
[INFO] 2021-07-12 18:46:44,650 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.009999874047935e-06, 802
[INFO] 2021-07-12 18:46:44,650 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 802
[INFO] 2021-07-12 18:46:44,650 [run_pretraining.py:  558]:	worker_index: 7, step: 802, cost: 8.374996, mlm loss: 8.374996, speed: 1.083057 steps/s, speed: 8.664456 samples/s, speed: 4436.201535 tokens/s, learning rate: 8.010e-06, loss_scalings: 13421.773438, pp_loss: 8.241563
[INFO] 2021-07-12 18:46:44,650 [run_pretraining.py:  512]:	********exe.run_802******* 
[INFO] 2021-07-12 18:46:45,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:45,573 [run_pretraining.py:  534]:	loss/total_loss, 8.724621772766113, 803
[INFO] 2021-07-12 18:46:45,573 [run_pretraining.py:  535]:	loss/mlm_loss, 8.724621772766113, 803
[INFO] 2021-07-12 18:46:45,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.019999768293928e-06, 803
[INFO] 2021-07-12 18:46:45,573 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 803
[INFO] 2021-07-12 18:46:45,573 [run_pretraining.py:  558]:	worker_index: 7, step: 803, cost: 8.724622, mlm loss: 8.724622, speed: 1.083750 steps/s, speed: 8.669997 samples/s, speed: 4439.038510 tokens/s, learning rate: 8.020e-06, loss_scalings: 13421.773438, pp_loss: 8.309652
[INFO] 2021-07-12 18:46:45,573 [run_pretraining.py:  512]:	********exe.run_803******* 
[INFO] 2021-07-12 18:46:46,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:46,498 [run_pretraining.py:  534]:	loss/total_loss, 8.443024635314941, 804
[INFO] 2021-07-12 18:46:46,498 [run_pretraining.py:  535]:	loss/mlm_loss, 8.443024635314941, 804
[INFO] 2021-07-12 18:46:46,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.030000572034623e-06, 804
[INFO] 2021-07-12 18:46:46,498 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 804
[INFO] 2021-07-12 18:46:46,498 [run_pretraining.py:  558]:	worker_index: 7, step: 804, cost: 8.443025, mlm loss: 8.443025, speed: 1.081591 steps/s, speed: 8.652728 samples/s, speed: 4430.196839 tokens/s, learning rate: 8.030e-06, loss_scalings: 13421.773438, pp_loss: 8.413510
[INFO] 2021-07-12 18:46:46,498 [run_pretraining.py:  512]:	********exe.run_804******* 
[INFO] 2021-07-12 18:46:47,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:47,411 [run_pretraining.py:  534]:	loss/total_loss, 8.525506019592285, 805
[INFO] 2021-07-12 18:46:47,411 [run_pretraining.py:  535]:	loss/mlm_loss, 8.525506019592285, 805
[INFO] 2021-07-12 18:46:47,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.039999556785915e-06, 805
[INFO] 2021-07-12 18:46:47,411 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 805
[INFO] 2021-07-12 18:46:47,411 [run_pretraining.py:  558]:	worker_index: 7, step: 805, cost: 8.525506, mlm loss: 8.525506, speed: 1.095996 steps/s, speed: 8.767965 samples/s, speed: 4489.198062 tokens/s, learning rate: 8.040e-06, loss_scalings: 13421.773438, pp_loss: 8.502609
[INFO] 2021-07-12 18:46:47,411 [run_pretraining.py:  512]:	********exe.run_805******* 
[INFO] 2021-07-12 18:46:48,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:48,401 [run_pretraining.py:  534]:	loss/total_loss, 8.13325023651123, 806
[INFO] 2021-07-12 18:46:48,401 [run_pretraining.py:  535]:	loss/mlm_loss, 8.13325023651123, 806
[INFO] 2021-07-12 18:46:48,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.049999451031908e-06, 806
[INFO] 2021-07-12 18:46:48,401 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 806
[INFO] 2021-07-12 18:46:48,401 [run_pretraining.py:  558]:	worker_index: 7, step: 806, cost: 8.133250, mlm loss: 8.133250, speed: 1.011029 steps/s, speed: 8.088229 samples/s, speed: 4141.173432 tokens/s, learning rate: 8.050e-06, loss_scalings: 13421.773438, pp_loss: 8.361669
[INFO] 2021-07-12 18:46:48,401 [run_pretraining.py:  512]:	********exe.run_806******* 
[INFO] 2021-07-12 18:46:49,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:49,460 [run_pretraining.py:  534]:	loss/total_loss, 8.319067001342773, 807
[INFO] 2021-07-12 18:46:49,460 [run_pretraining.py:  535]:	loss/mlm_loss, 8.319067001342773, 807
[INFO] 2021-07-12 18:46:49,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.060000254772604e-06, 807
[INFO] 2021-07-12 18:46:49,461 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 807
[INFO] 2021-07-12 18:46:49,461 [run_pretraining.py:  558]:	worker_index: 7, step: 807, cost: 8.319067, mlm loss: 8.319067, speed: 0.944382 steps/s, speed: 7.555057 samples/s, speed: 3868.189033 tokens/s, learning rate: 8.060e-06, loss_scalings: 13421.773438, pp_loss: 8.634228
[INFO] 2021-07-12 18:46:49,461 [run_pretraining.py:  512]:	********exe.run_807******* 
[INFO] 2021-07-12 18:46:50,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:46:50,527 [run_pretraining.py:  534]:	loss/total_loss, 8.818792343139648, 808
[INFO] 2021-07-12 18:46:50,527 [run_pretraining.py:  535]:	loss/mlm_loss, 8.818792343139648, 808
[INFO] 2021-07-12 18:46:50,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.070000149018597e-06, 808
[INFO] 2021-07-12 18:46:50,528 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 808
[INFO] 2021-07-12 18:46:50,528 [run_pretraining.py:  558]:	worker_index: 7, step: 808, cost: 8.818792, mlm loss: 8.818792, speed: 0.937800 steps/s, speed: 7.502398 samples/s, speed: 3841.228000 tokens/s, learning rate: 8.070e-06, loss_scalings: 13421.773438, pp_loss: 8.547625
[INFO] 2021-07-12 18:46:50,528 [run_pretraining.py:  512]:	********exe.run_808******* 
[INFO] 2021-07-12 18:47:16,745 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:16,745 [run_pretraining.py:  534]:	loss/total_loss, 8.56617546081543, 809
[INFO] 2021-07-12 18:47:16,745 [run_pretraining.py:  535]:	loss/mlm_loss, 8.56617546081543, 809
[INFO] 2021-07-12 18:47:16,745 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.079999133769888e-06, 809
[INFO] 2021-07-12 18:47:16,745 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 809
[INFO] 2021-07-12 18:47:16,745 [run_pretraining.py:  558]:	worker_index: 7, step: 809, cost: 8.566175, mlm loss: 8.566175, speed: 0.038143 steps/s, speed: 0.305144 samples/s, speed: 156.233586 tokens/s, learning rate: 8.080e-06, loss_scalings: 13421.773438, pp_loss: 8.408440
[INFO] 2021-07-12 18:47:16,746 [run_pretraining.py:  512]:	********exe.run_809******* 
[INFO] 2021-07-12 18:47:17,839 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:17,839 [run_pretraining.py:  534]:	loss/total_loss, 7.800369739532471, 810
[INFO] 2021-07-12 18:47:17,839 [run_pretraining.py:  535]:	loss/mlm_loss, 7.800369739532471, 810
[INFO] 2021-07-12 18:47:17,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.089999937510584e-06, 810
[INFO] 2021-07-12 18:47:17,839 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 810
[INFO] 2021-07-12 18:47:17,840 [run_pretraining.py:  558]:	worker_index: 7, step: 810, cost: 7.800370, mlm loss: 7.800370, speed: 0.914610 steps/s, speed: 7.316881 samples/s, speed: 3746.242920 tokens/s, learning rate: 8.090e-06, loss_scalings: 13421.773438, pp_loss: 8.114877
[INFO] 2021-07-12 18:47:17,840 [run_pretraining.py:  512]:	********exe.run_810******* 
[INFO] 2021-07-12 18:47:18,753 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:18,753 [run_pretraining.py:  534]:	loss/total_loss, 8.766338348388672, 811
[INFO] 2021-07-12 18:47:18,753 [run_pretraining.py:  535]:	loss/mlm_loss, 8.766338348388672, 811
[INFO] 2021-07-12 18:47:18,754 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.099999831756577e-06, 811
[INFO] 2021-07-12 18:47:18,754 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 811
[INFO] 2021-07-12 18:47:18,754 [run_pretraining.py:  558]:	worker_index: 7, step: 811, cost: 8.766338, mlm loss: 8.766338, speed: 1.094604 steps/s, speed: 8.756828 samples/s, speed: 4483.496064 tokens/s, learning rate: 8.100e-06, loss_scalings: 13421.773438, pp_loss: 8.739008
[INFO] 2021-07-12 18:47:18,754 [run_pretraining.py:  512]:	********exe.run_811******* 
[INFO] 2021-07-12 18:47:19,674 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:19,675 [run_pretraining.py:  534]:	loss/total_loss, 7.9519805908203125, 812
[INFO] 2021-07-12 18:47:19,675 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9519805908203125, 812
[INFO] 2021-07-12 18:47:19,675 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.10999972600257e-06, 812
[INFO] 2021-07-12 18:47:19,675 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 812
[INFO] 2021-07-12 18:47:19,675 [run_pretraining.py:  558]:	worker_index: 7, step: 812, cost: 7.951981, mlm loss: 7.951981, speed: 1.086357 steps/s, speed: 8.690854 samples/s, speed: 4449.717341 tokens/s, learning rate: 8.110e-06, loss_scalings: 13421.773438, pp_loss: 8.485992
[INFO] 2021-07-12 18:47:19,675 [run_pretraining.py:  512]:	********exe.run_812******* 
[INFO] 2021-07-12 18:47:20,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:20,606 [run_pretraining.py:  534]:	loss/total_loss, 8.615588188171387, 813
[INFO] 2021-07-12 18:47:20,606 [run_pretraining.py:  535]:	loss/mlm_loss, 8.615588188171387, 813
[INFO] 2021-07-12 18:47:20,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.120000529743265e-06, 813
[INFO] 2021-07-12 18:47:20,606 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 813
[INFO] 2021-07-12 18:47:20,606 [run_pretraining.py:  558]:	worker_index: 7, step: 813, cost: 8.615588, mlm loss: 8.615588, speed: 1.074744 steps/s, speed: 8.597955 samples/s, speed: 4402.153121 tokens/s, learning rate: 8.120e-06, loss_scalings: 13421.773438, pp_loss: 8.427341
[INFO] 2021-07-12 18:47:20,606 [run_pretraining.py:  512]:	********exe.run_813******* 
[INFO] 2021-07-12 18:47:21,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:21,524 [run_pretraining.py:  534]:	loss/total_loss, 7.894819736480713, 814
[INFO] 2021-07-12 18:47:21,524 [run_pretraining.py:  535]:	loss/mlm_loss, 7.894819736480713, 814
[INFO] 2021-07-12 18:47:21,524 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.129999514494557e-06, 814
[INFO] 2021-07-12 18:47:21,524 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 814
[INFO] 2021-07-12 18:47:21,524 [run_pretraining.py:  558]:	worker_index: 7, step: 814, cost: 7.894820, mlm loss: 7.894820, speed: 1.090287 steps/s, speed: 8.722297 samples/s, speed: 4465.816019 tokens/s, learning rate: 8.130e-06, loss_scalings: 13421.773438, pp_loss: 7.282820
[INFO] 2021-07-12 18:47:21,524 [run_pretraining.py:  512]:	********exe.run_814******* 
[INFO] 2021-07-12 18:47:22,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:22,451 [run_pretraining.py:  534]:	loss/total_loss, 8.281436920166016, 815
[INFO] 2021-07-12 18:47:22,452 [run_pretraining.py:  535]:	loss/mlm_loss, 8.281436920166016, 815
[INFO] 2021-07-12 18:47:22,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.13999940874055e-06, 815
[INFO] 2021-07-12 18:47:22,452 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 815
[INFO] 2021-07-12 18:47:22,452 [run_pretraining.py:  558]:	worker_index: 7, step: 815, cost: 8.281437, mlm loss: 8.281437, speed: 1.078518 steps/s, speed: 8.628147 samples/s, speed: 4417.611228 tokens/s, learning rate: 8.140e-06, loss_scalings: 13421.773438, pp_loss: 8.490702
[INFO] 2021-07-12 18:47:22,452 [run_pretraining.py:  512]:	********exe.run_815******* 
[INFO] 2021-07-12 18:47:23,395 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:23,395 [run_pretraining.py:  534]:	loss/total_loss, 8.549442291259766, 816
[INFO] 2021-07-12 18:47:23,395 [run_pretraining.py:  535]:	loss/mlm_loss, 8.549442291259766, 816
[INFO] 2021-07-12 18:47:23,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.150000212481245e-06, 816
[INFO] 2021-07-12 18:47:23,396 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 816
[INFO] 2021-07-12 18:47:23,396 [run_pretraining.py:  558]:	worker_index: 7, step: 816, cost: 8.549442, mlm loss: 8.549442, speed: 1.060291 steps/s, speed: 8.482329 samples/s, speed: 4342.952579 tokens/s, learning rate: 8.150e-06, loss_scalings: 13421.773438, pp_loss: 7.697483
[INFO] 2021-07-12 18:47:23,396 [run_pretraining.py:  512]:	********exe.run_816******* 
[INFO] 2021-07-12 18:47:24,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:24,314 [run_pretraining.py:  534]:	loss/total_loss, 8.558541297912598, 817
[INFO] 2021-07-12 18:47:24,314 [run_pretraining.py:  535]:	loss/mlm_loss, 8.558541297912598, 817
[INFO] 2021-07-12 18:47:24,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.160000106727239e-06, 817
[INFO] 2021-07-12 18:47:24,314 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 817
[INFO] 2021-07-12 18:47:24,314 [run_pretraining.py:  558]:	worker_index: 7, step: 817, cost: 8.558541, mlm loss: 8.558541, speed: 1.089319 steps/s, speed: 8.714554 samples/s, speed: 4461.851704 tokens/s, learning rate: 8.160e-06, loss_scalings: 13421.773438, pp_loss: 8.254785
[INFO] 2021-07-12 18:47:24,314 [run_pretraining.py:  512]:	********exe.run_817******* 
[INFO] 2021-07-12 18:47:25,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:25,235 [run_pretraining.py:  534]:	loss/total_loss, 8.400055885314941, 818
[INFO] 2021-07-12 18:47:25,235 [run_pretraining.py:  535]:	loss/mlm_loss, 8.400055885314941, 818
[INFO] 2021-07-12 18:47:25,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.16999909147853e-06, 818
[INFO] 2021-07-12 18:47:25,236 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 818
[INFO] 2021-07-12 18:47:25,236 [run_pretraining.py:  558]:	worker_index: 7, step: 818, cost: 8.400056, mlm loss: 8.400056, speed: 1.086138 steps/s, speed: 8.689103 samples/s, speed: 4448.820868 tokens/s, learning rate: 8.170e-06, loss_scalings: 13421.773438, pp_loss: 8.267249
[INFO] 2021-07-12 18:47:25,236 [run_pretraining.py:  512]:	********exe.run_818******* 
[INFO] 2021-07-12 18:47:26,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:26,154 [run_pretraining.py:  534]:	loss/total_loss, 8.146940231323242, 819
[INFO] 2021-07-12 18:47:26,154 [run_pretraining.py:  535]:	loss/mlm_loss, 8.146940231323242, 819
[INFO] 2021-07-12 18:47:26,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.179999895219225e-06, 819
[INFO] 2021-07-12 18:47:26,154 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 819
[INFO] 2021-07-12 18:47:26,154 [run_pretraining.py:  558]:	worker_index: 7, step: 819, cost: 8.146940, mlm loss: 8.146940, speed: 1.089697 steps/s, speed: 8.717574 samples/s, speed: 4463.398086 tokens/s, learning rate: 8.180e-06, loss_scalings: 13421.773438, pp_loss: 8.325801
[INFO] 2021-07-12 18:47:26,154 [run_pretraining.py:  512]:	********exe.run_819******* 
[INFO] 2021-07-12 18:47:27,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:27,065 [run_pretraining.py:  534]:	loss/total_loss, 8.37012767791748, 820
[INFO] 2021-07-12 18:47:27,065 [run_pretraining.py:  535]:	loss/mlm_loss, 8.37012767791748, 820
[INFO] 2021-07-12 18:47:27,065 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.189999789465219e-06, 820
[INFO] 2021-07-12 18:47:27,065 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 820
[INFO] 2021-07-12 18:47:27,065 [run_pretraining.py:  558]:	worker_index: 7, step: 820, cost: 8.370128, mlm loss: 8.370128, speed: 1.097771 steps/s, speed: 8.782168 samples/s, speed: 4496.469848 tokens/s, learning rate: 8.190e-06, loss_scalings: 13421.773438, pp_loss: 8.490090
[INFO] 2021-07-12 18:47:27,066 [run_pretraining.py:  512]:	********exe.run_820******* 
[INFO] 2021-07-12 18:47:28,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:28,022 [run_pretraining.py:  534]:	loss/total_loss, 8.270294189453125, 821
[INFO] 2021-07-12 18:47:28,022 [run_pretraining.py:  535]:	loss/mlm_loss, 8.270294189453125, 821
[INFO] 2021-07-12 18:47:28,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.199999683711212e-06, 821
[INFO] 2021-07-12 18:47:28,022 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 821
[INFO] 2021-07-12 18:47:28,022 [run_pretraining.py:  558]:	worker_index: 7, step: 821, cost: 8.270294, mlm loss: 8.270294, speed: 1.046236 steps/s, speed: 8.369885 samples/s, speed: 4285.380899 tokens/s, learning rate: 8.200e-06, loss_scalings: 13421.773438, pp_loss: 8.364406
[INFO] 2021-07-12 18:47:28,022 [run_pretraining.py:  512]:	********exe.run_821******* 
[INFO] 2021-07-12 18:47:29,031 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:29,032 [run_pretraining.py:  534]:	loss/total_loss, 8.694989204406738, 822
[INFO] 2021-07-12 18:47:29,032 [run_pretraining.py:  535]:	loss/mlm_loss, 8.694989204406738, 822
[INFO] 2021-07-12 18:47:29,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.209999577957205e-06, 822
[INFO] 2021-07-12 18:47:29,032 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 822
[INFO] 2021-07-12 18:47:29,032 [run_pretraining.py:  558]:	worker_index: 7, step: 822, cost: 8.694989, mlm loss: 8.694989, speed: 0.990707 steps/s, speed: 7.925657 samples/s, speed: 4057.936144 tokens/s, learning rate: 8.210e-06, loss_scalings: 13421.773438, pp_loss: 8.383861
[INFO] 2021-07-12 18:47:29,032 [run_pretraining.py:  512]:	********exe.run_822******* 
[INFO] 2021-07-12 18:47:30,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:30,102 [run_pretraining.py:  534]:	loss/total_loss, 8.067209243774414, 823
[INFO] 2021-07-12 18:47:30,102 [run_pretraining.py:  535]:	loss/mlm_loss, 8.067209243774414, 823
[INFO] 2021-07-12 18:47:30,102 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.219999472203199e-06, 823
[INFO] 2021-07-12 18:47:30,102 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 823
[INFO] 2021-07-12 18:47:30,102 [run_pretraining.py:  558]:	worker_index: 7, step: 823, cost: 8.067209, mlm loss: 8.067209, speed: 0.934739 steps/s, speed: 7.477916 samples/s, speed: 3828.692813 tokens/s, learning rate: 8.220e-06, loss_scalings: 13421.773438, pp_loss: 7.971473
[INFO] 2021-07-12 18:47:30,103 [run_pretraining.py:  512]:	********exe.run_823******* 
[INFO] 2021-07-12 18:47:31,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:31,140 [run_pretraining.py:  534]:	loss/total_loss, 8.358072280883789, 824
[INFO] 2021-07-12 18:47:31,140 [run_pretraining.py:  535]:	loss/mlm_loss, 8.358072280883789, 824
[INFO] 2021-07-12 18:47:31,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.229999366449192e-06, 824
[INFO] 2021-07-12 18:47:31,140 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 824
[INFO] 2021-07-12 18:47:31,140 [run_pretraining.py:  558]:	worker_index: 7, step: 824, cost: 8.358072, mlm loss: 8.358072, speed: 0.964565 steps/s, speed: 7.716517 samples/s, speed: 3950.856578 tokens/s, learning rate: 8.230e-06, loss_scalings: 13421.773438, pp_loss: 8.468729
[INFO] 2021-07-12 18:47:31,140 [run_pretraining.py:  512]:	********exe.run_824******* 
[INFO] 2021-07-12 18:47:32,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:32,207 [run_pretraining.py:  534]:	loss/total_loss, 8.774760246276855, 825
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  535]:	loss/mlm_loss, 8.774760246276855, 825
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.240000170189887e-06, 825
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 825
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  558]:	worker_index: 7, step: 825, cost: 8.774760, mlm loss: 8.774760, speed: 0.936987 steps/s, speed: 7.495899 samples/s, speed: 3837.900242 tokens/s, learning rate: 8.240e-06, loss_scalings: 13421.773438, pp_loss: 8.441878
[INFO] 2021-07-12 18:47:32,208 [run_pretraining.py:  512]:	********exe.run_825******* 
[INFO] 2021-07-12 18:47:33,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:33,272 [run_pretraining.py:  534]:	loss/total_loss, 8.207173347473145, 826
[INFO] 2021-07-12 18:47:33,272 [run_pretraining.py:  535]:	loss/mlm_loss, 8.207173347473145, 826
[INFO] 2021-07-12 18:47:33,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.25000006443588e-06, 826
[INFO] 2021-07-12 18:47:33,272 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 826
[INFO] 2021-07-12 18:47:33,273 [run_pretraining.py:  558]:	worker_index: 7, step: 826, cost: 8.207173, mlm loss: 8.207173, speed: 0.939775 steps/s, speed: 7.518201 samples/s, speed: 3849.319112 tokens/s, learning rate: 8.250e-06, loss_scalings: 13421.773438, pp_loss: 8.434904
[INFO] 2021-07-12 18:47:33,273 [run_pretraining.py:  512]:	********exe.run_826******* 
[INFO] 2021-07-12 18:47:34,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:34,344 [run_pretraining.py:  534]:	loss/total_loss, 8.116592407226562, 827
[INFO] 2021-07-12 18:47:34,344 [run_pretraining.py:  535]:	loss/mlm_loss, 8.116592407226562, 827
[INFO] 2021-07-12 18:47:34,344 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.259999958681874e-06, 827
[INFO] 2021-07-12 18:47:34,344 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 827
[INFO] 2021-07-12 18:47:34,344 [run_pretraining.py:  558]:	worker_index: 7, step: 827, cost: 8.116592, mlm loss: 8.116592, speed: 0.933606 steps/s, speed: 7.468849 samples/s, speed: 3824.050743 tokens/s, learning rate: 8.260e-06, loss_scalings: 13421.773438, pp_loss: 8.286203
[INFO] 2021-07-12 18:47:34,344 [run_pretraining.py:  512]:	********exe.run_827******* 
[INFO] 2021-07-12 18:47:35,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:35,409 [run_pretraining.py:  534]:	loss/total_loss, 8.23816204071045, 828
[INFO] 2021-07-12 18:47:35,409 [run_pretraining.py:  535]:	loss/mlm_loss, 8.23816204071045, 828
[INFO] 2021-07-12 18:47:35,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.269999852927867e-06, 828
[INFO] 2021-07-12 18:47:35,409 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 828
[INFO] 2021-07-12 18:47:35,409 [run_pretraining.py:  558]:	worker_index: 7, step: 828, cost: 8.238162, mlm loss: 8.238162, speed: 0.939436 steps/s, speed: 7.515492 samples/s, speed: 3847.931885 tokens/s, learning rate: 8.270e-06, loss_scalings: 13421.773438, pp_loss: 7.878147
[INFO] 2021-07-12 18:47:35,409 [run_pretraining.py:  512]:	********exe.run_828******* 
[INFO] 2021-07-12 18:47:36,477 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:36,477 [run_pretraining.py:  534]:	loss/total_loss, 8.684009552001953, 829
[INFO] 2021-07-12 18:47:36,477 [run_pretraining.py:  535]:	loss/mlm_loss, 8.684009552001953, 829
[INFO] 2021-07-12 18:47:36,477 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.27999974717386e-06, 829
[INFO] 2021-07-12 18:47:36,477 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 829
[INFO] 2021-07-12 18:47:36,477 [run_pretraining.py:  558]:	worker_index: 7, step: 829, cost: 8.684010, mlm loss: 8.684010, speed: 0.936861 steps/s, speed: 7.494886 samples/s, speed: 3837.381605 tokens/s, learning rate: 8.280e-06, loss_scalings: 13421.773438, pp_loss: 7.574406
[INFO] 2021-07-12 18:47:36,478 [run_pretraining.py:  512]:	********exe.run_829******* 
[INFO] 2021-07-12 18:47:37,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:37,545 [run_pretraining.py:  534]:	loss/total_loss, 8.267955780029297, 830
[INFO] 2021-07-12 18:47:37,546 [run_pretraining.py:  535]:	loss/mlm_loss, 8.267955780029297, 830
[INFO] 2021-07-12 18:47:37,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.289999641419854e-06, 830
[INFO] 2021-07-12 18:47:37,546 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 830
[INFO] 2021-07-12 18:47:37,546 [run_pretraining.py:  558]:	worker_index: 7, step: 830, cost: 8.267956, mlm loss: 8.267956, speed: 0.936555 steps/s, speed: 7.492438 samples/s, speed: 3836.128023 tokens/s, learning rate: 8.290e-06, loss_scalings: 13421.773438, pp_loss: 8.201538
[INFO] 2021-07-12 18:47:37,546 [run_pretraining.py:  512]:	********exe.run_830******* 
[INFO] 2021-07-12 18:47:38,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:38,614 [run_pretraining.py:  534]:	loss/total_loss, 7.976994514465332, 831
[INFO] 2021-07-12 18:47:38,614 [run_pretraining.py:  535]:	loss/mlm_loss, 7.976994514465332, 831
[INFO] 2021-07-12 18:47:38,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.299999535665847e-06, 831
[INFO] 2021-07-12 18:47:38,615 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 831
[INFO] 2021-07-12 18:47:38,615 [run_pretraining.py:  558]:	worker_index: 7, step: 831, cost: 7.976995, mlm loss: 7.976995, speed: 0.936139 steps/s, speed: 7.489115 samples/s, speed: 3834.426760 tokens/s, learning rate: 8.300e-06, loss_scalings: 13421.773438, pp_loss: 7.901891
[INFO] 2021-07-12 18:47:38,615 [run_pretraining.py:  512]:	********exe.run_831******* 
[INFO] 2021-07-12 18:47:39,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:39,676 [run_pretraining.py:  534]:	loss/total_loss, 8.614745140075684, 832
[INFO] 2021-07-12 18:47:39,677 [run_pretraining.py:  535]:	loss/mlm_loss, 8.614745140075684, 832
[INFO] 2021-07-12 18:47:39,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.30999942991184e-06, 832
[INFO] 2021-07-12 18:47:39,677 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 832
[INFO] 2021-07-12 18:47:39,677 [run_pretraining.py:  558]:	worker_index: 7, step: 832, cost: 8.614745, mlm loss: 8.614745, speed: 0.942157 steps/s, speed: 7.537253 samples/s, speed: 3859.073380 tokens/s, learning rate: 8.310e-06, loss_scalings: 13421.773438, pp_loss: 8.268613
[INFO] 2021-07-12 18:47:39,677 [run_pretraining.py:  512]:	********exe.run_832******* 
[INFO] 2021-07-12 18:47:40,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:40,742 [run_pretraining.py:  534]:	loss/total_loss, 8.509026527404785, 833
[INFO] 2021-07-12 18:47:40,742 [run_pretraining.py:  535]:	loss/mlm_loss, 8.509026527404785, 833
[INFO] 2021-07-12 18:47:40,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.320000233652536e-06, 833
[INFO] 2021-07-12 18:47:40,743 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 833
[INFO] 2021-07-12 18:47:40,743 [run_pretraining.py:  558]:	worker_index: 7, step: 833, cost: 8.509027, mlm loss: 8.509027, speed: 0.938777 steps/s, speed: 7.510215 samples/s, speed: 3845.230140 tokens/s, learning rate: 8.320e-06, loss_scalings: 13421.773438, pp_loss: 8.427282
[INFO] 2021-07-12 18:47:40,743 [run_pretraining.py:  512]:	********exe.run_833******* 
[INFO] 2021-07-12 18:47:41,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:41,737 [run_pretraining.py:  534]:	loss/total_loss, 7.83083963394165, 834
[INFO] 2021-07-12 18:47:41,737 [run_pretraining.py:  535]:	loss/mlm_loss, 7.83083963394165, 834
[INFO] 2021-07-12 18:47:41,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.33000012789853e-06, 834
[INFO] 2021-07-12 18:47:41,738 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 834
[INFO] 2021-07-12 18:47:41,738 [run_pretraining.py:  558]:	worker_index: 7, step: 834, cost: 7.830840, mlm loss: 7.830840, speed: 1.005674 steps/s, speed: 8.045390 samples/s, speed: 4119.239509 tokens/s, learning rate: 8.330e-06, loss_scalings: 13421.773438, pp_loss: 8.209294
[INFO] 2021-07-12 18:47:41,738 [run_pretraining.py:  512]:	********exe.run_834******* 
[INFO] 2021-07-12 18:47:42,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:42,654 [run_pretraining.py:  534]:	loss/total_loss, 7.898710250854492, 835
[INFO] 2021-07-12 18:47:42,654 [run_pretraining.py:  535]:	loss/mlm_loss, 7.898710250854492, 835
[INFO] 2021-07-12 18:47:42,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.340000022144523e-06, 835
[INFO] 2021-07-12 18:47:42,654 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 835
[INFO] 2021-07-12 18:47:42,655 [run_pretraining.py:  558]:	worker_index: 7, step: 835, cost: 7.898710, mlm loss: 7.898710, speed: 1.091350 steps/s, speed: 8.730796 samples/s, speed: 4470.167696 tokens/s, learning rate: 8.340e-06, loss_scalings: 13421.773438, pp_loss: 8.070635
[INFO] 2021-07-12 18:47:42,655 [run_pretraining.py:  512]:	********exe.run_835******* 
[INFO] 2021-07-12 18:47:43,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:43,572 [run_pretraining.py:  534]:	loss/total_loss, 8.380692481994629, 836
[INFO] 2021-07-12 18:47:43,572 [run_pretraining.py:  535]:	loss/mlm_loss, 8.380692481994629, 836
[INFO] 2021-07-12 18:47:43,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.349999916390516e-06, 836
[INFO] 2021-07-12 18:47:43,572 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 836
[INFO] 2021-07-12 18:47:43,572 [run_pretraining.py:  558]:	worker_index: 7, step: 836, cost: 8.380692, mlm loss: 8.380692, speed: 1.090264 steps/s, speed: 8.722111 samples/s, speed: 4465.720831 tokens/s, learning rate: 8.350e-06, loss_scalings: 13421.773438, pp_loss: 8.293974
[INFO] 2021-07-12 18:47:43,572 [run_pretraining.py:  512]:	********exe.run_836******* 
[INFO] 2021-07-12 18:47:44,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:44,493 [run_pretraining.py:  534]:	loss/total_loss, 8.626565933227539, 837
[INFO] 2021-07-12 18:47:44,493 [run_pretraining.py:  535]:	loss/mlm_loss, 8.626565933227539, 837
[INFO] 2021-07-12 18:47:44,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.35999981063651e-06, 837
[INFO] 2021-07-12 18:47:44,493 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 837
[INFO] 2021-07-12 18:47:44,493 [run_pretraining.py:  558]:	worker_index: 7, step: 837, cost: 8.626566, mlm loss: 8.626566, speed: 1.087021 steps/s, speed: 8.696165 samples/s, speed: 4452.436622 tokens/s, learning rate: 8.360e-06, loss_scalings: 13421.773438, pp_loss: 8.488033
[INFO] 2021-07-12 18:47:44,493 [run_pretraining.py:  512]:	********exe.run_837******* 
[INFO] 2021-07-12 18:47:45,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:45,408 [run_pretraining.py:  534]:	loss/total_loss, 8.137393951416016, 838
[INFO] 2021-07-12 18:47:45,408 [run_pretraining.py:  535]:	loss/mlm_loss, 8.137393951416016, 838
[INFO] 2021-07-12 18:47:45,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.369999704882503e-06, 838
[INFO] 2021-07-12 18:47:45,409 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 838
[INFO] 2021-07-12 18:47:45,409 [run_pretraining.py:  558]:	worker_index: 7, step: 838, cost: 8.137394, mlm loss: 8.137394, speed: 1.092938 steps/s, speed: 8.743505 samples/s, speed: 4476.674390 tokens/s, learning rate: 8.370e-06, loss_scalings: 13421.773438, pp_loss: 8.165924
[INFO] 2021-07-12 18:47:45,409 [run_pretraining.py:  512]:	********exe.run_838******* 
[INFO] 2021-07-12 18:47:46,324 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:46,325 [run_pretraining.py:  534]:	loss/total_loss, 8.503874778747559, 839
[INFO] 2021-07-12 18:47:46,325 [run_pretraining.py:  535]:	loss/mlm_loss, 8.503874778747559, 839
[INFO] 2021-07-12 18:47:46,325 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.380000508623198e-06, 839
[INFO] 2021-07-12 18:47:46,325 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 839
[INFO] 2021-07-12 18:47:46,325 [run_pretraining.py:  558]:	worker_index: 7, step: 839, cost: 8.503875, mlm loss: 8.503875, speed: 1.091844 steps/s, speed: 8.734751 samples/s, speed: 4472.192457 tokens/s, learning rate: 8.380e-06, loss_scalings: 13421.773438, pp_loss: 8.297622
[INFO] 2021-07-12 18:47:46,325 [run_pretraining.py:  512]:	********exe.run_839******* 
[INFO] 2021-07-12 18:47:47,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:47,257 [run_pretraining.py:  534]:	loss/total_loss, 8.20579719543457, 840
[INFO] 2021-07-12 18:47:47,257 [run_pretraining.py:  535]:	loss/mlm_loss, 8.20579719543457, 840
[INFO] 2021-07-12 18:47:47,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.38999949337449e-06, 840
[INFO] 2021-07-12 18:47:47,257 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 840
[INFO] 2021-07-12 18:47:47,257 [run_pretraining.py:  558]:	worker_index: 7, step: 840, cost: 8.205797, mlm loss: 8.205797, speed: 1.073437 steps/s, speed: 8.587499 samples/s, speed: 4396.799368 tokens/s, learning rate: 8.390e-06, loss_scalings: 13421.773438, pp_loss: 8.521517
[INFO] 2021-07-12 18:47:47,257 [run_pretraining.py:  512]:	********exe.run_840******* 
[INFO] 2021-07-12 18:47:48,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:48,319 [run_pretraining.py:  534]:	loss/total_loss, 8.100339889526367, 841
[INFO] 2021-07-12 18:47:48,319 [run_pretraining.py:  535]:	loss/mlm_loss, 8.100339889526367, 841
[INFO] 2021-07-12 18:47:48,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.399999387620483e-06, 841
[INFO] 2021-07-12 18:47:48,319 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 841
[INFO] 2021-07-12 18:47:48,320 [run_pretraining.py:  558]:	worker_index: 7, step: 841, cost: 8.100340, mlm loss: 8.100340, speed: 0.942092 steps/s, speed: 7.536740 samples/s, speed: 3858.810741 tokens/s, learning rate: 8.400e-06, loss_scalings: 13421.773438, pp_loss: 8.258673
[INFO] 2021-07-12 18:47:48,320 [run_pretraining.py:  512]:	********exe.run_841******* 
[INFO] 2021-07-12 18:47:49,373 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:49,373 [run_pretraining.py:  534]:	loss/total_loss, 8.170884132385254, 842
[INFO] 2021-07-12 18:47:49,373 [run_pretraining.py:  535]:	loss/mlm_loss, 8.170884132385254, 842
[INFO] 2021-07-12 18:47:49,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.410000191361178e-06, 842
[INFO] 2021-07-12 18:47:49,374 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 842
[INFO] 2021-07-12 18:47:49,374 [run_pretraining.py:  558]:	worker_index: 7, step: 842, cost: 8.170884, mlm loss: 8.170884, speed: 0.949267 steps/s, speed: 7.594136 samples/s, speed: 3888.197665 tokens/s, learning rate: 8.410e-06, loss_scalings: 13421.773438, pp_loss: 8.077155
[INFO] 2021-07-12 18:47:49,374 [run_pretraining.py:  512]:	********exe.run_842******* 
[INFO] 2021-07-12 18:47:50,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:50,437 [run_pretraining.py:  534]:	loss/total_loss, 8.475656509399414, 843
[INFO] 2021-07-12 18:47:50,437 [run_pretraining.py:  535]:	loss/mlm_loss, 8.475656509399414, 843
[INFO] 2021-07-12 18:47:50,437 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.420000085607171e-06, 843
[INFO] 2021-07-12 18:47:50,437 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 843
[INFO] 2021-07-12 18:47:50,437 [run_pretraining.py:  558]:	worker_index: 7, step: 843, cost: 8.475657, mlm loss: 8.475657, speed: 0.940763 steps/s, speed: 7.526107 samples/s, speed: 3853.366660 tokens/s, learning rate: 8.420e-06, loss_scalings: 13421.773438, pp_loss: 8.345154
[INFO] 2021-07-12 18:47:50,437 [run_pretraining.py:  512]:	********exe.run_843******* 
[INFO] 2021-07-12 18:47:51,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:51,500 [run_pretraining.py:  534]:	loss/total_loss, 8.332968711853027, 844
[INFO] 2021-07-12 18:47:51,500 [run_pretraining.py:  535]:	loss/mlm_loss, 8.332968711853027, 844
[INFO] 2021-07-12 18:47:51,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.429999070358463e-06, 844
[INFO] 2021-07-12 18:47:51,500 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 844
[INFO] 2021-07-12 18:47:51,500 [run_pretraining.py:  558]:	worker_index: 7, step: 844, cost: 8.332969, mlm loss: 8.332969, speed: 0.941424 steps/s, speed: 7.531389 samples/s, speed: 3856.071200 tokens/s, learning rate: 8.430e-06, loss_scalings: 13421.773438, pp_loss: 8.205367
[INFO] 2021-07-12 18:47:51,500 [run_pretraining.py:  512]:	********exe.run_844******* 
[INFO] 2021-07-12 18:47:52,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:52,561 [run_pretraining.py:  534]:	loss/total_loss, 8.086592674255371, 845
[INFO] 2021-07-12 18:47:52,561 [run_pretraining.py:  535]:	loss/mlm_loss, 8.086592674255371, 845
[INFO] 2021-07-12 18:47:52,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.439999874099158e-06, 845
[INFO] 2021-07-12 18:47:52,562 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 845
[INFO] 2021-07-12 18:47:52,562 [run_pretraining.py:  558]:	worker_index: 7, step: 845, cost: 8.086593, mlm loss: 8.086593, speed: 0.942534 steps/s, speed: 7.540274 samples/s, speed: 3860.620469 tokens/s, learning rate: 8.440e-06, loss_scalings: 13421.773438, pp_loss: 8.089654
[INFO] 2021-07-12 18:47:52,562 [run_pretraining.py:  512]:	********exe.run_845******* 
[INFO] 2021-07-12 18:47:53,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:53,620 [run_pretraining.py:  534]:	loss/total_loss, 4.407578945159912, 846
[INFO] 2021-07-12 18:47:53,620 [run_pretraining.py:  535]:	loss/mlm_loss, 4.407578945159912, 846
[INFO] 2021-07-12 18:47:53,620 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.449999768345151e-06, 846
[INFO] 2021-07-12 18:47:53,621 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 846
[INFO] 2021-07-12 18:47:53,621 [run_pretraining.py:  558]:	worker_index: 7, step: 846, cost: 4.407579, mlm loss: 4.407579, speed: 0.944982 steps/s, speed: 7.559855 samples/s, speed: 3870.645813 tokens/s, learning rate: 8.450e-06, loss_scalings: 13421.773438, pp_loss: 6.708231
[INFO] 2021-07-12 18:47:53,621 [run_pretraining.py:  512]:	********exe.run_846******* 
[INFO] 2021-07-12 18:47:54,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:54,685 [run_pretraining.py:  534]:	loss/total_loss, 7.951901435852051, 847
[INFO] 2021-07-12 18:47:54,685 [run_pretraining.py:  535]:	loss/mlm_loss, 7.951901435852051, 847
[INFO] 2021-07-12 18:47:54,685 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.459999662591144e-06, 847
[INFO] 2021-07-12 18:47:54,685 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 847
[INFO] 2021-07-12 18:47:54,685 [run_pretraining.py:  558]:	worker_index: 7, step: 847, cost: 7.951901, mlm loss: 7.951901, speed: 0.940157 steps/s, speed: 7.521255 samples/s, speed: 3850.882557 tokens/s, learning rate: 8.460e-06, loss_scalings: 13421.773438, pp_loss: 8.157819
[INFO] 2021-07-12 18:47:54,685 [run_pretraining.py:  512]:	********exe.run_847******* 
[INFO] 2021-07-12 18:47:55,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:55,751 [run_pretraining.py:  534]:	loss/total_loss, 8.396804809570312, 848
[INFO] 2021-07-12 18:47:55,751 [run_pretraining.py:  535]:	loss/mlm_loss, 8.396804809570312, 848
[INFO] 2021-07-12 18:47:55,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.47000046633184e-06, 848
[INFO] 2021-07-12 18:47:55,751 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 848
[INFO] 2021-07-12 18:47:55,751 [run_pretraining.py:  558]:	worker_index: 7, step: 848, cost: 8.396805, mlm loss: 8.396805, speed: 0.938270 steps/s, speed: 7.506156 samples/s, speed: 3843.151942 tokens/s, learning rate: 8.470e-06, loss_scalings: 13421.773438, pp_loss: 8.139142
[INFO] 2021-07-12 18:47:55,751 [run_pretraining.py:  512]:	********exe.run_848******* 
[INFO] 2021-07-12 18:47:56,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:56,821 [run_pretraining.py:  534]:	loss/total_loss, 8.484556198120117, 849
[INFO] 2021-07-12 18:47:56,821 [run_pretraining.py:  535]:	loss/mlm_loss, 8.484556198120117, 849
[INFO] 2021-07-12 18:47:56,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.479999451083131e-06, 849
[INFO] 2021-07-12 18:47:56,822 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 849
[INFO] 2021-07-12 18:47:56,822 [run_pretraining.py:  558]:	worker_index: 7, step: 849, cost: 8.484556, mlm loss: 8.484556, speed: 0.934878 steps/s, speed: 7.479021 samples/s, speed: 3829.258608 tokens/s, learning rate: 8.480e-06, loss_scalings: 13421.773438, pp_loss: 8.103681
[INFO] 2021-07-12 18:47:56,822 [run_pretraining.py:  512]:	********exe.run_849******* 
[INFO] 2021-07-12 18:47:57,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:57,882 [run_pretraining.py:  534]:	loss/total_loss, 8.489299774169922, 850
[INFO] 2021-07-12 18:47:57,882 [run_pretraining.py:  535]:	loss/mlm_loss, 8.489299774169922, 850
[INFO] 2021-07-12 18:47:57,883 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.489999345329124e-06, 850
[INFO] 2021-07-12 18:47:57,883 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 850
[INFO] 2021-07-12 18:47:57,883 [run_pretraining.py:  558]:	worker_index: 7, step: 850, cost: 8.489300, mlm loss: 8.489300, speed: 0.943069 steps/s, speed: 7.544554 samples/s, speed: 3862.811407 tokens/s, learning rate: 8.490e-06, loss_scalings: 13421.773438, pp_loss: 8.102571
[INFO] 2021-07-12 18:47:57,883 [run_pretraining.py:  512]:	********exe.run_850******* 
[INFO] 2021-07-12 18:47:59,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:47:59,122 [run_pretraining.py:  534]:	loss/total_loss, 7.914738178253174, 851
[INFO] 2021-07-12 18:47:59,122 [run_pretraining.py:  535]:	loss/mlm_loss, 7.914738178253174, 851
[INFO] 2021-07-12 18:47:59,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.50000014906982e-06, 851
[INFO] 2021-07-12 18:47:59,122 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 851
[INFO] 2021-07-12 18:47:59,122 [run_pretraining.py:  558]:	worker_index: 7, step: 851, cost: 7.914738, mlm loss: 7.914738, speed: 0.807214 steps/s, speed: 6.457709 samples/s, speed: 3306.347173 tokens/s, learning rate: 8.500e-06, loss_scalings: 13421.773438, pp_loss: 8.062282
[INFO] 2021-07-12 18:47:59,122 [run_pretraining.py:  512]:	********exe.run_851******* 
[INFO] 2021-07-12 18:48:00,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:00,187 [run_pretraining.py:  534]:	loss/total_loss, 8.357660293579102, 852
[INFO] 2021-07-12 18:48:00,187 [run_pretraining.py:  535]:	loss/mlm_loss, 8.357660293579102, 852
[INFO] 2021-07-12 18:48:00,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.510000043315813e-06, 852
[INFO] 2021-07-12 18:48:00,187 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 852
[INFO] 2021-07-12 18:48:00,187 [run_pretraining.py:  558]:	worker_index: 7, step: 852, cost: 8.357660, mlm loss: 8.357660, speed: 0.939833 steps/s, speed: 7.518661 samples/s, speed: 3849.554583 tokens/s, learning rate: 8.510e-06, loss_scalings: 13421.773438, pp_loss: 8.321348
[INFO] 2021-07-12 18:48:00,187 [run_pretraining.py:  512]:	********exe.run_852******* 
[INFO] 2021-07-12 18:48:01,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:01,253 [run_pretraining.py:  534]:	loss/total_loss, 8.220561027526855, 853
[INFO] 2021-07-12 18:48:01,254 [run_pretraining.py:  535]:	loss/mlm_loss, 8.220561027526855, 853
[INFO] 2021-07-12 18:48:01,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.519999028067105e-06, 853
[INFO] 2021-07-12 18:48:01,254 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 853
[INFO] 2021-07-12 18:48:01,254 [run_pretraining.py:  558]:	worker_index: 7, step: 853, cost: 8.220561, mlm loss: 8.220561, speed: 0.937922 steps/s, speed: 7.503380 samples/s, speed: 3841.730497 tokens/s, learning rate: 8.520e-06, loss_scalings: 13421.773438, pp_loss: 8.062486
[INFO] 2021-07-12 18:48:01,254 [run_pretraining.py:  512]:	********exe.run_853******* 
[INFO] 2021-07-12 18:48:02,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:02,372 [run_pretraining.py:  534]:	loss/total_loss, 8.522686958312988, 854
[INFO] 2021-07-12 18:48:02,372 [run_pretraining.py:  535]:	loss/mlm_loss, 8.522686958312988, 854
[INFO] 2021-07-12 18:48:02,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.5299998318078e-06, 854
[INFO] 2021-07-12 18:48:02,373 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 854
[INFO] 2021-07-12 18:48:02,373 [run_pretraining.py:  558]:	worker_index: 7, step: 854, cost: 8.522687, mlm loss: 8.522687, speed: 0.894197 steps/s, speed: 7.153578 samples/s, speed: 3662.632166 tokens/s, learning rate: 8.530e-06, loss_scalings: 13421.773438, pp_loss: 8.194796
[INFO] 2021-07-12 18:48:02,373 [run_pretraining.py:  512]:	********exe.run_854******* 
[INFO] 2021-07-12 18:48:03,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:03,441 [run_pretraining.py:  534]:	loss/total_loss, 6.836025238037109, 855
[INFO] 2021-07-12 18:48:03,441 [run_pretraining.py:  535]:	loss/mlm_loss, 6.836025238037109, 855
[INFO] 2021-07-12 18:48:03,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.539999726053793e-06, 855
[INFO] 2021-07-12 18:48:03,442 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 855
[INFO] 2021-07-12 18:48:03,442 [run_pretraining.py:  558]:	worker_index: 7, step: 855, cost: 6.836025, mlm loss: 6.836025, speed: 0.936149 steps/s, speed: 7.489190 samples/s, speed: 3834.465272 tokens/s, learning rate: 8.540e-06, loss_scalings: 13421.773438, pp_loss: 7.826201
[INFO] 2021-07-12 18:48:03,442 [run_pretraining.py:  512]:	********exe.run_855******* 
[INFO] 2021-07-12 18:48:04,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:04,506 [run_pretraining.py:  534]:	loss/total_loss, 7.8838653564453125, 856
[INFO] 2021-07-12 18:48:04,506 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8838653564453125, 856
[INFO] 2021-07-12 18:48:04,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.549999620299786e-06, 856
[INFO] 2021-07-12 18:48:04,506 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 856
[INFO] 2021-07-12 18:48:04,506 [run_pretraining.py:  558]:	worker_index: 7, step: 856, cost: 7.883865, mlm loss: 7.883865, speed: 0.939843 steps/s, speed: 7.518747 samples/s, speed: 3849.598575 tokens/s, learning rate: 8.550e-06, loss_scalings: 13421.773438, pp_loss: 8.164429
[INFO] 2021-07-12 18:48:04,506 [run_pretraining.py:  512]:	********exe.run_856******* 
[INFO] 2021-07-12 18:48:05,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:05,532 [run_pretraining.py:  534]:	loss/total_loss, 8.330698013305664, 857
[INFO] 2021-07-12 18:48:05,532 [run_pretraining.py:  535]:	loss/mlm_loss, 8.330698013305664, 857
[INFO] 2021-07-12 18:48:05,532 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.560000424040481e-06, 857
[INFO] 2021-07-12 18:48:05,532 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 857
[INFO] 2021-07-12 18:48:05,533 [run_pretraining.py:  558]:	worker_index: 7, step: 857, cost: 8.330698, mlm loss: 8.330698, speed: 0.974991 steps/s, speed: 7.799924 samples/s, speed: 3993.561248 tokens/s, learning rate: 8.560e-06, loss_scalings: 13421.773438, pp_loss: 8.438997
[INFO] 2021-07-12 18:48:05,533 [run_pretraining.py:  512]:	********exe.run_857******* 
[INFO] 2021-07-12 18:48:06,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:06,456 [run_pretraining.py:  534]:	loss/total_loss, 8.384289741516113, 858
[INFO] 2021-07-12 18:48:06,456 [run_pretraining.py:  535]:	loss/mlm_loss, 8.384289741516113, 858
[INFO] 2021-07-12 18:48:06,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.569999408791773e-06, 858
[INFO] 2021-07-12 18:48:06,456 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 858
[INFO] 2021-07-12 18:48:06,456 [run_pretraining.py:  558]:	worker_index: 7, step: 858, cost: 8.384290, mlm loss: 8.384290, speed: 1.083308 steps/s, speed: 8.666463 samples/s, speed: 4437.229305 tokens/s, learning rate: 8.570e-06, loss_scalings: 13421.773438, pp_loss: 8.310940
[INFO] 2021-07-12 18:48:06,456 [run_pretraining.py:  512]:	********exe.run_858******* 
[INFO] 2021-07-12 18:48:07,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:07,370 [run_pretraining.py:  534]:	loss/total_loss, 8.062419891357422, 859
[INFO] 2021-07-12 18:48:07,370 [run_pretraining.py:  535]:	loss/mlm_loss, 8.062419891357422, 859
[INFO] 2021-07-12 18:48:07,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.579999303037766e-06, 859
[INFO] 2021-07-12 18:48:07,370 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 859
[INFO] 2021-07-12 18:48:07,370 [run_pretraining.py:  558]:	worker_index: 7, step: 859, cost: 8.062420, mlm loss: 8.062420, speed: 1.095107 steps/s, speed: 8.760852 samples/s, speed: 4485.556342 tokens/s, learning rate: 8.580e-06, loss_scalings: 13421.773438, pp_loss: 8.101500
[INFO] 2021-07-12 18:48:07,370 [run_pretraining.py:  512]:	********exe.run_859******* 
[INFO] 2021-07-12 18:48:08,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:08,323 [run_pretraining.py:  534]:	loss/total_loss, 8.915609359741211, 860
[INFO] 2021-07-12 18:48:08,323 [run_pretraining.py:  535]:	loss/mlm_loss, 8.915609359741211, 860
[INFO] 2021-07-12 18:48:08,323 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.590000106778461e-06, 860
[INFO] 2021-07-12 18:48:08,323 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 860
[INFO] 2021-07-12 18:48:08,323 [run_pretraining.py:  558]:	worker_index: 7, step: 860, cost: 8.915609, mlm loss: 8.915609, speed: 1.050321 steps/s, speed: 8.402571 samples/s, speed: 4302.116338 tokens/s, learning rate: 8.590e-06, loss_scalings: 13421.773438, pp_loss: 8.450356
[INFO] 2021-07-12 18:48:08,323 [run_pretraining.py:  512]:	********exe.run_860******* 
[INFO] 2021-07-12 18:48:09,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  534]:	loss/total_loss, 8.097907066345215, 861
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  535]:	loss/mlm_loss, 8.097907066345215, 861
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.600000001024455e-06, 861
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 861
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  558]:	worker_index: 7, step: 861, cost: 8.097907, mlm loss: 8.097907, speed: 1.093499 steps/s, speed: 8.747995 samples/s, speed: 4478.973610 tokens/s, learning rate: 8.600e-06, loss_scalings: 13421.773438, pp_loss: 7.914193
[INFO] 2021-07-12 18:48:09,238 [run_pretraining.py:  512]:	********exe.run_861******* 
[INFO] 2021-07-12 18:48:10,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:10,166 [run_pretraining.py:  534]:	loss/total_loss, 8.57752799987793, 862
[INFO] 2021-07-12 18:48:10,166 [run_pretraining.py:  535]:	loss/mlm_loss, 8.57752799987793, 862
[INFO] 2021-07-12 18:48:10,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.609999895270448e-06, 862
[INFO] 2021-07-12 18:48:10,166 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 862
[INFO] 2021-07-12 18:48:10,166 [run_pretraining.py:  558]:	worker_index: 7, step: 862, cost: 8.577528, mlm loss: 8.577528, speed: 1.078429 steps/s, speed: 8.627435 samples/s, speed: 4417.246621 tokens/s, learning rate: 8.610e-06, loss_scalings: 13421.773438, pp_loss: 8.280695
[INFO] 2021-07-12 18:48:10,166 [run_pretraining.py:  512]:	********exe.run_862******* 
[INFO] 2021-07-12 18:48:11,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:11,085 [run_pretraining.py:  534]:	loss/total_loss, 7.929923057556152, 863
[INFO] 2021-07-12 18:48:11,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.929923057556152, 863
[INFO] 2021-07-12 18:48:11,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.619999789516442e-06, 863
[INFO] 2021-07-12 18:48:11,085 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 863
[INFO] 2021-07-12 18:48:11,085 [run_pretraining.py:  558]:	worker_index: 7, step: 863, cost: 7.929923, mlm loss: 7.929923, speed: 1.088725 steps/s, speed: 8.709804 samples/s, speed: 4459.419540 tokens/s, learning rate: 8.620e-06, loss_scalings: 13421.773438, pp_loss: 7.910892
[INFO] 2021-07-12 18:48:11,085 [run_pretraining.py:  512]:	********exe.run_863******* 
[INFO] 2021-07-12 18:48:12,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:12,005 [run_pretraining.py:  534]:	loss/total_loss, 8.199356079101562, 864
[INFO] 2021-07-12 18:48:12,005 [run_pretraining.py:  535]:	loss/mlm_loss, 8.199356079101562, 864
[INFO] 2021-07-12 18:48:12,005 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.629999683762435e-06, 864
[INFO] 2021-07-12 18:48:12,005 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 864
[INFO] 2021-07-12 18:48:12,005 [run_pretraining.py:  558]:	worker_index: 7, step: 864, cost: 8.199356, mlm loss: 8.199356, speed: 1.087271 steps/s, speed: 8.698167 samples/s, speed: 4453.461539 tokens/s, learning rate: 8.630e-06, loss_scalings: 13421.773438, pp_loss: 8.352264
[INFO] 2021-07-12 18:48:12,006 [run_pretraining.py:  512]:	********exe.run_864******* 
[INFO] 2021-07-12 18:48:12,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:12,922 [run_pretraining.py:  534]:	loss/total_loss, 8.339028358459473, 865
[INFO] 2021-07-12 18:48:12,923 [run_pretraining.py:  535]:	loss/mlm_loss, 8.339028358459473, 865
[INFO] 2021-07-12 18:48:12,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.639999578008428e-06, 865
[INFO] 2021-07-12 18:48:12,923 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 865
[INFO] 2021-07-12 18:48:12,923 [run_pretraining.py:  558]:	worker_index: 7, step: 865, cost: 8.339028, mlm loss: 8.339028, speed: 1.090896 steps/s, speed: 8.727170 samples/s, speed: 4468.310951 tokens/s, learning rate: 8.640e-06, loss_scalings: 13421.773438, pp_loss: 8.302498
[INFO] 2021-07-12 18:48:12,923 [run_pretraining.py:  512]:	********exe.run_865******* 
[INFO] 2021-07-12 18:48:13,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:13,844 [run_pretraining.py:  534]:	loss/total_loss, 8.381935119628906, 866
[INFO] 2021-07-12 18:48:13,844 [run_pretraining.py:  535]:	loss/mlm_loss, 8.381935119628906, 866
[INFO] 2021-07-12 18:48:13,844 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.649999472254422e-06, 866
[INFO] 2021-07-12 18:48:13,844 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 866
[INFO] 2021-07-12 18:48:13,844 [run_pretraining.py:  558]:	worker_index: 7, step: 866, cost: 8.381935, mlm loss: 8.381935, speed: 1.086146 steps/s, speed: 8.689166 samples/s, speed: 4448.853126 tokens/s, learning rate: 8.650e-06, loss_scalings: 13421.773438, pp_loss: 8.252167
[INFO] 2021-07-12 18:48:13,844 [run_pretraining.py:  512]:	********exe.run_866******* 
[INFO] 2021-07-12 18:48:14,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:14,757 [run_pretraining.py:  534]:	loss/total_loss, 8.076333045959473, 867
[INFO] 2021-07-12 18:48:14,757 [run_pretraining.py:  535]:	loss/mlm_loss, 8.076333045959473, 867
[INFO] 2021-07-12 18:48:14,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.659999366500415e-06, 867
[INFO] 2021-07-12 18:48:14,757 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 867
[INFO] 2021-07-12 18:48:14,758 [run_pretraining.py:  558]:	worker_index: 7, step: 867, cost: 8.076333, mlm loss: 8.076333, speed: 1.095580 steps/s, speed: 8.764640 samples/s, speed: 4487.495435 tokens/s, learning rate: 8.660e-06, loss_scalings: 13421.773438, pp_loss: 8.143543
[INFO] 2021-07-12 18:48:14,758 [run_pretraining.py:  512]:	********exe.run_867******* 
[INFO] 2021-07-12 18:48:15,670 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:15,671 [run_pretraining.py:  534]:	loss/total_loss, 8.189004898071289, 868
[INFO] 2021-07-12 18:48:15,671 [run_pretraining.py:  535]:	loss/mlm_loss, 8.189004898071289, 868
[INFO] 2021-07-12 18:48:15,671 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.67000017024111e-06, 868
[INFO] 2021-07-12 18:48:15,671 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 868
[INFO] 2021-07-12 18:48:15,671 [run_pretraining.py:  558]:	worker_index: 7, step: 868, cost: 8.189005, mlm loss: 8.189005, speed: 1.095340 steps/s, speed: 8.762724 samples/s, speed: 4486.514548 tokens/s, learning rate: 8.670e-06, loss_scalings: 13421.773438, pp_loss: 8.201999
[INFO] 2021-07-12 18:48:15,671 [run_pretraining.py:  512]:	********exe.run_868******* 
[INFO] 2021-07-12 18:48:16,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:16,585 [run_pretraining.py:  534]:	loss/total_loss, 8.22327995300293, 869
[INFO] 2021-07-12 18:48:16,585 [run_pretraining.py:  535]:	loss/mlm_loss, 8.22327995300293, 869
[INFO] 2021-07-12 18:48:16,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.680000064487103e-06, 869
[INFO] 2021-07-12 18:48:16,585 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 869
[INFO] 2021-07-12 18:48:16,585 [run_pretraining.py:  558]:	worker_index: 7, step: 869, cost: 8.223280, mlm loss: 8.223280, speed: 1.094476 steps/s, speed: 8.755807 samples/s, speed: 4482.973101 tokens/s, learning rate: 8.680e-06, loss_scalings: 13421.773438, pp_loss: 8.007730
[INFO] 2021-07-12 18:48:16,586 [run_pretraining.py:  512]:	********exe.run_869******* 
[INFO] 2021-07-12 18:48:17,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:17,506 [run_pretraining.py:  534]:	loss/total_loss, 8.080949783325195, 870
[INFO] 2021-07-12 18:48:17,507 [run_pretraining.py:  535]:	loss/mlm_loss, 8.080949783325195, 870
[INFO] 2021-07-12 18:48:17,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.689999958733097e-06, 870
[INFO] 2021-07-12 18:48:17,507 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 870
[INFO] 2021-07-12 18:48:17,507 [run_pretraining.py:  558]:	worker_index: 7, step: 870, cost: 8.080950, mlm loss: 8.080950, speed: 1.086174 steps/s, speed: 8.689396 samples/s, speed: 4448.970639 tokens/s, learning rate: 8.690e-06, loss_scalings: 13421.773438, pp_loss: 8.164171
[INFO] 2021-07-12 18:48:17,507 [run_pretraining.py:  512]:	********exe.run_870******* 
[INFO] 2021-07-12 18:48:44,188 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  534]:	loss/total_loss, 8.321484565734863, 871
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  535]:	loss/mlm_loss, 8.321484565734863, 871
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.69999985297909e-06, 871
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 871
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  558]:	worker_index: 7, step: 871, cost: 8.321485, mlm loss: 8.321485, speed: 0.037479 steps/s, speed: 0.299833 samples/s, speed: 153.514423 tokens/s, learning rate: 8.700e-06, loss_scalings: 13421.773438, pp_loss: 8.073839
[INFO] 2021-07-12 18:48:44,189 [run_pretraining.py:  512]:	********exe.run_871******* 
[INFO] 2021-07-12 18:48:45,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:48:45,091 [run_pretraining.py:  534]:	loss/total_loss, 8.411263465881348, 872
[INFO] 2021-07-12 18:48:45,091 [run_pretraining.py:  535]:	loss/mlm_loss, 8.411263465881348, 872
[INFO] 2021-07-12 18:48:45,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.709999747225083e-06, 872
[INFO] 2021-07-12 18:48:45,091 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 872
[INFO] 2021-07-12 18:48:45,091 [run_pretraining.py:  558]:	worker_index: 7, step: 872, cost: 8.411263, mlm loss: 8.411263, speed: 1.109057 steps/s, speed: 8.872456 samples/s, speed: 4542.697633 tokens/s, learning rate: 8.710e-06, loss_scalings: 13421.773438, pp_loss: 8.167459
[INFO] 2021-07-12 18:48:45,091 [run_pretraining.py:  512]:	********exe.run_872******* 
[INFO] 2021-07-12 18:49:12,295 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:12,295 [run_pretraining.py:  534]:	loss/total_loss, 8.112483978271484, 873
[INFO] 2021-07-12 18:49:12,295 [run_pretraining.py:  535]:	loss/mlm_loss, 8.112483978271484, 873
[INFO] 2021-07-12 18:49:12,296 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.719999641471077e-06, 873
[INFO] 2021-07-12 18:49:12,296 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 873
[INFO] 2021-07-12 18:49:12,296 [run_pretraining.py:  558]:	worker_index: 7, step: 873, cost: 8.112484, mlm loss: 8.112484, speed: 0.036760 steps/s, speed: 0.294078 samples/s, speed: 150.567920 tokens/s, learning rate: 8.720e-06, loss_scalings: 13421.773438, pp_loss: 8.321692
[INFO] 2021-07-12 18:49:12,296 [run_pretraining.py:  512]:	********exe.run_873******* 
[INFO] 2021-07-12 18:49:13,255 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:13,256 [run_pretraining.py:  534]:	loss/total_loss, 8.6123628616333, 874
[INFO] 2021-07-12 18:49:13,256 [run_pretraining.py:  535]:	loss/mlm_loss, 8.6123628616333, 874
[INFO] 2021-07-12 18:49:13,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.730000445211772e-06, 874
[INFO] 2021-07-12 18:49:13,256 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 874
[INFO] 2021-07-12 18:49:13,256 [run_pretraining.py:  558]:	worker_index: 7, step: 874, cost: 8.612363, mlm loss: 8.612363, speed: 1.042127 steps/s, speed: 8.337012 samples/s, speed: 4268.550305 tokens/s, learning rate: 8.730e-06, loss_scalings: 13421.773438, pp_loss: 8.229640
[INFO] 2021-07-12 18:49:13,256 [run_pretraining.py:  512]:	********exe.run_874******* 
[INFO] 2021-07-12 18:49:14,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:14,164 [run_pretraining.py:  534]:	loss/total_loss, 8.28866195678711, 875
[INFO] 2021-07-12 18:49:14,164 [run_pretraining.py:  535]:	loss/mlm_loss, 8.28866195678711, 875
[INFO] 2021-07-12 18:49:14,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.739999429963063e-06, 875
[INFO] 2021-07-12 18:49:14,164 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 875
[INFO] 2021-07-12 18:49:14,164 [run_pretraining.py:  558]:	worker_index: 7, step: 875, cost: 8.288662, mlm loss: 8.288662, speed: 1.102124 steps/s, speed: 8.816995 samples/s, speed: 4514.301401 tokens/s, learning rate: 8.740e-06, loss_scalings: 13421.773438, pp_loss: 8.060588
[INFO] 2021-07-12 18:49:14,164 [run_pretraining.py:  512]:	********exe.run_875******* 
[INFO] 2021-07-12 18:49:40,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:40,914 [run_pretraining.py:  534]:	loss/total_loss, 8.099299430847168, 876
[INFO] 2021-07-12 18:49:40,914 [run_pretraining.py:  535]:	loss/mlm_loss, 8.099299430847168, 876
[INFO] 2021-07-12 18:49:40,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.749999324209057e-06, 876
[INFO] 2021-07-12 18:49:40,914 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 876
[INFO] 2021-07-12 18:49:40,914 [run_pretraining.py:  558]:	worker_index: 7, step: 876, cost: 8.099299, mlm loss: 8.099299, speed: 0.037384 steps/s, speed: 0.299068 samples/s, speed: 153.123027 tokens/s, learning rate: 8.750e-06, loss_scalings: 13421.773438, pp_loss: 8.098521
[INFO] 2021-07-12 18:49:40,914 [run_pretraining.py:  512]:	********exe.run_876******* 
[INFO] 2021-07-12 18:49:41,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:41,865 [run_pretraining.py:  534]:	loss/total_loss, 8.124722480773926, 877
[INFO] 2021-07-12 18:49:41,870 [run_pretraining.py:  535]:	loss/mlm_loss, 8.124722480773926, 877
[INFO] 2021-07-12 18:49:41,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.760000127949752e-06, 877
[INFO] 2021-07-12 18:49:41,880 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 877
[INFO] 2021-07-12 18:49:41,885 [run_pretraining.py:  558]:	worker_index: 7, step: 877, cost: 8.124722, mlm loss: 8.124722, speed: 1.052611 steps/s, speed: 8.420887 samples/s, speed: 4311.494332 tokens/s, learning rate: 8.760e-06, loss_scalings: 13421.773438, pp_loss: 8.095073
[INFO] 2021-07-12 18:49:41,891 [run_pretraining.py:  512]:	********exe.run_877******* 
[INFO] 2021-07-12 18:49:42,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:42,787 [run_pretraining.py:  534]:	loss/total_loss, 8.142428398132324, 878
[INFO] 2021-07-12 18:49:42,787 [run_pretraining.py:  535]:	loss/mlm_loss, 8.142428398132324, 878
[INFO] 2021-07-12 18:49:42,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.770000022195745e-06, 878
[INFO] 2021-07-12 18:49:42,787 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 878
[INFO] 2021-07-12 18:49:42,787 [run_pretraining.py:  558]:	worker_index: 7, step: 878, cost: 8.142428, mlm loss: 8.142428, speed: 1.115742 steps/s, speed: 8.925936 samples/s, speed: 4570.079209 tokens/s, learning rate: 8.770e-06, loss_scalings: 13421.773438, pp_loss: 8.072913
[INFO] 2021-07-12 18:49:42,787 [run_pretraining.py:  512]:	********exe.run_878******* 
[INFO] 2021-07-12 18:49:43,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:43,801 [run_pretraining.py:  534]:	loss/total_loss, 7.99691915512085, 879
[INFO] 2021-07-12 18:49:43,801 [run_pretraining.py:  535]:	loss/mlm_loss, 7.99691915512085, 879
[INFO] 2021-07-12 18:49:43,801 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.779999916441739e-06, 879
[INFO] 2021-07-12 18:49:43,802 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 879
[INFO] 2021-07-12 18:49:43,802 [run_pretraining.py:  558]:	worker_index: 7, step: 879, cost: 7.996919, mlm loss: 7.996919, speed: 0.986586 steps/s, speed: 7.892691 samples/s, speed: 4041.057548 tokens/s, learning rate: 8.780e-06, loss_scalings: 13421.773438, pp_loss: 7.079999
[INFO] 2021-07-12 18:49:43,802 [run_pretraining.py:  512]:	********exe.run_879******* 
[INFO] 2021-07-12 18:49:44,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:44,729 [run_pretraining.py:  534]:	loss/total_loss, 8.489066123962402, 880
[INFO] 2021-07-12 18:49:44,729 [run_pretraining.py:  535]:	loss/mlm_loss, 8.489066123962402, 880
[INFO] 2021-07-12 18:49:44,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.789999810687732e-06, 880
[INFO] 2021-07-12 18:49:44,729 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 880
[INFO] 2021-07-12 18:49:44,730 [run_pretraining.py:  558]:	worker_index: 7, step: 880, cost: 8.489066, mlm loss: 8.489066, speed: 1.078446 steps/s, speed: 8.627566 samples/s, speed: 4417.313632 tokens/s, learning rate: 8.790e-06, loss_scalings: 13421.773438, pp_loss: 8.264151
[INFO] 2021-07-12 18:49:44,730 [run_pretraining.py:  512]:	********exe.run_880******* 
[INFO] 2021-07-12 18:49:45,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:45,727 [run_pretraining.py:  534]:	loss/total_loss, 7.946956157684326, 881
[INFO] 2021-07-12 18:49:45,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.946956157684326, 881
[INFO] 2021-07-12 18:49:45,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.799999704933725e-06, 881
[INFO] 2021-07-12 18:49:45,728 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 881
[INFO] 2021-07-12 18:49:45,728 [run_pretraining.py:  558]:	worker_index: 7, step: 881, cost: 7.946956, mlm loss: 7.946956, speed: 1.002504 steps/s, speed: 8.020031 samples/s, speed: 4106.256085 tokens/s, learning rate: 8.800e-06, loss_scalings: 13421.773438, pp_loss: 7.940894
[INFO] 2021-07-12 18:49:45,728 [run_pretraining.py:  512]:	********exe.run_881******* 
[INFO] 2021-07-12 18:49:46,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:46,790 [run_pretraining.py:  534]:	loss/total_loss, 8.326431274414062, 882
[INFO] 2021-07-12 18:49:46,790 [run_pretraining.py:  535]:	loss/mlm_loss, 8.326431274414062, 882
[INFO] 2021-07-12 18:49:46,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.809999599179719e-06, 882
[INFO] 2021-07-12 18:49:46,790 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 882
[INFO] 2021-07-12 18:49:46,790 [run_pretraining.py:  558]:	worker_index: 7, step: 882, cost: 8.326431, mlm loss: 8.326431, speed: 0.941890 steps/s, speed: 7.535123 samples/s, speed: 3857.983186 tokens/s, learning rate: 8.810e-06, loss_scalings: 13421.773438, pp_loss: 7.942863
[INFO] 2021-07-12 18:49:46,790 [run_pretraining.py:  512]:	********exe.run_882******* 
[INFO] 2021-07-12 18:49:47,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:47,852 [run_pretraining.py:  534]:	loss/total_loss, 6.93434476852417, 883
[INFO] 2021-07-12 18:49:47,852 [run_pretraining.py:  535]:	loss/mlm_loss, 6.93434476852417, 883
[INFO] 2021-07-12 18:49:47,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.820000402920414e-06, 883
[INFO] 2021-07-12 18:49:47,852 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 883
[INFO] 2021-07-12 18:49:47,852 [run_pretraining.py:  558]:	worker_index: 7, step: 883, cost: 6.934345, mlm loss: 6.934345, speed: 0.942279 steps/s, speed: 7.538235 samples/s, speed: 3859.576222 tokens/s, learning rate: 8.820e-06, loss_scalings: 13421.773438, pp_loss: 7.835956
[INFO] 2021-07-12 18:49:47,852 [run_pretraining.py:  512]:	********exe.run_883******* 
[INFO] 2021-07-12 18:49:48,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:48,915 [run_pretraining.py:  534]:	loss/total_loss, 8.2701416015625, 884
[INFO] 2021-07-12 18:49:48,915 [run_pretraining.py:  535]:	loss/mlm_loss, 8.2701416015625, 884
[INFO] 2021-07-12 18:49:48,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.829999387671705e-06, 884
[INFO] 2021-07-12 18:49:48,916 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 884
[INFO] 2021-07-12 18:49:48,916 [run_pretraining.py:  558]:	worker_index: 7, step: 884, cost: 8.270142, mlm loss: 8.270142, speed: 0.940699 steps/s, speed: 7.525595 samples/s, speed: 3853.104797 tokens/s, learning rate: 8.830e-06, loss_scalings: 13421.773438, pp_loss: 8.016790
[INFO] 2021-07-12 18:49:48,916 [run_pretraining.py:  512]:	********exe.run_884******* 
[INFO] 2021-07-12 18:49:49,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:49,996 [run_pretraining.py:  534]:	loss/total_loss, 8.177874565124512, 885
[INFO] 2021-07-12 18:49:49,996 [run_pretraining.py:  535]:	loss/mlm_loss, 8.177874565124512, 885
[INFO] 2021-07-12 18:49:49,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.839999281917699e-06, 885
[INFO] 2021-07-12 18:49:49,997 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 885
[INFO] 2021-07-12 18:49:49,997 [run_pretraining.py:  558]:	worker_index: 7, step: 885, cost: 8.177875, mlm loss: 8.177875, speed: 0.925681 steps/s, speed: 7.405449 samples/s, speed: 3791.590106 tokens/s, learning rate: 8.840e-06, loss_scalings: 13421.773438, pp_loss: 8.157315
[INFO] 2021-07-12 18:49:49,997 [run_pretraining.py:  512]:	********exe.run_885******* 
[INFO] 2021-07-12 18:49:51,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  534]:	loss/total_loss, 8.422863006591797, 886
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  535]:	loss/mlm_loss, 8.422863006591797, 886
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.850000085658394e-06, 886
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 886
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  558]:	worker_index: 7, step: 886, cost: 8.422863, mlm loss: 8.422863, speed: 0.922821 steps/s, speed: 7.382567 samples/s, speed: 3779.874366 tokens/s, learning rate: 8.850e-06, loss_scalings: 13421.773438, pp_loss: 8.265060
[INFO] 2021-07-12 18:49:51,081 [run_pretraining.py:  512]:	********exe.run_886******* 
[INFO] 2021-07-12 18:49:52,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:52,154 [run_pretraining.py:  534]:	loss/total_loss, 8.281721115112305, 887
[INFO] 2021-07-12 18:49:52,154 [run_pretraining.py:  535]:	loss/mlm_loss, 8.281721115112305, 887
[INFO] 2021-07-12 18:49:52,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.859999979904387e-06, 887
[INFO] 2021-07-12 18:49:52,154 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 887
[INFO] 2021-07-12 18:49:52,154 [run_pretraining.py:  558]:	worker_index: 7, step: 887, cost: 8.281721, mlm loss: 8.281721, speed: 0.932468 steps/s, speed: 7.459743 samples/s, speed: 3819.388498 tokens/s, learning rate: 8.860e-06, loss_scalings: 13421.773438, pp_loss: 8.105925
[INFO] 2021-07-12 18:49:52,154 [run_pretraining.py:  512]:	********exe.run_887******* 
[INFO] 2021-07-12 18:49:53,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:53,221 [run_pretraining.py:  534]:	loss/total_loss, 8.321845054626465, 888
[INFO] 2021-07-12 18:49:53,221 [run_pretraining.py:  535]:	loss/mlm_loss, 8.321845054626465, 888
[INFO] 2021-07-12 18:49:53,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.86999987415038e-06, 888
[INFO] 2021-07-12 18:49:53,221 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 888
[INFO] 2021-07-12 18:49:53,221 [run_pretraining.py:  558]:	worker_index: 7, step: 888, cost: 8.321845, mlm loss: 8.321845, speed: 0.937737 steps/s, speed: 7.501899 samples/s, speed: 3840.972078 tokens/s, learning rate: 8.870e-06, loss_scalings: 13421.773438, pp_loss: 8.248564
[INFO] 2021-07-12 18:49:53,221 [run_pretraining.py:  512]:	********exe.run_888******* 
[INFO] 2021-07-12 18:49:54,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:54,295 [run_pretraining.py:  534]:	loss/total_loss, 8.324277877807617, 889
[INFO] 2021-07-12 18:49:54,295 [run_pretraining.py:  535]:	loss/mlm_loss, 8.324277877807617, 889
[INFO] 2021-07-12 18:49:54,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.879999768396374e-06, 889
[INFO] 2021-07-12 18:49:54,295 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 889
[INFO] 2021-07-12 18:49:54,295 [run_pretraining.py:  558]:	worker_index: 7, step: 889, cost: 8.324278, mlm loss: 8.324278, speed: 0.931322 steps/s, speed: 7.450580 samples/s, speed: 3814.696950 tokens/s, learning rate: 8.880e-06, loss_scalings: 13421.773438, pp_loss: 8.041973
[INFO] 2021-07-12 18:49:54,295 [run_pretraining.py:  512]:	********exe.run_889******* 
[INFO] 2021-07-12 18:49:55,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:55,208 [run_pretraining.py:  534]:	loss/total_loss, 8.303797721862793, 890
[INFO] 2021-07-12 18:49:55,208 [run_pretraining.py:  535]:	loss/mlm_loss, 8.303797721862793, 890
[INFO] 2021-07-12 18:49:55,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.889999662642367e-06, 890
[INFO] 2021-07-12 18:49:55,208 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 890
[INFO] 2021-07-12 18:49:55,208 [run_pretraining.py:  558]:	worker_index: 7, step: 890, cost: 8.303798, mlm loss: 8.303798, speed: 1.096224 steps/s, speed: 8.769796 samples/s, speed: 4490.135527 tokens/s, learning rate: 8.890e-06, loss_scalings: 13421.773438, pp_loss: 8.104913
[INFO] 2021-07-12 18:49:55,208 [run_pretraining.py:  512]:	********exe.run_890******* 
[INFO] 2021-07-12 18:49:56,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:56,117 [run_pretraining.py:  534]:	loss/total_loss, 8.189733505249023, 891
[INFO] 2021-07-12 18:49:56,117 [run_pretraining.py:  535]:	loss/mlm_loss, 8.189733505249023, 891
[INFO] 2021-07-12 18:49:56,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.89999955688836e-06, 891
[INFO] 2021-07-12 18:49:56,117 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 891
[INFO] 2021-07-12 18:49:56,117 [run_pretraining.py:  558]:	worker_index: 7, step: 891, cost: 8.189734, mlm loss: 8.189734, speed: 1.101377 steps/s, speed: 8.811017 samples/s, speed: 4511.240686 tokens/s, learning rate: 8.900e-06, loss_scalings: 13421.773438, pp_loss: 8.025833
[INFO] 2021-07-12 18:49:56,117 [run_pretraining.py:  512]:	********exe.run_891******* 
[INFO] 2021-07-12 18:49:57,031 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:57,031 [run_pretraining.py:  534]:	loss/total_loss, 8.01108169555664, 892
[INFO] 2021-07-12 18:49:57,032 [run_pretraining.py:  535]:	loss/mlm_loss, 8.01108169555664, 892
[INFO] 2021-07-12 18:49:57,032 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.910000360629056e-06, 892
[INFO] 2021-07-12 18:49:57,032 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 892
[INFO] 2021-07-12 18:49:57,032 [run_pretraining.py:  558]:	worker_index: 7, step: 892, cost: 8.011082, mlm loss: 8.011082, speed: 1.093837 steps/s, speed: 8.750699 samples/s, speed: 4480.357780 tokens/s, learning rate: 8.910e-06, loss_scalings: 13421.773438, pp_loss: 7.844564
[INFO] 2021-07-12 18:49:57,032 [run_pretraining.py:  512]:	********exe.run_892******* 
[INFO] 2021-07-12 18:49:57,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:57,942 [run_pretraining.py:  534]:	loss/total_loss, 8.457818031311035, 893
[INFO] 2021-07-12 18:49:57,942 [run_pretraining.py:  535]:	loss/mlm_loss, 8.457818031311035, 893
[INFO] 2021-07-12 18:49:57,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.919999345380347e-06, 893
[INFO] 2021-07-12 18:49:57,943 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 893
[INFO] 2021-07-12 18:49:57,943 [run_pretraining.py:  558]:	worker_index: 7, step: 893, cost: 8.457818, mlm loss: 8.457818, speed: 1.098679 steps/s, speed: 8.789432 samples/s, speed: 4500.189435 tokens/s, learning rate: 8.920e-06, loss_scalings: 13421.773438, pp_loss: 8.046923
[INFO] 2021-07-12 18:49:57,943 [run_pretraining.py:  512]:	********exe.run_893******* 
[INFO] 2021-07-12 18:49:58,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:58,851 [run_pretraining.py:  534]:	loss/total_loss, 7.969753265380859, 894
[INFO] 2021-07-12 18:49:58,851 [run_pretraining.py:  535]:	loss/mlm_loss, 7.969753265380859, 894
[INFO] 2021-07-12 18:49:58,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.92999923962634e-06, 894
[INFO] 2021-07-12 18:49:58,851 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 894
[INFO] 2021-07-12 18:49:58,852 [run_pretraining.py:  558]:	worker_index: 7, step: 894, cost: 7.969753, mlm loss: 7.969753, speed: 1.100930 steps/s, speed: 8.807444 samples/s, speed: 4509.411219 tokens/s, learning rate: 8.930e-06, loss_scalings: 13421.773438, pp_loss: 7.893549
[INFO] 2021-07-12 18:49:58,852 [run_pretraining.py:  512]:	********exe.run_894******* 
[INFO] 2021-07-12 18:49:59,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:49:59,774 [run_pretraining.py:  534]:	loss/total_loss, 7.7123260498046875, 895
[INFO] 2021-07-12 18:49:59,775 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7123260498046875, 895
[INFO] 2021-07-12 18:49:59,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.940000043367036e-06, 895
[INFO] 2021-07-12 18:49:59,777 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 895
[INFO] 2021-07-12 18:49:59,780 [run_pretraining.py:  558]:	worker_index: 7, step: 895, cost: 7.712326, mlm loss: 7.712326, speed: 1.084973 steps/s, speed: 8.679784 samples/s, speed: 4444.049606 tokens/s, learning rate: 8.940e-06, loss_scalings: 13421.773438, pp_loss: 8.018745
[INFO] 2021-07-12 18:49:59,781 [run_pretraining.py:  512]:	********exe.run_895******* 
[INFO] 2021-07-12 18:50:00,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:00,693 [run_pretraining.py:  534]:	loss/total_loss, 7.744680881500244, 896
[INFO] 2021-07-12 18:50:00,693 [run_pretraining.py:  535]:	loss/mlm_loss, 7.744680881500244, 896
[INFO] 2021-07-12 18:50:00,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.949999937613029e-06, 896
[INFO] 2021-07-12 18:50:00,694 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 896
[INFO] 2021-07-12 18:50:00,694 [run_pretraining.py:  558]:	worker_index: 7, step: 896, cost: 7.744681, mlm loss: 7.744681, speed: 1.096156 steps/s, speed: 8.769248 samples/s, speed: 4489.855068 tokens/s, learning rate: 8.950e-06, loss_scalings: 13421.773438, pp_loss: 7.905042
[INFO] 2021-07-12 18:50:00,694 [run_pretraining.py:  512]:	********exe.run_896******* 
[INFO] 2021-07-12 18:50:01,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:01,609 [run_pretraining.py:  534]:	loss/total_loss, 7.8615546226501465, 897
[INFO] 2021-07-12 18:50:01,610 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8615546226501465, 897
[INFO] 2021-07-12 18:50:01,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.959999831859022e-06, 897
[INFO] 2021-07-12 18:50:01,610 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 897
[INFO] 2021-07-12 18:50:01,610 [run_pretraining.py:  558]:	worker_index: 7, step: 897, cost: 7.861555, mlm loss: 7.861555, speed: 1.092254 steps/s, speed: 8.738033 samples/s, speed: 4473.873004 tokens/s, learning rate: 8.960e-06, loss_scalings: 13421.773438, pp_loss: 7.881067
[INFO] 2021-07-12 18:50:01,610 [run_pretraining.py:  512]:	********exe.run_897******* 
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  534]:	loss/total_loss, 7.900118827819824, 898
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  535]:	loss/mlm_loss, 7.900118827819824, 898
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.969999726105016e-06, 898
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 898
[INFO] 2021-07-12 18:50:02,531 [run_pretraining.py:  558]:	worker_index: 7, step: 898, cost: 7.900119, mlm loss: 7.900119, speed: 1.085840 steps/s, speed: 8.686721 samples/s, speed: 4447.601185 tokens/s, learning rate: 8.970e-06, loss_scalings: 13421.773438, pp_loss: 8.114820
[INFO] 2021-07-12 18:50:02,532 [run_pretraining.py:  512]:	********exe.run_898******* 
[INFO] 2021-07-12 18:50:03,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:03,445 [run_pretraining.py:  534]:	loss/total_loss, 7.9279327392578125, 899
[INFO] 2021-07-12 18:50:03,445 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9279327392578125, 899
[INFO] 2021-07-12 18:50:03,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.979999620351009e-06, 899
[INFO] 2021-07-12 18:50:03,446 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 899
[INFO] 2021-07-12 18:50:03,446 [run_pretraining.py:  558]:	worker_index: 7, step: 899, cost: 7.927933, mlm loss: 7.927933, speed: 1.094626 steps/s, speed: 8.757007 samples/s, speed: 4483.587331 tokens/s, learning rate: 8.980e-06, loss_scalings: 13421.773438, pp_loss: 7.904439
[INFO] 2021-07-12 18:50:03,446 [run_pretraining.py:  512]:	********exe.run_899******* 
[INFO] 2021-07-12 18:50:04,367 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:04,368 [run_pretraining.py:  534]:	loss/total_loss, 7.976029872894287, 900
[INFO] 2021-07-12 18:50:04,368 [run_pretraining.py:  535]:	loss/mlm_loss, 7.976029872894287, 900
[INFO] 2021-07-12 18:50:04,368 [run_pretraining.py:  536]:	lr/scheduled_lr, 8.989999514597002e-06, 900
[INFO] 2021-07-12 18:50:04,368 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 900
[INFO] 2021-07-12 18:50:04,368 [run_pretraining.py:  558]:	worker_index: 7, step: 900, cost: 7.976030, mlm loss: 7.976030, speed: 1.084873 steps/s, speed: 8.678985 samples/s, speed: 4443.640394 tokens/s, learning rate: 8.990e-06, loss_scalings: 13421.773438, pp_loss: 8.014070
[INFO] 2021-07-12 18:50:04,368 [run_pretraining.py:  512]:	********exe.run_900******* 
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  534]:	loss/total_loss, 7.738905429840088, 901
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  535]:	loss/mlm_loss, 7.738905429840088, 901
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.000000318337698e-06, 901
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 901
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  558]:	worker_index: 7, step: 901, cost: 7.738905, mlm loss: 7.738905, speed: 0.940139 steps/s, speed: 7.521113 samples/s, speed: 3850.810051 tokens/s, learning rate: 9.000e-06, loss_scalings: 13421.773438, pp_loss: 7.980681
[INFO] 2021-07-12 18:50:05,432 [run_pretraining.py:  512]:	********exe.run_901******* 
[INFO] 2021-07-12 18:50:06,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:06,493 [run_pretraining.py:  534]:	loss/total_loss, 7.778925895690918, 902
[INFO] 2021-07-12 18:50:06,493 [run_pretraining.py:  535]:	loss/mlm_loss, 7.778925895690918, 902
[INFO] 2021-07-12 18:50:06,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.009999303088989e-06, 902
[INFO] 2021-07-12 18:50:06,493 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 902
[INFO] 2021-07-12 18:50:06,493 [run_pretraining.py:  558]:	worker_index: 7, step: 902, cost: 7.778926, mlm loss: 7.778926, speed: 0.943072 steps/s, speed: 7.544572 samples/s, speed: 3862.820961 tokens/s, learning rate: 9.010e-06, loss_scalings: 13421.773438, pp_loss: 7.826413
[INFO] 2021-07-12 18:50:06,493 [run_pretraining.py:  512]:	********exe.run_902******* 
[INFO] 2021-07-12 18:50:07,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:07,566 [run_pretraining.py:  534]:	loss/total_loss, 8.123737335205078, 903
[INFO] 2021-07-12 18:50:07,566 [run_pretraining.py:  535]:	loss/mlm_loss, 8.123737335205078, 903
[INFO] 2021-07-12 18:50:07,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.020000106829684e-06, 903
[INFO] 2021-07-12 18:50:07,566 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 903
[INFO] 2021-07-12 18:50:07,567 [run_pretraining.py:  558]:	worker_index: 7, step: 903, cost: 8.123737, mlm loss: 8.123737, speed: 0.932424 steps/s, speed: 7.459392 samples/s, speed: 3819.208494 tokens/s, learning rate: 9.020e-06, loss_scalings: 13421.773438, pp_loss: 7.927217
[INFO] 2021-07-12 18:50:07,567 [run_pretraining.py:  512]:	********exe.run_903******* 
[INFO] 2021-07-12 18:50:08,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:08,633 [run_pretraining.py:  534]:	loss/total_loss, 8.117585182189941, 904
[INFO] 2021-07-12 18:50:08,633 [run_pretraining.py:  535]:	loss/mlm_loss, 8.117585182189941, 904
[INFO] 2021-07-12 18:50:08,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.030000001075678e-06, 904
[INFO] 2021-07-12 18:50:08,633 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 904
[INFO] 2021-07-12 18:50:08,633 [run_pretraining.py:  558]:	worker_index: 7, step: 904, cost: 8.117585, mlm loss: 8.117585, speed: 0.938065 steps/s, speed: 7.504521 samples/s, speed: 3842.314760 tokens/s, learning rate: 9.030e-06, loss_scalings: 13421.773438, pp_loss: 8.066131
[INFO] 2021-07-12 18:50:08,633 [run_pretraining.py:  512]:	********exe.run_904******* 
[INFO] 2021-07-12 18:50:09,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:09,702 [run_pretraining.py:  534]:	loss/total_loss, 8.089015007019043, 905
[INFO] 2021-07-12 18:50:09,703 [run_pretraining.py:  535]:	loss/mlm_loss, 8.089015007019043, 905
[INFO] 2021-07-12 18:50:09,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.039999895321671e-06, 905
[INFO] 2021-07-12 18:50:09,703 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 905
[INFO] 2021-07-12 18:50:09,703 [run_pretraining.py:  558]:	worker_index: 7, step: 905, cost: 8.089015, mlm loss: 8.089015, speed: 0.935529 steps/s, speed: 7.484232 samples/s, speed: 3831.926837 tokens/s, learning rate: 9.040e-06, loss_scalings: 13421.773438, pp_loss: 7.605153
[INFO] 2021-07-12 18:50:09,703 [run_pretraining.py:  512]:	********exe.run_905******* 
[INFO] 2021-07-12 18:50:10,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:10,787 [run_pretraining.py:  534]:	loss/total_loss, 7.993221282958984, 906
[INFO] 2021-07-12 18:50:10,787 [run_pretraining.py:  535]:	loss/mlm_loss, 7.993221282958984, 906
[INFO] 2021-07-12 18:50:10,787 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.049999789567664e-06, 906
[INFO] 2021-07-12 18:50:10,787 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 906
[INFO] 2021-07-12 18:50:10,787 [run_pretraining.py:  558]:	worker_index: 7, step: 906, cost: 7.993221, mlm loss: 7.993221, speed: 0.922491 steps/s, speed: 7.379932 samples/s, speed: 3778.525098 tokens/s, learning rate: 9.050e-06, loss_scalings: 13421.773438, pp_loss: 8.247393
[INFO] 2021-07-12 18:50:10,788 [run_pretraining.py:  512]:	********exe.run_906******* 
[INFO] 2021-07-12 18:50:11,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:11,855 [run_pretraining.py:  534]:	loss/total_loss, 8.103400230407715, 907
[INFO] 2021-07-12 18:50:11,855 [run_pretraining.py:  535]:	loss/mlm_loss, 8.103400230407715, 907
[INFO] 2021-07-12 18:50:11,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.059999683813658e-06, 907
[INFO] 2021-07-12 18:50:11,855 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 907
[INFO] 2021-07-12 18:50:11,855 [run_pretraining.py:  558]:	worker_index: 7, step: 907, cost: 8.103400, mlm loss: 8.103400, speed: 0.937177 steps/s, speed: 7.497420 samples/s, speed: 3838.678891 tokens/s, learning rate: 9.060e-06, loss_scalings: 13421.773438, pp_loss: 8.218333
[INFO] 2021-07-12 18:50:11,855 [run_pretraining.py:  512]:	********exe.run_907******* 
[INFO] 2021-07-12 18:50:12,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:12,917 [run_pretraining.py:  534]:	loss/total_loss, 7.665953636169434, 908
[INFO] 2021-07-12 18:50:12,917 [run_pretraining.py:  535]:	loss/mlm_loss, 7.665953636169434, 908
[INFO] 2021-07-12 18:50:12,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.069999578059651e-06, 908
[INFO] 2021-07-12 18:50:12,918 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 908
[INFO] 2021-07-12 18:50:12,918 [run_pretraining.py:  558]:	worker_index: 7, step: 908, cost: 7.665954, mlm loss: 7.665954, speed: 0.941638 steps/s, speed: 7.533100 samples/s, speed: 3856.947291 tokens/s, learning rate: 9.070e-06, loss_scalings: 13421.773438, pp_loss: 7.775010
[INFO] 2021-07-12 18:50:12,918 [run_pretraining.py:  512]:	********exe.run_908******* 
[INFO] 2021-07-12 18:50:13,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:13,984 [run_pretraining.py:  534]:	loss/total_loss, 7.605640411376953, 909
[INFO] 2021-07-12 18:50:13,985 [run_pretraining.py:  535]:	loss/mlm_loss, 7.605640411376953, 909
[INFO] 2021-07-12 18:50:13,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.080000381800346e-06, 909
[INFO] 2021-07-12 18:50:13,985 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 909
[INFO] 2021-07-12 18:50:13,985 [run_pretraining.py:  558]:	worker_index: 7, step: 909, cost: 7.605640, mlm loss: 7.605640, speed: 0.937775 steps/s, speed: 7.502199 samples/s, speed: 3841.125799 tokens/s, learning rate: 9.080e-06, loss_scalings: 13421.773438, pp_loss: 8.025601
[INFO] 2021-07-12 18:50:13,985 [run_pretraining.py:  512]:	********exe.run_909******* 
[INFO] 2021-07-12 18:50:15,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:15,051 [run_pretraining.py:  534]:	loss/total_loss, 7.6994829177856445, 910
[INFO] 2021-07-12 18:50:15,051 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6994829177856445, 910
[INFO] 2021-07-12 18:50:15,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.089999366551638e-06, 910
[INFO] 2021-07-12 18:50:15,051 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 910
[INFO] 2021-07-12 18:50:15,051 [run_pretraining.py:  558]:	worker_index: 7, step: 910, cost: 7.699483, mlm loss: 7.699483, speed: 0.938198 steps/s, speed: 7.505585 samples/s, speed: 3842.859661 tokens/s, learning rate: 9.090e-06, loss_scalings: 13421.773438, pp_loss: 7.917989
[INFO] 2021-07-12 18:50:15,051 [run_pretraining.py:  512]:	********exe.run_910******* 
[INFO] 2021-07-12 18:50:16,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:16,114 [run_pretraining.py:  534]:	loss/total_loss, 7.681905746459961, 911
[INFO] 2021-07-12 18:50:16,114 [run_pretraining.py:  535]:	loss/mlm_loss, 7.681905746459961, 911
[INFO] 2021-07-12 18:50:16,114 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.099999260797631e-06, 911
[INFO] 2021-07-12 18:50:16,114 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 911
[INFO] 2021-07-12 18:50:16,114 [run_pretraining.py:  558]:	worker_index: 7, step: 911, cost: 7.681906, mlm loss: 7.681906, speed: 0.941265 steps/s, speed: 7.530121 samples/s, speed: 3855.422180 tokens/s, learning rate: 9.100e-06, loss_scalings: 13421.773438, pp_loss: 8.020555
[INFO] 2021-07-12 18:50:16,114 [run_pretraining.py:  512]:	********exe.run_911******* 
[INFO] 2021-07-12 18:50:17,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:17,161 [run_pretraining.py:  534]:	loss/total_loss, 8.455048561096191, 912
[INFO] 2021-07-12 18:50:17,161 [run_pretraining.py:  535]:	loss/mlm_loss, 8.455048561096191, 912
[INFO] 2021-07-12 18:50:17,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.110000064538326e-06, 912
[INFO] 2021-07-12 18:50:17,161 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 912
[INFO] 2021-07-12 18:50:17,161 [run_pretraining.py:  558]:	worker_index: 7, step: 912, cost: 8.455049, mlm loss: 8.455049, speed: 0.955717 steps/s, speed: 7.645733 samples/s, speed: 3914.615431 tokens/s, learning rate: 9.110e-06, loss_scalings: 13421.773438, pp_loss: 6.249401
[INFO] 2021-07-12 18:50:17,161 [run_pretraining.py:  512]:	********exe.run_912******* 
[INFO] 2021-07-12 18:50:18,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:18,220 [run_pretraining.py:  534]:	loss/total_loss, 7.983392238616943, 913
[INFO] 2021-07-12 18:50:18,220 [run_pretraining.py:  535]:	loss/mlm_loss, 7.983392238616943, 913
[INFO] 2021-07-12 18:50:18,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.11999995878432e-06, 913
[INFO] 2021-07-12 18:50:18,221 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 913
[INFO] 2021-07-12 18:50:18,221 [run_pretraining.py:  558]:	worker_index: 7, step: 913, cost: 7.983392, mlm loss: 7.983392, speed: 0.944626 steps/s, speed: 7.557012 samples/s, speed: 3869.190019 tokens/s, learning rate: 9.120e-06, loss_scalings: 13421.773438, pp_loss: 8.034791
[INFO] 2021-07-12 18:50:18,221 [run_pretraining.py:  512]:	********exe.run_913******* 
[INFO] 2021-07-12 18:50:19,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:19,285 [run_pretraining.py:  534]:	loss/total_loss, 8.294790267944336, 914
[INFO] 2021-07-12 18:50:19,285 [run_pretraining.py:  535]:	loss/mlm_loss, 8.294790267944336, 914
[INFO] 2021-07-12 18:50:19,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.129999853030313e-06, 914
[INFO] 2021-07-12 18:50:19,285 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 914
[INFO] 2021-07-12 18:50:19,286 [run_pretraining.py:  558]:	worker_index: 7, step: 914, cost: 8.294790, mlm loss: 8.294790, speed: 0.939568 steps/s, speed: 7.516546 samples/s, speed: 3848.471483 tokens/s, learning rate: 9.130e-06, loss_scalings: 13421.773438, pp_loss: 7.995094
[INFO] 2021-07-12 18:50:19,286 [run_pretraining.py:  512]:	********exe.run_914******* 
[INFO] 2021-07-12 18:50:20,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:20,350 [run_pretraining.py:  534]:	loss/total_loss, 8.206208229064941, 915
[INFO] 2021-07-12 18:50:20,350 [run_pretraining.py:  535]:	loss/mlm_loss, 8.206208229064941, 915
[INFO] 2021-07-12 18:50:20,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.139999747276306e-06, 915
[INFO] 2021-07-12 18:50:20,350 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 915
[INFO] 2021-07-12 18:50:20,350 [run_pretraining.py:  558]:	worker_index: 7, step: 915, cost: 8.206208, mlm loss: 8.206208, speed: 0.939900 steps/s, speed: 7.519202 samples/s, speed: 3849.831492 tokens/s, learning rate: 9.140e-06, loss_scalings: 13421.773438, pp_loss: 8.124142
[INFO] 2021-07-12 18:50:20,350 [run_pretraining.py:  512]:	********exe.run_915******* 
[INFO] 2021-07-12 18:50:21,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  534]:	loss/total_loss, 8.040796279907227, 916
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  535]:	loss/mlm_loss, 8.040796279907227, 916
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.1499996415223e-06, 916
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 916
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  558]:	worker_index: 7, step: 916, cost: 8.040796, mlm loss: 8.040796, speed: 1.056634 steps/s, speed: 8.453073 samples/s, speed: 4327.973504 tokens/s, learning rate: 9.150e-06, loss_scalings: 13421.773438, pp_loss: 8.076939
[INFO] 2021-07-12 18:50:21,297 [run_pretraining.py:  512]:	********exe.run_916******* 
[INFO] 2021-07-12 18:50:22,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:22,210 [run_pretraining.py:  534]:	loss/total_loss, 7.741599082946777, 917
[INFO] 2021-07-12 18:50:22,210 [run_pretraining.py:  535]:	loss/mlm_loss, 7.741599082946777, 917
[INFO] 2021-07-12 18:50:22,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.159999535768293e-06, 917
[INFO] 2021-07-12 18:50:22,211 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 917
[INFO] 2021-07-12 18:50:22,211 [run_pretraining.py:  558]:	worker_index: 7, step: 917, cost: 7.741599, mlm loss: 7.741599, speed: 1.095579 steps/s, speed: 8.764630 samples/s, speed: 4487.490746 tokens/s, learning rate: 9.160e-06, loss_scalings: 13421.773438, pp_loss: 7.940213
[INFO] 2021-07-12 18:50:22,211 [run_pretraining.py:  512]:	********exe.run_917******* 
[INFO] 2021-07-12 18:50:23,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:23,126 [run_pretraining.py:  534]:	loss/total_loss, 8.255230903625488, 918
[INFO] 2021-07-12 18:50:23,126 [run_pretraining.py:  535]:	loss/mlm_loss, 8.255230903625488, 918
[INFO] 2021-07-12 18:50:23,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.170000339508988e-06, 918
[INFO] 2021-07-12 18:50:23,126 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 918
[INFO] 2021-07-12 18:50:23,126 [run_pretraining.py:  558]:	worker_index: 7, step: 918, cost: 8.255231, mlm loss: 8.255231, speed: 1.092849 steps/s, speed: 8.742789 samples/s, speed: 4476.308134 tokens/s, learning rate: 9.170e-06, loss_scalings: 13421.773438, pp_loss: 7.808048
[INFO] 2021-07-12 18:50:23,126 [run_pretraining.py:  512]:	********exe.run_918******* 
[INFO] 2021-07-12 18:50:24,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:24,036 [run_pretraining.py:  534]:	loss/total_loss, 8.194498062133789, 919
[INFO] 2021-07-12 18:50:24,036 [run_pretraining.py:  535]:	loss/mlm_loss, 8.194498062133789, 919
[INFO] 2021-07-12 18:50:24,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.17999932426028e-06, 919
[INFO] 2021-07-12 18:50:24,036 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 919
[INFO] 2021-07-12 18:50:24,036 [run_pretraining.py:  558]:	worker_index: 7, step: 919, cost: 8.194498, mlm loss: 8.194498, speed: 1.099765 steps/s, speed: 8.798123 samples/s, speed: 4504.639101 tokens/s, learning rate: 9.180e-06, loss_scalings: 13421.773438, pp_loss: 7.440843
[INFO] 2021-07-12 18:50:24,036 [run_pretraining.py:  512]:	********exe.run_919******* 
[INFO] 2021-07-12 18:50:24,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:24,957 [run_pretraining.py:  534]:	loss/total_loss, 8.312216758728027, 920
[INFO] 2021-07-12 18:50:24,957 [run_pretraining.py:  535]:	loss/mlm_loss, 8.312216758728027, 920
[INFO] 2021-07-12 18:50:24,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.189999218506273e-06, 920
[INFO] 2021-07-12 18:50:24,958 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 920
[INFO] 2021-07-12 18:50:24,958 [run_pretraining.py:  558]:	worker_index: 7, step: 920, cost: 8.312217, mlm loss: 8.312217, speed: 1.086097 steps/s, speed: 8.688779 samples/s, speed: 4448.654980 tokens/s, learning rate: 9.190e-06, loss_scalings: 13421.773438, pp_loss: 8.027608
[INFO] 2021-07-12 18:50:24,958 [run_pretraining.py:  512]:	********exe.run_920******* 
[INFO] 2021-07-12 18:50:25,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:25,876 [run_pretraining.py:  534]:	loss/total_loss, 8.017003059387207, 921
[INFO] 2021-07-12 18:50:25,876 [run_pretraining.py:  535]:	loss/mlm_loss, 8.017003059387207, 921
[INFO] 2021-07-12 18:50:25,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.200000022246968e-06, 921
[INFO] 2021-07-12 18:50:25,876 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 921
[INFO] 2021-07-12 18:50:25,876 [run_pretraining.py:  558]:	worker_index: 7, step: 921, cost: 8.017003, mlm loss: 8.017003, speed: 1.089547 steps/s, speed: 8.716376 samples/s, speed: 4462.784738 tokens/s, learning rate: 9.200e-06, loss_scalings: 13421.773438, pp_loss: 7.988309
[INFO] 2021-07-12 18:50:25,876 [run_pretraining.py:  512]:	********exe.run_921******* 
[INFO] 2021-07-12 18:50:26,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:26,794 [run_pretraining.py:  534]:	loss/total_loss, 6.804863929748535, 922
[INFO] 2021-07-12 18:50:26,794 [run_pretraining.py:  535]:	loss/mlm_loss, 6.804863929748535, 922
[INFO] 2021-07-12 18:50:26,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.209999916492961e-06, 922
[INFO] 2021-07-12 18:50:26,794 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 922
[INFO] 2021-07-12 18:50:26,794 [run_pretraining.py:  558]:	worker_index: 7, step: 922, cost: 6.804864, mlm loss: 6.804864, speed: 1.089829 steps/s, speed: 8.718630 samples/s, speed: 4463.938529 tokens/s, learning rate: 9.210e-06, loss_scalings: 13421.773438, pp_loss: 7.071231
[INFO] 2021-07-12 18:50:26,794 [run_pretraining.py:  512]:	********exe.run_922******* 
[INFO] 2021-07-12 18:50:27,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:27,713 [run_pretraining.py:  534]:	loss/total_loss, 7.912217140197754, 923
[INFO] 2021-07-12 18:50:27,713 [run_pretraining.py:  535]:	loss/mlm_loss, 7.912217140197754, 923
[INFO] 2021-07-12 18:50:27,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.219999810738955e-06, 923
[INFO] 2021-07-12 18:50:27,713 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 923
[INFO] 2021-07-12 18:50:27,713 [run_pretraining.py:  558]:	worker_index: 7, step: 923, cost: 7.912217, mlm loss: 7.912217, speed: 1.089192 steps/s, speed: 8.713536 samples/s, speed: 4461.330303 tokens/s, learning rate: 9.220e-06, loss_scalings: 13421.773438, pp_loss: 8.051499
[INFO] 2021-07-12 18:50:27,713 [run_pretraining.py:  512]:	********exe.run_923******* 
[INFO] 2021-07-12 18:50:28,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:28,632 [run_pretraining.py:  534]:	loss/total_loss, 8.213531494140625, 924
[INFO] 2021-07-12 18:50:28,632 [run_pretraining.py:  535]:	loss/mlm_loss, 8.213531494140625, 924
[INFO] 2021-07-12 18:50:28,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.229999704984948e-06, 924
[INFO] 2021-07-12 18:50:28,632 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 924
[INFO] 2021-07-12 18:50:28,632 [run_pretraining.py:  558]:	worker_index: 7, step: 924, cost: 8.213531, mlm loss: 8.213531, speed: 1.088821 steps/s, speed: 8.710570 samples/s, speed: 4459.811981 tokens/s, learning rate: 9.230e-06, loss_scalings: 13421.773438, pp_loss: 8.150201
[INFO] 2021-07-12 18:50:28,632 [run_pretraining.py:  512]:	********exe.run_924******* 
[INFO] 2021-07-12 18:50:29,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:29,552 [run_pretraining.py:  534]:	loss/total_loss, 8.078941345214844, 925
[INFO] 2021-07-12 18:50:29,552 [run_pretraining.py:  535]:	loss/mlm_loss, 8.078941345214844, 925
[INFO] 2021-07-12 18:50:29,552 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.239999599230941e-06, 925
[INFO] 2021-07-12 18:50:29,552 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 925
[INFO] 2021-07-12 18:50:29,553 [run_pretraining.py:  558]:	worker_index: 7, step: 925, cost: 8.078941, mlm loss: 8.078941, speed: 1.087263 steps/s, speed: 8.698102 samples/s, speed: 4453.428060 tokens/s, learning rate: 9.240e-06, loss_scalings: 13421.773438, pp_loss: 8.192591
[INFO] 2021-07-12 18:50:29,553 [run_pretraining.py:  512]:	********exe.run_925******* 
[INFO] 2021-07-12 18:50:30,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:30,476 [run_pretraining.py:  534]:	loss/total_loss, 5.562282085418701, 926
[INFO] 2021-07-12 18:50:30,476 [run_pretraining.py:  535]:	loss/mlm_loss, 5.562282085418701, 926
[INFO] 2021-07-12 18:50:30,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.249999493476935e-06, 926
[INFO] 2021-07-12 18:50:30,476 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 926
[INFO] 2021-07-12 18:50:30,476 [run_pretraining.py:  558]:	worker_index: 7, step: 926, cost: 5.562282, mlm loss: 5.562282, speed: 1.083164 steps/s, speed: 8.665315 samples/s, speed: 4436.641459 tokens/s, learning rate: 9.250e-06, loss_scalings: 13421.773438, pp_loss: 6.829006
[INFO] 2021-07-12 18:50:30,476 [run_pretraining.py:  512]:	********exe.run_926******* 
[INFO] 2021-07-12 18:50:31,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:31,399 [run_pretraining.py:  534]:	loss/total_loss, 8.59634017944336, 927
[INFO] 2021-07-12 18:50:31,399 [run_pretraining.py:  535]:	loss/mlm_loss, 8.59634017944336, 927
[INFO] 2021-07-12 18:50:31,399 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.26000029721763e-06, 927
[INFO] 2021-07-12 18:50:31,399 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 927
[INFO] 2021-07-12 18:50:31,399 [run_pretraining.py:  558]:	worker_index: 7, step: 927, cost: 8.596340, mlm loss: 8.596340, speed: 1.084163 steps/s, speed: 8.673303 samples/s, speed: 4440.730959 tokens/s, learning rate: 9.260e-06, loss_scalings: 13421.773438, pp_loss: 8.396580
[INFO] 2021-07-12 18:50:31,399 [run_pretraining.py:  512]:	********exe.run_927******* 
[INFO] 2021-07-12 18:50:32,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:32,322 [run_pretraining.py:  534]:	loss/total_loss, 8.265140533447266, 928
[INFO] 2021-07-12 18:50:32,322 [run_pretraining.py:  535]:	loss/mlm_loss, 8.265140533447266, 928
[INFO] 2021-07-12 18:50:32,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.269999281968921e-06, 928
[INFO] 2021-07-12 18:50:32,322 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 928
[INFO] 2021-07-12 18:50:32,322 [run_pretraining.py:  558]:	worker_index: 7, step: 928, cost: 8.265141, mlm loss: 8.265141, speed: 1.084113 steps/s, speed: 8.672906 samples/s, speed: 4440.527797 tokens/s, learning rate: 9.270e-06, loss_scalings: 13421.773438, pp_loss: 8.005865
[INFO] 2021-07-12 18:50:32,323 [run_pretraining.py:  512]:	********exe.run_928******* 
[INFO] 2021-07-12 18:50:33,241 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:33,241 [run_pretraining.py:  534]:	loss/total_loss, 8.355031967163086, 929
[INFO] 2021-07-12 18:50:33,242 [run_pretraining.py:  535]:	loss/mlm_loss, 8.355031967163086, 929
[INFO] 2021-07-12 18:50:33,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.280000085709617e-06, 929
[INFO] 2021-07-12 18:50:33,242 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 929
[INFO] 2021-07-12 18:50:33,242 [run_pretraining.py:  558]:	worker_index: 7, step: 929, cost: 8.355032, mlm loss: 8.355032, speed: 1.088516 steps/s, speed: 8.708124 samples/s, speed: 4458.559652 tokens/s, learning rate: 9.280e-06, loss_scalings: 13421.773438, pp_loss: 8.573093
[INFO] 2021-07-12 18:50:33,242 [run_pretraining.py:  512]:	********exe.run_929******* 
[INFO] 2021-07-12 18:50:34,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:34,160 [run_pretraining.py:  534]:	loss/total_loss, 7.920715808868408, 930
[INFO] 2021-07-12 18:50:34,160 [run_pretraining.py:  535]:	loss/mlm_loss, 7.920715808868408, 930
[INFO] 2021-07-12 18:50:34,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.28999997995561e-06, 930
[INFO] 2021-07-12 18:50:34,160 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 930
[INFO] 2021-07-12 18:50:34,161 [run_pretraining.py:  558]:	worker_index: 7, step: 930, cost: 7.920716, mlm loss: 7.920716, speed: 1.089210 steps/s, speed: 8.713683 samples/s, speed: 4461.405609 tokens/s, learning rate: 9.290e-06, loss_scalings: 13421.773438, pp_loss: 8.276606
[INFO] 2021-07-12 18:50:34,161 [run_pretraining.py:  512]:	********exe.run_930******* 
[INFO] 2021-07-12 18:50:35,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:35,074 [run_pretraining.py:  534]:	loss/total_loss, 7.796759605407715, 931
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  535]:	loss/mlm_loss, 7.796759605407715, 931
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.299999874201603e-06, 931
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 931
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  558]:	worker_index: 7, step: 931, cost: 7.796760, mlm loss: 7.796760, speed: 1.094588 steps/s, speed: 8.756700 samples/s, speed: 4483.430540 tokens/s, learning rate: 9.300e-06, loss_scalings: 13421.773438, pp_loss: 8.039856
[INFO] 2021-07-12 18:50:35,075 [run_pretraining.py:  512]:	********exe.run_931******* 
[INFO] 2021-07-12 18:50:35,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:35,982 [run_pretraining.py:  534]:	loss/total_loss, 8.460114479064941, 932
[INFO] 2021-07-12 18:50:35,982 [run_pretraining.py:  535]:	loss/mlm_loss, 8.460114479064941, 932
[INFO] 2021-07-12 18:50:35,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.309999768447597e-06, 932
[INFO] 2021-07-12 18:50:35,982 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 932
[INFO] 2021-07-12 18:50:35,982 [run_pretraining.py:  558]:	worker_index: 7, step: 932, cost: 8.460114, mlm loss: 8.460114, speed: 1.102463 steps/s, speed: 8.819704 samples/s, speed: 4515.688506 tokens/s, learning rate: 9.310e-06, loss_scalings: 13421.773438, pp_loss: 8.220432
[INFO] 2021-07-12 18:50:35,983 [run_pretraining.py:  512]:	********exe.run_932******* 
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  534]:	loss/total_loss, 8.204153060913086, 933
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  535]:	loss/mlm_loss, 8.204153060913086, 933
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.31999966269359e-06, 933
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 933
[INFO] 2021-07-12 18:50:36,902 [run_pretraining.py:  558]:	worker_index: 7, step: 933, cost: 8.204153, mlm loss: 8.204153, speed: 1.087711 steps/s, speed: 8.701690 samples/s, speed: 4455.265522 tokens/s, learning rate: 9.320e-06, loss_scalings: 13421.773438, pp_loss: 8.395705
[INFO] 2021-07-12 18:50:36,903 [run_pretraining.py:  512]:	********exe.run_933******* 
[INFO] 2021-07-12 18:50:37,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:37,827 [run_pretraining.py:  534]:	loss/total_loss, 8.20378303527832, 934
[INFO] 2021-07-12 18:50:37,827 [run_pretraining.py:  535]:	loss/mlm_loss, 8.20378303527832, 934
[INFO] 2021-07-12 18:50:37,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.329999556939583e-06, 934
[INFO] 2021-07-12 18:50:37,827 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 934
[INFO] 2021-07-12 18:50:37,827 [run_pretraining.py:  558]:	worker_index: 7, step: 934, cost: 8.203783, mlm loss: 8.203783, speed: 1.082427 steps/s, speed: 8.659416 samples/s, speed: 4433.621035 tokens/s, learning rate: 9.330e-06, loss_scalings: 13421.773438, pp_loss: 8.290489
[INFO] 2021-07-12 18:50:37,827 [run_pretraining.py:  512]:	********exe.run_934******* 
[INFO] 2021-07-12 18:50:38,753 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:38,753 [run_pretraining.py:  534]:	loss/total_loss, 8.36679744720459, 935
[INFO] 2021-07-12 18:50:38,753 [run_pretraining.py:  535]:	loss/mlm_loss, 8.36679744720459, 935
[INFO] 2021-07-12 18:50:38,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.340000360680278e-06, 935
[INFO] 2021-07-12 18:50:38,753 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 935
[INFO] 2021-07-12 18:50:38,753 [run_pretraining.py:  558]:	worker_index: 7, step: 935, cost: 8.366797, mlm loss: 8.366797, speed: 1.080126 steps/s, speed: 8.641012 samples/s, speed: 4424.198123 tokens/s, learning rate: 9.340e-06, loss_scalings: 13421.773438, pp_loss: 8.236197
[INFO] 2021-07-12 18:50:38,754 [run_pretraining.py:  512]:	********exe.run_935******* 
[INFO] 2021-07-12 18:50:39,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  534]:	loss/total_loss, 7.7443437576293945, 936
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7443437576293945, 936
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.350000254926272e-06, 936
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 936
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  558]:	worker_index: 7, step: 936, cost: 7.744344, mlm loss: 7.744344, speed: 0.883425 steps/s, speed: 7.067401 samples/s, speed: 3618.509551 tokens/s, learning rate: 9.350e-06, loss_scalings: 13421.773438, pp_loss: 8.196766
[INFO] 2021-07-12 18:50:39,886 [run_pretraining.py:  512]:	********exe.run_936******* 
[INFO] 2021-07-12 18:50:40,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:40,817 [run_pretraining.py:  534]:	loss/total_loss, 8.12570571899414, 937
[INFO] 2021-07-12 18:50:40,817 [run_pretraining.py:  535]:	loss/mlm_loss, 8.12570571899414, 937
[INFO] 2021-07-12 18:50:40,817 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.359999239677563e-06, 937
[INFO] 2021-07-12 18:50:40,817 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 937
[INFO] 2021-07-12 18:50:40,817 [run_pretraining.py:  558]:	worker_index: 7, step: 937, cost: 8.125706, mlm loss: 8.125706, speed: 1.074688 steps/s, speed: 8.597504 samples/s, speed: 4401.921893 tokens/s, learning rate: 9.360e-06, loss_scalings: 13421.773438, pp_loss: 7.903628
[INFO] 2021-07-12 18:50:40,817 [run_pretraining.py:  512]:	********exe.run_937******* 
[INFO] 2021-07-12 18:50:41,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:41,775 [run_pretraining.py:  534]:	loss/total_loss, 7.880098342895508, 938
[INFO] 2021-07-12 18:50:41,775 [run_pretraining.py:  535]:	loss/mlm_loss, 7.880098342895508, 938
[INFO] 2021-07-12 18:50:41,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.370000043418258e-06, 938
[INFO] 2021-07-12 18:50:41,776 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 938
[INFO] 2021-07-12 18:50:41,776 [run_pretraining.py:  558]:	worker_index: 7, step: 938, cost: 7.880098, mlm loss: 7.880098, speed: 1.044042 steps/s, speed: 8.352338 samples/s, speed: 4276.397042 tokens/s, learning rate: 9.370e-06, loss_scalings: 13421.773438, pp_loss: 8.111645
[INFO] 2021-07-12 18:50:41,776 [run_pretraining.py:  512]:	********exe.run_938******* 
[INFO] 2021-07-12 18:50:42,688 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:42,688 [run_pretraining.py:  534]:	loss/total_loss, 8.054821014404297, 939
[INFO] 2021-07-12 18:50:42,689 [run_pretraining.py:  535]:	loss/mlm_loss, 8.054821014404297, 939
[INFO] 2021-07-12 18:50:42,689 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.379999937664252e-06, 939
[INFO] 2021-07-12 18:50:42,689 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 939
[INFO] 2021-07-12 18:50:42,689 [run_pretraining.py:  558]:	worker_index: 7, step: 939, cost: 8.054821, mlm loss: 8.054821, speed: 1.095931 steps/s, speed: 8.767447 samples/s, speed: 4488.932967 tokens/s, learning rate: 9.380e-06, loss_scalings: 13421.773438, pp_loss: 8.024082
[INFO] 2021-07-12 18:50:42,689 [run_pretraining.py:  512]:	********exe.run_939******* 
[INFO] 2021-07-12 18:50:43,598 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:43,599 [run_pretraining.py:  534]:	loss/total_loss, 7.903543472290039, 940
[INFO] 2021-07-12 18:50:43,599 [run_pretraining.py:  535]:	loss/mlm_loss, 7.903543472290039, 940
[INFO] 2021-07-12 18:50:43,599 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.389999831910245e-06, 940
[INFO] 2021-07-12 18:50:43,599 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 940
[INFO] 2021-07-12 18:50:43,599 [run_pretraining.py:  558]:	worker_index: 7, step: 940, cost: 7.903543, mlm loss: 7.903543, speed: 1.099048 steps/s, speed: 8.792387 samples/s, speed: 4501.702349 tokens/s, learning rate: 9.390e-06, loss_scalings: 13421.773438, pp_loss: 7.742631
[INFO] 2021-07-12 18:50:43,599 [run_pretraining.py:  512]:	********exe.run_940******* 
[INFO] 2021-07-12 18:50:44,512 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:44,513 [run_pretraining.py:  534]:	loss/total_loss, 7.45698356628418, 941
[INFO] 2021-07-12 18:50:44,513 [run_pretraining.py:  535]:	loss/mlm_loss, 7.45698356628418, 941
[INFO] 2021-07-12 18:50:44,513 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.399999726156238e-06, 941
[INFO] 2021-07-12 18:50:44,513 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 941
[INFO] 2021-07-12 18:50:44,513 [run_pretraining.py:  558]:	worker_index: 7, step: 941, cost: 7.456984, mlm loss: 7.456984, speed: 1.095014 steps/s, speed: 8.760116 samples/s, speed: 4485.179263 tokens/s, learning rate: 9.400e-06, loss_scalings: 13421.773438, pp_loss: 7.727938
[INFO] 2021-07-12 18:50:44,513 [run_pretraining.py:  512]:	********exe.run_941******* 
[INFO] 2021-07-12 18:50:45,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:45,430 [run_pretraining.py:  534]:	loss/total_loss, 8.013280868530273, 942
[INFO] 2021-07-12 18:50:45,431 [run_pretraining.py:  535]:	loss/mlm_loss, 8.013280868530273, 942
[INFO] 2021-07-12 18:50:45,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.409999620402232e-06, 942
[INFO] 2021-07-12 18:50:45,431 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 942
[INFO] 2021-07-12 18:50:45,431 [run_pretraining.py:  558]:	worker_index: 7, step: 942, cost: 8.013281, mlm loss: 8.013281, speed: 1.090610 steps/s, speed: 8.724880 samples/s, speed: 4467.138637 tokens/s, learning rate: 9.410e-06, loss_scalings: 13421.773438, pp_loss: 8.088577
[INFO] 2021-07-12 18:50:45,431 [run_pretraining.py:  512]:	********exe.run_942******* 
[INFO] 2021-07-12 18:50:46,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:46,350 [run_pretraining.py:  534]:	loss/total_loss, 8.434427261352539, 943
[INFO] 2021-07-12 18:50:46,350 [run_pretraining.py:  535]:	loss/mlm_loss, 8.434427261352539, 943
[INFO] 2021-07-12 18:50:46,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.419999514648225e-06, 943
[INFO] 2021-07-12 18:50:46,350 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 943
[INFO] 2021-07-12 18:50:46,350 [run_pretraining.py:  558]:	worker_index: 7, step: 943, cost: 8.434427, mlm loss: 8.434427, speed: 1.088518 steps/s, speed: 8.708140 samples/s, speed: 4458.567752 tokens/s, learning rate: 9.420e-06, loss_scalings: 13421.773438, pp_loss: 7.231074
[INFO] 2021-07-12 18:50:46,350 [run_pretraining.py:  512]:	********exe.run_943******* 
[INFO] 2021-07-12 18:50:47,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:47,258 [run_pretraining.py:  534]:	loss/total_loss, 6.661838531494141, 944
[INFO] 2021-07-12 18:50:47,258 [run_pretraining.py:  535]:	loss/mlm_loss, 6.661838531494141, 944
[INFO] 2021-07-12 18:50:47,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.43000031838892e-06, 944
[INFO] 2021-07-12 18:50:47,258 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 944
[INFO] 2021-07-12 18:50:47,258 [run_pretraining.py:  558]:	worker_index: 7, step: 944, cost: 6.661839, mlm loss: 6.661839, speed: 1.101830 steps/s, speed: 8.814637 samples/s, speed: 4513.094163 tokens/s, learning rate: 9.430e-06, loss_scalings: 13421.773438, pp_loss: 7.827187
[INFO] 2021-07-12 18:50:47,258 [run_pretraining.py:  512]:	********exe.run_944******* 
[INFO] 2021-07-12 18:50:48,173 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:48,173 [run_pretraining.py:  534]:	loss/total_loss, 7.847872734069824, 945
[INFO] 2021-07-12 18:50:48,174 [run_pretraining.py:  535]:	loss/mlm_loss, 7.847872734069824, 945
[INFO] 2021-07-12 18:50:48,174 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.440000212634914e-06, 945
[INFO] 2021-07-12 18:50:48,174 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 945
[INFO] 2021-07-12 18:50:48,174 [run_pretraining.py:  558]:	worker_index: 7, step: 945, cost: 7.847873, mlm loss: 7.847873, speed: 1.093217 steps/s, speed: 8.745738 samples/s, speed: 4477.817869 tokens/s, learning rate: 9.440e-06, loss_scalings: 13421.773438, pp_loss: 8.025194
[INFO] 2021-07-12 18:50:48,174 [run_pretraining.py:  512]:	********exe.run_945******* 
[INFO] 2021-07-12 18:50:49,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:49,087 [run_pretraining.py:  534]:	loss/total_loss, 7.883271217346191, 946
[INFO] 2021-07-12 18:50:49,087 [run_pretraining.py:  535]:	loss/mlm_loss, 7.883271217346191, 946
[INFO] 2021-07-12 18:50:49,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.449999197386205e-06, 946
[INFO] 2021-07-12 18:50:49,087 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 946
[INFO] 2021-07-12 18:50:49,087 [run_pretraining.py:  558]:	worker_index: 7, step: 946, cost: 7.883271, mlm loss: 7.883271, speed: 1.095277 steps/s, speed: 8.762216 samples/s, speed: 4486.254457 tokens/s, learning rate: 9.450e-06, loss_scalings: 13421.773438, pp_loss: 7.924782
[INFO] 2021-07-12 18:50:49,087 [run_pretraining.py:  512]:	********exe.run_946******* 
[INFO] 2021-07-12 18:50:50,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:50,075 [run_pretraining.py:  534]:	loss/total_loss, 8.583276748657227, 947
[INFO] 2021-07-12 18:50:50,075 [run_pretraining.py:  535]:	loss/mlm_loss, 8.583276748657227, 947
[INFO] 2021-07-12 18:50:50,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.4600000011269e-06, 947
[INFO] 2021-07-12 18:50:50,075 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 947
[INFO] 2021-07-12 18:50:50,076 [run_pretraining.py:  558]:	worker_index: 7, step: 947, cost: 8.583277, mlm loss: 8.583277, speed: 1.012733 steps/s, speed: 8.101861 samples/s, speed: 4148.152762 tokens/s, learning rate: 9.460e-06, loss_scalings: 13421.773438, pp_loss: 8.198681
[INFO] 2021-07-12 18:50:50,076 [run_pretraining.py:  512]:	********exe.run_947******* 
[INFO] 2021-07-12 18:50:51,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:51,139 [run_pretraining.py:  534]:	loss/total_loss, 7.1514692306518555, 948
[INFO] 2021-07-12 18:50:51,139 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1514692306518555, 948
[INFO] 2021-07-12 18:50:51,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.469999895372894e-06, 948
[INFO] 2021-07-12 18:50:51,139 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 948
[INFO] 2021-07-12 18:50:51,139 [run_pretraining.py:  558]:	worker_index: 7, step: 948, cost: 7.151469, mlm loss: 7.151469, speed: 0.940755 steps/s, speed: 7.526041 samples/s, speed: 3853.332953 tokens/s, learning rate: 9.470e-06, loss_scalings: 13421.773438, pp_loss: 7.819385
[INFO] 2021-07-12 18:50:51,139 [run_pretraining.py:  512]:	********exe.run_948******* 
[INFO] 2021-07-12 18:50:52,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:52,204 [run_pretraining.py:  534]:	loss/total_loss, 8.11792278289795, 949
[INFO] 2021-07-12 18:50:52,204 [run_pretraining.py:  535]:	loss/mlm_loss, 8.11792278289795, 949
[INFO] 2021-07-12 18:50:52,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.479999789618887e-06, 949
[INFO] 2021-07-12 18:50:52,204 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 949
[INFO] 2021-07-12 18:50:52,205 [run_pretraining.py:  558]:	worker_index: 7, step: 949, cost: 8.117923, mlm loss: 8.117923, speed: 0.939239 steps/s, speed: 7.513915 samples/s, speed: 3847.124495 tokens/s, learning rate: 9.480e-06, loss_scalings: 13421.773438, pp_loss: 8.217291
[INFO] 2021-07-12 18:50:52,205 [run_pretraining.py:  512]:	********exe.run_949******* 
[INFO] 2021-07-12 18:50:53,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  534]:	loss/total_loss, 8.27385139465332, 950
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  535]:	loss/mlm_loss, 8.27385139465332, 950
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.48999968386488e-06, 950
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 950
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  558]:	worker_index: 7, step: 950, cost: 8.273851, mlm loss: 8.273851, speed: 0.949802 steps/s, speed: 7.598418 samples/s, speed: 3890.390071 tokens/s, learning rate: 9.490e-06, loss_scalings: 13421.773438, pp_loss: 8.366734
[INFO] 2021-07-12 18:50:53,258 [run_pretraining.py:  512]:	********exe.run_950******* 
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  534]:	loss/total_loss, 8.105602264404297, 951
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  535]:	loss/mlm_loss, 8.105602264404297, 951
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.499999578110874e-06, 951
[INFO] 2021-07-12 18:50:54,322 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 951
[INFO] 2021-07-12 18:50:54,323 [run_pretraining.py:  558]:	worker_index: 7, step: 951, cost: 8.105602, mlm loss: 8.105602, speed: 0.939963 steps/s, speed: 7.519704 samples/s, speed: 3850.088596 tokens/s, learning rate: 9.500e-06, loss_scalings: 13421.773438, pp_loss: 7.940727
[INFO] 2021-07-12 18:50:54,323 [run_pretraining.py:  512]:	********exe.run_951******* 
[INFO] 2021-07-12 18:50:55,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:55,389 [run_pretraining.py:  534]:	loss/total_loss, 7.854680061340332, 952
[INFO] 2021-07-12 18:50:55,389 [run_pretraining.py:  535]:	loss/mlm_loss, 7.854680061340332, 952
[INFO] 2021-07-12 18:50:55,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.509999472356867e-06, 952
[INFO] 2021-07-12 18:50:55,389 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 952
[INFO] 2021-07-12 18:50:55,390 [run_pretraining.py:  558]:	worker_index: 7, step: 952, cost: 7.854680, mlm loss: 7.854680, speed: 0.937827 steps/s, speed: 7.502620 samples/s, speed: 3841.341373 tokens/s, learning rate: 9.510e-06, loss_scalings: 13421.773438, pp_loss: 8.089430
[INFO] 2021-07-12 18:50:55,390 [run_pretraining.py:  512]:	********exe.run_952******* 
[INFO] 2021-07-12 18:50:56,467 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:56,467 [run_pretraining.py:  534]:	loss/total_loss, 7.880316257476807, 953
[INFO] 2021-07-12 18:50:56,467 [run_pretraining.py:  535]:	loss/mlm_loss, 7.880316257476807, 953
[INFO] 2021-07-12 18:50:56,467 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.520000276097562e-06, 953
[INFO] 2021-07-12 18:50:56,467 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 953
[INFO] 2021-07-12 18:50:56,468 [run_pretraining.py:  558]:	worker_index: 7, step: 953, cost: 7.880316, mlm loss: 7.880316, speed: 0.928231 steps/s, speed: 7.425847 samples/s, speed: 3802.033635 tokens/s, learning rate: 9.520e-06, loss_scalings: 13421.773438, pp_loss: 7.611533
[INFO] 2021-07-12 18:50:56,468 [run_pretraining.py:  512]:	********exe.run_953******* 
[INFO] 2021-07-12 18:50:57,552 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:57,553 [run_pretraining.py:  534]:	loss/total_loss, 8.080900192260742, 954
[INFO] 2021-07-12 18:50:57,553 [run_pretraining.py:  535]:	loss/mlm_loss, 8.080900192260742, 954
[INFO] 2021-07-12 18:50:57,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.529999260848854e-06, 954
[INFO] 2021-07-12 18:50:57,553 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 954
[INFO] 2021-07-12 18:50:57,553 [run_pretraining.py:  558]:	worker_index: 7, step: 954, cost: 8.080900, mlm loss: 8.080900, speed: 0.921512 steps/s, speed: 7.372096 samples/s, speed: 3774.512920 tokens/s, learning rate: 9.530e-06, loss_scalings: 13421.773438, pp_loss: 8.020294
[INFO] 2021-07-12 18:50:57,553 [run_pretraining.py:  512]:	********exe.run_954******* 
[INFO] 2021-07-12 18:50:58,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:58,623 [run_pretraining.py:  534]:	loss/total_loss, 8.555353164672852, 955
[INFO] 2021-07-12 18:50:58,623 [run_pretraining.py:  535]:	loss/mlm_loss, 8.555353164672852, 955
[INFO] 2021-07-12 18:50:58,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.539999155094847e-06, 955
[INFO] 2021-07-12 18:50:58,624 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 955
[INFO] 2021-07-12 18:50:58,624 [run_pretraining.py:  558]:	worker_index: 7, step: 955, cost: 8.555353, mlm loss: 8.555353, speed: 0.934906 steps/s, speed: 7.479246 samples/s, speed: 3829.373836 tokens/s, learning rate: 9.540e-06, loss_scalings: 13421.773438, pp_loss: 8.101894
[INFO] 2021-07-12 18:50:58,624 [run_pretraining.py:  512]:	********exe.run_955******* 
[INFO] 2021-07-12 18:50:59,690 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:50:59,690 [run_pretraining.py:  534]:	loss/total_loss, 7.389967441558838, 956
[INFO] 2021-07-12 18:50:59,690 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389967441558838, 956
[INFO] 2021-07-12 18:50:59,691 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.549999958835542e-06, 956
[INFO] 2021-07-12 18:50:59,691 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 956
[INFO] 2021-07-12 18:50:59,691 [run_pretraining.py:  558]:	worker_index: 7, step: 956, cost: 7.389967, mlm loss: 7.389967, speed: 0.937702 steps/s, speed: 7.501617 samples/s, speed: 3840.827815 tokens/s, learning rate: 9.550e-06, loss_scalings: 13421.773438, pp_loss: 7.924570
[INFO] 2021-07-12 18:50:59,691 [run_pretraining.py:  512]:	********exe.run_956******* 
[INFO] 2021-07-12 18:51:00,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:00,758 [run_pretraining.py:  534]:	loss/total_loss, 7.9184160232543945, 957
[INFO] 2021-07-12 18:51:00,759 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9184160232543945, 957
[INFO] 2021-07-12 18:51:00,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.559999853081536e-06, 957
[INFO] 2021-07-12 18:51:00,759 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 957
[INFO] 2021-07-12 18:51:00,759 [run_pretraining.py:  558]:	worker_index: 7, step: 957, cost: 7.918416, mlm loss: 7.918416, speed: 0.936816 steps/s, speed: 7.494524 samples/s, speed: 3837.196472 tokens/s, learning rate: 9.560e-06, loss_scalings: 13421.773438, pp_loss: 8.323753
[INFO] 2021-07-12 18:51:00,759 [run_pretraining.py:  512]:	********exe.run_957******* 
[INFO] 2021-07-12 18:51:01,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  534]:	loss/total_loss, 8.258549690246582, 958
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  535]:	loss/mlm_loss, 8.258549690246582, 958
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.569999747327529e-06, 958
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 958
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  558]:	worker_index: 7, step: 958, cost: 8.258550, mlm loss: 8.258550, speed: 0.930585 steps/s, speed: 7.444680 samples/s, speed: 3811.676284 tokens/s, learning rate: 9.570e-06, loss_scalings: 13421.773438, pp_loss: 8.196382
[INFO] 2021-07-12 18:51:01,834 [run_pretraining.py:  512]:	********exe.run_958******* 
[INFO] 2021-07-12 18:51:02,901 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:02,902 [run_pretraining.py:  534]:	loss/total_loss, 8.086648941040039, 959
[INFO] 2021-07-12 18:51:02,902 [run_pretraining.py:  535]:	loss/mlm_loss, 8.086648941040039, 959
[INFO] 2021-07-12 18:51:02,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.579999641573522e-06, 959
[INFO] 2021-07-12 18:51:02,902 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 959
[INFO] 2021-07-12 18:51:02,902 [run_pretraining.py:  558]:	worker_index: 7, step: 959, cost: 8.086649, mlm loss: 8.086649, speed: 0.936970 steps/s, speed: 7.495763 samples/s, speed: 3837.830797 tokens/s, learning rate: 9.580e-06, loss_scalings: 13421.773438, pp_loss: 7.326942
[INFO] 2021-07-12 18:51:02,902 [run_pretraining.py:  512]:	********exe.run_959******* 
[INFO] 2021-07-12 18:51:03,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:03,969 [run_pretraining.py:  534]:	loss/total_loss, 7.792793273925781, 960
[INFO] 2021-07-12 18:51:03,969 [run_pretraining.py:  535]:	loss/mlm_loss, 7.792793273925781, 960
[INFO] 2021-07-12 18:51:03,969 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.589999535819516e-06, 960
[INFO] 2021-07-12 18:51:03,969 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 960
[INFO] 2021-07-12 18:51:03,969 [run_pretraining.py:  558]:	worker_index: 7, step: 960, cost: 7.792793, mlm loss: 7.792793, speed: 0.937769 steps/s, speed: 7.502154 samples/s, speed: 3841.102611 tokens/s, learning rate: 9.590e-06, loss_scalings: 13421.773438, pp_loss: 7.864473
[INFO] 2021-07-12 18:51:03,969 [run_pretraining.py:  512]:	********exe.run_960******* 
[INFO] 2021-07-12 18:51:05,030 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:05,031 [run_pretraining.py:  534]:	loss/total_loss, 8.173444747924805, 961
[INFO] 2021-07-12 18:51:05,031 [run_pretraining.py:  535]:	loss/mlm_loss, 8.173444747924805, 961
[INFO] 2021-07-12 18:51:05,031 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.599999430065509e-06, 961
[INFO] 2021-07-12 18:51:05,031 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 961
[INFO] 2021-07-12 18:51:05,031 [run_pretraining.py:  558]:	worker_index: 7, step: 961, cost: 8.173445, mlm loss: 8.173445, speed: 0.941850 steps/s, speed: 7.534800 samples/s, speed: 3857.817717 tokens/s, learning rate: 9.600e-06, loss_scalings: 13421.773438, pp_loss: 7.845255
[INFO] 2021-07-12 18:51:05,032 [run_pretraining.py:  512]:	********exe.run_961******* 
[INFO] 2021-07-12 18:51:05,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  534]:	loss/total_loss, 8.361810684204102, 962
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  535]:	loss/mlm_loss, 8.361810684204102, 962
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.610000233806204e-06, 962
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 962
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  558]:	worker_index: 7, step: 962, cost: 8.361811, mlm loss: 8.361811, speed: 1.064955 steps/s, speed: 8.519640 samples/s, speed: 4362.055713 tokens/s, learning rate: 9.610e-06, loss_scalings: 13421.773438, pp_loss: 8.135727
[INFO] 2021-07-12 18:51:05,971 [run_pretraining.py:  512]:	********exe.run_962******* 
[INFO] 2021-07-12 18:51:06,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:06,886 [run_pretraining.py:  534]:	loss/total_loss, 8.100040435791016, 963
[INFO] 2021-07-12 18:51:06,886 [run_pretraining.py:  535]:	loss/mlm_loss, 8.100040435791016, 963
[INFO] 2021-07-12 18:51:06,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.619999218557496e-06, 963
[INFO] 2021-07-12 18:51:06,886 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 963
[INFO] 2021-07-12 18:51:06,886 [run_pretraining.py:  558]:	worker_index: 7, step: 963, cost: 8.100040, mlm loss: 8.100040, speed: 1.093612 steps/s, speed: 8.748899 samples/s, speed: 4479.436073 tokens/s, learning rate: 9.620e-06, loss_scalings: 13421.773438, pp_loss: 8.018063
[INFO] 2021-07-12 18:51:06,886 [run_pretraining.py:  512]:	********exe.run_963******* 
[INFO] 2021-07-12 18:51:07,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:07,803 [run_pretraining.py:  534]:	loss/total_loss, 7.98648738861084, 964
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  535]:	loss/mlm_loss, 7.98648738861084, 964
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.63000002229819e-06, 964
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 964
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  558]:	worker_index: 7, step: 964, cost: 7.986487, mlm loss: 7.986487, speed: 1.090524 steps/s, speed: 8.724191 samples/s, speed: 4466.785552 tokens/s, learning rate: 9.630e-06, loss_scalings: 13421.773438, pp_loss: 8.167708
[INFO] 2021-07-12 18:51:07,804 [run_pretraining.py:  512]:	********exe.run_964******* 
[INFO] 2021-07-12 18:51:08,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:08,719 [run_pretraining.py:  534]:	loss/total_loss, 7.861374378204346, 965
[INFO] 2021-07-12 18:51:08,719 [run_pretraining.py:  535]:	loss/mlm_loss, 7.861374378204346, 965
[INFO] 2021-07-12 18:51:08,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.639999916544184e-06, 965
[INFO] 2021-07-12 18:51:08,719 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 965
[INFO] 2021-07-12 18:51:08,719 [run_pretraining.py:  558]:	worker_index: 7, step: 965, cost: 7.861374, mlm loss: 7.861374, speed: 1.093346 steps/s, speed: 8.746768 samples/s, speed: 4478.345467 tokens/s, learning rate: 9.640e-06, loss_scalings: 13421.773438, pp_loss: 8.080738
[INFO] 2021-07-12 18:51:08,719 [run_pretraining.py:  512]:	********exe.run_965******* 
[INFO] 2021-07-12 18:51:09,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:09,631 [run_pretraining.py:  534]:	loss/total_loss, 8.342609405517578, 966
[INFO] 2021-07-12 18:51:09,631 [run_pretraining.py:  535]:	loss/mlm_loss, 8.342609405517578, 966
[INFO] 2021-07-12 18:51:09,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.649999810790177e-06, 966
[INFO] 2021-07-12 18:51:09,631 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 966
[INFO] 2021-07-12 18:51:09,631 [run_pretraining.py:  558]:	worker_index: 7, step: 966, cost: 8.342609, mlm loss: 8.342609, speed: 1.097508 steps/s, speed: 8.780063 samples/s, speed: 4495.392105 tokens/s, learning rate: 9.650e-06, loss_scalings: 13421.773438, pp_loss: 8.345295
[INFO] 2021-07-12 18:51:09,631 [run_pretraining.py:  512]:	********exe.run_966******* 
[INFO] 2021-07-12 18:51:10,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:10,540 [run_pretraining.py:  534]:	loss/total_loss, 8.280691146850586, 967
[INFO] 2021-07-12 18:51:10,541 [run_pretraining.py:  535]:	loss/mlm_loss, 8.280691146850586, 967
[INFO] 2021-07-12 18:51:10,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.65999970503617e-06, 967
[INFO] 2021-07-12 18:51:10,541 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 967
[INFO] 2021-07-12 18:51:10,541 [run_pretraining.py:  558]:	worker_index: 7, step: 967, cost: 8.280691, mlm loss: 8.280691, speed: 1.099787 steps/s, speed: 8.798296 samples/s, speed: 4504.727688 tokens/s, learning rate: 9.660e-06, loss_scalings: 13421.773438, pp_loss: 7.950737
[INFO] 2021-07-12 18:51:10,541 [run_pretraining.py:  512]:	********exe.run_967******* 
[INFO] 2021-07-12 18:51:11,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:11,474 [run_pretraining.py:  534]:	loss/total_loss, 7.730808734893799, 968
[INFO] 2021-07-12 18:51:11,474 [run_pretraining.py:  535]:	loss/mlm_loss, 7.730808734893799, 968
[INFO] 2021-07-12 18:51:11,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.669999599282164e-06, 968
[INFO] 2021-07-12 18:51:11,474 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 968
[INFO] 2021-07-12 18:51:11,475 [run_pretraining.py:  558]:	worker_index: 7, step: 968, cost: 7.730809, mlm loss: 7.730809, speed: 1.071684 steps/s, speed: 8.573469 samples/s, speed: 4389.616201 tokens/s, learning rate: 9.670e-06, loss_scalings: 13421.773438, pp_loss: 7.916667
[INFO] 2021-07-12 18:51:11,475 [run_pretraining.py:  512]:	********exe.run_968******* 
[INFO] 2021-07-12 18:51:12,381 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:12,382 [run_pretraining.py:  534]:	loss/total_loss, 4.877597808837891, 969
[INFO] 2021-07-12 18:51:12,382 [run_pretraining.py:  535]:	loss/mlm_loss, 4.877597808837891, 969
[INFO] 2021-07-12 18:51:12,382 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.679999493528157e-06, 969
[INFO] 2021-07-12 18:51:12,382 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 969
[INFO] 2021-07-12 18:51:12,382 [run_pretraining.py:  558]:	worker_index: 7, step: 969, cost: 4.877598, mlm loss: 4.877598, speed: 1.102413 steps/s, speed: 8.819308 samples/s, speed: 4515.485548 tokens/s, learning rate: 9.680e-06, loss_scalings: 13421.773438, pp_loss: 7.268897
[INFO] 2021-07-12 18:51:12,382 [run_pretraining.py:  512]:	********exe.run_969******* 
[INFO] 2021-07-12 18:51:13,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:13,284 [run_pretraining.py:  534]:	loss/total_loss, 8.693578720092773, 970
[INFO] 2021-07-12 18:51:13,284 [run_pretraining.py:  535]:	loss/mlm_loss, 8.693578720092773, 970
[INFO] 2021-07-12 18:51:13,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.690000297268853e-06, 970
[INFO] 2021-07-12 18:51:13,284 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 970
[INFO] 2021-07-12 18:51:13,284 [run_pretraining.py:  558]:	worker_index: 7, step: 970, cost: 8.693579, mlm loss: 8.693579, speed: 1.109506 steps/s, speed: 8.876052 samples/s, speed: 4544.538585 tokens/s, learning rate: 9.690e-06, loss_scalings: 13421.773438, pp_loss: 7.909236
[INFO] 2021-07-12 18:51:13,284 [run_pretraining.py:  512]:	********exe.run_970******* 
[INFO] 2021-07-12 18:51:14,195 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:14,196 [run_pretraining.py:  534]:	loss/total_loss, 8.701083183288574, 971
[INFO] 2021-07-12 18:51:14,196 [run_pretraining.py:  535]:	loss/mlm_loss, 8.701083183288574, 971
[INFO] 2021-07-12 18:51:14,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.700000191514846e-06, 971
[INFO] 2021-07-12 18:51:14,196 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 971
[INFO] 2021-07-12 18:51:14,196 [run_pretraining.py:  558]:	worker_index: 7, step: 971, cost: 8.701083, mlm loss: 8.701083, speed: 1.097505 steps/s, speed: 8.780040 samples/s, speed: 4495.380342 tokens/s, learning rate: 9.700e-06, loss_scalings: 13421.773438, pp_loss: 7.193583
[INFO] 2021-07-12 18:51:14,196 [run_pretraining.py:  512]:	********exe.run_971******* 
[INFO] 2021-07-12 18:51:15,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:15,104 [run_pretraining.py:  534]:	loss/total_loss, 8.058862686157227, 972
[INFO] 2021-07-12 18:51:15,104 [run_pretraining.py:  535]:	loss/mlm_loss, 8.058862686157227, 972
[INFO] 2021-07-12 18:51:15,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.709999176266138e-06, 972
[INFO] 2021-07-12 18:51:15,104 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 972
[INFO] 2021-07-12 18:51:15,104 [run_pretraining.py:  558]:	worker_index: 7, step: 972, cost: 8.058863, mlm loss: 8.058863, speed: 1.101838 steps/s, speed: 8.814707 samples/s, speed: 4513.129731 tokens/s, learning rate: 9.710e-06, loss_scalings: 13421.773438, pp_loss: 7.997454
[INFO] 2021-07-12 18:51:15,104 [run_pretraining.py:  512]:	********exe.run_972******* 
[INFO] 2021-07-12 18:51:16,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:16,016 [run_pretraining.py:  534]:	loss/total_loss, 7.693268299102783, 973
[INFO] 2021-07-12 18:51:16,017 [run_pretraining.py:  535]:	loss/mlm_loss, 7.693268299102783, 973
[INFO] 2021-07-12 18:51:16,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.719999980006833e-06, 973
[INFO] 2021-07-12 18:51:16,017 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 973
[INFO] 2021-07-12 18:51:16,017 [run_pretraining.py:  558]:	worker_index: 7, step: 973, cost: 7.693268, mlm loss: 7.693268, speed: 1.096711 steps/s, speed: 8.773685 samples/s, speed: 4492.126739 tokens/s, learning rate: 9.720e-06, loss_scalings: 13421.773438, pp_loss: 7.981417
[INFO] 2021-07-12 18:51:16,017 [run_pretraining.py:  512]:	********exe.run_973******* 
[INFO] 2021-07-12 18:51:16,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:16,942 [run_pretraining.py:  534]:	loss/total_loss, 7.325694561004639, 974
[INFO] 2021-07-12 18:51:16,942 [run_pretraining.py:  535]:	loss/mlm_loss, 7.325694561004639, 974
[INFO] 2021-07-12 18:51:16,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.729999874252826e-06, 974
[INFO] 2021-07-12 18:51:16,942 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 974
[INFO] 2021-07-12 18:51:16,942 [run_pretraining.py:  558]:	worker_index: 7, step: 974, cost: 7.325695, mlm loss: 7.325695, speed: 1.081758 steps/s, speed: 8.654063 samples/s, speed: 4430.880113 tokens/s, learning rate: 9.730e-06, loss_scalings: 13421.773438, pp_loss: 7.436466
[INFO] 2021-07-12 18:51:16,942 [run_pretraining.py:  512]:	********exe.run_974******* 
[INFO] 2021-07-12 18:51:17,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:17,845 [run_pretraining.py:  534]:	loss/total_loss, 7.918567180633545, 975
[INFO] 2021-07-12 18:51:17,845 [run_pretraining.py:  535]:	loss/mlm_loss, 7.918567180633545, 975
[INFO] 2021-07-12 18:51:17,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.73999976849882e-06, 975
[INFO] 2021-07-12 18:51:17,846 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 975
[INFO] 2021-07-12 18:51:17,846 [run_pretraining.py:  558]:	worker_index: 7, step: 975, cost: 7.918567, mlm loss: 7.918567, speed: 1.107323 steps/s, speed: 8.858587 samples/s, speed: 4535.596569 tokens/s, learning rate: 9.740e-06, loss_scalings: 13421.773438, pp_loss: 7.543090
[INFO] 2021-07-12 18:51:17,846 [run_pretraining.py:  512]:	********exe.run_975******* 
[INFO] 2021-07-12 18:51:18,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:18,758 [run_pretraining.py:  534]:	loss/total_loss, 8.043484687805176, 976
[INFO] 2021-07-12 18:51:18,758 [run_pretraining.py:  535]:	loss/mlm_loss, 8.043484687805176, 976
[INFO] 2021-07-12 18:51:18,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.749999662744813e-06, 976
[INFO] 2021-07-12 18:51:18,759 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 976
[INFO] 2021-07-12 18:51:18,759 [run_pretraining.py:  558]:	worker_index: 7, step: 976, cost: 8.043485, mlm loss: 8.043485, speed: 1.096111 steps/s, speed: 8.768891 samples/s, speed: 4489.672025 tokens/s, learning rate: 9.750e-06, loss_scalings: 13421.773438, pp_loss: 7.911586
[INFO] 2021-07-12 18:51:18,759 [run_pretraining.py:  512]:	********exe.run_976******* 
[INFO] 2021-07-12 18:51:19,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:19,664 [run_pretraining.py:  534]:	loss/total_loss, 8.28388500213623, 977
[INFO] 2021-07-12 18:51:19,664 [run_pretraining.py:  535]:	loss/mlm_loss, 8.28388500213623, 977
[INFO] 2021-07-12 18:51:19,664 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.759999556990806e-06, 977
[INFO] 2021-07-12 18:51:19,664 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 977
[INFO] 2021-07-12 18:51:19,664 [run_pretraining.py:  558]:	worker_index: 7, step: 977, cost: 8.283885, mlm loss: 8.283885, speed: 1.104872 steps/s, speed: 8.838974 samples/s, speed: 4525.554479 tokens/s, learning rate: 9.760e-06, loss_scalings: 13421.773438, pp_loss: 8.083776
[INFO] 2021-07-12 18:51:19,664 [run_pretraining.py:  512]:	********exe.run_977******* 
[INFO] 2021-07-12 18:51:20,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:20,570 [run_pretraining.py:  534]:	loss/total_loss, 8.040069580078125, 978
[INFO] 2021-07-12 18:51:20,570 [run_pretraining.py:  535]:	loss/mlm_loss, 8.040069580078125, 978
[INFO] 2021-07-12 18:51:20,570 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.7699994512368e-06, 978
[INFO] 2021-07-12 18:51:20,570 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 978
[INFO] 2021-07-12 18:51:20,570 [run_pretraining.py:  558]:	worker_index: 7, step: 978, cost: 8.040070, mlm loss: 8.040070, speed: 1.104669 steps/s, speed: 8.837351 samples/s, speed: 4524.723717 tokens/s, learning rate: 9.770e-06, loss_scalings: 13421.773438, pp_loss: 7.974833
[INFO] 2021-07-12 18:51:20,570 [run_pretraining.py:  512]:	********exe.run_978******* 
[INFO] 2021-07-12 18:51:21,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:21,476 [run_pretraining.py:  534]:	loss/total_loss, 7.819170951843262, 979
[INFO] 2021-07-12 18:51:21,476 [run_pretraining.py:  535]:	loss/mlm_loss, 7.819170951843262, 979
[INFO] 2021-07-12 18:51:21,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.780000254977494e-06, 979
[INFO] 2021-07-12 18:51:21,476 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 979
[INFO] 2021-07-12 18:51:21,476 [run_pretraining.py:  558]:	worker_index: 7, step: 979, cost: 7.819171, mlm loss: 7.819171, speed: 1.104781 steps/s, speed: 8.838252 samples/s, speed: 4525.184949 tokens/s, learning rate: 9.780e-06, loss_scalings: 13421.773438, pp_loss: 8.043080
[INFO] 2021-07-12 18:51:21,476 [run_pretraining.py:  512]:	********exe.run_979******* 
[INFO] 2021-07-12 18:51:22,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:22,384 [run_pretraining.py:  534]:	loss/total_loss, 8.048970222473145, 980
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  535]:	loss/mlm_loss, 8.048970222473145, 980
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.790000149223488e-06, 980
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 980
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  558]:	worker_index: 7, step: 980, cost: 8.048970, mlm loss: 8.048970, speed: 1.101172 steps/s, speed: 8.809372 samples/s, speed: 4510.398592 tokens/s, learning rate: 9.790e-06, loss_scalings: 13421.773438, pp_loss: 7.961855
[INFO] 2021-07-12 18:51:22,385 [run_pretraining.py:  512]:	********exe.run_980******* 
[INFO] 2021-07-12 18:51:23,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:23,301 [run_pretraining.py:  534]:	loss/total_loss, 7.7287797927856445, 981
[INFO] 2021-07-12 18:51:23,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7287797927856445, 981
[INFO] 2021-07-12 18:51:23,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.79999913397478e-06, 981
[INFO] 2021-07-12 18:51:23,301 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 981
[INFO] 2021-07-12 18:51:23,301 [run_pretraining.py:  558]:	worker_index: 7, step: 981, cost: 7.728780, mlm loss: 7.728780, speed: 1.092271 steps/s, speed: 8.738165 samples/s, speed: 4473.940578 tokens/s, learning rate: 9.800e-06, loss_scalings: 13421.773438, pp_loss: 8.033886
[INFO] 2021-07-12 18:51:23,301 [run_pretraining.py:  512]:	********exe.run_981******* 
[INFO] 2021-07-12 18:51:24,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:24,207 [run_pretraining.py:  534]:	loss/total_loss, 7.627322673797607, 982
[INFO] 2021-07-12 18:51:24,208 [run_pretraining.py:  535]:	loss/mlm_loss, 7.627322673797607, 982
[INFO] 2021-07-12 18:51:24,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.809999937715475e-06, 982
[INFO] 2021-07-12 18:51:24,208 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 982
[INFO] 2021-07-12 18:51:24,208 [run_pretraining.py:  558]:	worker_index: 7, step: 982, cost: 7.627323, mlm loss: 7.627323, speed: 1.103669 steps/s, speed: 8.829352 samples/s, speed: 4520.628005 tokens/s, learning rate: 9.810e-06, loss_scalings: 13421.773438, pp_loss: 7.808316
[INFO] 2021-07-12 18:51:24,208 [run_pretraining.py:  512]:	********exe.run_982******* 
[INFO] 2021-07-12 18:51:25,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:25,122 [run_pretraining.py:  534]:	loss/total_loss, 8.153573989868164, 983
[INFO] 2021-07-12 18:51:25,122 [run_pretraining.py:  535]:	loss/mlm_loss, 8.153573989868164, 983
[INFO] 2021-07-12 18:51:25,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.819999831961468e-06, 983
[INFO] 2021-07-12 18:51:25,122 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 983
[INFO] 2021-07-12 18:51:25,122 [run_pretraining.py:  558]:	worker_index: 7, step: 983, cost: 8.153574, mlm loss: 8.153574, speed: 1.094154 steps/s, speed: 8.753228 samples/s, speed: 4481.652784 tokens/s, learning rate: 9.820e-06, loss_scalings: 13421.773438, pp_loss: 7.888180
[INFO] 2021-07-12 18:51:25,122 [run_pretraining.py:  512]:	********exe.run_983******* 
[INFO] 2021-07-12 18:51:26,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:26,052 [run_pretraining.py:  534]:	loss/total_loss, 8.488502502441406, 984
[INFO] 2021-07-12 18:51:26,052 [run_pretraining.py:  535]:	loss/mlm_loss, 8.488502502441406, 984
[INFO] 2021-07-12 18:51:26,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.829999726207461e-06, 984
[INFO] 2021-07-12 18:51:26,052 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 984
[INFO] 2021-07-12 18:51:26,052 [run_pretraining.py:  558]:	worker_index: 7, step: 984, cost: 8.488503, mlm loss: 8.488503, speed: 1.076294 steps/s, speed: 8.610348 samples/s, speed: 4408.498249 tokens/s, learning rate: 9.830e-06, loss_scalings: 13421.773438, pp_loss: 8.259817
[INFO] 2021-07-12 18:51:26,052 [run_pretraining.py:  512]:	********exe.run_984******* 
[INFO] 2021-07-12 18:51:26,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:26,956 [run_pretraining.py:  534]:	loss/total_loss, 5.97877311706543, 985
[INFO] 2021-07-12 18:51:26,956 [run_pretraining.py:  535]:	loss/mlm_loss, 5.97877311706543, 985
[INFO] 2021-07-12 18:51:26,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.839999620453455e-06, 985
[INFO] 2021-07-12 18:51:26,956 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 985
[INFO] 2021-07-12 18:51:26,957 [run_pretraining.py:  558]:	worker_index: 7, step: 985, cost: 5.978773, mlm loss: 5.978773, speed: 1.106475 steps/s, speed: 8.851798 samples/s, speed: 4532.120709 tokens/s, learning rate: 9.840e-06, loss_scalings: 13421.773438, pp_loss: 7.267112
[INFO] 2021-07-12 18:51:26,957 [run_pretraining.py:  512]:	********exe.run_985******* 
[INFO] 2021-07-12 18:51:27,901 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:27,902 [run_pretraining.py:  534]:	loss/total_loss, 8.198762893676758, 986
[INFO] 2021-07-12 18:51:27,902 [run_pretraining.py:  535]:	loss/mlm_loss, 8.198762893676758, 986
[INFO] 2021-07-12 18:51:27,902 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.849999514699448e-06, 986
[INFO] 2021-07-12 18:51:27,902 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 986
[INFO] 2021-07-12 18:51:27,902 [run_pretraining.py:  558]:	worker_index: 7, step: 986, cost: 8.198763, mlm loss: 8.198763, speed: 1.058066 steps/s, speed: 8.464531 samples/s, speed: 4333.839671 tokens/s, learning rate: 9.850e-06, loss_scalings: 13421.773438, pp_loss: 8.057650
[INFO] 2021-07-12 18:51:27,902 [run_pretraining.py:  512]:	********exe.run_986******* 
[INFO] 2021-07-12 18:51:28,823 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:28,823 [run_pretraining.py:  534]:	loss/total_loss, 7.593945503234863, 987
[INFO] 2021-07-12 18:51:28,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.593945503234863, 987
[INFO] 2021-07-12 18:51:28,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.859999408945441e-06, 987
[INFO] 2021-07-12 18:51:28,823 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 987
[INFO] 2021-07-12 18:51:28,823 [run_pretraining.py:  558]:	worker_index: 7, step: 987, cost: 7.593946, mlm loss: 7.593946, speed: 1.086432 steps/s, speed: 8.691453 samples/s, speed: 4450.023930 tokens/s, learning rate: 9.860e-06, loss_scalings: 13421.773438, pp_loss: 6.879281
[INFO] 2021-07-12 18:51:28,824 [run_pretraining.py:  512]:	********exe.run_987******* 
[INFO] 2021-07-12 18:51:29,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:29,727 [run_pretraining.py:  534]:	loss/total_loss, 7.725541114807129, 988
[INFO] 2021-07-12 18:51:29,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.725541114807129, 988
[INFO] 2021-07-12 18:51:29,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.870000212686136e-06, 988
[INFO] 2021-07-12 18:51:29,727 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 988
[INFO] 2021-07-12 18:51:29,728 [run_pretraining.py:  558]:	worker_index: 7, step: 988, cost: 7.725541, mlm loss: 7.725541, speed: 1.106828 steps/s, speed: 8.854627 samples/s, speed: 4533.569034 tokens/s, learning rate: 9.870e-06, loss_scalings: 13421.773438, pp_loss: 7.829001
[INFO] 2021-07-12 18:51:29,728 [run_pretraining.py:  512]:	********exe.run_988******* 
[INFO] 2021-07-12 18:51:30,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:30,634 [run_pretraining.py:  534]:	loss/total_loss, 7.3613128662109375, 989
[INFO] 2021-07-12 18:51:30,634 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3613128662109375, 989
[INFO] 2021-07-12 18:51:30,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.88000010693213e-06, 989
[INFO] 2021-07-12 18:51:30,634 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 989
[INFO] 2021-07-12 18:51:30,634 [run_pretraining.py:  558]:	worker_index: 7, step: 989, cost: 7.361313, mlm loss: 7.361313, speed: 1.103880 steps/s, speed: 8.831041 samples/s, speed: 4521.492963 tokens/s, learning rate: 9.880e-06, loss_scalings: 13421.773438, pp_loss: 7.779183
[INFO] 2021-07-12 18:51:30,634 [run_pretraining.py:  512]:	********exe.run_989******* 
[INFO] 2021-07-12 18:51:31,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:31,542 [run_pretraining.py:  534]:	loss/total_loss, 8.171009063720703, 990
[INFO] 2021-07-12 18:51:31,542 [run_pretraining.py:  535]:	loss/mlm_loss, 8.171009063720703, 990
[INFO] 2021-07-12 18:51:31,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.889999091683421e-06, 990
[INFO] 2021-07-12 18:51:31,542 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 990
[INFO] 2021-07-12 18:51:31,542 [run_pretraining.py:  558]:	worker_index: 7, step: 990, cost: 8.171009, mlm loss: 8.171009, speed: 1.101774 steps/s, speed: 8.814195 samples/s, speed: 4512.867730 tokens/s, learning rate: 9.890e-06, loss_scalings: 13421.773438, pp_loss: 7.954534
[INFO] 2021-07-12 18:51:31,542 [run_pretraining.py:  512]:	********exe.run_990******* 
[INFO] 2021-07-12 18:51:32,455 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:32,455 [run_pretraining.py:  534]:	loss/total_loss, 7.7898173332214355, 991
[INFO] 2021-07-12 18:51:32,456 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7898173332214355, 991
[INFO] 2021-07-12 18:51:32,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.899999895424116e-06, 991
[INFO] 2021-07-12 18:51:32,456 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 991
[INFO] 2021-07-12 18:51:32,456 [run_pretraining.py:  558]:	worker_index: 7, step: 991, cost: 7.789817, mlm loss: 7.789817, speed: 1.095621 steps/s, speed: 8.764967 samples/s, speed: 4487.663060 tokens/s, learning rate: 9.900e-06, loss_scalings: 13421.773438, pp_loss: 8.007607
[INFO] 2021-07-12 18:51:32,456 [run_pretraining.py:  512]:	********exe.run_991******* 
[INFO] 2021-07-12 18:51:33,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:33,360 [run_pretraining.py:  534]:	loss/total_loss, 8.156877517700195, 992
[INFO] 2021-07-12 18:51:33,360 [run_pretraining.py:  535]:	loss/mlm_loss, 8.156877517700195, 992
[INFO] 2021-07-12 18:51:33,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.90999978967011e-06, 992
[INFO] 2021-07-12 18:51:33,360 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 992
[INFO] 2021-07-12 18:51:33,360 [run_pretraining.py:  558]:	worker_index: 7, step: 992, cost: 8.156878, mlm loss: 8.156878, speed: 1.106522 steps/s, speed: 8.852177 samples/s, speed: 4532.314404 tokens/s, learning rate: 9.910e-06, loss_scalings: 13421.773438, pp_loss: 8.238108
[INFO] 2021-07-12 18:51:33,360 [run_pretraining.py:  512]:	********exe.run_992******* 
[INFO] 2021-07-12 18:51:34,281 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:34,282 [run_pretraining.py:  534]:	loss/total_loss, 7.657712459564209, 993
[INFO] 2021-07-12 18:51:34,282 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657712459564209, 993
[INFO] 2021-07-12 18:51:34,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.919999683916103e-06, 993
[INFO] 2021-07-12 18:51:34,282 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 993
[INFO] 2021-07-12 18:51:34,282 [run_pretraining.py:  558]:	worker_index: 7, step: 993, cost: 7.657712, mlm loss: 7.657712, speed: 1.085684 steps/s, speed: 8.685475 samples/s, speed: 4446.963393 tokens/s, learning rate: 9.920e-06, loss_scalings: 13421.773438, pp_loss: 7.606474
[INFO] 2021-07-12 18:51:34,282 [run_pretraining.py:  512]:	********exe.run_993******* 
[INFO] 2021-07-12 18:51:35,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:35,189 [run_pretraining.py:  534]:	loss/total_loss, 8.167113304138184, 994
[INFO] 2021-07-12 18:51:35,189 [run_pretraining.py:  535]:	loss/mlm_loss, 8.167113304138184, 994
[INFO] 2021-07-12 18:51:35,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.929999578162096e-06, 994
[INFO] 2021-07-12 18:51:35,189 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 994
[INFO] 2021-07-12 18:51:35,190 [run_pretraining.py:  558]:	worker_index: 7, step: 994, cost: 8.167113, mlm loss: 8.167113, speed: 1.102561 steps/s, speed: 8.820490 samples/s, speed: 4516.090913 tokens/s, learning rate: 9.930e-06, loss_scalings: 13421.773438, pp_loss: 8.006023
[INFO] 2021-07-12 18:51:35,190 [run_pretraining.py:  512]:	********exe.run_994******* 
[INFO] 2021-07-12 18:51:36,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:36,123 [run_pretraining.py:  534]:	loss/total_loss, 8.006516456604004, 995
[INFO] 2021-07-12 18:51:36,123 [run_pretraining.py:  535]:	loss/mlm_loss, 8.006516456604004, 995
[INFO] 2021-07-12 18:51:36,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.93999947240809e-06, 995
[INFO] 2021-07-12 18:51:36,123 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 995
[INFO] 2021-07-12 18:51:36,123 [run_pretraining.py:  558]:	worker_index: 7, step: 995, cost: 8.006516, mlm loss: 8.006516, speed: 1.072043 steps/s, speed: 8.576342 samples/s, speed: 4391.087095 tokens/s, learning rate: 9.940e-06, loss_scalings: 13421.773438, pp_loss: 7.034796
[INFO] 2021-07-12 18:51:36,123 [run_pretraining.py:  512]:	********exe.run_995******* 
[INFO] 2021-07-12 18:51:37,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:37,033 [run_pretraining.py:  534]:	loss/total_loss, 7.735302448272705, 996
[INFO] 2021-07-12 18:51:37,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.735302448272705, 996
[INFO] 2021-07-12 18:51:37,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.949999366654083e-06, 996
[INFO] 2021-07-12 18:51:37,033 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 996
[INFO] 2021-07-12 18:51:37,033 [run_pretraining.py:  558]:	worker_index: 7, step: 996, cost: 7.735302, mlm loss: 7.735302, speed: 1.099139 steps/s, speed: 8.793109 samples/s, speed: 4502.071593 tokens/s, learning rate: 9.950e-06, loss_scalings: 13421.773438, pp_loss: 7.797036
[INFO] 2021-07-12 18:51:37,034 [run_pretraining.py:  512]:	********exe.run_996******* 
[INFO] 2021-07-12 18:51:37,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  534]:	loss/total_loss, 7.947515487670898, 997
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  535]:	loss/mlm_loss, 7.947515487670898, 997
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.960000170394778e-06, 997
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 997
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  558]:	worker_index: 7, step: 997, cost: 7.947515, mlm loss: 7.947515, speed: 1.090441 steps/s, speed: 8.723531 samples/s, speed: 4466.447619 tokens/s, learning rate: 9.960e-06, loss_scalings: 13421.773438, pp_loss: 7.953256
[INFO] 2021-07-12 18:51:37,951 [run_pretraining.py:  512]:	********exe.run_997******* 
[INFO] 2021-07-12 18:51:38,864 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:38,865 [run_pretraining.py:  534]:	loss/total_loss, 7.133890151977539, 998
[INFO] 2021-07-12 18:51:38,865 [run_pretraining.py:  535]:	loss/mlm_loss, 7.133890151977539, 998
[INFO] 2021-07-12 18:51:38,865 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.96999915514607e-06, 998
[INFO] 2021-07-12 18:51:38,865 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 998
[INFO] 2021-07-12 18:51:38,865 [run_pretraining.py:  558]:	worker_index: 7, step: 998, cost: 7.133890, mlm loss: 7.133890, speed: 1.095167 steps/s, speed: 8.761333 samples/s, speed: 4485.802297 tokens/s, learning rate: 9.970e-06, loss_scalings: 13421.773438, pp_loss: 7.712773
[INFO] 2021-07-12 18:51:38,865 [run_pretraining.py:  512]:	********exe.run_998******* 
[INFO] 2021-07-12 18:51:39,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:39,862 [run_pretraining.py:  534]:	loss/total_loss, 7.982561111450195, 999
[INFO] 2021-07-12 18:51:39,862 [run_pretraining.py:  535]:	loss/mlm_loss, 7.982561111450195, 999
[INFO] 2021-07-12 18:51:39,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.979999958886765e-06, 999
[INFO] 2021-07-12 18:51:39,862 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 999
[INFO] 2021-07-12 18:51:39,862 [run_pretraining.py:  558]:	worker_index: 7, step: 999, cost: 7.982561, mlm loss: 7.982561, speed: 1.003279 steps/s, speed: 8.026232 samples/s, speed: 4109.430613 tokens/s, learning rate: 9.980e-06, loss_scalings: 13421.773438, pp_loss: 8.011169
[INFO] 2021-07-12 18:51:39,862 [run_pretraining.py:  512]:	********exe.run_999******* 
[INFO] 2021-07-12 18:51:40,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  534]:	loss/total_loss, 8.1618070602417, 1000
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  535]:	loss/mlm_loss, 8.1618070602417, 1000
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.989999853132758e-06, 1000
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1000
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  558]:	worker_index: 7, step: 1000, cost: 8.161807, mlm loss: 8.161807, speed: 1.100748 steps/s, speed: 8.805988 samples/s, speed: 4508.665649 tokens/s, learning rate: 9.990e-06, loss_scalings: 13421.773438, pp_loss: 8.026635
[INFO] 2021-07-12 18:51:40,771 [run_pretraining.py:  512]:	********exe.run_1000******* 
[INFO] 2021-07-12 18:51:41,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:41,687 [run_pretraining.py:  534]:	loss/total_loss, 7.581797122955322, 1001
[INFO] 2021-07-12 18:51:41,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.581797122955322, 1001
[INFO] 2021-07-12 18:51:41,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 9.999999747378752e-06, 1001
[INFO] 2021-07-12 18:51:41,687 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1001
[INFO] 2021-07-12 18:51:41,687 [run_pretraining.py:  558]:	worker_index: 7, step: 1001, cost: 7.581797, mlm loss: 7.581797, speed: 1.092635 steps/s, speed: 8.741081 samples/s, speed: 4475.433560 tokens/s, learning rate: 1.000e-05, loss_scalings: 13421.773438, pp_loss: 7.733162
[INFO] 2021-07-12 18:51:41,687 [run_pretraining.py:  512]:	********exe.run_1001******* 
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  534]:	loss/total_loss, 6.784934997558594, 1002
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  535]:	loss/mlm_loss, 6.784934997558594, 1002
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0009999641624745e-05, 1002
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1002
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  558]:	worker_index: 7, step: 1002, cost: 6.784935, mlm loss: 6.784935, speed: 1.099546 steps/s, speed: 8.796368 samples/s, speed: 4503.740436 tokens/s, learning rate: 1.001e-05, loss_scalings: 13421.773438, pp_loss: 7.637360
[INFO] 2021-07-12 18:51:42,597 [run_pretraining.py:  512]:	********exe.run_1002******* 
[INFO] 2021-07-12 18:51:43,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:51:43,513 [run_pretraining.py:  534]:	loss/total_loss, 8.16475772857666, 1003
[INFO] 2021-07-12 18:51:43,513 [run_pretraining.py:  535]:	loss/mlm_loss, 8.16475772857666, 1003
[INFO] 2021-07-12 18:51:43,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0019999535870738e-05, 1003
[INFO] 2021-07-12 18:51:43,514 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1003
[INFO] 2021-07-12 18:51:43,514 [run_pretraining.py:  558]:	worker_index: 7, step: 1003, cost: 8.164758, mlm loss: 8.164758, speed: 1.092138 steps/s, speed: 8.737100 samples/s, speed: 4473.395381 tokens/s, learning rate: 1.002e-05, loss_scalings: 13421.773438, pp_loss: 7.913629
[INFO] 2021-07-12 18:51:43,514 [run_pretraining.py:  512]:	********exe.run_1003******* 
[INFO] 2021-07-12 18:52:09,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:09,835 [run_pretraining.py:  534]:	loss/total_loss, 7.976138114929199, 1004
[INFO] 2021-07-12 18:52:09,835 [run_pretraining.py:  535]:	loss/mlm_loss, 7.976138114929199, 1004
[INFO] 2021-07-12 18:52:09,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0029999430116732e-05, 1004
[INFO] 2021-07-12 18:52:09,835 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1004
[INFO] 2021-07-12 18:52:09,835 [run_pretraining.py:  558]:	worker_index: 7, step: 1004, cost: 7.976138, mlm loss: 7.976138, speed: 0.037992 steps/s, speed: 0.303939 samples/s, speed: 155.616773 tokens/s, learning rate: 1.003e-05, loss_scalings: 13421.773438, pp_loss: 7.229238
[INFO] 2021-07-12 18:52:09,836 [run_pretraining.py:  512]:	********exe.run_1004******* 
[INFO] 2021-07-12 18:52:10,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:10,763 [run_pretraining.py:  534]:	loss/total_loss, 7.850172996520996, 1005
[INFO] 2021-07-12 18:52:10,763 [run_pretraining.py:  535]:	loss/mlm_loss, 7.850172996520996, 1005
[INFO] 2021-07-12 18:52:10,763 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0040000233857427e-05, 1005
[INFO] 2021-07-12 18:52:10,763 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1005
[INFO] 2021-07-12 18:52:10,764 [run_pretraining.py:  558]:	worker_index: 7, step: 1005, cost: 7.850173, mlm loss: 7.850173, speed: 1.078175 steps/s, speed: 8.625399 samples/s, speed: 4416.204247 tokens/s, learning rate: 1.004e-05, loss_scalings: 13421.773438, pp_loss: 8.022365
[INFO] 2021-07-12 18:52:10,764 [run_pretraining.py:  512]:	********exe.run_1005******* 
[INFO] 2021-07-12 18:52:11,684 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:11,684 [run_pretraining.py:  534]:	loss/total_loss, 7.195306301116943, 1006
[INFO] 2021-07-12 18:52:11,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195306301116943, 1006
[INFO] 2021-07-12 18:52:11,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.005000012810342e-05, 1006
[INFO] 2021-07-12 18:52:11,684 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1006
[INFO] 2021-07-12 18:52:11,685 [run_pretraining.py:  558]:	worker_index: 7, step: 1006, cost: 7.195306, mlm loss: 7.195306, speed: 1.086602 steps/s, speed: 8.692820 samples/s, speed: 4450.723710 tokens/s, learning rate: 1.005e-05, loss_scalings: 13421.773438, pp_loss: 7.612029
[INFO] 2021-07-12 18:52:11,685 [run_pretraining.py:  512]:	********exe.run_1006******* 
[INFO] 2021-07-12 18:52:12,594 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:12,594 [run_pretraining.py:  534]:	loss/total_loss, 7.15366268157959, 1007
[INFO] 2021-07-12 18:52:12,594 [run_pretraining.py:  535]:	loss/mlm_loss, 7.15366268157959, 1007
[INFO] 2021-07-12 18:52:12,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0059999112854712e-05, 1007
[INFO] 2021-07-12 18:52:12,594 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1007
[INFO] 2021-07-12 18:52:12,594 [run_pretraining.py:  558]:	worker_index: 7, step: 1007, cost: 7.153663, mlm loss: 7.153663, speed: 1.099782 steps/s, speed: 8.798257 samples/s, speed: 4504.707608 tokens/s, learning rate: 1.006e-05, loss_scalings: 13421.773438, pp_loss: 7.498991
[INFO] 2021-07-12 18:52:12,595 [run_pretraining.py:  512]:	********exe.run_1007******* 
[INFO] 2021-07-12 18:52:13,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:13,519 [run_pretraining.py:  534]:	loss/total_loss, 7.7964019775390625, 1008
[INFO] 2021-07-12 18:52:13,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7964019775390625, 1008
[INFO] 2021-07-12 18:52:13,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0069999916595407e-05, 1008
[INFO] 2021-07-12 18:52:13,519 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1008
[INFO] 2021-07-12 18:52:13,519 [run_pretraining.py:  558]:	worker_index: 7, step: 1008, cost: 7.796402, mlm loss: 7.796402, speed: 1.081936 steps/s, speed: 8.655485 samples/s, speed: 4431.608179 tokens/s, learning rate: 1.007e-05, loss_scalings: 13421.773438, pp_loss: 8.062211
[INFO] 2021-07-12 18:52:13,519 [run_pretraining.py:  512]:	********exe.run_1008******* 
[INFO] 2021-07-12 18:52:14,440 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:14,441 [run_pretraining.py:  534]:	loss/total_loss, 7.639149188995361, 1009
[INFO] 2021-07-12 18:52:14,441 [run_pretraining.py:  535]:	loss/mlm_loss, 7.639149188995361, 1009
[INFO] 2021-07-12 18:52:14,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.00799998108414e-05, 1009
[INFO] 2021-07-12 18:52:14,441 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1009
[INFO] 2021-07-12 18:52:14,441 [run_pretraining.py:  558]:	worker_index: 7, step: 1009, cost: 7.639149, mlm loss: 7.639149, speed: 1.085959 steps/s, speed: 8.687670 samples/s, speed: 4448.087136 tokens/s, learning rate: 1.008e-05, loss_scalings: 13421.773438, pp_loss: 7.829911
[INFO] 2021-07-12 18:52:14,441 [run_pretraining.py:  512]:	********exe.run_1009******* 
[INFO] 2021-07-12 18:52:15,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:15,358 [run_pretraining.py:  534]:	loss/total_loss, 8.326539039611816, 1010
[INFO] 2021-07-12 18:52:15,358 [run_pretraining.py:  535]:	loss/mlm_loss, 8.326539039611816, 1010
[INFO] 2021-07-12 18:52:15,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0089999705087394e-05, 1010
[INFO] 2021-07-12 18:52:15,358 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1010
[INFO] 2021-07-12 18:52:15,358 [run_pretraining.py:  558]:	worker_index: 7, step: 1010, cost: 8.326539, mlm loss: 8.326539, speed: 1.091288 steps/s, speed: 8.730306 samples/s, speed: 4469.916474 tokens/s, learning rate: 1.009e-05, loss_scalings: 13421.773438, pp_loss: 7.713232
[INFO] 2021-07-12 18:52:15,358 [run_pretraining.py:  512]:	********exe.run_1010******* 
[INFO] 2021-07-12 18:52:16,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:16,264 [run_pretraining.py:  534]:	loss/total_loss, 7.886610507965088, 1011
[INFO] 2021-07-12 18:52:16,264 [run_pretraining.py:  535]:	loss/mlm_loss, 7.886610507965088, 1011
[INFO] 2021-07-12 18:52:16,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0100000508828089e-05, 1011
[INFO] 2021-07-12 18:52:16,264 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1011
[INFO] 2021-07-12 18:52:16,264 [run_pretraining.py:  558]:	worker_index: 7, step: 1011, cost: 7.886611, mlm loss: 7.886611, speed: 1.104054 steps/s, speed: 8.832436 samples/s, speed: 4522.207071 tokens/s, learning rate: 1.010e-05, loss_scalings: 13421.773438, pp_loss: 7.985706
[INFO] 2021-07-12 18:52:16,264 [run_pretraining.py:  512]:	********exe.run_1011******* 
[INFO] 2021-07-12 18:52:17,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:17,171 [run_pretraining.py:  534]:	loss/total_loss, 8.262989044189453, 1012
[INFO] 2021-07-12 18:52:17,171 [run_pretraining.py:  535]:	loss/mlm_loss, 8.262989044189453, 1012
[INFO] 2021-07-12 18:52:17,171 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.010999949357938e-05, 1012
[INFO] 2021-07-12 18:52:17,171 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1012
[INFO] 2021-07-12 18:52:17,172 [run_pretraining.py:  558]:	worker_index: 7, step: 1012, cost: 8.262989, mlm loss: 8.262989, speed: 1.102976 steps/s, speed: 8.823809 samples/s, speed: 4517.790364 tokens/s, learning rate: 1.011e-05, loss_scalings: 13421.773438, pp_loss: 8.246181
[INFO] 2021-07-12 18:52:17,172 [run_pretraining.py:  512]:	********exe.run_1012******* 
[INFO] 2021-07-12 18:52:18,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:18,087 [run_pretraining.py:  534]:	loss/total_loss, 8.808980941772461, 1013
[INFO] 2021-07-12 18:52:18,087 [run_pretraining.py:  535]:	loss/mlm_loss, 8.808980941772461, 1013
[INFO] 2021-07-12 18:52:18,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0119999387825374e-05, 1013
[INFO] 2021-07-12 18:52:18,087 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1013
[INFO] 2021-07-12 18:52:18,087 [run_pretraining.py:  558]:	worker_index: 7, step: 1013, cost: 8.808981, mlm loss: 8.808981, speed: 1.093312 steps/s, speed: 8.746493 samples/s, speed: 4478.204217 tokens/s, learning rate: 1.012e-05, loss_scalings: 13421.773438, pp_loss: 7.959134
[INFO] 2021-07-12 18:52:18,087 [run_pretraining.py:  512]:	********exe.run_1013******* 
[INFO] 2021-07-12 18:52:18,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:18,991 [run_pretraining.py:  534]:	loss/total_loss, 7.407736301422119, 1014
[INFO] 2021-07-12 18:52:18,991 [run_pretraining.py:  535]:	loss/mlm_loss, 7.407736301422119, 1014
[INFO] 2021-07-12 18:52:18,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0130000191566069e-05, 1014
[INFO] 2021-07-12 18:52:18,991 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1014
[INFO] 2021-07-12 18:52:18,991 [run_pretraining.py:  558]:	worker_index: 7, step: 1014, cost: 7.407736, mlm loss: 7.407736, speed: 1.106505 steps/s, speed: 8.852041 samples/s, speed: 4532.245054 tokens/s, learning rate: 1.013e-05, loss_scalings: 13421.773438, pp_loss: 6.772659
[INFO] 2021-07-12 18:52:18,991 [run_pretraining.py:  512]:	********exe.run_1014******* 
[INFO] 2021-07-12 18:52:19,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:19,904 [run_pretraining.py:  534]:	loss/total_loss, 7.3362717628479, 1015
[INFO] 2021-07-12 18:52:19,904 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3362717628479, 1015
[INFO] 2021-07-12 18:52:19,904 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0140000085812062e-05, 1015
[INFO] 2021-07-12 18:52:19,904 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1015
[INFO] 2021-07-12 18:52:19,904 [run_pretraining.py:  558]:	worker_index: 7, step: 1015, cost: 7.336272, mlm loss: 7.336272, speed: 1.096217 steps/s, speed: 8.769739 samples/s, speed: 4490.106188 tokens/s, learning rate: 1.014e-05, loss_scalings: 13421.773438, pp_loss: 7.875197
[INFO] 2021-07-12 18:52:19,904 [run_pretraining.py:  512]:	********exe.run_1015******* 
[INFO] 2021-07-12 18:52:20,817 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:20,818 [run_pretraining.py:  534]:	loss/total_loss, 7.698577880859375, 1016
[INFO] 2021-07-12 18:52:20,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.698577880859375, 1016
[INFO] 2021-07-12 18:52:20,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0149999070563354e-05, 1016
[INFO] 2021-07-12 18:52:20,818 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1016
[INFO] 2021-07-12 18:52:20,818 [run_pretraining.py:  558]:	worker_index: 7, step: 1016, cost: 7.698578, mlm loss: 7.698578, speed: 1.095169 steps/s, speed: 8.761349 samples/s, speed: 4485.810496 tokens/s, learning rate: 1.015e-05, loss_scalings: 13421.773438, pp_loss: 7.837747
[INFO] 2021-07-12 18:52:20,818 [run_pretraining.py:  512]:	********exe.run_1016******* 
[INFO] 2021-07-12 18:52:21,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:21,726 [run_pretraining.py:  534]:	loss/total_loss, 7.472699165344238, 1017
[INFO] 2021-07-12 18:52:21,726 [run_pretraining.py:  535]:	loss/mlm_loss, 7.472699165344238, 1017
[INFO] 2021-07-12 18:52:21,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0159999874304049e-05, 1017
[INFO] 2021-07-12 18:52:21,727 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1017
[INFO] 2021-07-12 18:52:21,727 [run_pretraining.py:  558]:	worker_index: 7, step: 1017, cost: 7.472699, mlm loss: 7.472699, speed: 1.101144 steps/s, speed: 8.809153 samples/s, speed: 4510.286099 tokens/s, learning rate: 1.016e-05, loss_scalings: 13421.773438, pp_loss: 7.548347
[INFO] 2021-07-12 18:52:21,727 [run_pretraining.py:  512]:	********exe.run_1017******* 
[INFO] 2021-07-12 18:52:22,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:22,634 [run_pretraining.py:  534]:	loss/total_loss, 7.720585823059082, 1018
[INFO] 2021-07-12 18:52:22,634 [run_pretraining.py:  535]:	loss/mlm_loss, 7.720585823059082, 1018
[INFO] 2021-07-12 18:52:22,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0169999768550042e-05, 1018
[INFO] 2021-07-12 18:52:22,635 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1018
[INFO] 2021-07-12 18:52:22,635 [run_pretraining.py:  558]:	worker_index: 7, step: 1018, cost: 7.720586, mlm loss: 7.720586, speed: 1.102194 steps/s, speed: 8.817553 samples/s, speed: 4514.587296 tokens/s, learning rate: 1.017e-05, loss_scalings: 13421.773438, pp_loss: 7.633322
[INFO] 2021-07-12 18:52:22,635 [run_pretraining.py:  512]:	********exe.run_1018******* 
[INFO] 2021-07-12 18:52:23,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:23,534 [run_pretraining.py:  534]:	loss/total_loss, 8.065837860107422, 1019
[INFO] 2021-07-12 18:52:23,534 [run_pretraining.py:  535]:	loss/mlm_loss, 8.065837860107422, 1019
[INFO] 2021-07-12 18:52:23,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0179999662796035e-05, 1019
[INFO] 2021-07-12 18:52:23,535 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1019
[INFO] 2021-07-12 18:52:23,535 [run_pretraining.py:  558]:	worker_index: 7, step: 1019, cost: 8.065838, mlm loss: 8.065838, speed: 1.111938 steps/s, speed: 8.895500 samples/s, speed: 4554.496150 tokens/s, learning rate: 1.018e-05, loss_scalings: 13421.773438, pp_loss: 7.889356
[INFO] 2021-07-12 18:52:23,535 [run_pretraining.py:  512]:	********exe.run_1019******* 
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  534]:	loss/total_loss, 4.849348545074463, 1020
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  535]:	loss/mlm_loss, 4.849348545074463, 1020
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0189999557042029e-05, 1020
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1020
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  558]:	worker_index: 7, step: 1020, cost: 4.849349, mlm loss: 4.849349, speed: 1.101160 steps/s, speed: 8.809282 samples/s, speed: 4510.352410 tokens/s, learning rate: 1.019e-05, loss_scalings: 13421.773438, pp_loss: 7.433057
[INFO] 2021-07-12 18:52:24,443 [run_pretraining.py:  512]:	********exe.run_1020******* 
[INFO] 2021-07-12 18:52:25,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:25,419 [run_pretraining.py:  534]:	loss/total_loss, 8.26207160949707, 1021
[INFO] 2021-07-12 18:52:25,419 [run_pretraining.py:  535]:	loss/mlm_loss, 8.26207160949707, 1021
[INFO] 2021-07-12 18:52:25,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0199999451288022e-05, 1021
[INFO] 2021-07-12 18:52:25,419 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1021
[INFO] 2021-07-12 18:52:25,419 [run_pretraining.py:  558]:	worker_index: 7, step: 1021, cost: 8.262072, mlm loss: 8.262072, speed: 1.025647 steps/s, speed: 8.205179 samples/s, speed: 4201.051734 tokens/s, learning rate: 1.020e-05, loss_scalings: 13421.773438, pp_loss: 8.008872
[INFO] 2021-07-12 18:52:25,419 [run_pretraining.py:  512]:	********exe.run_1021******* 
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  534]:	loss/total_loss, 8.257631301879883, 1022
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  535]:	loss/mlm_loss, 8.257631301879883, 1022
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0209999345534015e-05, 1022
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1022
[INFO] 2021-07-12 18:52:26,474 [run_pretraining.py:  558]:	worker_index: 7, step: 1022, cost: 8.257631, mlm loss: 8.257631, speed: 0.948054 steps/s, speed: 7.584429 samples/s, speed: 3883.227693 tokens/s, learning rate: 1.021e-05, loss_scalings: 13421.773438, pp_loss: 7.945798
[INFO] 2021-07-12 18:52:26,475 [run_pretraining.py:  512]:	********exe.run_1022******* 
[INFO] 2021-07-12 18:52:27,538 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:27,539 [run_pretraining.py:  534]:	loss/total_loss, 7.667778491973877, 1023
[INFO] 2021-07-12 18:52:27,539 [run_pretraining.py:  535]:	loss/mlm_loss, 7.667778491973877, 1023
[INFO] 2021-07-12 18:52:27,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.022000014927471e-05, 1023
[INFO] 2021-07-12 18:52:27,539 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1023
[INFO] 2021-07-12 18:52:27,539 [run_pretraining.py:  558]:	worker_index: 7, step: 1023, cost: 7.667778, mlm loss: 7.667778, speed: 0.939720 steps/s, speed: 7.517762 samples/s, speed: 3849.094019 tokens/s, learning rate: 1.022e-05, loss_scalings: 13421.773438, pp_loss: 8.109202
[INFO] 2021-07-12 18:52:27,539 [run_pretraining.py:  512]:	********exe.run_1023******* 
[INFO] 2021-07-12 18:52:28,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:28,597 [run_pretraining.py:  534]:	loss/total_loss, 8.073197364807129, 1024
[INFO] 2021-07-12 18:52:28,597 [run_pretraining.py:  535]:	loss/mlm_loss, 8.073197364807129, 1024
[INFO] 2021-07-12 18:52:28,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0230000043520704e-05, 1024
[INFO] 2021-07-12 18:52:28,597 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1024
[INFO] 2021-07-12 18:52:28,597 [run_pretraining.py:  558]:	worker_index: 7, step: 1024, cost: 8.073197, mlm loss: 8.073197, speed: 0.945898 steps/s, speed: 7.567186 samples/s, speed: 3874.399313 tokens/s, learning rate: 1.023e-05, loss_scalings: 13421.773438, pp_loss: 7.838717
[INFO] 2021-07-12 18:52:28,597 [run_pretraining.py:  512]:	********exe.run_1024******* 
[INFO] 2021-07-12 18:52:29,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:29,659 [run_pretraining.py:  534]:	loss/total_loss, 7.7213134765625, 1025
[INFO] 2021-07-12 18:52:29,659 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7213134765625, 1025
[INFO] 2021-07-12 18:52:29,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0239999028271995e-05, 1025
[INFO] 2021-07-12 18:52:29,659 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1025
[INFO] 2021-07-12 18:52:29,659 [run_pretraining.py:  558]:	worker_index: 7, step: 1025, cost: 7.721313, mlm loss: 7.721313, speed: 0.942416 steps/s, speed: 7.539327 samples/s, speed: 3860.135570 tokens/s, learning rate: 1.024e-05, loss_scalings: 13421.773438, pp_loss: 7.987285
[INFO] 2021-07-12 18:52:29,659 [run_pretraining.py:  512]:	********exe.run_1025******* 
[INFO] 2021-07-12 18:52:30,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:30,722 [run_pretraining.py:  534]:	loss/total_loss, 7.890069007873535, 1026
[INFO] 2021-07-12 18:52:30,722 [run_pretraining.py:  535]:	loss/mlm_loss, 7.890069007873535, 1026
[INFO] 2021-07-12 18:52:30,722 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.024999983201269e-05, 1026
[INFO] 2021-07-12 18:52:30,722 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1026
[INFO] 2021-07-12 18:52:30,722 [run_pretraining.py:  558]:	worker_index: 7, step: 1026, cost: 7.890069, mlm loss: 7.890069, speed: 0.940868 steps/s, speed: 7.526942 samples/s, speed: 3853.794532 tokens/s, learning rate: 1.025e-05, loss_scalings: 13421.773438, pp_loss: 7.856747
[INFO] 2021-07-12 18:52:30,722 [run_pretraining.py:  512]:	********exe.run_1026******* 
[INFO] 2021-07-12 18:52:31,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:31,884 [run_pretraining.py:  534]:	loss/total_loss, 7.941357135772705, 1027
[INFO] 2021-07-12 18:52:31,884 [run_pretraining.py:  535]:	loss/mlm_loss, 7.941357135772705, 1027
[INFO] 2021-07-12 18:52:31,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0259999726258684e-05, 1027
[INFO] 2021-07-12 18:52:31,884 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1027
[INFO] 2021-07-12 18:52:31,884 [run_pretraining.py:  558]:	worker_index: 7, step: 1027, cost: 7.941357, mlm loss: 7.941357, speed: 0.861142 steps/s, speed: 6.889136 samples/s, speed: 3527.237582 tokens/s, learning rate: 1.026e-05, loss_scalings: 13421.773438, pp_loss: 7.923828
[INFO] 2021-07-12 18:52:31,884 [run_pretraining.py:  512]:	********exe.run_1027******* 
[INFO] 2021-07-12 18:52:32,929 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:32,930 [run_pretraining.py:  534]:	loss/total_loss, 8.091645240783691, 1028
[INFO] 2021-07-12 18:52:32,930 [run_pretraining.py:  535]:	loss/mlm_loss, 8.091645240783691, 1028
[INFO] 2021-07-12 18:52:32,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0269999620504677e-05, 1028
[INFO] 2021-07-12 18:52:32,930 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1028
[INFO] 2021-07-12 18:52:32,930 [run_pretraining.py:  558]:	worker_index: 7, step: 1028, cost: 8.091645, mlm loss: 8.091645, speed: 0.956546 steps/s, speed: 7.652366 samples/s, speed: 3918.011492 tokens/s, learning rate: 1.027e-05, loss_scalings: 13421.773438, pp_loss: 7.667681
[INFO] 2021-07-12 18:52:32,930 [run_pretraining.py:  512]:	********exe.run_1028******* 
[INFO] 2021-07-12 18:52:33,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:33,989 [run_pretraining.py:  534]:	loss/total_loss, 8.269180297851562, 1029
[INFO] 2021-07-12 18:52:33,989 [run_pretraining.py:  535]:	loss/mlm_loss, 8.269180297851562, 1029
[INFO] 2021-07-12 18:52:33,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.027999951475067e-05, 1029
[INFO] 2021-07-12 18:52:33,989 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1029
[INFO] 2021-07-12 18:52:33,989 [run_pretraining.py:  558]:	worker_index: 7, step: 1029, cost: 8.269180, mlm loss: 8.269180, speed: 0.944948 steps/s, speed: 7.559584 samples/s, speed: 3870.507161 tokens/s, learning rate: 1.028e-05, loss_scalings: 13421.773438, pp_loss: 7.920747
[INFO] 2021-07-12 18:52:33,989 [run_pretraining.py:  512]:	********exe.run_1029******* 
[INFO] 2021-07-12 18:52:35,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:35,044 [run_pretraining.py:  534]:	loss/total_loss, 8.069232940673828, 1030
[INFO] 2021-07-12 18:52:35,044 [run_pretraining.py:  535]:	loss/mlm_loss, 8.069232940673828, 1030
[INFO] 2021-07-12 18:52:35,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0289999408996664e-05, 1030
[INFO] 2021-07-12 18:52:35,044 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1030
[INFO] 2021-07-12 18:52:35,044 [run_pretraining.py:  558]:	worker_index: 7, step: 1030, cost: 8.069233, mlm loss: 8.069233, speed: 0.948720 steps/s, speed: 7.589758 samples/s, speed: 3885.955869 tokens/s, learning rate: 1.029e-05, loss_scalings: 13421.773438, pp_loss: 7.951745
[INFO] 2021-07-12 18:52:35,044 [run_pretraining.py:  512]:	********exe.run_1030******* 
[INFO] 2021-07-12 18:52:36,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:36,104 [run_pretraining.py:  534]:	loss/total_loss, 7.940079689025879, 1031
[INFO] 2021-07-12 18:52:36,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.940079689025879, 1031
[INFO] 2021-07-12 18:52:36,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0299999303242657e-05, 1031
[INFO] 2021-07-12 18:52:36,104 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1031
[INFO] 2021-07-12 18:52:36,104 [run_pretraining.py:  558]:	worker_index: 7, step: 1031, cost: 7.940080, mlm loss: 7.940080, speed: 0.943997 steps/s, speed: 7.551977 samples/s, speed: 3866.612377 tokens/s, learning rate: 1.030e-05, loss_scalings: 13421.773438, pp_loss: 7.852070
[INFO] 2021-07-12 18:52:36,104 [run_pretraining.py:  512]:	********exe.run_1031******* 
[INFO] 2021-07-12 18:52:37,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:37,168 [run_pretraining.py:  534]:	loss/total_loss, 8.009294509887695, 1032
[INFO] 2021-07-12 18:52:37,169 [run_pretraining.py:  535]:	loss/mlm_loss, 8.009294509887695, 1032
[INFO] 2021-07-12 18:52:37,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0310000106983352e-05, 1032
[INFO] 2021-07-12 18:52:37,169 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1032
[INFO] 2021-07-12 18:52:37,169 [run_pretraining.py:  558]:	worker_index: 7, step: 1032, cost: 8.009295, mlm loss: 8.009295, speed: 0.939655 steps/s, speed: 7.517236 samples/s, speed: 3848.824976 tokens/s, learning rate: 1.031e-05, loss_scalings: 13421.773438, pp_loss: 7.900269
[INFO] 2021-07-12 18:52:37,169 [run_pretraining.py:  512]:	********exe.run_1032******* 
[INFO] 2021-07-12 18:52:38,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:38,227 [run_pretraining.py:  534]:	loss/total_loss, 7.981098651885986, 1033
[INFO] 2021-07-12 18:52:38,227 [run_pretraining.py:  535]:	loss/mlm_loss, 7.981098651885986, 1033
[INFO] 2021-07-12 18:52:38,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0320000001229346e-05, 1033
[INFO] 2021-07-12 18:52:38,227 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1033
[INFO] 2021-07-12 18:52:38,227 [run_pretraining.py:  558]:	worker_index: 7, step: 1033, cost: 7.981099, mlm loss: 7.981099, speed: 0.945242 steps/s, speed: 7.561934 samples/s, speed: 3871.710021 tokens/s, learning rate: 1.032e-05, loss_scalings: 13421.773438, pp_loss: 7.834970
[INFO] 2021-07-12 18:52:38,227 [run_pretraining.py:  512]:	********exe.run_1033******* 
[INFO] 2021-07-12 18:52:39,340 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:39,340 [run_pretraining.py:  534]:	loss/total_loss, 7.839590072631836, 1034
[INFO] 2021-07-12 18:52:39,341 [run_pretraining.py:  535]:	loss/mlm_loss, 7.839590072631836, 1034
[INFO] 2021-07-12 18:52:39,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0329999895475339e-05, 1034
[INFO] 2021-07-12 18:52:39,341 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1034
[INFO] 2021-07-12 18:52:39,341 [run_pretraining.py:  558]:	worker_index: 7, step: 1034, cost: 7.839590, mlm loss: 7.839590, speed: 0.898627 steps/s, speed: 7.189013 samples/s, speed: 3680.774808 tokens/s, learning rate: 1.033e-05, loss_scalings: 13421.773438, pp_loss: 7.842893
[INFO] 2021-07-12 18:52:39,341 [run_pretraining.py:  512]:	********exe.run_1034******* 
[INFO] 2021-07-12 18:52:40,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:40,379 [run_pretraining.py:  534]:	loss/total_loss, 7.806556701660156, 1035
[INFO] 2021-07-12 18:52:40,379 [run_pretraining.py:  535]:	loss/mlm_loss, 7.806556701660156, 1035
[INFO] 2021-07-12 18:52:40,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0339999789721332e-05, 1035
[INFO] 2021-07-12 18:52:40,379 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1035
[INFO] 2021-07-12 18:52:40,379 [run_pretraining.py:  558]:	worker_index: 7, step: 1035, cost: 7.806557, mlm loss: 7.806557, speed: 0.963616 steps/s, speed: 7.708927 samples/s, speed: 3946.970777 tokens/s, learning rate: 1.034e-05, loss_scalings: 13421.773438, pp_loss: 7.956401
[INFO] 2021-07-12 18:52:40,379 [run_pretraining.py:  512]:	********exe.run_1035******* 
[INFO] 2021-07-12 18:52:41,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:41,441 [run_pretraining.py:  534]:	loss/total_loss, 8.036737442016602, 1036
[INFO] 2021-07-12 18:52:41,441 [run_pretraining.py:  535]:	loss/mlm_loss, 8.036737442016602, 1036
[INFO] 2021-07-12 18:52:41,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0349999683967326e-05, 1036
[INFO] 2021-07-12 18:52:41,441 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1036
[INFO] 2021-07-12 18:52:41,442 [run_pretraining.py:  558]:	worker_index: 7, step: 1036, cost: 8.036737, mlm loss: 8.036737, speed: 0.941931 steps/s, speed: 7.535445 samples/s, speed: 3858.147802 tokens/s, learning rate: 1.035e-05, loss_scalings: 13421.773438, pp_loss: 7.785244
[INFO] 2021-07-12 18:52:41,442 [run_pretraining.py:  512]:	********exe.run_1036******* 
[INFO] 2021-07-12 18:52:42,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:42,504 [run_pretraining.py:  534]:	loss/total_loss, 7.8759050369262695, 1037
[INFO] 2021-07-12 18:52:42,504 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8759050369262695, 1037
[INFO] 2021-07-12 18:52:42,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.035999957821332e-05, 1037
[INFO] 2021-07-12 18:52:42,505 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1037
[INFO] 2021-07-12 18:52:42,505 [run_pretraining.py:  558]:	worker_index: 7, step: 1037, cost: 7.875905, mlm loss: 7.875905, speed: 0.941179 steps/s, speed: 7.529434 samples/s, speed: 3855.070069 tokens/s, learning rate: 1.036e-05, loss_scalings: 13421.773438, pp_loss: 8.110787
[INFO] 2021-07-12 18:52:42,505 [run_pretraining.py:  512]:	********exe.run_1037******* 
[INFO] 2021-07-12 18:52:43,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:43,555 [run_pretraining.py:  534]:	loss/total_loss, 7.326357364654541, 1038
[INFO] 2021-07-12 18:52:43,556 [run_pretraining.py:  535]:	loss/mlm_loss, 7.326357364654541, 1038
[INFO] 2021-07-12 18:52:43,556 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0369999472459313e-05, 1038
[INFO] 2021-07-12 18:52:43,556 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1038
[INFO] 2021-07-12 18:52:43,556 [run_pretraining.py:  558]:	worker_index: 7, step: 1038, cost: 7.326357, mlm loss: 7.326357, speed: 0.952031 steps/s, speed: 7.616245 samples/s, speed: 3899.517252 tokens/s, learning rate: 1.037e-05, loss_scalings: 13421.773438, pp_loss: 7.695282
[INFO] 2021-07-12 18:52:43,556 [run_pretraining.py:  512]:	********exe.run_1038******* 
[INFO] 2021-07-12 18:52:44,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:44,534 [run_pretraining.py:  534]:	loss/total_loss, 5.673379421234131, 1039
[INFO] 2021-07-12 18:52:44,534 [run_pretraining.py:  535]:	loss/mlm_loss, 5.673379421234131, 1039
[INFO] 2021-07-12 18:52:44,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0379999366705306e-05, 1039
[INFO] 2021-07-12 18:52:44,534 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1039
[INFO] 2021-07-12 18:52:44,534 [run_pretraining.py:  558]:	worker_index: 7, step: 1039, cost: 5.673379, mlm loss: 5.673379, speed: 1.022581 steps/s, speed: 8.180652 samples/s, speed: 4188.493692 tokens/s, learning rate: 1.038e-05, loss_scalings: 13421.773438, pp_loss: 6.885291
[INFO] 2021-07-12 18:52:44,534 [run_pretraining.py:  512]:	********exe.run_1039******* 
[INFO] 2021-07-12 18:52:45,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:45,495 [run_pretraining.py:  534]:	loss/total_loss, 7.685420989990234, 1040
[INFO] 2021-07-12 18:52:45,495 [run_pretraining.py:  535]:	loss/mlm_loss, 7.685420989990234, 1040
[INFO] 2021-07-12 18:52:45,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0390000170446001e-05, 1040
[INFO] 2021-07-12 18:52:45,495 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1040
[INFO] 2021-07-12 18:52:45,495 [run_pretraining.py:  558]:	worker_index: 7, step: 1040, cost: 7.685421, mlm loss: 7.685421, speed: 1.041503 steps/s, speed: 8.332023 samples/s, speed: 4265.995852 tokens/s, learning rate: 1.039e-05, loss_scalings: 13421.773438, pp_loss: 7.518672
[INFO] 2021-07-12 18:52:45,495 [run_pretraining.py:  512]:	********exe.run_1040******* 
[INFO] 2021-07-12 18:52:46,456 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:46,456 [run_pretraining.py:  534]:	loss/total_loss, 7.54128885269165, 1041
[INFO] 2021-07-12 18:52:46,456 [run_pretraining.py:  535]:	loss/mlm_loss, 7.54128885269165, 1041
[INFO] 2021-07-12 18:52:46,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0400000064691994e-05, 1041
[INFO] 2021-07-12 18:52:46,456 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1041
[INFO] 2021-07-12 18:52:46,456 [run_pretraining.py:  558]:	worker_index: 7, step: 1041, cost: 7.541289, mlm loss: 7.541289, speed: 1.041000 steps/s, speed: 8.327997 samples/s, speed: 4263.934382 tokens/s, learning rate: 1.040e-05, loss_scalings: 13421.773438, pp_loss: 7.903622
[INFO] 2021-07-12 18:52:46,456 [run_pretraining.py:  512]:	********exe.run_1041******* 
[INFO] 2021-07-12 18:52:47,407 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:47,408 [run_pretraining.py:  534]:	loss/total_loss, 7.477224349975586, 1042
[INFO] 2021-07-12 18:52:47,408 [run_pretraining.py:  535]:	loss/mlm_loss, 7.477224349975586, 1042
[INFO] 2021-07-12 18:52:47,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0409999049443286e-05, 1042
[INFO] 2021-07-12 18:52:47,408 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1042
[INFO] 2021-07-12 18:52:47,408 [run_pretraining.py:  558]:	worker_index: 7, step: 1042, cost: 7.477224, mlm loss: 7.477224, speed: 1.051289 steps/s, speed: 8.410309 samples/s, speed: 4306.078054 tokens/s, learning rate: 1.041e-05, loss_scalings: 13421.773438, pp_loss: 7.871717
[INFO] 2021-07-12 18:52:47,408 [run_pretraining.py:  512]:	********exe.run_1042******* 
[INFO] 2021-07-12 18:52:48,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:48,359 [run_pretraining.py:  534]:	loss/total_loss, 7.782583713531494, 1043
[INFO] 2021-07-12 18:52:48,359 [run_pretraining.py:  535]:	loss/mlm_loss, 7.782583713531494, 1043
[INFO] 2021-07-12 18:52:48,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0419999853183981e-05, 1043
[INFO] 2021-07-12 18:52:48,359 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1043
[INFO] 2021-07-12 18:52:48,359 [run_pretraining.py:  558]:	worker_index: 7, step: 1043, cost: 7.782584, mlm loss: 7.782584, speed: 1.052247 steps/s, speed: 8.417974 samples/s, speed: 4310.002741 tokens/s, learning rate: 1.042e-05, loss_scalings: 13421.773438, pp_loss: 7.838243
[INFO] 2021-07-12 18:52:48,359 [run_pretraining.py:  512]:	********exe.run_1043******* 
[INFO] 2021-07-12 18:52:49,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:49,328 [run_pretraining.py:  534]:	loss/total_loss, 7.9776611328125, 1044
[INFO] 2021-07-12 18:52:49,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9776611328125, 1044
[INFO] 2021-07-12 18:52:49,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0429999747429974e-05, 1044
[INFO] 2021-07-12 18:52:49,329 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1044
[INFO] 2021-07-12 18:52:49,329 [run_pretraining.py:  558]:	worker_index: 7, step: 1044, cost: 7.977661, mlm loss: 7.977661, speed: 1.032056 steps/s, speed: 8.256445 samples/s, speed: 4227.299850 tokens/s, learning rate: 1.043e-05, loss_scalings: 13421.773438, pp_loss: 7.855920
[INFO] 2021-07-12 18:52:49,329 [run_pretraining.py:  512]:	********exe.run_1044******* 
[INFO] 2021-07-12 18:52:50,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:50,286 [run_pretraining.py:  534]:	loss/total_loss, 8.787117004394531, 1045
[INFO] 2021-07-12 18:52:50,287 [run_pretraining.py:  535]:	loss/mlm_loss, 8.787117004394531, 1045
[INFO] 2021-07-12 18:52:50,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0439999641675968e-05, 1045
[INFO] 2021-07-12 18:52:50,287 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1045
[INFO] 2021-07-12 18:52:50,287 [run_pretraining.py:  558]:	worker_index: 7, step: 1045, cost: 8.787117, mlm loss: 8.787117, speed: 1.044548 steps/s, speed: 8.356382 samples/s, speed: 4278.467387 tokens/s, learning rate: 1.044e-05, loss_scalings: 13421.773438, pp_loss: 7.906658
[INFO] 2021-07-12 18:52:50,287 [run_pretraining.py:  512]:	********exe.run_1045******* 
[INFO] 2021-07-12 18:52:51,184 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  534]:	loss/total_loss, 7.416050910949707, 1046
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  535]:	loss/mlm_loss, 7.416050910949707, 1046
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0450000445416663e-05, 1046
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1046
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  558]:	worker_index: 7, step: 1046, cost: 7.416051, mlm loss: 7.416051, speed: 1.113683 steps/s, speed: 8.909467 samples/s, speed: 4561.646874 tokens/s, learning rate: 1.045e-05, loss_scalings: 13421.773438, pp_loss: 7.991595
[INFO] 2021-07-12 18:52:51,185 [run_pretraining.py:  512]:	********exe.run_1046******* 
[INFO] 2021-07-12 18:52:52,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:52,095 [run_pretraining.py:  534]:	loss/total_loss, 7.346502304077148, 1047
[INFO] 2021-07-12 18:52:52,095 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346502304077148, 1047
[INFO] 2021-07-12 18:52:52,095 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0459999430167954e-05, 1047
[INFO] 2021-07-12 18:52:52,095 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1047
[INFO] 2021-07-12 18:52:52,095 [run_pretraining.py:  558]:	worker_index: 7, step: 1047, cost: 7.346502, mlm loss: 7.346502, speed: 1.099675 steps/s, speed: 8.797399 samples/s, speed: 4504.268255 tokens/s, learning rate: 1.046e-05, loss_scalings: 13421.773438, pp_loss: 7.739954
[INFO] 2021-07-12 18:52:52,095 [run_pretraining.py:  512]:	********exe.run_1047******* 
[INFO] 2021-07-12 18:52:52,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:52,999 [run_pretraining.py:  534]:	loss/total_loss, 8.16054916381836, 1048
[INFO] 2021-07-12 18:52:52,999 [run_pretraining.py:  535]:	loss/mlm_loss, 8.16054916381836, 1048
[INFO] 2021-07-12 18:52:52,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0469999324413948e-05, 1048
[INFO] 2021-07-12 18:52:53,000 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1048
[INFO] 2021-07-12 18:52:53,000 [run_pretraining.py:  558]:	worker_index: 7, step: 1048, cost: 8.160549, mlm loss: 8.160549, speed: 1.106707 steps/s, speed: 8.853655 samples/s, speed: 4533.071405 tokens/s, learning rate: 1.047e-05, loss_scalings: 13421.773438, pp_loss: 7.790630
[INFO] 2021-07-12 18:52:53,000 [run_pretraining.py:  512]:	********exe.run_1048******* 
[INFO] 2021-07-12 18:52:53,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:53,902 [run_pretraining.py:  534]:	loss/total_loss, 7.990575790405273, 1049
[INFO] 2021-07-12 18:52:53,902 [run_pretraining.py:  535]:	loss/mlm_loss, 7.990575790405273, 1049
[INFO] 2021-07-12 18:52:53,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0480000128154643e-05, 1049
[INFO] 2021-07-12 18:52:53,903 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1049
[INFO] 2021-07-12 18:52:53,903 [run_pretraining.py:  558]:	worker_index: 7, step: 1049, cost: 7.990576, mlm loss: 7.990576, speed: 1.108156 steps/s, speed: 8.865248 samples/s, speed: 4539.007008 tokens/s, learning rate: 1.048e-05, loss_scalings: 13421.773438, pp_loss: 7.897788
[INFO] 2021-07-12 18:52:53,903 [run_pretraining.py:  512]:	********exe.run_1049******* 
[INFO] 2021-07-12 18:52:54,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:54,812 [run_pretraining.py:  534]:	loss/total_loss, 8.416841506958008, 1050
[INFO] 2021-07-12 18:52:54,812 [run_pretraining.py:  535]:	loss/mlm_loss, 8.416841506958008, 1050
[INFO] 2021-07-12 18:52:54,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0490000022400636e-05, 1050
[INFO] 2021-07-12 18:52:54,812 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1050
[INFO] 2021-07-12 18:52:54,812 [run_pretraining.py:  558]:	worker_index: 7, step: 1050, cost: 8.416842, mlm loss: 8.416842, speed: 1.099944 steps/s, speed: 8.799554 samples/s, speed: 4505.371525 tokens/s, learning rate: 1.049e-05, loss_scalings: 13421.773438, pp_loss: 8.015331
[INFO] 2021-07-12 18:52:54,813 [run_pretraining.py:  512]:	********exe.run_1050******* 
[INFO] 2021-07-12 18:52:55,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:55,720 [run_pretraining.py:  534]:	loss/total_loss, 7.677616119384766, 1051
[INFO] 2021-07-12 18:52:55,720 [run_pretraining.py:  535]:	loss/mlm_loss, 7.677616119384766, 1051
[INFO] 2021-07-12 18:52:55,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0499999007151928e-05, 1051
[INFO] 2021-07-12 18:52:55,720 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1051
[INFO] 2021-07-12 18:52:55,720 [run_pretraining.py:  558]:	worker_index: 7, step: 1051, cost: 7.677616, mlm loss: 7.677616, speed: 1.102912 steps/s, speed: 8.823297 samples/s, speed: 4517.527822 tokens/s, learning rate: 1.050e-05, loss_scalings: 13421.773438, pp_loss: 7.828150
[INFO] 2021-07-12 18:52:55,720 [run_pretraining.py:  512]:	********exe.run_1051******* 
[INFO] 2021-07-12 18:52:56,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:56,628 [run_pretraining.py:  534]:	loss/total_loss, 7.806252956390381, 1052
[INFO] 2021-07-12 18:52:56,629 [run_pretraining.py:  535]:	loss/mlm_loss, 7.806252956390381, 1052
[INFO] 2021-07-12 18:52:56,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0509999810892623e-05, 1052
[INFO] 2021-07-12 18:52:56,629 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1052
[INFO] 2021-07-12 18:52:56,629 [run_pretraining.py:  558]:	worker_index: 7, step: 1052, cost: 7.806253, mlm loss: 7.806253, speed: 1.101024 steps/s, speed: 8.808193 samples/s, speed: 4509.794751 tokens/s, learning rate: 1.051e-05, loss_scalings: 13421.773438, pp_loss: 7.840073
[INFO] 2021-07-12 18:52:56,629 [run_pretraining.py:  512]:	********exe.run_1052******* 
[INFO] 2021-07-12 18:52:57,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:57,534 [run_pretraining.py:  534]:	loss/total_loss, 8.2203369140625, 1053
[INFO] 2021-07-12 18:52:57,535 [run_pretraining.py:  535]:	loss/mlm_loss, 8.2203369140625, 1053
[INFO] 2021-07-12 18:52:57,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0519999705138616e-05, 1053
[INFO] 2021-07-12 18:52:57,535 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1053
[INFO] 2021-07-12 18:52:57,535 [run_pretraining.py:  558]:	worker_index: 7, step: 1053, cost: 8.220337, mlm loss: 8.220337, speed: 1.104456 steps/s, speed: 8.835650 samples/s, speed: 4523.852757 tokens/s, learning rate: 1.052e-05, loss_scalings: 13421.773438, pp_loss: 7.950857
[INFO] 2021-07-12 18:52:57,535 [run_pretraining.py:  512]:	********exe.run_1053******* 
[INFO] 2021-07-12 18:52:58,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:58,482 [run_pretraining.py:  534]:	loss/total_loss, 7.762825012207031, 1054
[INFO] 2021-07-12 18:52:58,482 [run_pretraining.py:  535]:	loss/mlm_loss, 7.762825012207031, 1054
[INFO] 2021-07-12 18:52:58,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.052999959938461e-05, 1054
[INFO] 2021-07-12 18:52:58,482 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1054
[INFO] 2021-07-12 18:52:58,483 [run_pretraining.py:  558]:	worker_index: 7, step: 1054, cost: 7.762825, mlm loss: 7.762825, speed: 1.055905 steps/s, speed: 8.447236 samples/s, speed: 4324.984853 tokens/s, learning rate: 1.053e-05, loss_scalings: 13421.773438, pp_loss: 8.146066
[INFO] 2021-07-12 18:52:58,483 [run_pretraining.py:  512]:	********exe.run_1054******* 
[INFO] 2021-07-12 18:52:59,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:52:59,546 [run_pretraining.py:  534]:	loss/total_loss, 7.668865203857422, 1055
[INFO] 2021-07-12 18:52:59,546 [run_pretraining.py:  535]:	loss/mlm_loss, 7.668865203857422, 1055
[INFO] 2021-07-12 18:52:59,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0540000403125305e-05, 1055
[INFO] 2021-07-12 18:52:59,547 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1055
[INFO] 2021-07-12 18:52:59,547 [run_pretraining.py:  558]:	worker_index: 7, step: 1055, cost: 7.668865, mlm loss: 7.668865, speed: 0.940313 steps/s, speed: 7.522504 samples/s, speed: 3851.522278 tokens/s, learning rate: 1.054e-05, loss_scalings: 13421.773438, pp_loss: 7.517833
[INFO] 2021-07-12 18:52:59,547 [run_pretraining.py:  512]:	********exe.run_1055******* 
[INFO] 2021-07-12 18:53:00,608 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:00,608 [run_pretraining.py:  534]:	loss/total_loss, 7.780535697937012, 1056
[INFO] 2021-07-12 18:53:00,609 [run_pretraining.py:  535]:	loss/mlm_loss, 7.780535697937012, 1056
[INFO] 2021-07-12 18:53:00,609 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0549999387876596e-05, 1056
[INFO] 2021-07-12 18:53:00,609 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1056
[INFO] 2021-07-12 18:53:00,609 [run_pretraining.py:  558]:	worker_index: 7, step: 1056, cost: 7.780536, mlm loss: 7.780536, speed: 0.942110 steps/s, speed: 7.536880 samples/s, speed: 3858.882682 tokens/s, learning rate: 1.055e-05, loss_scalings: 13421.773438, pp_loss: 7.228169
[INFO] 2021-07-12 18:53:00,609 [run_pretraining.py:  512]:	********exe.run_1056******* 
[INFO] 2021-07-12 18:53:01,699 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:01,700 [run_pretraining.py:  534]:	loss/total_loss, 7.846626281738281, 1057
[INFO] 2021-07-12 18:53:01,700 [run_pretraining.py:  535]:	loss/mlm_loss, 7.846626281738281, 1057
[INFO] 2021-07-12 18:53:01,700 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.055999928212259e-05, 1057
[INFO] 2021-07-12 18:53:01,700 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1057
[INFO] 2021-07-12 18:53:01,700 [run_pretraining.py:  558]:	worker_index: 7, step: 1057, cost: 7.846626, mlm loss: 7.846626, speed: 0.916619 steps/s, speed: 7.332956 samples/s, speed: 3754.473317 tokens/s, learning rate: 1.056e-05, loss_scalings: 13421.773438, pp_loss: 7.640176
[INFO] 2021-07-12 18:53:01,700 [run_pretraining.py:  512]:	********exe.run_1057******* 
[INFO] 2021-07-12 18:53:02,811 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:02,811 [run_pretraining.py:  534]:	loss/total_loss, 8.484405517578125, 1058
[INFO] 2021-07-12 18:53:02,811 [run_pretraining.py:  535]:	loss/mlm_loss, 8.484405517578125, 1058
[INFO] 2021-07-12 18:53:02,811 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0570000085863285e-05, 1058
[INFO] 2021-07-12 18:53:02,811 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1058
[INFO] 2021-07-12 18:53:02,811 [run_pretraining.py:  558]:	worker_index: 7, step: 1058, cost: 8.484406, mlm loss: 8.484406, speed: 0.900566 steps/s, speed: 7.204525 samples/s, speed: 3688.716582 tokens/s, learning rate: 1.057e-05, loss_scalings: 13421.773438, pp_loss: 7.783583
[INFO] 2021-07-12 18:53:02,812 [run_pretraining.py:  512]:	********exe.run_1058******* 
[INFO] 2021-07-12 18:53:03,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:03,904 [run_pretraining.py:  534]:	loss/total_loss, 8.046722412109375, 1059
[INFO] 2021-07-12 18:53:03,904 [run_pretraining.py:  535]:	loss/mlm_loss, 8.046722412109375, 1059
[INFO] 2021-07-12 18:53:03,904 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0579999980109278e-05, 1059
[INFO] 2021-07-12 18:53:03,904 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1059
[INFO] 2021-07-12 18:53:03,904 [run_pretraining.py:  558]:	worker_index: 7, step: 1059, cost: 8.046722, mlm loss: 8.046722, speed: 0.915915 steps/s, speed: 7.327318 samples/s, speed: 3751.586561 tokens/s, learning rate: 1.058e-05, loss_scalings: 13421.773438, pp_loss: 7.993708
[INFO] 2021-07-12 18:53:03,904 [run_pretraining.py:  512]:	********exe.run_1059******* 
[INFO] 2021-07-12 18:53:04,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:04,999 [run_pretraining.py:  534]:	loss/total_loss, 8.036596298217773, 1060
[INFO] 2021-07-12 18:53:04,999 [run_pretraining.py:  535]:	loss/mlm_loss, 8.036596298217773, 1060
[INFO] 2021-07-12 18:53:04,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0589999874355271e-05, 1060
[INFO] 2021-07-12 18:53:04,999 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1060
[INFO] 2021-07-12 18:53:04,999 [run_pretraining.py:  558]:	worker_index: 7, step: 1060, cost: 8.036596, mlm loss: 8.036596, speed: 0.913445 steps/s, speed: 7.307564 samples/s, speed: 3741.472554 tokens/s, learning rate: 1.059e-05, loss_scalings: 13421.773438, pp_loss: 7.950566
[INFO] 2021-07-12 18:53:04,999 [run_pretraining.py:  512]:	********exe.run_1060******* 
[INFO] 2021-07-12 18:53:06,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:06,085 [run_pretraining.py:  534]:	loss/total_loss, 7.26577615737915, 1061
[INFO] 2021-07-12 18:53:06,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.26577615737915, 1061
[INFO] 2021-07-12 18:53:06,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0599999768601265e-05, 1061
[INFO] 2021-07-12 18:53:06,086 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1061
[INFO] 2021-07-12 18:53:06,086 [run_pretraining.py:  558]:	worker_index: 7, step: 1061, cost: 7.265776, mlm loss: 7.265776, speed: 0.921030 steps/s, speed: 7.368239 samples/s, speed: 3772.538605 tokens/s, learning rate: 1.060e-05, loss_scalings: 13421.773438, pp_loss: 7.619013
[INFO] 2021-07-12 18:53:06,086 [run_pretraining.py:  512]:	********exe.run_1061******* 
[INFO] 2021-07-12 18:53:07,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:07,180 [run_pretraining.py:  534]:	loss/total_loss, 8.347982406616211, 1062
[INFO] 2021-07-12 18:53:07,180 [run_pretraining.py:  535]:	loss/mlm_loss, 8.347982406616211, 1062
[INFO] 2021-07-12 18:53:07,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0609999662847258e-05, 1062
[INFO] 2021-07-12 18:53:07,181 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1062
[INFO] 2021-07-12 18:53:07,181 [run_pretraining.py:  558]:	worker_index: 7, step: 1062, cost: 8.347982, mlm loss: 8.347982, speed: 0.913870 steps/s, speed: 7.310963 samples/s, speed: 3743.213018 tokens/s, learning rate: 1.061e-05, loss_scalings: 13421.773438, pp_loss: 7.999562
[INFO] 2021-07-12 18:53:07,181 [run_pretraining.py:  512]:	********exe.run_1062******* 
[INFO] 2021-07-12 18:53:08,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:08,278 [run_pretraining.py:  534]:	loss/total_loss, 7.660027503967285, 1063
[INFO] 2021-07-12 18:53:08,279 [run_pretraining.py:  535]:	loss/mlm_loss, 7.660027503967285, 1063
[INFO] 2021-07-12 18:53:08,279 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0619999557093251e-05, 1063
[INFO] 2021-07-12 18:53:08,279 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1063
[INFO] 2021-07-12 18:53:08,279 [run_pretraining.py:  558]:	worker_index: 7, step: 1063, cost: 7.660028, mlm loss: 7.660028, speed: 0.911191 steps/s, speed: 7.289528 samples/s, speed: 3732.238155 tokens/s, learning rate: 1.062e-05, loss_scalings: 13421.773438, pp_loss: 7.602155
[INFO] 2021-07-12 18:53:08,279 [run_pretraining.py:  512]:	********exe.run_1063******* 
[INFO] 2021-07-12 18:53:09,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:09,372 [run_pretraining.py:  534]:	loss/total_loss, 8.189167976379395, 1064
[INFO] 2021-07-12 18:53:09,372 [run_pretraining.py:  535]:	loss/mlm_loss, 8.189167976379395, 1064
[INFO] 2021-07-12 18:53:09,372 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0629999451339245e-05, 1064
[INFO] 2021-07-12 18:53:09,373 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1064
[INFO] 2021-07-12 18:53:09,373 [run_pretraining.py:  558]:	worker_index: 7, step: 1064, cost: 8.189168, mlm loss: 8.189168, speed: 0.914748 steps/s, speed: 7.317983 samples/s, speed: 3746.807487 tokens/s, learning rate: 1.063e-05, loss_scalings: 13421.773438, pp_loss: 8.012333
[INFO] 2021-07-12 18:53:09,373 [run_pretraining.py:  512]:	********exe.run_1064******* 
[INFO] 2021-07-12 18:53:10,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:10,338 [run_pretraining.py:  534]:	loss/total_loss, 8.098154067993164, 1065
[INFO] 2021-07-12 18:53:10,338 [run_pretraining.py:  535]:	loss/mlm_loss, 8.098154067993164, 1065
[INFO] 2021-07-12 18:53:10,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0639999345585238e-05, 1065
[INFO] 2021-07-12 18:53:10,339 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1065
[INFO] 2021-07-12 18:53:10,339 [run_pretraining.py:  558]:	worker_index: 7, step: 1065, cost: 8.098154, mlm loss: 8.098154, speed: 1.035731 steps/s, speed: 8.285849 samples/s, speed: 4242.354674 tokens/s, learning rate: 1.064e-05, loss_scalings: 13421.773438, pp_loss: 7.780192
[INFO] 2021-07-12 18:53:10,339 [run_pretraining.py:  512]:	********exe.run_1065******* 
[INFO] 2021-07-12 18:53:11,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:11,232 [run_pretraining.py:  534]:	loss/total_loss, 7.724582195281982, 1066
[INFO] 2021-07-12 18:53:11,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.724582195281982, 1066
[INFO] 2021-07-12 18:53:11,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0650000149325933e-05, 1066
[INFO] 2021-07-12 18:53:11,232 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1066
[INFO] 2021-07-12 18:53:11,232 [run_pretraining.py:  558]:	worker_index: 7, step: 1066, cost: 7.724582, mlm loss: 7.724582, speed: 1.120054 steps/s, speed: 8.960429 samples/s, speed: 4587.739636 tokens/s, learning rate: 1.065e-05, loss_scalings: 13421.773438, pp_loss: 7.333235
[INFO] 2021-07-12 18:53:11,232 [run_pretraining.py:  512]:	********exe.run_1066******* 
[INFO] 2021-07-12 18:53:12,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:12,140 [run_pretraining.py:  534]:	loss/total_loss, 6.997819900512695, 1067
[INFO] 2021-07-12 18:53:12,140 [run_pretraining.py:  535]:	loss/mlm_loss, 6.997819900512695, 1067
[INFO] 2021-07-12 18:53:12,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0660000043571927e-05, 1067
[INFO] 2021-07-12 18:53:12,140 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1067
[INFO] 2021-07-12 18:53:12,140 [run_pretraining.py:  558]:	worker_index: 7, step: 1067, cost: 6.997820, mlm loss: 6.997820, speed: 1.101801 steps/s, speed: 8.814405 samples/s, speed: 4512.975609 tokens/s, learning rate: 1.066e-05, loss_scalings: 13421.773438, pp_loss: 7.500789
[INFO] 2021-07-12 18:53:12,141 [run_pretraining.py:  512]:	********exe.run_1067******* 
[INFO] 2021-07-12 18:53:13,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  534]:	loss/total_loss, 7.701750755310059, 1068
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.701750755310059, 1068
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.066999993781792e-05, 1068
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1068
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  558]:	worker_index: 7, step: 1068, cost: 7.701751, mlm loss: 7.701751, speed: 1.103383 steps/s, speed: 8.827061 samples/s, speed: 4519.455426 tokens/s, learning rate: 1.067e-05, loss_scalings: 13421.773438, pp_loss: 7.794214
[INFO] 2021-07-12 18:53:13,047 [run_pretraining.py:  512]:	********exe.run_1068******* 
[INFO] 2021-07-12 18:53:13,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:13,957 [run_pretraining.py:  534]:	loss/total_loss, 7.33608865737915, 1069
[INFO] 2021-07-12 18:53:13,957 [run_pretraining.py:  535]:	loss/mlm_loss, 7.33608865737915, 1069
[INFO] 2021-07-12 18:53:13,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0679999832063913e-05, 1069
[INFO] 2021-07-12 18:53:13,957 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1069
[INFO] 2021-07-12 18:53:13,957 [run_pretraining.py:  558]:	worker_index: 7, step: 1069, cost: 7.336089, mlm loss: 7.336089, speed: 1.099754 steps/s, speed: 8.798033 samples/s, speed: 4504.593038 tokens/s, learning rate: 1.068e-05, loss_scalings: 13421.773438, pp_loss: 7.953016
[INFO] 2021-07-12 18:53:13,957 [run_pretraining.py:  512]:	********exe.run_1069******* 
[INFO] 2021-07-12 18:53:14,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:14,866 [run_pretraining.py:  534]:	loss/total_loss, 7.950429916381836, 1070
[INFO] 2021-07-12 18:53:14,866 [run_pretraining.py:  535]:	loss/mlm_loss, 7.950429916381836, 1070
[INFO] 2021-07-12 18:53:14,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0689999726309907e-05, 1070
[INFO] 2021-07-12 18:53:14,867 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1070
[INFO] 2021-07-12 18:53:14,867 [run_pretraining.py:  558]:	worker_index: 7, step: 1070, cost: 7.950430, mlm loss: 7.950430, speed: 1.100523 steps/s, speed: 8.804181 samples/s, speed: 4507.740538 tokens/s, learning rate: 1.069e-05, loss_scalings: 13421.773438, pp_loss: 7.897400
[INFO] 2021-07-12 18:53:14,867 [run_pretraining.py:  512]:	********exe.run_1070******* 
[INFO] 2021-07-12 18:53:15,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:15,774 [run_pretraining.py:  534]:	loss/total_loss, 7.264694690704346, 1071
[INFO] 2021-07-12 18:53:15,775 [run_pretraining.py:  535]:	loss/mlm_loss, 7.264694690704346, 1071
[INFO] 2021-07-12 18:53:15,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.06999996205559e-05, 1071
[INFO] 2021-07-12 18:53:15,775 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1071
[INFO] 2021-07-12 18:53:15,775 [run_pretraining.py:  558]:	worker_index: 7, step: 1071, cost: 7.264695, mlm loss: 7.264695, speed: 1.101915 steps/s, speed: 8.815320 samples/s, speed: 4513.443935 tokens/s, learning rate: 1.070e-05, loss_scalings: 13421.773438, pp_loss: 7.620092
[INFO] 2021-07-12 18:53:15,775 [run_pretraining.py:  512]:	********exe.run_1071******* 
[INFO] 2021-07-12 18:53:16,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:16,692 [run_pretraining.py:  534]:	loss/total_loss, 7.489008903503418, 1072
[INFO] 2021-07-12 18:53:16,692 [run_pretraining.py:  535]:	loss/mlm_loss, 7.489008903503418, 1072
[INFO] 2021-07-12 18:53:16,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0710000424296595e-05, 1072
[INFO] 2021-07-12 18:53:16,692 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1072
[INFO] 2021-07-12 18:53:16,692 [run_pretraining.py:  558]:	worker_index: 7, step: 1072, cost: 7.489009, mlm loss: 7.489009, speed: 1.090966 steps/s, speed: 8.727731 samples/s, speed: 4468.598024 tokens/s, learning rate: 1.071e-05, loss_scalings: 13421.773438, pp_loss: 7.729374
[INFO] 2021-07-12 18:53:16,692 [run_pretraining.py:  512]:	********exe.run_1072******* 
[INFO] 2021-07-12 18:53:17,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:17,597 [run_pretraining.py:  534]:	loss/total_loss, 7.6014580726623535, 1073
[INFO] 2021-07-12 18:53:17,598 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6014580726623535, 1073
[INFO] 2021-07-12 18:53:17,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0719999409047887e-05, 1073
[INFO] 2021-07-12 18:53:17,598 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1073
[INFO] 2021-07-12 18:53:17,598 [run_pretraining.py:  558]:	worker_index: 7, step: 1073, cost: 7.601458, mlm loss: 7.601458, speed: 1.104942 steps/s, speed: 8.839532 samples/s, speed: 4525.840609 tokens/s, learning rate: 1.072e-05, loss_scalings: 13421.773438, pp_loss: 7.441774
[INFO] 2021-07-12 18:53:17,598 [run_pretraining.py:  512]:	********exe.run_1073******* 
[INFO] 2021-07-12 18:53:18,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:18,503 [run_pretraining.py:  534]:	loss/total_loss, 8.082818984985352, 1074
[INFO] 2021-07-12 18:53:18,503 [run_pretraining.py:  535]:	loss/mlm_loss, 8.082818984985352, 1074
[INFO] 2021-07-12 18:53:18,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.072999930329388e-05, 1074
[INFO] 2021-07-12 18:53:18,503 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1074
[INFO] 2021-07-12 18:53:18,503 [run_pretraining.py:  558]:	worker_index: 7, step: 1074, cost: 8.082819, mlm loss: 8.082819, speed: 1.105256 steps/s, speed: 8.842050 samples/s, speed: 4527.129832 tokens/s, learning rate: 1.073e-05, loss_scalings: 13421.773438, pp_loss: 8.325258
[INFO] 2021-07-12 18:53:18,503 [run_pretraining.py:  512]:	********exe.run_1074******* 
[INFO] 2021-07-12 18:53:19,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:19,412 [run_pretraining.py:  534]:	loss/total_loss, 7.736692428588867, 1075
[INFO] 2021-07-12 18:53:19,412 [run_pretraining.py:  535]:	loss/mlm_loss, 7.736692428588867, 1075
[INFO] 2021-07-12 18:53:19,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0740000107034575e-05, 1075
[INFO] 2021-07-12 18:53:19,412 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1075
[INFO] 2021-07-12 18:53:19,413 [run_pretraining.py:  558]:	worker_index: 7, step: 1075, cost: 7.736692, mlm loss: 7.736692, speed: 1.100418 steps/s, speed: 8.803345 samples/s, speed: 4507.312418 tokens/s, learning rate: 1.074e-05, loss_scalings: 13421.773438, pp_loss: 7.942251
[INFO] 2021-07-12 18:53:19,413 [run_pretraining.py:  512]:	********exe.run_1075******* 
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  534]:	loss/total_loss, 6.760882377624512, 1076
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  535]:	loss/mlm_loss, 6.760882377624512, 1076
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0750000001280569e-05, 1076
[INFO] 2021-07-12 18:53:20,320 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1076
[INFO] 2021-07-12 18:53:20,321 [run_pretraining.py:  558]:	worker_index: 7, step: 1076, cost: 6.760882, mlm loss: 6.760882, speed: 1.102148 steps/s, speed: 8.817180 samples/s, speed: 4514.396300 tokens/s, learning rate: 1.075e-05, loss_scalings: 13421.773438, pp_loss: 7.577098
[INFO] 2021-07-12 18:53:20,321 [run_pretraining.py:  512]:	********exe.run_1076******* 
[INFO] 2021-07-12 18:53:21,221 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:21,221 [run_pretraining.py:  534]:	loss/total_loss, 8.403640747070312, 1077
[INFO] 2021-07-12 18:53:21,221 [run_pretraining.py:  535]:	loss/mlm_loss, 8.403640747070312, 1077
[INFO] 2021-07-12 18:53:21,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0759999895526562e-05, 1077
[INFO] 2021-07-12 18:53:21,222 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1077
[INFO] 2021-07-12 18:53:21,222 [run_pretraining.py:  558]:	worker_index: 7, step: 1077, cost: 8.403641, mlm loss: 8.403641, speed: 1.110572 steps/s, speed: 8.884574 samples/s, speed: 4548.901777 tokens/s, learning rate: 1.076e-05, loss_scalings: 13421.773438, pp_loss: 8.018866
[INFO] 2021-07-12 18:53:21,222 [run_pretraining.py:  512]:	********exe.run_1077******* 
[INFO] 2021-07-12 18:53:22,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:22,129 [run_pretraining.py:  534]:	loss/total_loss, 7.862133979797363, 1078
[INFO] 2021-07-12 18:53:22,129 [run_pretraining.py:  535]:	loss/mlm_loss, 7.862133979797363, 1078
[INFO] 2021-07-12 18:53:22,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0769999789772555e-05, 1078
[INFO] 2021-07-12 18:53:22,129 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1078
[INFO] 2021-07-12 18:53:22,129 [run_pretraining.py:  558]:	worker_index: 7, step: 1078, cost: 7.862134, mlm loss: 7.862134, speed: 1.102525 steps/s, speed: 8.820198 samples/s, speed: 4515.941338 tokens/s, learning rate: 1.077e-05, loss_scalings: 13421.773438, pp_loss: 7.686682
[INFO] 2021-07-12 18:53:22,129 [run_pretraining.py:  512]:	********exe.run_1078******* 
[INFO] 2021-07-12 18:53:23,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:23,035 [run_pretraining.py:  534]:	loss/total_loss, 7.546634197235107, 1079
[INFO] 2021-07-12 18:53:23,035 [run_pretraining.py:  535]:	loss/mlm_loss, 7.546634197235107, 1079
[INFO] 2021-07-12 18:53:23,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0779999684018549e-05, 1079
[INFO] 2021-07-12 18:53:23,036 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1079
[INFO] 2021-07-12 18:53:23,036 [run_pretraining.py:  558]:	worker_index: 7, step: 1079, cost: 7.546634, mlm loss: 7.546634, speed: 1.104153 steps/s, speed: 8.833222 samples/s, speed: 4522.609451 tokens/s, learning rate: 1.078e-05, loss_scalings: 13421.773438, pp_loss: 7.731855
[INFO] 2021-07-12 18:53:23,036 [run_pretraining.py:  512]:	********exe.run_1079******* 
[INFO] 2021-07-12 18:53:23,937 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:23,938 [run_pretraining.py:  534]:	loss/total_loss, 7.306325912475586, 1080
[INFO] 2021-07-12 18:53:23,938 [run_pretraining.py:  535]:	loss/mlm_loss, 7.306325912475586, 1080
[INFO] 2021-07-12 18:53:23,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0789999578264542e-05, 1080
[INFO] 2021-07-12 18:53:23,938 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1080
[INFO] 2021-07-12 18:53:23,938 [run_pretraining.py:  558]:	worker_index: 7, step: 1080, cost: 7.306326, mlm loss: 7.306326, speed: 1.108967 steps/s, speed: 8.871736 samples/s, speed: 4542.328901 tokens/s, learning rate: 1.079e-05, loss_scalings: 13421.773438, pp_loss: 7.688408
[INFO] 2021-07-12 18:53:23,938 [run_pretraining.py:  512]:	********exe.run_1080******* 
[INFO] 2021-07-12 18:53:24,840 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:24,841 [run_pretraining.py:  534]:	loss/total_loss, 7.481237888336182, 1081
[INFO] 2021-07-12 18:53:24,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.481237888336182, 1081
[INFO] 2021-07-12 18:53:24,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0800000382005237e-05, 1081
[INFO] 2021-07-12 18:53:24,841 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1081
[INFO] 2021-07-12 18:53:24,841 [run_pretraining.py:  558]:	worker_index: 7, step: 1081, cost: 7.481238, mlm loss: 7.481238, speed: 1.107823 steps/s, speed: 8.862583 samples/s, speed: 4537.642696 tokens/s, learning rate: 1.080e-05, loss_scalings: 13421.773438, pp_loss: 7.535434
[INFO] 2021-07-12 18:53:24,841 [run_pretraining.py:  512]:	********exe.run_1081******* 
[INFO] 2021-07-12 18:53:25,749 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:25,750 [run_pretraining.py:  534]:	loss/total_loss, 7.645013809204102, 1082
[INFO] 2021-07-12 18:53:25,750 [run_pretraining.py:  535]:	loss/mlm_loss, 7.645013809204102, 1082
[INFO] 2021-07-12 18:53:25,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0809999366756529e-05, 1082
[INFO] 2021-07-12 18:53:25,750 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1082
[INFO] 2021-07-12 18:53:25,750 [run_pretraining.py:  558]:	worker_index: 7, step: 1082, cost: 7.645014, mlm loss: 7.645014, speed: 1.101447 steps/s, speed: 8.811579 samples/s, speed: 4511.528562 tokens/s, learning rate: 1.081e-05, loss_scalings: 13421.773438, pp_loss: 7.613797
[INFO] 2021-07-12 18:53:25,750 [run_pretraining.py:  512]:	********exe.run_1082******* 
[INFO] 2021-07-12 18:53:26,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:26,711 [run_pretraining.py:  534]:	loss/total_loss, 7.723565101623535, 1083
[INFO] 2021-07-12 18:53:26,711 [run_pretraining.py:  535]:	loss/mlm_loss, 7.723565101623535, 1083
[INFO] 2021-07-12 18:53:26,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0819999261002522e-05, 1083
[INFO] 2021-07-12 18:53:26,711 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1083
[INFO] 2021-07-12 18:53:26,711 [run_pretraining.py:  558]:	worker_index: 7, step: 1083, cost: 7.723565, mlm loss: 7.723565, speed: 1.041124 steps/s, speed: 8.328995 samples/s, speed: 4264.445593 tokens/s, learning rate: 1.082e-05, loss_scalings: 13421.773438, pp_loss: 6.933315
[INFO] 2021-07-12 18:53:26,711 [run_pretraining.py:  512]:	********exe.run_1083******* 
[INFO] 2021-07-12 18:53:27,613 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:27,613 [run_pretraining.py:  534]:	loss/total_loss, 8.064988136291504, 1084
[INFO] 2021-07-12 18:53:27,613 [run_pretraining.py:  535]:	loss/mlm_loss, 8.064988136291504, 1084
[INFO] 2021-07-12 18:53:27,613 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0830000064743217e-05, 1084
[INFO] 2021-07-12 18:53:27,613 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1084
[INFO] 2021-07-12 18:53:27,614 [run_pretraining.py:  558]:	worker_index: 7, step: 1084, cost: 8.064988, mlm loss: 8.064988, speed: 1.108838 steps/s, speed: 8.870707 samples/s, speed: 4541.801730 tokens/s, learning rate: 1.083e-05, loss_scalings: 13421.773438, pp_loss: 7.629706
[INFO] 2021-07-12 18:53:27,614 [run_pretraining.py:  512]:	********exe.run_1084******* 
[INFO] 2021-07-12 18:53:28,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:28,530 [run_pretraining.py:  534]:	loss/total_loss, 7.567225456237793, 1085
[INFO] 2021-07-12 18:53:28,531 [run_pretraining.py:  535]:	loss/mlm_loss, 7.567225456237793, 1085
[INFO] 2021-07-12 18:53:28,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.083999995898921e-05, 1085
[INFO] 2021-07-12 18:53:28,531 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1085
[INFO] 2021-07-12 18:53:28,531 [run_pretraining.py:  558]:	worker_index: 7, step: 1085, cost: 7.567225, mlm loss: 7.567225, speed: 1.091000 steps/s, speed: 8.728003 samples/s, speed: 4468.737505 tokens/s, learning rate: 1.084e-05, loss_scalings: 13421.773438, pp_loss: 7.792407
[INFO] 2021-07-12 18:53:28,531 [run_pretraining.py:  512]:	********exe.run_1085******* 
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  534]:	loss/total_loss, 7.794461250305176, 1086
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  535]:	loss/mlm_loss, 7.794461250305176, 1086
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0849998943740502e-05, 1086
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1086
[INFO] 2021-07-12 18:53:29,436 [run_pretraining.py:  558]:	worker_index: 7, step: 1086, cost: 7.794461, mlm loss: 7.794461, speed: 1.105002 steps/s, speed: 8.840019 samples/s, speed: 4526.089809 tokens/s, learning rate: 1.085e-05, loss_scalings: 13421.773438, pp_loss: 7.995337
[INFO] 2021-07-12 18:53:29,437 [run_pretraining.py:  512]:	********exe.run_1086******* 
[INFO] 2021-07-12 18:53:30,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:30,345 [run_pretraining.py:  534]:	loss/total_loss, 7.188048362731934, 1087
[INFO] 2021-07-12 18:53:30,345 [run_pretraining.py:  535]:	loss/mlm_loss, 7.188048362731934, 1087
[INFO] 2021-07-12 18:53:30,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0859999747481197e-05, 1087
[INFO] 2021-07-12 18:53:30,345 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1087
[INFO] 2021-07-12 18:53:30,345 [run_pretraining.py:  558]:	worker_index: 7, step: 1087, cost: 7.188048, mlm loss: 7.188048, speed: 1.100888 steps/s, speed: 8.807106 samples/s, speed: 4509.238414 tokens/s, learning rate: 1.086e-05, loss_scalings: 13421.773438, pp_loss: 7.598658
[INFO] 2021-07-12 18:53:30,346 [run_pretraining.py:  512]:	********exe.run_1087******* 
[INFO] 2021-07-12 18:53:31,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:31,246 [run_pretraining.py:  534]:	loss/total_loss, 8.125381469726562, 1088
[INFO] 2021-07-12 18:53:31,246 [run_pretraining.py:  535]:	loss/mlm_loss, 8.125381469726562, 1088
[INFO] 2021-07-12 18:53:31,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.086999964172719e-05, 1088
[INFO] 2021-07-12 18:53:31,246 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1088
[INFO] 2021-07-12 18:53:31,247 [run_pretraining.py:  558]:	worker_index: 7, step: 1088, cost: 8.125381, mlm loss: 8.125381, speed: 1.110621 steps/s, speed: 8.884964 samples/s, speed: 4549.101727 tokens/s, learning rate: 1.087e-05, loss_scalings: 13421.773438, pp_loss: 7.725256
[INFO] 2021-07-12 18:53:31,247 [run_pretraining.py:  512]:	********exe.run_1088******* 
[INFO] 2021-07-12 18:53:32,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:32,146 [run_pretraining.py:  534]:	loss/total_loss, 7.925768852233887, 1089
[INFO] 2021-07-12 18:53:32,147 [run_pretraining.py:  535]:	loss/mlm_loss, 7.925768852233887, 1089
[INFO] 2021-07-12 18:53:32,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0879999535973184e-05, 1089
[INFO] 2021-07-12 18:53:32,147 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1089
[INFO] 2021-07-12 18:53:32,147 [run_pretraining.py:  558]:	worker_index: 7, step: 1089, cost: 7.925769, mlm loss: 7.925769, speed: 1.111641 steps/s, speed: 8.893131 samples/s, speed: 4553.283009 tokens/s, learning rate: 1.088e-05, loss_scalings: 13421.773438, pp_loss: 7.717949
[INFO] 2021-07-12 18:53:32,147 [run_pretraining.py:  512]:	********exe.run_1089******* 
[INFO] 2021-07-12 18:53:33,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:33,091 [run_pretraining.py:  534]:	loss/total_loss, 8.022850036621094, 1090
[INFO] 2021-07-12 18:53:33,091 [run_pretraining.py:  535]:	loss/mlm_loss, 8.022850036621094, 1090
[INFO] 2021-07-12 18:53:33,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0890000339713879e-05, 1090
[INFO] 2021-07-12 18:53:33,091 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1090
[INFO] 2021-07-12 18:53:33,091 [run_pretraining.py:  558]:	worker_index: 7, step: 1090, cost: 8.022850, mlm loss: 8.022850, speed: 1.059767 steps/s, speed: 8.478133 samples/s, speed: 4340.804016 tokens/s, learning rate: 1.089e-05, loss_scalings: 13421.773438, pp_loss: 7.740427
[INFO] 2021-07-12 18:53:33,091 [run_pretraining.py:  512]:	********exe.run_1090******* 
[INFO] 2021-07-12 18:53:33,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:33,996 [run_pretraining.py:  534]:	loss/total_loss, 7.515275001525879, 1091
[INFO] 2021-07-12 18:53:33,996 [run_pretraining.py:  535]:	loss/mlm_loss, 7.515275001525879, 1091
[INFO] 2021-07-12 18:53:33,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.089999932446517e-05, 1091
[INFO] 2021-07-12 18:53:33,996 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1091
[INFO] 2021-07-12 18:53:33,997 [run_pretraining.py:  558]:	worker_index: 7, step: 1091, cost: 7.515275, mlm loss: 7.515275, speed: 1.105097 steps/s, speed: 8.840774 samples/s, speed: 4526.476184 tokens/s, learning rate: 1.090e-05, loss_scalings: 13421.773438, pp_loss: 7.696223
[INFO] 2021-07-12 18:53:33,997 [run_pretraining.py:  512]:	********exe.run_1091******* 
[INFO] 2021-07-12 18:53:34,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:34,999 [run_pretraining.py:  534]:	loss/total_loss, 7.77923059463501, 1092
[INFO] 2021-07-12 18:53:35,004 [run_pretraining.py:  535]:	loss/mlm_loss, 7.77923059463501, 1092
[INFO] 2021-07-12 18:53:35,009 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0909999218711164e-05, 1092
[INFO] 2021-07-12 18:53:35,014 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1092
[INFO] 2021-07-12 18:53:35,019 [run_pretraining.py:  558]:	worker_index: 7, step: 1092, cost: 7.779231, mlm loss: 7.779231, speed: 0.998267 steps/s, speed: 7.986139 samples/s, speed: 4088.902943 tokens/s, learning rate: 1.091e-05, loss_scalings: 13421.773438, pp_loss: 7.481586
[INFO] 2021-07-12 18:53:35,025 [run_pretraining.py:  512]:	********exe.run_1092******* 
[INFO] 2021-07-12 18:53:35,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:35,924 [run_pretraining.py:  534]:	loss/total_loss, 7.726424217224121, 1093
[INFO] 2021-07-12 18:53:35,924 [run_pretraining.py:  535]:	loss/mlm_loss, 7.726424217224121, 1093
[INFO] 2021-07-12 18:53:35,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0920000022451859e-05, 1093
[INFO] 2021-07-12 18:53:35,924 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1093
[INFO] 2021-07-12 18:53:35,924 [run_pretraining.py:  558]:	worker_index: 7, step: 1093, cost: 7.726424, mlm loss: 7.726424, speed: 1.112306 steps/s, speed: 8.898447 samples/s, speed: 4556.004726 tokens/s, learning rate: 1.092e-05, loss_scalings: 13421.773438, pp_loss: 8.098058
[INFO] 2021-07-12 18:53:35,924 [run_pretraining.py:  512]:	********exe.run_1093******* 
[INFO] 2021-07-12 18:53:36,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:36,836 [run_pretraining.py:  534]:	loss/total_loss, 7.595726490020752, 1094
[INFO] 2021-07-12 18:53:36,836 [run_pretraining.py:  535]:	loss/mlm_loss, 7.595726490020752, 1094
[INFO] 2021-07-12 18:53:36,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0929999916697852e-05, 1094
[INFO] 2021-07-12 18:53:36,836 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1094
[INFO] 2021-07-12 18:53:36,836 [run_pretraining.py:  558]:	worker_index: 7, step: 1094, cost: 7.595726, mlm loss: 7.595726, speed: 1.097163 steps/s, speed: 8.777304 samples/s, speed: 4493.979822 tokens/s, learning rate: 1.093e-05, loss_scalings: 13421.773438, pp_loss: 7.699809
[INFO] 2021-07-12 18:53:36,836 [run_pretraining.py:  512]:	********exe.run_1094******* 
[INFO] 2021-07-12 18:53:37,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:37,739 [run_pretraining.py:  534]:	loss/total_loss, 7.685609340667725, 1095
[INFO] 2021-07-12 18:53:37,739 [run_pretraining.py:  535]:	loss/mlm_loss, 7.685609340667725, 1095
[INFO] 2021-07-12 18:53:37,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0939999810943846e-05, 1095
[INFO] 2021-07-12 18:53:37,739 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1095
[INFO] 2021-07-12 18:53:37,739 [run_pretraining.py:  558]:	worker_index: 7, step: 1095, cost: 7.685609, mlm loss: 7.685609, speed: 1.107900 steps/s, speed: 8.863201 samples/s, speed: 4537.959124 tokens/s, learning rate: 1.094e-05, loss_scalings: 13421.773438, pp_loss: 7.132464
[INFO] 2021-07-12 18:53:37,740 [run_pretraining.py:  512]:	********exe.run_1095******* 
[INFO] 2021-07-12 18:53:38,643 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:38,644 [run_pretraining.py:  534]:	loss/total_loss, 7.383614540100098, 1096
[INFO] 2021-07-12 18:53:38,644 [run_pretraining.py:  535]:	loss/mlm_loss, 7.383614540100098, 1096
[INFO] 2021-07-12 18:53:38,644 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0949999705189839e-05, 1096
[INFO] 2021-07-12 18:53:38,644 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1096
[INFO] 2021-07-12 18:53:38,644 [run_pretraining.py:  558]:	worker_index: 7, step: 1096, cost: 7.383615, mlm loss: 7.383615, speed: 1.106539 steps/s, speed: 8.852310 samples/s, speed: 4532.382559 tokens/s, learning rate: 1.095e-05, loss_scalings: 13421.773438, pp_loss: 7.400828
[INFO] 2021-07-12 18:53:38,644 [run_pretraining.py:  512]:	********exe.run_1096******* 
[INFO] 2021-07-12 18:53:39,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:39,553 [run_pretraining.py:  534]:	loss/total_loss, 7.190927505493164, 1097
[INFO] 2021-07-12 18:53:39,553 [run_pretraining.py:  535]:	loss/mlm_loss, 7.190927505493164, 1097
[INFO] 2021-07-12 18:53:39,554 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0959999599435832e-05, 1097
[INFO] 2021-07-12 18:53:39,554 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1097
[INFO] 2021-07-12 18:53:39,554 [run_pretraining.py:  558]:	worker_index: 7, step: 1097, cost: 7.190928, mlm loss: 7.190928, speed: 1.099863 steps/s, speed: 8.798905 samples/s, speed: 4505.039542 tokens/s, learning rate: 1.096e-05, loss_scalings: 13421.773438, pp_loss: 7.593001
[INFO] 2021-07-12 18:53:39,554 [run_pretraining.py:  512]:	********exe.run_1097******* 
[INFO] 2021-07-12 18:53:40,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:40,459 [run_pretraining.py:  534]:	loss/total_loss, 7.562158584594727, 1098
[INFO] 2021-07-12 18:53:40,459 [run_pretraining.py:  535]:	loss/mlm_loss, 7.562158584594727, 1098
[INFO] 2021-07-12 18:53:40,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0969999493681826e-05, 1098
[INFO] 2021-07-12 18:53:40,459 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1098
[INFO] 2021-07-12 18:53:40,459 [run_pretraining.py:  558]:	worker_index: 7, step: 1098, cost: 7.562159, mlm loss: 7.562159, speed: 1.105158 steps/s, speed: 8.841265 samples/s, speed: 4526.727840 tokens/s, learning rate: 1.097e-05, loss_scalings: 13421.773438, pp_loss: 7.577540
[INFO] 2021-07-12 18:53:40,459 [run_pretraining.py:  512]:	********exe.run_1098******* 
[INFO] 2021-07-12 18:53:41,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:41,366 [run_pretraining.py:  534]:	loss/total_loss, 7.733458042144775, 1099
[INFO] 2021-07-12 18:53:41,366 [run_pretraining.py:  535]:	loss/mlm_loss, 7.733458042144775, 1099
[INFO] 2021-07-12 18:53:41,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.098000029742252e-05, 1099
[INFO] 2021-07-12 18:53:41,366 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1099
[INFO] 2021-07-12 18:53:41,366 [run_pretraining.py:  558]:	worker_index: 7, step: 1099, cost: 7.733458, mlm loss: 7.733458, speed: 1.103331 steps/s, speed: 8.826648 samples/s, speed: 4519.243808 tokens/s, learning rate: 1.098e-05, loss_scalings: 13421.773438, pp_loss: 7.475555
[INFO] 2021-07-12 18:53:41,366 [run_pretraining.py:  512]:	********exe.run_1099******* 
[INFO] 2021-07-12 18:53:42,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:42,272 [run_pretraining.py:  534]:	loss/total_loss, 4.901749134063721, 1100
[INFO] 2021-07-12 18:53:42,273 [run_pretraining.py:  535]:	loss/mlm_loss, 4.901749134063721, 1100
[INFO] 2021-07-12 18:53:42,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.0989999282173812e-05, 1100
[INFO] 2021-07-12 18:53:42,273 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1100
[INFO] 2021-07-12 18:53:42,273 [run_pretraining.py:  558]:	worker_index: 7, step: 1100, cost: 4.901749, mlm loss: 4.901749, speed: 1.103910 steps/s, speed: 8.831280 samples/s, speed: 4521.615536 tokens/s, learning rate: 1.099e-05, loss_scalings: 13421.773438, pp_loss: 6.920756
[INFO] 2021-07-12 18:53:42,273 [run_pretraining.py:  512]:	********exe.run_1100******* 
[INFO] 2021-07-12 18:53:43,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:43,240 [run_pretraining.py:  534]:	loss/total_loss, 7.557491302490234, 1101
[INFO] 2021-07-12 18:53:43,240 [run_pretraining.py:  535]:	loss/mlm_loss, 7.557491302490234, 1101
[INFO] 2021-07-12 18:53:43,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1000000085914508e-05, 1101
[INFO] 2021-07-12 18:53:43,240 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1101
[INFO] 2021-07-12 18:53:43,240 [run_pretraining.py:  558]:	worker_index: 7, step: 1101, cost: 7.557491, mlm loss: 7.557491, speed: 1.034341 steps/s, speed: 8.274725 samples/s, speed: 4236.659214 tokens/s, learning rate: 1.100e-05, loss_scalings: 13421.773438, pp_loss: 6.750134
[INFO] 2021-07-12 18:53:43,240 [run_pretraining.py:  512]:	********exe.run_1101******* 
[INFO] 2021-07-12 18:53:44,306 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:44,307 [run_pretraining.py:  534]:	loss/total_loss, 8.000204086303711, 1102
[INFO] 2021-07-12 18:53:44,307 [run_pretraining.py:  535]:	loss/mlm_loss, 8.000204086303711, 1102
[INFO] 2021-07-12 18:53:44,307 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1009999980160501e-05, 1102
[INFO] 2021-07-12 18:53:44,307 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1102
[INFO] 2021-07-12 18:53:44,307 [run_pretraining.py:  558]:	worker_index: 7, step: 1102, cost: 8.000204, mlm loss: 8.000204, speed: 0.937918 steps/s, speed: 7.503345 samples/s, speed: 3841.712456 tokens/s, learning rate: 1.101e-05, loss_scalings: 13421.773438, pp_loss: 7.932890
[INFO] 2021-07-12 18:53:44,307 [run_pretraining.py:  512]:	********exe.run_1102******* 
[INFO] 2021-07-12 18:53:45,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:45,384 [run_pretraining.py:  534]:	loss/total_loss, 4.286746501922607, 1103
[INFO] 2021-07-12 18:53:45,384 [run_pretraining.py:  535]:	loss/mlm_loss, 4.286746501922607, 1103
[INFO] 2021-07-12 18:53:45,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1019999874406494e-05, 1103
[INFO] 2021-07-12 18:53:45,385 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1103
[INFO] 2021-07-12 18:53:45,385 [run_pretraining.py:  558]:	worker_index: 7, step: 1103, cost: 4.286747, mlm loss: 4.286747, speed: 0.928489 steps/s, speed: 7.427908 samples/s, speed: 3803.089067 tokens/s, learning rate: 1.102e-05, loss_scalings: 13421.773438, pp_loss: 6.970520
[INFO] 2021-07-12 18:53:45,385 [run_pretraining.py:  512]:	********exe.run_1103******* 
[INFO] 2021-07-12 18:53:46,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:46,495 [run_pretraining.py:  534]:	loss/total_loss, 7.759918212890625, 1104
[INFO] 2021-07-12 18:53:46,495 [run_pretraining.py:  535]:	loss/mlm_loss, 7.759918212890625, 1104
[INFO] 2021-07-12 18:53:46,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1029999768652488e-05, 1104
[INFO] 2021-07-12 18:53:46,495 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1104
[INFO] 2021-07-12 18:53:46,495 [run_pretraining.py:  558]:	worker_index: 7, step: 1104, cost: 7.759918, mlm loss: 7.759918, speed: 0.901190 steps/s, speed: 7.209523 samples/s, speed: 3691.275757 tokens/s, learning rate: 1.103e-05, loss_scalings: 13421.773438, pp_loss: 7.784117
[INFO] 2021-07-12 18:53:46,495 [run_pretraining.py:  512]:	********exe.run_1104******* 
[INFO] 2021-07-12 18:53:47,590 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:47,591 [run_pretraining.py:  534]:	loss/total_loss, 7.78997802734375, 1105
[INFO] 2021-07-12 18:53:47,591 [run_pretraining.py:  535]:	loss/mlm_loss, 7.78997802734375, 1105
[INFO] 2021-07-12 18:53:47,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1039999662898481e-05, 1105
[INFO] 2021-07-12 18:53:47,591 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1105
[INFO] 2021-07-12 18:53:47,591 [run_pretraining.py:  558]:	worker_index: 7, step: 1105, cost: 7.789978, mlm loss: 7.789978, speed: 0.913042 steps/s, speed: 7.304338 samples/s, speed: 3739.820815 tokens/s, learning rate: 1.104e-05, loss_scalings: 13421.773438, pp_loss: 7.817822
[INFO] 2021-07-12 18:53:47,591 [run_pretraining.py:  512]:	********exe.run_1105******* 
[INFO] 2021-07-12 18:53:48,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:48,550 [run_pretraining.py:  534]:	loss/total_loss, 7.419352054595947, 1106
[INFO] 2021-07-12 18:53:48,550 [run_pretraining.py:  535]:	loss/mlm_loss, 7.419352054595947, 1106
[INFO] 2021-07-12 18:53:48,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1049999557144474e-05, 1106
[INFO] 2021-07-12 18:53:48,550 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1106
[INFO] 2021-07-12 18:53:48,550 [run_pretraining.py:  558]:	worker_index: 7, step: 1106, cost: 7.419352, mlm loss: 7.419352, speed: 1.043133 steps/s, speed: 8.345063 samples/s, speed: 4272.672491 tokens/s, learning rate: 1.105e-05, loss_scalings: 13421.773438, pp_loss: 7.738616
[INFO] 2021-07-12 18:53:48,550 [run_pretraining.py:  512]:	********exe.run_1106******* 
[INFO] 2021-07-12 18:53:49,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:49,452 [run_pretraining.py:  534]:	loss/total_loss, 8.3201265335083, 1107
[INFO] 2021-07-12 18:53:49,453 [run_pretraining.py:  535]:	loss/mlm_loss, 8.3201265335083, 1107
[INFO] 2021-07-12 18:53:49,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.106000036088517e-05, 1107
[INFO] 2021-07-12 18:53:49,453 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1107
[INFO] 2021-07-12 18:53:49,453 [run_pretraining.py:  558]:	worker_index: 7, step: 1107, cost: 8.320127, mlm loss: 8.320127, speed: 1.108807 steps/s, speed: 8.870458 samples/s, speed: 4541.674459 tokens/s, learning rate: 1.106e-05, loss_scalings: 13421.773438, pp_loss: 7.760993
[INFO] 2021-07-12 18:53:49,453 [run_pretraining.py:  512]:	********exe.run_1107******* 
[INFO] 2021-07-12 18:53:50,360 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:50,360 [run_pretraining.py:  534]:	loss/total_loss, 7.3519287109375, 1108
[INFO] 2021-07-12 18:53:50,360 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3519287109375, 1108
[INFO] 2021-07-12 18:53:50,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1069999345636461e-05, 1108
[INFO] 2021-07-12 18:53:50,361 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1108
[INFO] 2021-07-12 18:53:50,361 [run_pretraining.py:  558]:	worker_index: 7, step: 1108, cost: 7.351929, mlm loss: 7.351929, speed: 1.102270 steps/s, speed: 8.818163 samples/s, speed: 4514.899330 tokens/s, learning rate: 1.107e-05, loss_scalings: 13421.773438, pp_loss: 7.615390
[INFO] 2021-07-12 18:53:50,361 [run_pretraining.py:  512]:	********exe.run_1108******* 
[INFO] 2021-07-12 18:53:51,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:51,286 [run_pretraining.py:  534]:	loss/total_loss, 7.864127159118652, 1109
[INFO] 2021-07-12 18:53:51,286 [run_pretraining.py:  535]:	loss/mlm_loss, 7.864127159118652, 1109
[INFO] 2021-07-12 18:53:51,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1079999239882454e-05, 1109
[INFO] 2021-07-12 18:53:51,286 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1109
[INFO] 2021-07-12 18:53:51,286 [run_pretraining.py:  558]:	worker_index: 7, step: 1109, cost: 7.864127, mlm loss: 7.864127, speed: 1.081092 steps/s, speed: 8.648736 samples/s, speed: 4428.152849 tokens/s, learning rate: 1.108e-05, loss_scalings: 13421.773438, pp_loss: 7.789252
[INFO] 2021-07-12 18:53:51,286 [run_pretraining.py:  512]:	********exe.run_1109******* 
[INFO] 2021-07-12 18:53:52,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:52,204 [run_pretraining.py:  534]:	loss/total_loss, 7.545291900634766, 1110
[INFO] 2021-07-12 18:53:52,204 [run_pretraining.py:  535]:	loss/mlm_loss, 7.545291900634766, 1110
[INFO] 2021-07-12 18:53:52,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.109000004362315e-05, 1110
[INFO] 2021-07-12 18:53:52,204 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1110
[INFO] 2021-07-12 18:53:52,204 [run_pretraining.py:  558]:	worker_index: 7, step: 1110, cost: 7.545292, mlm loss: 7.545292, speed: 1.089874 steps/s, speed: 8.718992 samples/s, speed: 4464.124119 tokens/s, learning rate: 1.109e-05, loss_scalings: 13421.773438, pp_loss: 7.774722
[INFO] 2021-07-12 18:53:52,204 [run_pretraining.py:  512]:	********exe.run_1110******* 
[INFO] 2021-07-12 18:53:53,105 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:53,106 [run_pretraining.py:  534]:	loss/total_loss, 7.940664768218994, 1111
[INFO] 2021-07-12 18:53:53,106 [run_pretraining.py:  535]:	loss/mlm_loss, 7.940664768218994, 1111
[INFO] 2021-07-12 18:53:53,106 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1099999937869143e-05, 1111
[INFO] 2021-07-12 18:53:53,106 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1111
[INFO] 2021-07-12 18:53:53,106 [run_pretraining.py:  558]:	worker_index: 7, step: 1111, cost: 7.940665, mlm loss: 7.940665, speed: 1.109661 steps/s, speed: 8.877292 samples/s, speed: 4545.173411 tokens/s, learning rate: 1.110e-05, loss_scalings: 13421.773438, pp_loss: 7.764005
[INFO] 2021-07-12 18:53:53,106 [run_pretraining.py:  512]:	********exe.run_1111******* 
[INFO] 2021-07-12 18:53:54,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:54,007 [run_pretraining.py:  534]:	loss/total_loss, 8.367419242858887, 1112
[INFO] 2021-07-12 18:53:54,007 [run_pretraining.py:  535]:	loss/mlm_loss, 8.367419242858887, 1112
[INFO] 2021-07-12 18:53:54,007 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1109999832115136e-05, 1112
[INFO] 2021-07-12 18:53:54,007 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1112
[INFO] 2021-07-12 18:53:54,007 [run_pretraining.py:  558]:	worker_index: 7, step: 1112, cost: 8.367419, mlm loss: 8.367419, speed: 1.111215 steps/s, speed: 8.889717 samples/s, speed: 4551.535051 tokens/s, learning rate: 1.111e-05, loss_scalings: 13421.773438, pp_loss: 7.752899
[INFO] 2021-07-12 18:53:54,007 [run_pretraining.py:  512]:	********exe.run_1112******* 
[INFO] 2021-07-12 18:53:54,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:54,912 [run_pretraining.py:  534]:	loss/total_loss, 7.928064823150635, 1113
[INFO] 2021-07-12 18:53:54,913 [run_pretraining.py:  535]:	loss/mlm_loss, 7.928064823150635, 1113
[INFO] 2021-07-12 18:53:54,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.111999972636113e-05, 1113
[INFO] 2021-07-12 18:53:54,913 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1113
[INFO] 2021-07-12 18:53:54,913 [run_pretraining.py:  558]:	worker_index: 7, step: 1113, cost: 7.928065, mlm loss: 7.928065, speed: 1.104597 steps/s, speed: 8.836774 samples/s, speed: 4524.428196 tokens/s, learning rate: 1.112e-05, loss_scalings: 13421.773438, pp_loss: 7.979702
[INFO] 2021-07-12 18:53:54,913 [run_pretraining.py:  512]:	********exe.run_1113******* 
[INFO] 2021-07-12 18:53:55,876 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:55,877 [run_pretraining.py:  534]:	loss/total_loss, 7.793822765350342, 1114
[INFO] 2021-07-12 18:53:55,877 [run_pretraining.py:  535]:	loss/mlm_loss, 7.793822765350342, 1114
[INFO] 2021-07-12 18:53:55,877 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1129999620607123e-05, 1114
[INFO] 2021-07-12 18:53:55,877 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1114
[INFO] 2021-07-12 18:53:55,877 [run_pretraining.py:  558]:	worker_index: 7, step: 1114, cost: 7.793823, mlm loss: 7.793823, speed: 1.037758 steps/s, speed: 8.302063 samples/s, speed: 4250.656329 tokens/s, learning rate: 1.113e-05, loss_scalings: 13421.773438, pp_loss: 7.601581
[INFO] 2021-07-12 18:53:55,877 [run_pretraining.py:  512]:	********exe.run_1114******* 
[INFO] 2021-07-12 18:53:56,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:56,943 [run_pretraining.py:  534]:	loss/total_loss, 7.9769439697265625, 1115
[INFO] 2021-07-12 18:53:56,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9769439697265625, 1115
[INFO] 2021-07-12 18:53:56,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1139999514853116e-05, 1115
[INFO] 2021-07-12 18:53:56,943 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1115
[INFO] 2021-07-12 18:53:56,943 [run_pretraining.py:  558]:	worker_index: 7, step: 1115, cost: 7.976944, mlm loss: 7.976944, speed: 0.938405 steps/s, speed: 7.507238 samples/s, speed: 3843.705679 tokens/s, learning rate: 1.114e-05, loss_scalings: 13421.773438, pp_loss: 7.651914
[INFO] 2021-07-12 18:53:56,943 [run_pretraining.py:  512]:	********exe.run_1115******* 
[INFO] 2021-07-12 18:53:58,006 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:58,006 [run_pretraining.py:  534]:	loss/total_loss, 7.0124616622924805, 1116
[INFO] 2021-07-12 18:53:58,006 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0124616622924805, 1116
[INFO] 2021-07-12 18:53:58,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1150000318593811e-05, 1116
[INFO] 2021-07-12 18:53:58,007 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1116
[INFO] 2021-07-12 18:53:58,007 [run_pretraining.py:  558]:	worker_index: 7, step: 1116, cost: 7.012462, mlm loss: 7.012462, speed: 0.941108 steps/s, speed: 7.528863 samples/s, speed: 3854.777702 tokens/s, learning rate: 1.115e-05, loss_scalings: 13421.773438, pp_loss: 7.582125
[INFO] 2021-07-12 18:53:58,007 [run_pretraining.py:  512]:	********exe.run_1116******* 
[INFO] 2021-07-12 18:53:59,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:53:59,078 [run_pretraining.py:  534]:	loss/total_loss, 3.843810558319092, 1117
[INFO] 2021-07-12 18:53:59,078 [run_pretraining.py:  535]:	loss/mlm_loss, 3.843810558319092, 1117
[INFO] 2021-07-12 18:53:59,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1159999303345103e-05, 1117
[INFO] 2021-07-12 18:53:59,078 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1117
[INFO] 2021-07-12 18:53:59,078 [run_pretraining.py:  558]:	worker_index: 7, step: 1117, cost: 3.843811, mlm loss: 3.843811, speed: 0.933712 steps/s, speed: 7.469697 samples/s, speed: 3824.484900 tokens/s, learning rate: 1.116e-05, loss_scalings: 13421.773438, pp_loss: 6.770873
[INFO] 2021-07-12 18:53:59,078 [run_pretraining.py:  512]:	********exe.run_1117******* 
[INFO] 2021-07-12 18:54:00,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:00,162 [run_pretraining.py:  534]:	loss/total_loss, 7.55432653427124, 1118
[INFO] 2021-07-12 18:54:00,162 [run_pretraining.py:  535]:	loss/mlm_loss, 7.55432653427124, 1118
[INFO] 2021-07-12 18:54:00,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1169999197591096e-05, 1118
[INFO] 2021-07-12 18:54:00,162 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1118
[INFO] 2021-07-12 18:54:00,162 [run_pretraining.py:  558]:	worker_index: 7, step: 1118, cost: 7.554327, mlm loss: 7.554327, speed: 0.923275 steps/s, speed: 7.386198 samples/s, speed: 3781.733162 tokens/s, learning rate: 1.117e-05, loss_scalings: 13421.773438, pp_loss: 7.784228
[INFO] 2021-07-12 18:54:00,162 [run_pretraining.py:  512]:	********exe.run_1118******* 
[INFO] 2021-07-12 18:54:01,220 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:01,220 [run_pretraining.py:  534]:	loss/total_loss, 7.155666351318359, 1119
[INFO] 2021-07-12 18:54:01,221 [run_pretraining.py:  535]:	loss/mlm_loss, 7.155666351318359, 1119
[INFO] 2021-07-12 18:54:01,221 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1180000001331791e-05, 1119
[INFO] 2021-07-12 18:54:01,221 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1119
[INFO] 2021-07-12 18:54:01,221 [run_pretraining.py:  558]:	worker_index: 7, step: 1119, cost: 7.155666, mlm loss: 7.155666, speed: 0.945035 steps/s, speed: 7.560283 samples/s, speed: 3870.864713 tokens/s, learning rate: 1.118e-05, loss_scalings: 13421.773438, pp_loss: 7.745396
[INFO] 2021-07-12 18:54:01,221 [run_pretraining.py:  512]:	********exe.run_1119******* 
[INFO] 2021-07-12 18:54:02,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:02,284 [run_pretraining.py:  534]:	loss/total_loss, 7.467870235443115, 1120
[INFO] 2021-07-12 18:54:02,284 [run_pretraining.py:  535]:	loss/mlm_loss, 7.467870235443115, 1120
[INFO] 2021-07-12 18:54:02,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1189999895577785e-05, 1120
[INFO] 2021-07-12 18:54:02,285 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1120
[INFO] 2021-07-12 18:54:02,285 [run_pretraining.py:  558]:	worker_index: 7, step: 1120, cost: 7.467870, mlm loss: 7.467870, speed: 0.940581 steps/s, speed: 7.524645 samples/s, speed: 3852.618328 tokens/s, learning rate: 1.119e-05, loss_scalings: 13421.773438, pp_loss: 7.713895
[INFO] 2021-07-12 18:54:02,285 [run_pretraining.py:  512]:	********exe.run_1120******* 
[INFO] 2021-07-12 18:54:03,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:03,354 [run_pretraining.py:  534]:	loss/total_loss, 7.198408126831055, 1121
[INFO] 2021-07-12 18:54:03,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.198408126831055, 1121
[INFO] 2021-07-12 18:54:03,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1199999789823778e-05, 1121
[INFO] 2021-07-12 18:54:03,354 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1121
[INFO] 2021-07-12 18:54:03,354 [run_pretraining.py:  558]:	worker_index: 7, step: 1121, cost: 7.198408, mlm loss: 7.198408, speed: 0.935786 steps/s, speed: 7.486288 samples/s, speed: 3832.979264 tokens/s, learning rate: 1.120e-05, loss_scalings: 13421.773438, pp_loss: 7.558956
[INFO] 2021-07-12 18:54:03,354 [run_pretraining.py:  512]:	********exe.run_1121******* 
[INFO] 2021-07-12 18:54:04,410 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:04,410 [run_pretraining.py:  534]:	loss/total_loss, 7.657268524169922, 1122
[INFO] 2021-07-12 18:54:04,410 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657268524169922, 1122
[INFO] 2021-07-12 18:54:04,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1209999684069771e-05, 1122
[INFO] 2021-07-12 18:54:04,411 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1122
[INFO] 2021-07-12 18:54:04,411 [run_pretraining.py:  558]:	worker_index: 7, step: 1122, cost: 7.657269, mlm loss: 7.657269, speed: 0.946772 steps/s, speed: 7.574178 samples/s, speed: 3877.978890 tokens/s, learning rate: 1.121e-05, loss_scalings: 13421.773438, pp_loss: 6.575535
[INFO] 2021-07-12 18:54:04,411 [run_pretraining.py:  512]:	********exe.run_1122******* 
[INFO] 2021-07-12 18:54:05,475 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:05,476 [run_pretraining.py:  534]:	loss/total_loss, 7.261909008026123, 1123
[INFO] 2021-07-12 18:54:05,476 [run_pretraining.py:  535]:	loss/mlm_loss, 7.261909008026123, 1123
[INFO] 2021-07-12 18:54:05,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1219999578315765e-05, 1123
[INFO] 2021-07-12 18:54:05,476 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1123
[INFO] 2021-07-12 18:54:05,476 [run_pretraining.py:  558]:	worker_index: 7, step: 1123, cost: 7.261909, mlm loss: 7.261909, speed: 0.939173 steps/s, speed: 7.513382 samples/s, speed: 3846.851421 tokens/s, learning rate: 1.122e-05, loss_scalings: 13421.773438, pp_loss: 7.614488
[INFO] 2021-07-12 18:54:05,476 [run_pretraining.py:  512]:	********exe.run_1123******* 
[INFO] 2021-07-12 18:54:06,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:06,546 [run_pretraining.py:  534]:	loss/total_loss, 7.546378135681152, 1124
[INFO] 2021-07-12 18:54:06,546 [run_pretraining.py:  535]:	loss/mlm_loss, 7.546378135681152, 1124
[INFO] 2021-07-12 18:54:06,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1229999472561758e-05, 1124
[INFO] 2021-07-12 18:54:06,547 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1124
[INFO] 2021-07-12 18:54:06,547 [run_pretraining.py:  558]:	worker_index: 7, step: 1124, cost: 7.546378, mlm loss: 7.546378, speed: 0.934711 steps/s, speed: 7.477687 samples/s, speed: 3828.575920 tokens/s, learning rate: 1.123e-05, loss_scalings: 13421.773438, pp_loss: 5.802033
[INFO] 2021-07-12 18:54:06,547 [run_pretraining.py:  512]:	********exe.run_1124******* 
[INFO] 2021-07-12 18:54:07,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:07,503 [run_pretraining.py:  534]:	loss/total_loss, 7.462834358215332, 1125
[INFO] 2021-07-12 18:54:07,503 [run_pretraining.py:  535]:	loss/mlm_loss, 7.462834358215332, 1125
[INFO] 2021-07-12 18:54:07,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1240000276302453e-05, 1125
[INFO] 2021-07-12 18:54:07,503 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1125
[INFO] 2021-07-12 18:54:07,503 [run_pretraining.py:  558]:	worker_index: 7, step: 1125, cost: 7.462834, mlm loss: 7.462834, speed: 1.045891 steps/s, speed: 8.367127 samples/s, speed: 4283.969276 tokens/s, learning rate: 1.124e-05, loss_scalings: 13421.773438, pp_loss: 7.570838
[INFO] 2021-07-12 18:54:07,504 [run_pretraining.py:  512]:	********exe.run_1125******* 
[INFO] 2021-07-12 18:54:08,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:08,423 [run_pretraining.py:  534]:	loss/total_loss, 7.9776692390441895, 1126
[INFO] 2021-07-12 18:54:08,423 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9776692390441895, 1126
[INFO] 2021-07-12 18:54:08,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1249999261053745e-05, 1126
[INFO] 2021-07-12 18:54:08,424 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1126
[INFO] 2021-07-12 18:54:08,424 [run_pretraining.py:  558]:	worker_index: 7, step: 1126, cost: 7.977669, mlm loss: 7.977669, speed: 1.087565 steps/s, speed: 8.700519 samples/s, speed: 4454.665957 tokens/s, learning rate: 1.125e-05, loss_scalings: 13421.773438, pp_loss: 7.664792
[INFO] 2021-07-12 18:54:08,424 [run_pretraining.py:  512]:	********exe.run_1126******* 
[INFO] 2021-07-12 18:54:09,344 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:09,345 [run_pretraining.py:  534]:	loss/total_loss, 7.813789367675781, 1127
[INFO] 2021-07-12 18:54:09,345 [run_pretraining.py:  535]:	loss/mlm_loss, 7.813789367675781, 1127
[INFO] 2021-07-12 18:54:09,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1259999155299738e-05, 1127
[INFO] 2021-07-12 18:54:09,345 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1127
[INFO] 2021-07-12 18:54:09,345 [run_pretraining.py:  558]:	worker_index: 7, step: 1127, cost: 7.813789, mlm loss: 7.813789, speed: 1.086199 steps/s, speed: 8.689594 samples/s, speed: 4449.072028 tokens/s, learning rate: 1.126e-05, loss_scalings: 13421.773438, pp_loss: 7.648949
[INFO] 2021-07-12 18:54:09,345 [run_pretraining.py:  512]:	********exe.run_1127******* 
[INFO] 2021-07-12 18:54:10,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:10,268 [run_pretraining.py:  534]:	loss/total_loss, 7.235050201416016, 1128
[INFO] 2021-07-12 18:54:10,268 [run_pretraining.py:  535]:	loss/mlm_loss, 7.235050201416016, 1128
[INFO] 2021-07-12 18:54:10,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1269999959040433e-05, 1128
[INFO] 2021-07-12 18:54:10,269 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1128
[INFO] 2021-07-12 18:54:10,269 [run_pretraining.py:  558]:	worker_index: 7, step: 1128, cost: 7.235050, mlm loss: 7.235050, speed: 1.083309 steps/s, speed: 8.666472 samples/s, speed: 4437.233889 tokens/s, learning rate: 1.127e-05, loss_scalings: 13421.773438, pp_loss: 7.699615
[INFO] 2021-07-12 18:54:10,269 [run_pretraining.py:  512]:	********exe.run_1128******* 
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  534]:	loss/total_loss, 7.615379810333252, 1129
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  535]:	loss/mlm_loss, 7.615379810333252, 1129
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1279999853286427e-05, 1129
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1129
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  558]:	worker_index: 7, step: 1129, cost: 7.615380, mlm loss: 7.615380, speed: 1.085650 steps/s, speed: 8.685203 samples/s, speed: 4446.824116 tokens/s, learning rate: 1.128e-05, loss_scalings: 13421.773438, pp_loss: 7.663081
[INFO] 2021-07-12 18:54:11,190 [run_pretraining.py:  512]:	********exe.run_1129******* 
[INFO] 2021-07-12 18:54:12,105 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:12,106 [run_pretraining.py:  534]:	loss/total_loss, 6.941123008728027, 1130
[INFO] 2021-07-12 18:54:12,106 [run_pretraining.py:  535]:	loss/mlm_loss, 6.941123008728027, 1130
[INFO] 2021-07-12 18:54:12,106 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.128999974753242e-05, 1130
[INFO] 2021-07-12 18:54:12,106 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1130
[INFO] 2021-07-12 18:54:12,106 [run_pretraining.py:  558]:	worker_index: 7, step: 1130, cost: 6.941123, mlm loss: 6.941123, speed: 1.092977 steps/s, speed: 8.743819 samples/s, speed: 4476.835376 tokens/s, learning rate: 1.129e-05, loss_scalings: 13421.773438, pp_loss: 7.309388
[INFO] 2021-07-12 18:54:12,106 [run_pretraining.py:  512]:	********exe.run_1130******* 
[INFO] 2021-07-12 18:54:13,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:13,024 [run_pretraining.py:  534]:	loss/total_loss, 7.416652202606201, 1131
[INFO] 2021-07-12 18:54:13,025 [run_pretraining.py:  535]:	loss/mlm_loss, 7.416652202606201, 1131
[INFO] 2021-07-12 18:54:13,025 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1299999641778413e-05, 1131
[INFO] 2021-07-12 18:54:13,025 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1131
[INFO] 2021-07-12 18:54:13,025 [run_pretraining.py:  558]:	worker_index: 7, step: 1131, cost: 7.416652, mlm loss: 7.416652, speed: 1.089220 steps/s, speed: 8.713760 samples/s, speed: 4461.445001 tokens/s, learning rate: 1.130e-05, loss_scalings: 13421.773438, pp_loss: 7.517584
[INFO] 2021-07-12 18:54:13,025 [run_pretraining.py:  512]:	********exe.run_1131******* 
[INFO] 2021-07-12 18:54:13,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:13,946 [run_pretraining.py:  534]:	loss/total_loss, 7.593918800354004, 1132
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.593918800354004, 1132
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1309999536024407e-05, 1132
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1132
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  558]:	worker_index: 7, step: 1132, cost: 7.593919, mlm loss: 7.593919, speed: 1.085379 steps/s, speed: 8.683035 samples/s, speed: 4445.713666 tokens/s, learning rate: 1.131e-05, loss_scalings: 13421.773438, pp_loss: 7.807024
[INFO] 2021-07-12 18:54:13,947 [run_pretraining.py:  512]:	********exe.run_1132******* 
[INFO] 2021-07-12 18:54:14,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:14,858 [run_pretraining.py:  534]:	loss/total_loss, 7.453399658203125, 1133
[INFO] 2021-07-12 18:54:14,858 [run_pretraining.py:  535]:	loss/mlm_loss, 7.453399658203125, 1133
[INFO] 2021-07-12 18:54:14,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.13199994302704e-05, 1133
[INFO] 2021-07-12 18:54:14,858 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1133
[INFO] 2021-07-12 18:54:14,858 [run_pretraining.py:  558]:	worker_index: 7, step: 1133, cost: 7.453400, mlm loss: 7.453400, speed: 1.097732 steps/s, speed: 8.781860 samples/s, speed: 4496.312154 tokens/s, learning rate: 1.132e-05, loss_scalings: 13421.773438, pp_loss: 7.469540
[INFO] 2021-07-12 18:54:14,858 [run_pretraining.py:  512]:	********exe.run_1133******* 
[INFO] 2021-07-12 18:54:15,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:15,776 [run_pretraining.py:  534]:	loss/total_loss, 7.959972381591797, 1134
[INFO] 2021-07-12 18:54:15,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.959972381591797, 1134
[INFO] 2021-07-12 18:54:15,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1330000234011095e-05, 1134
[INFO] 2021-07-12 18:54:15,776 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1134
[INFO] 2021-07-12 18:54:15,776 [run_pretraining.py:  558]:	worker_index: 7, step: 1134, cost: 7.959972, mlm loss: 7.959972, speed: 1.090649 steps/s, speed: 8.725196 samples/s, speed: 4467.300098 tokens/s, learning rate: 1.133e-05, loss_scalings: 13421.773438, pp_loss: 7.536994
[INFO] 2021-07-12 18:54:15,776 [run_pretraining.py:  512]:	********exe.run_1134******* 
[INFO] 2021-07-12 18:54:16,706 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:16,706 [run_pretraining.py:  534]:	loss/total_loss, 7.585493564605713, 1135
[INFO] 2021-07-12 18:54:16,706 [run_pretraining.py:  535]:	loss/mlm_loss, 7.585493564605713, 1135
[INFO] 2021-07-12 18:54:16,706 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1339999218762387e-05, 1135
[INFO] 2021-07-12 18:54:16,706 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1135
[INFO] 2021-07-12 18:54:16,706 [run_pretraining.py:  558]:	worker_index: 7, step: 1135, cost: 7.585494, mlm loss: 7.585494, speed: 1.075418 steps/s, speed: 8.603343 samples/s, speed: 4404.911689 tokens/s, learning rate: 1.134e-05, loss_scalings: 13421.773438, pp_loss: 7.654652
[INFO] 2021-07-12 18:54:16,707 [run_pretraining.py:  512]:	********exe.run_1135******* 
[INFO] 2021-07-12 18:54:17,625 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:17,626 [run_pretraining.py:  534]:	loss/total_loss, 8.182900428771973, 1136
[INFO] 2021-07-12 18:54:17,626 [run_pretraining.py:  535]:	loss/mlm_loss, 8.182900428771973, 1136
[INFO] 2021-07-12 18:54:17,626 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1350000022503082e-05, 1136
[INFO] 2021-07-12 18:54:17,626 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1136
[INFO] 2021-07-12 18:54:17,626 [run_pretraining.py:  558]:	worker_index: 7, step: 1136, cost: 8.182900, mlm loss: 8.182900, speed: 1.088360 steps/s, speed: 8.706877 samples/s, speed: 4457.921027 tokens/s, learning rate: 1.135e-05, loss_scalings: 13421.773438, pp_loss: 7.938850
[INFO] 2021-07-12 18:54:17,626 [run_pretraining.py:  512]:	********exe.run_1136******* 
[INFO] 2021-07-12 18:54:18,550 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:18,550 [run_pretraining.py:  534]:	loss/total_loss, 7.180724620819092, 1137
[INFO] 2021-07-12 18:54:18,551 [run_pretraining.py:  535]:	loss/mlm_loss, 7.180724620819092, 1137
[INFO] 2021-07-12 18:54:18,551 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1359999916749075e-05, 1137
[INFO] 2021-07-12 18:54:18,551 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1137
[INFO] 2021-07-12 18:54:18,551 [run_pretraining.py:  558]:	worker_index: 7, step: 1137, cost: 7.180725, mlm loss: 7.180725, speed: 1.081936 steps/s, speed: 8.655485 samples/s, speed: 4431.608179 tokens/s, learning rate: 1.136e-05, loss_scalings: 13421.773438, pp_loss: 7.667226
[INFO] 2021-07-12 18:54:18,551 [run_pretraining.py:  512]:	********exe.run_1137******* 
[INFO] 2021-07-12 18:54:19,474 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:19,475 [run_pretraining.py:  534]:	loss/total_loss, 7.786043167114258, 1138
[INFO] 2021-07-12 18:54:19,475 [run_pretraining.py:  535]:	loss/mlm_loss, 7.786043167114258, 1138
[INFO] 2021-07-12 18:54:19,475 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1369999810995068e-05, 1138
[INFO] 2021-07-12 18:54:19,475 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1138
[INFO] 2021-07-12 18:54:19,475 [run_pretraining.py:  558]:	worker_index: 7, step: 1138, cost: 7.786043, mlm loss: 7.786043, speed: 1.082868 steps/s, speed: 8.662942 samples/s, speed: 4435.426154 tokens/s, learning rate: 1.137e-05, loss_scalings: 13421.773438, pp_loss: 7.661549
[INFO] 2021-07-12 18:54:19,475 [run_pretraining.py:  512]:	********exe.run_1138******* 
[INFO] 2021-07-12 18:54:20,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:20,395 [run_pretraining.py:  534]:	loss/total_loss, 8.431224822998047, 1139
[INFO] 2021-07-12 18:54:20,395 [run_pretraining.py:  535]:	loss/mlm_loss, 8.431224822998047, 1139
[INFO] 2021-07-12 18:54:20,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1379999705241062e-05, 1139
[INFO] 2021-07-12 18:54:20,395 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1139
[INFO] 2021-07-12 18:54:20,395 [run_pretraining.py:  558]:	worker_index: 7, step: 1139, cost: 8.431225, mlm loss: 8.431225, speed: 1.087709 steps/s, speed: 8.701672 samples/s, speed: 4455.256279 tokens/s, learning rate: 1.138e-05, loss_scalings: 13421.773438, pp_loss: 7.765110
[INFO] 2021-07-12 18:54:20,395 [run_pretraining.py:  512]:	********exe.run_1139******* 
[INFO] 2021-07-12 18:54:21,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:21,315 [run_pretraining.py:  534]:	loss/total_loss, 7.331092834472656, 1140
[INFO] 2021-07-12 18:54:21,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.331092834472656, 1140
[INFO] 2021-07-12 18:54:21,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1389999599487055e-05, 1140
[INFO] 2021-07-12 18:54:21,315 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1140
[INFO] 2021-07-12 18:54:21,315 [run_pretraining.py:  558]:	worker_index: 7, step: 1140, cost: 7.331093, mlm loss: 7.331093, speed: 1.087184 steps/s, speed: 8.697470 samples/s, speed: 4453.104842 tokens/s, learning rate: 1.139e-05, loss_scalings: 13421.773438, pp_loss: 7.253814
[INFO] 2021-07-12 18:54:21,316 [run_pretraining.py:  512]:	********exe.run_1140******* 
[INFO] 2021-07-12 18:54:22,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:22,232 [run_pretraining.py:  534]:	loss/total_loss, 7.884902000427246, 1141
[INFO] 2021-07-12 18:54:22,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.884902000427246, 1141
[INFO] 2021-07-12 18:54:22,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1399999493733048e-05, 1141
[INFO] 2021-07-12 18:54:22,233 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1141
[INFO] 2021-07-12 18:54:22,233 [run_pretraining.py:  558]:	worker_index: 7, step: 1141, cost: 7.884902, mlm loss: 7.884902, speed: 1.091119 steps/s, speed: 8.728952 samples/s, speed: 4469.223435 tokens/s, learning rate: 1.140e-05, loss_scalings: 13421.773438, pp_loss: 7.735731
[INFO] 2021-07-12 18:54:22,233 [run_pretraining.py:  512]:	********exe.run_1141******* 
[INFO] 2021-07-12 18:54:23,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:23,153 [run_pretraining.py:  534]:	loss/total_loss, 7.919376373291016, 1142
[INFO] 2021-07-12 18:54:23,153 [run_pretraining.py:  535]:	loss/mlm_loss, 7.919376373291016, 1142
[INFO] 2021-07-12 18:54:23,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1410000297473744e-05, 1142
[INFO] 2021-07-12 18:54:23,154 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1142
[INFO] 2021-07-12 18:54:23,154 [run_pretraining.py:  558]:	worker_index: 7, step: 1142, cost: 7.919376, mlm loss: 7.919376, speed: 1.086461 steps/s, speed: 8.691687 samples/s, speed: 4450.143811 tokens/s, learning rate: 1.141e-05, loss_scalings: 13421.773438, pp_loss: 7.780787
[INFO] 2021-07-12 18:54:23,154 [run_pretraining.py:  512]:	********exe.run_1142******* 
[INFO] 2021-07-12 18:54:24,091 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:24,092 [run_pretraining.py:  534]:	loss/total_loss, 6.737504005432129, 1143
[INFO] 2021-07-12 18:54:24,092 [run_pretraining.py:  535]:	loss/mlm_loss, 6.737504005432129, 1143
[INFO] 2021-07-12 18:54:24,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1420000191719737e-05, 1143
[INFO] 2021-07-12 18:54:24,092 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1143
[INFO] 2021-07-12 18:54:24,092 [run_pretraining.py:  558]:	worker_index: 7, step: 1143, cost: 6.737504, mlm loss: 6.737504, speed: 1.066266 steps/s, speed: 8.530131 samples/s, speed: 4367.427282 tokens/s, learning rate: 1.142e-05, loss_scalings: 13421.773438, pp_loss: 7.423815
[INFO] 2021-07-12 18:54:24,092 [run_pretraining.py:  512]:	********exe.run_1143******* 
[INFO] 2021-07-12 18:54:25,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:25,011 [run_pretraining.py:  534]:	loss/total_loss, 7.42402982711792, 1144
[INFO] 2021-07-12 18:54:25,011 [run_pretraining.py:  535]:	loss/mlm_loss, 7.42402982711792, 1144
[INFO] 2021-07-12 18:54:25,011 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1429999176471028e-05, 1144
[INFO] 2021-07-12 18:54:25,011 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1144
[INFO] 2021-07-12 18:54:25,012 [run_pretraining.py:  558]:	worker_index: 7, step: 1144, cost: 7.424030, mlm loss: 7.424030, speed: 1.088509 steps/s, speed: 8.708075 samples/s, speed: 4458.534196 tokens/s, learning rate: 1.143e-05, loss_scalings: 13421.773438, pp_loss: 7.561899
[INFO] 2021-07-12 18:54:25,012 [run_pretraining.py:  512]:	********exe.run_1144******* 
[INFO] 2021-07-12 18:54:25,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:25,927 [run_pretraining.py:  534]:	loss/total_loss, 7.3151655197143555, 1145
[INFO] 2021-07-12 18:54:25,927 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3151655197143555, 1145
[INFO] 2021-07-12 18:54:25,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1439999980211724e-05, 1145
[INFO] 2021-07-12 18:54:25,928 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1145
[INFO] 2021-07-12 18:54:25,928 [run_pretraining.py:  558]:	worker_index: 7, step: 1145, cost: 7.315166, mlm loss: 7.315166, speed: 1.092428 steps/s, speed: 8.739421 samples/s, speed: 4474.583802 tokens/s, learning rate: 1.144e-05, loss_scalings: 13421.773438, pp_loss: 7.536793
[INFO] 2021-07-12 18:54:25,928 [run_pretraining.py:  512]:	********exe.run_1145******* 
[INFO] 2021-07-12 18:54:26,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:26,843 [run_pretraining.py:  534]:	loss/total_loss, 7.364089012145996, 1146
[INFO] 2021-07-12 18:54:26,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.364089012145996, 1146
[INFO] 2021-07-12 18:54:26,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1449999874457717e-05, 1146
[INFO] 2021-07-12 18:54:26,843 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1146
[INFO] 2021-07-12 18:54:26,843 [run_pretraining.py:  558]:	worker_index: 7, step: 1146, cost: 7.364089, mlm loss: 7.364089, speed: 1.092680 steps/s, speed: 8.741441 samples/s, speed: 4475.617775 tokens/s, learning rate: 1.145e-05, loss_scalings: 13421.773438, pp_loss: 7.723248
[INFO] 2021-07-12 18:54:26,843 [run_pretraining.py:  512]:	********exe.run_1146******* 
[INFO] 2021-07-12 18:54:27,763 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:27,764 [run_pretraining.py:  534]:	loss/total_loss, 7.704886436462402, 1147
[INFO] 2021-07-12 18:54:27,764 [run_pretraining.py:  535]:	loss/mlm_loss, 7.704886436462402, 1147
[INFO] 2021-07-12 18:54:27,764 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.145999976870371e-05, 1147
[INFO] 2021-07-12 18:54:27,764 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1147
[INFO] 2021-07-12 18:54:27,764 [run_pretraining.py:  558]:	worker_index: 7, step: 1147, cost: 7.704886, mlm loss: 7.704886, speed: 1.086985 steps/s, speed: 8.695884 samples/s, speed: 4452.292387 tokens/s, learning rate: 1.146e-05, loss_scalings: 13421.773438, pp_loss: 7.774583
[INFO] 2021-07-12 18:54:27,764 [run_pretraining.py:  512]:	********exe.run_1147******* 
[INFO] 2021-07-12 18:54:28,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  534]:	loss/total_loss, 4.263519287109375, 1148
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  535]:	loss/mlm_loss, 4.263519287109375, 1148
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1469999662949704e-05, 1148
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1148
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  558]:	worker_index: 7, step: 1148, cost: 4.263519, mlm loss: 4.263519, speed: 1.096256 steps/s, speed: 8.770048 samples/s, speed: 4490.264620 tokens/s, learning rate: 1.147e-05, loss_scalings: 13421.773438, pp_loss: 7.025098
[INFO] 2021-07-12 18:54:28,677 [run_pretraining.py:  512]:	********exe.run_1148******* 
[INFO] 2021-07-12 18:54:29,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:29,586 [run_pretraining.py:  534]:	loss/total_loss, 7.602578639984131, 1149
[INFO] 2021-07-12 18:54:29,586 [run_pretraining.py:  535]:	loss/mlm_loss, 7.602578639984131, 1149
[INFO] 2021-07-12 18:54:29,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1479999557195697e-05, 1149
[INFO] 2021-07-12 18:54:29,586 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1149
[INFO] 2021-07-12 18:54:29,587 [run_pretraining.py:  558]:	worker_index: 7, step: 1149, cost: 7.602579, mlm loss: 7.602579, speed: 1.100113 steps/s, speed: 8.800904 samples/s, speed: 4506.062821 tokens/s, learning rate: 1.148e-05, loss_scalings: 13421.773438, pp_loss: 7.773210
[INFO] 2021-07-12 18:54:29,587 [run_pretraining.py:  512]:	********exe.run_1149******* 
[INFO] 2021-07-12 18:54:30,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:30,498 [run_pretraining.py:  534]:	loss/total_loss, 7.625142574310303, 1150
[INFO] 2021-07-12 18:54:30,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.625142574310303, 1150
[INFO] 2021-07-12 18:54:30,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.148999945144169e-05, 1150
[INFO] 2021-07-12 18:54:30,498 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1150
[INFO] 2021-07-12 18:54:30,498 [run_pretraining.py:  558]:	worker_index: 7, step: 1150, cost: 7.625143, mlm loss: 7.625143, speed: 1.097767 steps/s, speed: 8.782135 samples/s, speed: 4496.453372 tokens/s, learning rate: 1.149e-05, loss_scalings: 13421.773438, pp_loss: 7.093984
[INFO] 2021-07-12 18:54:30,498 [run_pretraining.py:  512]:	********exe.run_1150******* 
[INFO] 2021-07-12 18:54:31,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:31,414 [run_pretraining.py:  534]:	loss/total_loss, 7.656583786010742, 1151
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  535]:	loss/mlm_loss, 7.656583786010742, 1151
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1500000255182385e-05, 1151
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1151
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  558]:	worker_index: 7, step: 1151, cost: 7.656584, mlm loss: 7.656584, speed: 1.091788 steps/s, speed: 8.734303 samples/s, speed: 4471.963125 tokens/s, learning rate: 1.150e-05, loss_scalings: 13421.773438, pp_loss: 7.517606
[INFO] 2021-07-12 18:54:31,415 [run_pretraining.py:  512]:	********exe.run_1151******* 
[INFO] 2021-07-12 18:54:32,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:32,334 [run_pretraining.py:  534]:	loss/total_loss, 7.274411678314209, 1152
[INFO] 2021-07-12 18:54:32,335 [run_pretraining.py:  535]:	loss/mlm_loss, 7.274411678314209, 1152
[INFO] 2021-07-12 18:54:32,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1509999239933677e-05, 1152
[INFO] 2021-07-12 18:54:32,335 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1152
[INFO] 2021-07-12 18:54:32,335 [run_pretraining.py:  558]:	worker_index: 7, step: 1152, cost: 7.274412, mlm loss: 7.274412, speed: 1.087620 steps/s, speed: 8.700957 samples/s, speed: 4454.890053 tokens/s, learning rate: 1.151e-05, loss_scalings: 13421.773438, pp_loss: 7.610788
[INFO] 2021-07-12 18:54:32,335 [run_pretraining.py:  512]:	********exe.run_1152******* 
[INFO] 2021-07-12 18:54:33,242 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:33,243 [run_pretraining.py:  534]:	loss/total_loss, 7.901417255401611, 1153
[INFO] 2021-07-12 18:54:33,243 [run_pretraining.py:  535]:	loss/mlm_loss, 7.901417255401611, 1153
[INFO] 2021-07-12 18:54:33,243 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.151999913417967e-05, 1153
[INFO] 2021-07-12 18:54:33,243 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1153
[INFO] 2021-07-12 18:54:33,243 [run_pretraining.py:  558]:	worker_index: 7, step: 1153, cost: 7.901417, mlm loss: 7.901417, speed: 1.102070 steps/s, speed: 8.816562 samples/s, speed: 4514.079591 tokens/s, learning rate: 1.152e-05, loss_scalings: 13421.773438, pp_loss: 7.787739
[INFO] 2021-07-12 18:54:33,243 [run_pretraining.py:  512]:	********exe.run_1153******* 
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  534]:	loss/total_loss, 7.15629768371582, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  535]:	loss/mlm_loss, 7.15629768371582, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1529999937920365e-05, 1154
[INFO] 2021-07-12 18:54:34,162 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1154
[INFO] 2021-07-12 18:54:34,163 [run_pretraining.py:  558]:	worker_index: 7, step: 1154, cost: 7.156298, mlm loss: 7.156298, speed: 1.088106 steps/s, speed: 8.704849 samples/s, speed: 4456.882494 tokens/s, learning rate: 1.153e-05, loss_scalings: 13421.773438, pp_loss: 7.576555
[INFO] 2021-07-12 18:54:34,163 [run_pretraining.py:  512]:	********exe.run_1154******* 
[INFO] 2021-07-12 18:54:35,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:35,081 [run_pretraining.py:  534]:	loss/total_loss, 7.7528181076049805, 1155
[INFO] 2021-07-12 18:54:35,081 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7528181076049805, 1155
[INFO] 2021-07-12 18:54:35,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1539999832166359e-05, 1155
[INFO] 2021-07-12 18:54:35,081 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1155
[INFO] 2021-07-12 18:54:35,081 [run_pretraining.py:  558]:	worker_index: 7, step: 1155, cost: 7.752818, mlm loss: 7.752818, speed: 1.089145 steps/s, speed: 8.713158 samples/s, speed: 4461.136836 tokens/s, learning rate: 1.154e-05, loss_scalings: 13421.773438, pp_loss: 7.734972
[INFO] 2021-07-12 18:54:35,081 [run_pretraining.py:  512]:	********exe.run_1155******* 
[INFO] 2021-07-12 18:54:35,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:35,985 [run_pretraining.py:  534]:	loss/total_loss, 6.922388076782227, 1156
[INFO] 2021-07-12 18:54:35,985 [run_pretraining.py:  535]:	loss/mlm_loss, 6.922388076782227, 1156
[INFO] 2021-07-12 18:54:35,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1549999726412352e-05, 1156
[INFO] 2021-07-12 18:54:35,985 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1156
[INFO] 2021-07-12 18:54:35,985 [run_pretraining.py:  558]:	worker_index: 7, step: 1156, cost: 6.922388, mlm loss: 6.922388, speed: 1.107308 steps/s, speed: 8.858465 samples/s, speed: 4535.534303 tokens/s, learning rate: 1.155e-05, loss_scalings: 13421.773438, pp_loss: 7.631846
[INFO] 2021-07-12 18:54:35,985 [run_pretraining.py:  512]:	********exe.run_1156******* 
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  534]:	loss/total_loss, 7.87444543838501, 1157
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  535]:	loss/mlm_loss, 7.87444543838501, 1157
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1559999620658346e-05, 1157
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1157
[INFO] 2021-07-12 18:54:36,903 [run_pretraining.py:  558]:	worker_index: 7, step: 1157, cost: 7.874445, mlm loss: 7.874445, speed: 1.089666 steps/s, speed: 8.717330 samples/s, speed: 4463.272852 tokens/s, learning rate: 1.156e-05, loss_scalings: 13421.773438, pp_loss: 7.550087
[INFO] 2021-07-12 18:54:36,904 [run_pretraining.py:  512]:	********exe.run_1157******* 
[INFO] 2021-07-12 18:54:37,816 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:37,816 [run_pretraining.py:  534]:	loss/total_loss, 7.9433441162109375, 1158
[INFO] 2021-07-12 18:54:37,816 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9433441162109375, 1158
[INFO] 2021-07-12 18:54:37,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1569999514904339e-05, 1158
[INFO] 2021-07-12 18:54:37,816 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1158
[INFO] 2021-07-12 18:54:37,816 [run_pretraining.py:  558]:	worker_index: 7, step: 1158, cost: 7.943344, mlm loss: 7.943344, speed: 1.096165 steps/s, speed: 8.769319 samples/s, speed: 4489.891443 tokens/s, learning rate: 1.157e-05, loss_scalings: 13421.773438, pp_loss: 7.491920
[INFO] 2021-07-12 18:54:37,816 [run_pretraining.py:  512]:	********exe.run_1158******* 
[INFO] 2021-07-12 18:54:38,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:38,728 [run_pretraining.py:  534]:	loss/total_loss, 7.504996299743652, 1159
[INFO] 2021-07-12 18:54:38,728 [run_pretraining.py:  535]:	loss/mlm_loss, 7.504996299743652, 1159
[INFO] 2021-07-12 18:54:38,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1579999409150332e-05, 1159
[INFO] 2021-07-12 18:54:38,728 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1159
[INFO] 2021-07-12 18:54:38,728 [run_pretraining.py:  558]:	worker_index: 7, step: 1159, cost: 7.504996, mlm loss: 7.504996, speed: 1.097763 steps/s, speed: 8.782103 samples/s, speed: 4496.436896 tokens/s, learning rate: 1.158e-05, loss_scalings: 13421.773438, pp_loss: 6.942698
[INFO] 2021-07-12 18:54:38,728 [run_pretraining.py:  512]:	********exe.run_1159******* 
[INFO] 2021-07-12 18:54:39,638 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:39,639 [run_pretraining.py:  534]:	loss/total_loss, 7.571073532104492, 1160
[INFO] 2021-07-12 18:54:39,639 [run_pretraining.py:  535]:	loss/mlm_loss, 7.571073532104492, 1160
[INFO] 2021-07-12 18:54:39,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1590000212891027e-05, 1160
[INFO] 2021-07-12 18:54:39,639 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1160
[INFO] 2021-07-12 18:54:39,639 [run_pretraining.py:  558]:	worker_index: 7, step: 1160, cost: 7.571074, mlm loss: 7.571074, speed: 1.098369 steps/s, speed: 8.786949 samples/s, speed: 4498.917864 tokens/s, learning rate: 1.159e-05, loss_scalings: 13421.773438, pp_loss: 7.430042
[INFO] 2021-07-12 18:54:39,639 [run_pretraining.py:  512]:	********exe.run_1160******* 
[INFO] 2021-07-12 18:54:40,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:40,553 [run_pretraining.py:  534]:	loss/total_loss, 7.66519832611084, 1161
[INFO] 2021-07-12 18:54:40,553 [run_pretraining.py:  535]:	loss/mlm_loss, 7.66519832611084, 1161
[INFO] 2021-07-12 18:54:40,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1599999197642319e-05, 1161
[INFO] 2021-07-12 18:54:40,553 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1161
[INFO] 2021-07-12 18:54:40,553 [run_pretraining.py:  558]:	worker_index: 7, step: 1161, cost: 7.665198, mlm loss: 7.665198, speed: 1.094486 steps/s, speed: 8.755887 samples/s, speed: 4483.014045 tokens/s, learning rate: 1.160e-05, loss_scalings: 13421.773438, pp_loss: 7.611130
[INFO] 2021-07-12 18:54:40,553 [run_pretraining.py:  512]:	********exe.run_1161******* 
[INFO] 2021-07-12 18:54:41,467 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:41,468 [run_pretraining.py:  534]:	loss/total_loss, 7.297630310058594, 1162
[INFO] 2021-07-12 18:54:41,468 [run_pretraining.py:  535]:	loss/mlm_loss, 7.297630310058594, 1162
[INFO] 2021-07-12 18:54:41,468 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1609999091888312e-05, 1162
[INFO] 2021-07-12 18:54:41,468 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1162
[INFO] 2021-07-12 18:54:41,468 [run_pretraining.py:  558]:	worker_index: 7, step: 1162, cost: 7.297630, mlm loss: 7.297630, speed: 1.093981 steps/s, speed: 8.751845 samples/s, speed: 4480.944413 tokens/s, learning rate: 1.161e-05, loss_scalings: 13421.773438, pp_loss: 7.715722
[INFO] 2021-07-12 18:54:41,468 [run_pretraining.py:  512]:	********exe.run_1162******* 
[INFO] 2021-07-12 18:54:42,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:42,383 [run_pretraining.py:  534]:	loss/total_loss, 7.614750385284424, 1163
[INFO] 2021-07-12 18:54:42,383 [run_pretraining.py:  535]:	loss/mlm_loss, 7.614750385284424, 1163
[INFO] 2021-07-12 18:54:42,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1619999895629007e-05, 1163
[INFO] 2021-07-12 18:54:42,383 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1163
[INFO] 2021-07-12 18:54:42,383 [run_pretraining.py:  558]:	worker_index: 7, step: 1163, cost: 7.614750, mlm loss: 7.614750, speed: 1.093813 steps/s, speed: 8.750505 samples/s, speed: 4480.258465 tokens/s, learning rate: 1.162e-05, loss_scalings: 13421.773438, pp_loss: 7.841776
[INFO] 2021-07-12 18:54:42,383 [run_pretraining.py:  512]:	********exe.run_1163******* 
[INFO] 2021-07-12 18:54:43,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:43,297 [run_pretraining.py:  534]:	loss/total_loss, 7.946455001831055, 1164
[INFO] 2021-07-12 18:54:43,297 [run_pretraining.py:  535]:	loss/mlm_loss, 7.946455001831055, 1164
[INFO] 2021-07-12 18:54:43,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1629999789875e-05, 1164
[INFO] 2021-07-12 18:54:43,297 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1164
[INFO] 2021-07-12 18:54:43,297 [run_pretraining.py:  558]:	worker_index: 7, step: 1164, cost: 7.946455, mlm loss: 7.946455, speed: 1.094782 steps/s, speed: 8.758257 samples/s, speed: 4484.227480 tokens/s, learning rate: 1.163e-05, loss_scalings: 13421.773438, pp_loss: 8.003644
[INFO] 2021-07-12 18:54:43,297 [run_pretraining.py:  512]:	********exe.run_1164******* 
[INFO] 2021-07-12 18:54:44,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:44,213 [run_pretraining.py:  534]:	loss/total_loss, 7.651883125305176, 1165
[INFO] 2021-07-12 18:54:44,213 [run_pretraining.py:  535]:	loss/mlm_loss, 7.651883125305176, 1165
[INFO] 2021-07-12 18:54:44,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1639999684120994e-05, 1165
[INFO] 2021-07-12 18:54:44,213 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1165
[INFO] 2021-07-12 18:54:44,213 [run_pretraining.py:  558]:	worker_index: 7, step: 1165, cost: 7.651883, mlm loss: 7.651883, speed: 1.092431 steps/s, speed: 8.739444 samples/s, speed: 4474.595456 tokens/s, learning rate: 1.164e-05, loss_scalings: 13421.773438, pp_loss: 7.555387
[INFO] 2021-07-12 18:54:44,213 [run_pretraining.py:  512]:	********exe.run_1165******* 
[INFO] 2021-07-12 18:54:45,125 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:45,126 [run_pretraining.py:  534]:	loss/total_loss, 8.242923736572266, 1166
[INFO] 2021-07-12 18:54:45,126 [run_pretraining.py:  535]:	loss/mlm_loss, 8.242923736572266, 1166
[INFO] 2021-07-12 18:54:45,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1649999578366987e-05, 1166
[INFO] 2021-07-12 18:54:45,126 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1166
[INFO] 2021-07-12 18:54:45,126 [run_pretraining.py:  558]:	worker_index: 7, step: 1166, cost: 8.242924, mlm loss: 8.242924, speed: 1.096293 steps/s, speed: 8.770344 samples/s, speed: 4490.416021 tokens/s, learning rate: 1.165e-05, loss_scalings: 13421.773438, pp_loss: 7.833677
[INFO] 2021-07-12 18:54:45,126 [run_pretraining.py:  512]:	********exe.run_1166******* 
[INFO] 2021-07-12 18:54:46,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:46,041 [run_pretraining.py:  534]:	loss/total_loss, 7.9487433433532715, 1167
[INFO] 2021-07-12 18:54:46,041 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9487433433532715, 1167
[INFO] 2021-07-12 18:54:46,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.165999947261298e-05, 1167
[INFO] 2021-07-12 18:54:46,041 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1167
[INFO] 2021-07-12 18:54:46,042 [run_pretraining.py:  558]:	worker_index: 7, step: 1167, cost: 7.948743, mlm loss: 7.948743, speed: 1.093022 steps/s, speed: 8.744177 samples/s, speed: 4477.018539 tokens/s, learning rate: 1.166e-05, loss_scalings: 13421.773438, pp_loss: 7.874258
[INFO] 2021-07-12 18:54:46,042 [run_pretraining.py:  512]:	********exe.run_1167******* 
[INFO] 2021-07-12 18:54:46,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:46,951 [run_pretraining.py:  534]:	loss/total_loss, 8.461591720581055, 1168
[INFO] 2021-07-12 18:54:46,951 [run_pretraining.py:  535]:	loss/mlm_loss, 8.461591720581055, 1168
[INFO] 2021-07-12 18:54:46,951 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1669999366858974e-05, 1168
[INFO] 2021-07-12 18:54:46,951 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1168
[INFO] 2021-07-12 18:54:46,951 [run_pretraining.py:  558]:	worker_index: 7, step: 1168, cost: 8.461592, mlm loss: 8.461592, speed: 1.100379 steps/s, speed: 8.803033 samples/s, speed: 4507.152781 tokens/s, learning rate: 1.167e-05, loss_scalings: 13421.773438, pp_loss: 7.366651
[INFO] 2021-07-12 18:54:46,951 [run_pretraining.py:  512]:	********exe.run_1168******* 
[INFO] 2021-07-12 18:54:47,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:47,863 [run_pretraining.py:  534]:	loss/total_loss, 8.033767700195312, 1169
[INFO] 2021-07-12 18:54:47,863 [run_pretraining.py:  535]:	loss/mlm_loss, 8.033767700195312, 1169
[INFO] 2021-07-12 18:54:47,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.168000017059967e-05, 1169
[INFO] 2021-07-12 18:54:47,864 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1169
[INFO] 2021-07-12 18:54:47,864 [run_pretraining.py:  558]:	worker_index: 7, step: 1169, cost: 8.033768, mlm loss: 8.033768, speed: 1.096472 steps/s, speed: 8.771779 samples/s, speed: 4491.150871 tokens/s, learning rate: 1.168e-05, loss_scalings: 13421.773438, pp_loss: 7.864719
[INFO] 2021-07-12 18:54:47,864 [run_pretraining.py:  512]:	********exe.run_1169******* 
[INFO] 2021-07-12 18:54:48,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:48,784 [run_pretraining.py:  534]:	loss/total_loss, 7.529632091522217, 1170
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  535]:	loss/mlm_loss, 7.529632091522217, 1170
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.168999915535096e-05, 1170
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1170
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  558]:	worker_index: 7, step: 1170, cost: 7.529632, mlm loss: 7.529632, speed: 1.086323 steps/s, speed: 8.690584 samples/s, speed: 4449.579044 tokens/s, learning rate: 1.169e-05, loss_scalings: 13421.773438, pp_loss: 7.331954
[INFO] 2021-07-12 18:54:48,785 [run_pretraining.py:  512]:	********exe.run_1170******* 
[INFO] 2021-07-12 18:54:49,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:49,694 [run_pretraining.py:  534]:	loss/total_loss, 5.254290580749512, 1171
[INFO] 2021-07-12 18:54:49,694 [run_pretraining.py:  535]:	loss/mlm_loss, 5.254290580749512, 1171
[INFO] 2021-07-12 18:54:49,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1699999959091656e-05, 1171
[INFO] 2021-07-12 18:54:49,695 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1171
[INFO] 2021-07-12 18:54:49,695 [run_pretraining.py:  558]:	worker_index: 7, step: 1171, cost: 5.254291, mlm loss: 5.254291, speed: 1.099832 steps/s, speed: 8.798656 samples/s, speed: 4504.911961 tokens/s, learning rate: 1.170e-05, loss_scalings: 13421.773438, pp_loss: 5.958508
[INFO] 2021-07-12 18:54:49,695 [run_pretraining.py:  512]:	********exe.run_1171******* 
[INFO] 2021-07-12 18:54:50,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:50,610 [run_pretraining.py:  534]:	loss/total_loss, 4.213194847106934, 1172
[INFO] 2021-07-12 18:54:50,610 [run_pretraining.py:  535]:	loss/mlm_loss, 4.213194847106934, 1172
[INFO] 2021-07-12 18:54:50,610 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.170999985333765e-05, 1172
[INFO] 2021-07-12 18:54:50,611 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1172
[INFO] 2021-07-12 18:54:50,611 [run_pretraining.py:  558]:	worker_index: 7, step: 1172, cost: 4.213195, mlm loss: 4.213195, speed: 1.092551 steps/s, speed: 8.740407 samples/s, speed: 4475.088489 tokens/s, learning rate: 1.171e-05, loss_scalings: 13421.773438, pp_loss: 6.650135
[INFO] 2021-07-12 18:54:50,611 [run_pretraining.py:  512]:	********exe.run_1172******* 
[INFO] 2021-07-12 18:54:51,525 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:51,525 [run_pretraining.py:  534]:	loss/total_loss, 6.961203575134277, 1173
[INFO] 2021-07-12 18:54:51,525 [run_pretraining.py:  535]:	loss/mlm_loss, 6.961203575134277, 1173
[INFO] 2021-07-12 18:54:51,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1719999747583643e-05, 1173
[INFO] 2021-07-12 18:54:51,525 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1173
[INFO] 2021-07-12 18:54:51,525 [run_pretraining.py:  558]:	worker_index: 7, step: 1173, cost: 6.961204, mlm loss: 6.961204, speed: 1.093850 steps/s, speed: 8.750804 samples/s, speed: 4480.411529 tokens/s, learning rate: 1.172e-05, loss_scalings: 13421.773438, pp_loss: 7.301477
[INFO] 2021-07-12 18:54:51,526 [run_pretraining.py:  512]:	********exe.run_1173******* 
[INFO] 2021-07-12 18:54:52,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  534]:	loss/total_loss, 7.733958721160889, 1174
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  535]:	loss/mlm_loss, 7.733958721160889, 1174
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1729999641829636e-05, 1174
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1174
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  558]:	worker_index: 7, step: 1174, cost: 7.733959, mlm loss: 7.733959, speed: 1.095016 steps/s, speed: 8.760129 samples/s, speed: 4485.186289 tokens/s, learning rate: 1.173e-05, loss_scalings: 13421.773438, pp_loss: 6.880941
[INFO] 2021-07-12 18:54:52,439 [run_pretraining.py:  512]:	********exe.run_1174******* 
[INFO] 2021-07-12 18:54:53,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:53,345 [run_pretraining.py:  534]:	loss/total_loss, 7.886267185211182, 1175
[INFO] 2021-07-12 18:54:53,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.886267185211182, 1175
[INFO] 2021-07-12 18:54:53,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.173999953607563e-05, 1175
[INFO] 2021-07-12 18:54:53,346 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1175
[INFO] 2021-07-12 18:54:53,346 [run_pretraining.py:  558]:	worker_index: 7, step: 1175, cost: 7.886267, mlm loss: 7.886267, speed: 1.104001 steps/s, speed: 8.832010 samples/s, speed: 4521.989244 tokens/s, learning rate: 1.174e-05, loss_scalings: 13421.773438, pp_loss: 8.030334
[INFO] 2021-07-12 18:54:53,346 [run_pretraining.py:  512]:	********exe.run_1175******* 
[INFO] 2021-07-12 18:54:54,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:54,269 [run_pretraining.py:  534]:	loss/total_loss, 7.284976482391357, 1176
[INFO] 2021-07-12 18:54:54,269 [run_pretraining.py:  535]:	loss/mlm_loss, 7.284976482391357, 1176
[INFO] 2021-07-12 18:54:54,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1749999430321623e-05, 1176
[INFO] 2021-07-12 18:54:54,269 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1176
[INFO] 2021-07-12 18:54:54,269 [run_pretraining.py:  558]:	worker_index: 7, step: 1176, cost: 7.284976, mlm loss: 7.284976, speed: 1.083641 steps/s, speed: 8.669126 samples/s, speed: 4438.592378 tokens/s, learning rate: 1.175e-05, loss_scalings: 13421.773438, pp_loss: 7.404403
[INFO] 2021-07-12 18:54:54,269 [run_pretraining.py:  512]:	********exe.run_1176******* 
[INFO] 2021-07-12 18:54:55,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:55,180 [run_pretraining.py:  534]:	loss/total_loss, 7.823729515075684, 1177
[INFO] 2021-07-12 18:54:55,180 [run_pretraining.py:  535]:	loss/mlm_loss, 7.823729515075684, 1177
[INFO] 2021-07-12 18:54:55,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1760000234062318e-05, 1177
[INFO] 2021-07-12 18:54:55,180 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1177
[INFO] 2021-07-12 18:54:55,180 [run_pretraining.py:  558]:	worker_index: 7, step: 1177, cost: 7.823730, mlm loss: 7.823730, speed: 1.098231 steps/s, speed: 8.785847 samples/s, speed: 4498.353607 tokens/s, learning rate: 1.176e-05, loss_scalings: 13421.773438, pp_loss: 7.758171
[INFO] 2021-07-12 18:54:55,181 [run_pretraining.py:  512]:	********exe.run_1177******* 
[INFO] 2021-07-12 18:54:56,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:56,102 [run_pretraining.py:  534]:	loss/total_loss, 7.310341835021973, 1178
[INFO] 2021-07-12 18:54:56,103 [run_pretraining.py:  535]:	loss/mlm_loss, 7.310341835021973, 1178
[INFO] 2021-07-12 18:54:56,103 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1770000128308311e-05, 1178
[INFO] 2021-07-12 18:54:56,103 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1178
[INFO] 2021-07-12 18:54:56,103 [run_pretraining.py:  558]:	worker_index: 7, step: 1178, cost: 7.310342, mlm loss: 7.310342, speed: 1.084958 steps/s, speed: 8.679661 samples/s, speed: 4443.986380 tokens/s, learning rate: 1.177e-05, loss_scalings: 13421.773438, pp_loss: 7.297907
[INFO] 2021-07-12 18:54:56,103 [run_pretraining.py:  512]:	********exe.run_1178******* 
[INFO] 2021-07-12 18:54:57,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:57,015 [run_pretraining.py:  534]:	loss/total_loss, 7.204588413238525, 1179
[INFO] 2021-07-12 18:54:57,015 [run_pretraining.py:  535]:	loss/mlm_loss, 7.204588413238525, 1179
[INFO] 2021-07-12 18:54:57,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1779999113059603e-05, 1179
[INFO] 2021-07-12 18:54:57,015 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1179
[INFO] 2021-07-12 18:54:57,015 [run_pretraining.py:  558]:	worker_index: 7, step: 1179, cost: 7.204588, mlm loss: 7.204588, speed: 1.096469 steps/s, speed: 8.771749 samples/s, speed: 4491.135608 tokens/s, learning rate: 1.178e-05, loss_scalings: 13421.773438, pp_loss: 7.479567
[INFO] 2021-07-12 18:54:57,016 [run_pretraining.py:  512]:	********exe.run_1179******* 
[INFO] 2021-07-12 18:54:57,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:57,940 [run_pretraining.py:  534]:	loss/total_loss, 7.628047943115234, 1180
[INFO] 2021-07-12 18:54:57,940 [run_pretraining.py:  535]:	loss/mlm_loss, 7.628047943115234, 1180
[INFO] 2021-07-12 18:54:57,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1789999916800298e-05, 1180
[INFO] 2021-07-12 18:54:57,940 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1180
[INFO] 2021-07-12 18:54:57,940 [run_pretraining.py:  558]:	worker_index: 7, step: 1180, cost: 7.628048, mlm loss: 7.628048, speed: 1.081883 steps/s, speed: 8.655063 samples/s, speed: 4431.392134 tokens/s, learning rate: 1.179e-05, loss_scalings: 13421.773438, pp_loss: 7.524943
[INFO] 2021-07-12 18:54:57,940 [run_pretraining.py:  512]:	********exe.run_1180******* 
[INFO] 2021-07-12 18:54:58,872 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:58,873 [run_pretraining.py:  534]:	loss/total_loss, 7.539195537567139, 1181
[INFO] 2021-07-12 18:54:58,873 [run_pretraining.py:  535]:	loss/mlm_loss, 7.539195537567139, 1181
[INFO] 2021-07-12 18:54:58,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1799999811046291e-05, 1181
[INFO] 2021-07-12 18:54:58,873 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1181
[INFO] 2021-07-12 18:54:58,873 [run_pretraining.py:  558]:	worker_index: 7, step: 1181, cost: 7.539196, mlm loss: 7.539196, speed: 1.073178 steps/s, speed: 8.585427 samples/s, speed: 4395.738502 tokens/s, learning rate: 1.180e-05, loss_scalings: 13421.773438, pp_loss: 7.638247
[INFO] 2021-07-12 18:54:58,873 [run_pretraining.py:  512]:	********exe.run_1181******* 
[INFO] 2021-07-12 18:54:59,804 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:54:59,804 [run_pretraining.py:  534]:	loss/total_loss, 7.4759745597839355, 1182
[INFO] 2021-07-12 18:54:59,804 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4759745597839355, 1182
[INFO] 2021-07-12 18:54:59,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1809999705292284e-05, 1182
[INFO] 2021-07-12 18:54:59,804 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1182
[INFO] 2021-07-12 18:54:59,804 [run_pretraining.py:  558]:	worker_index: 7, step: 1182, cost: 7.475975, mlm loss: 7.475975, speed: 1.074227 steps/s, speed: 8.593820 samples/s, speed: 4400.035750 tokens/s, learning rate: 1.181e-05, loss_scalings: 13421.773438, pp_loss: 7.667892
[INFO] 2021-07-12 18:54:59,804 [run_pretraining.py:  512]:	********exe.run_1182******* 
[INFO] 2021-07-12 18:55:00,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:00,725 [run_pretraining.py:  534]:	loss/total_loss, 7.975698471069336, 1183
[INFO] 2021-07-12 18:55:00,725 [run_pretraining.py:  535]:	loss/mlm_loss, 7.975698471069336, 1183
[INFO] 2021-07-12 18:55:00,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1819999599538278e-05, 1183
[INFO] 2021-07-12 18:55:00,725 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1183
[INFO] 2021-07-12 18:55:00,725 [run_pretraining.py:  558]:	worker_index: 7, step: 1183, cost: 7.975698, mlm loss: 7.975698, speed: 1.086626 steps/s, speed: 8.693009 samples/s, speed: 4450.820567 tokens/s, learning rate: 1.182e-05, loss_scalings: 13421.773438, pp_loss: 7.747940
[INFO] 2021-07-12 18:55:00,725 [run_pretraining.py:  512]:	********exe.run_1183******* 
[INFO] 2021-07-12 18:55:01,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:01,657 [run_pretraining.py:  534]:	loss/total_loss, 7.986995697021484, 1184
[INFO] 2021-07-12 18:55:01,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.986995697021484, 1184
[INFO] 2021-07-12 18:55:01,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1829999493784271e-05, 1184
[INFO] 2021-07-12 18:55:01,657 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1184
[INFO] 2021-07-12 18:55:01,657 [run_pretraining.py:  558]:	worker_index: 7, step: 1184, cost: 7.986996, mlm loss: 7.986996, speed: 1.074027 steps/s, speed: 8.592218 samples/s, speed: 4399.215506 tokens/s, learning rate: 1.183e-05, loss_scalings: 13421.773438, pp_loss: 7.558002
[INFO] 2021-07-12 18:55:01,657 [run_pretraining.py:  512]:	********exe.run_1184******* 
[INFO] 2021-07-12 18:55:02,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:02,575 [run_pretraining.py:  534]:	loss/total_loss, 7.701263427734375, 1185
[INFO] 2021-07-12 18:55:02,575 [run_pretraining.py:  535]:	loss/mlm_loss, 7.701263427734375, 1185
[INFO] 2021-07-12 18:55:02,575 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1839999388030265e-05, 1185
[INFO] 2021-07-12 18:55:02,575 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1185
[INFO] 2021-07-12 18:55:02,575 [run_pretraining.py:  558]:	worker_index: 7, step: 1185, cost: 7.701263, mlm loss: 7.701263, speed: 1.089990 steps/s, speed: 8.719921 samples/s, speed: 4464.599764 tokens/s, learning rate: 1.184e-05, loss_scalings: 13421.773438, pp_loss: 7.835947
[INFO] 2021-07-12 18:55:02,575 [run_pretraining.py:  512]:	********exe.run_1185******* 
[INFO] 2021-07-12 18:55:03,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:03,495 [run_pretraining.py:  534]:	loss/total_loss, 7.805395126342773, 1186
[INFO] 2021-07-12 18:55:03,495 [run_pretraining.py:  535]:	loss/mlm_loss, 7.805395126342773, 1186
[INFO] 2021-07-12 18:55:03,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.185000019177096e-05, 1186
[INFO] 2021-07-12 18:55:03,495 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1186
[INFO] 2021-07-12 18:55:03,495 [run_pretraining.py:  558]:	worker_index: 7, step: 1186, cost: 7.805395, mlm loss: 7.805395, speed: 1.087827 steps/s, speed: 8.702616 samples/s, speed: 4455.739281 tokens/s, learning rate: 1.185e-05, loss_scalings: 13421.773438, pp_loss: 7.751717
[INFO] 2021-07-12 18:55:03,495 [run_pretraining.py:  512]:	********exe.run_1186******* 
[INFO] 2021-07-12 18:55:04,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:04,418 [run_pretraining.py:  534]:	loss/total_loss, 6.007055282592773, 1187
[INFO] 2021-07-12 18:55:04,418 [run_pretraining.py:  535]:	loss/mlm_loss, 6.007055282592773, 1187
[INFO] 2021-07-12 18:55:04,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1860000086016953e-05, 1187
[INFO] 2021-07-12 18:55:04,419 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1187
[INFO] 2021-07-12 18:55:04,419 [run_pretraining.py:  558]:	worker_index: 7, step: 1187, cost: 6.007055, mlm loss: 6.007055, speed: 1.083439 steps/s, speed: 8.667513 samples/s, speed: 4437.766868 tokens/s, learning rate: 1.186e-05, loss_scalings: 13421.773438, pp_loss: 7.260131
[INFO] 2021-07-12 18:55:04,419 [run_pretraining.py:  512]:	********exe.run_1187******* 
[INFO] 2021-07-12 18:55:05,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:05,338 [run_pretraining.py:  534]:	loss/total_loss, 7.765608310699463, 1188
[INFO] 2021-07-12 18:55:05,338 [run_pretraining.py:  535]:	loss/mlm_loss, 7.765608310699463, 1188
[INFO] 2021-07-12 18:55:05,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1869999070768245e-05, 1188
[INFO] 2021-07-12 18:55:05,339 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1188
[INFO] 2021-07-12 18:55:05,339 [run_pretraining.py:  558]:	worker_index: 7, step: 1188, cost: 7.765608, mlm loss: 7.765608, speed: 1.087814 steps/s, speed: 8.702512 samples/s, speed: 4455.686122 tokens/s, learning rate: 1.187e-05, loss_scalings: 13421.773438, pp_loss: 7.527438
[INFO] 2021-07-12 18:55:05,339 [run_pretraining.py:  512]:	********exe.run_1188******* 
[INFO] 2021-07-12 18:55:06,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:06,269 [run_pretraining.py:  534]:	loss/total_loss, 7.447236061096191, 1189
[INFO] 2021-07-12 18:55:06,269 [run_pretraining.py:  535]:	loss/mlm_loss, 7.447236061096191, 1189
[INFO] 2021-07-12 18:55:06,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.187999987450894e-05, 1189
[INFO] 2021-07-12 18:55:06,269 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1189
[INFO] 2021-07-12 18:55:06,269 [run_pretraining.py:  558]:	worker_index: 7, step: 1189, cost: 7.447236, mlm loss: 7.447236, speed: 1.075225 steps/s, speed: 8.601801 samples/s, speed: 4404.122368 tokens/s, learning rate: 1.188e-05, loss_scalings: 13421.773438, pp_loss: 7.361529
[INFO] 2021-07-12 18:55:06,269 [run_pretraining.py:  512]:	********exe.run_1189******* 
[INFO] 2021-07-12 18:55:07,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:07,192 [run_pretraining.py:  534]:	loss/total_loss, 7.825292587280273, 1190
[INFO] 2021-07-12 18:55:07,192 [run_pretraining.py:  535]:	loss/mlm_loss, 7.825292587280273, 1190
[INFO] 2021-07-12 18:55:07,192 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1889999768754933e-05, 1190
[INFO] 2021-07-12 18:55:07,192 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1190
[INFO] 2021-07-12 18:55:07,192 [run_pretraining.py:  558]:	worker_index: 7, step: 1190, cost: 7.825293, mlm loss: 7.825293, speed: 1.084752 steps/s, speed: 8.678013 samples/s, speed: 4443.142775 tokens/s, learning rate: 1.189e-05, loss_scalings: 13421.773438, pp_loss: 7.544215
[INFO] 2021-07-12 18:55:07,192 [run_pretraining.py:  512]:	********exe.run_1190******* 
[INFO] 2021-07-12 18:55:08,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:08,108 [run_pretraining.py:  534]:	loss/total_loss, 7.925945281982422, 1191
[INFO] 2021-07-12 18:55:08,108 [run_pretraining.py:  535]:	loss/mlm_loss, 7.925945281982422, 1191
[INFO] 2021-07-12 18:55:08,108 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1899999663000926e-05, 1191
[INFO] 2021-07-12 18:55:08,108 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1191
[INFO] 2021-07-12 18:55:08,108 [run_pretraining.py:  558]:	worker_index: 7, step: 1191, cost: 7.925945, mlm loss: 7.925945, speed: 1.092456 steps/s, speed: 8.739649 samples/s, speed: 4474.700348 tokens/s, learning rate: 1.190e-05, loss_scalings: 13421.773438, pp_loss: 7.737762
[INFO] 2021-07-12 18:55:08,108 [run_pretraining.py:  512]:	********exe.run_1191******* 
[INFO] 2021-07-12 18:55:09,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:09,028 [run_pretraining.py:  534]:	loss/total_loss, 8.318710327148438, 1192
[INFO] 2021-07-12 18:55:09,028 [run_pretraining.py:  535]:	loss/mlm_loss, 8.318710327148438, 1192
[INFO] 2021-07-12 18:55:09,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.190999955724692e-05, 1192
[INFO] 2021-07-12 18:55:09,028 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1192
[INFO] 2021-07-12 18:55:09,028 [run_pretraining.py:  558]:	worker_index: 7, step: 1192, cost: 8.318710, mlm loss: 8.318710, speed: 1.087780 steps/s, speed: 8.702237 samples/s, speed: 4455.545143 tokens/s, learning rate: 1.191e-05, loss_scalings: 13421.773438, pp_loss: 7.822083
[INFO] 2021-07-12 18:55:09,028 [run_pretraining.py:  512]:	********exe.run_1192******* 
[INFO] 2021-07-12 18:55:09,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:09,960 [run_pretraining.py:  534]:	loss/total_loss, 7.985339641571045, 1193
[INFO] 2021-07-12 18:55:09,960 [run_pretraining.py:  535]:	loss/mlm_loss, 7.985339641571045, 1193
[INFO] 2021-07-12 18:55:09,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1919999451492913e-05, 1193
[INFO] 2021-07-12 18:55:09,960 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1193
[INFO] 2021-07-12 18:55:09,960 [run_pretraining.py:  558]:	worker_index: 7, step: 1193, cost: 7.985340, mlm loss: 7.985340, speed: 1.073690 steps/s, speed: 8.589517 samples/s, speed: 4397.832601 tokens/s, learning rate: 1.192e-05, loss_scalings: 13421.773438, pp_loss: 7.827816
[INFO] 2021-07-12 18:55:09,960 [run_pretraining.py:  512]:	********exe.run_1193******* 
[INFO] 2021-07-12 18:55:10,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:10,868 [run_pretraining.py:  534]:	loss/total_loss, 7.8370561599731445, 1194
[INFO] 2021-07-12 18:55:10,868 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8370561599731445, 1194
[INFO] 2021-07-12 18:55:10,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1929999345738906e-05, 1194
[INFO] 2021-07-12 18:55:10,868 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1194
[INFO] 2021-07-12 18:55:10,868 [run_pretraining.py:  558]:	worker_index: 7, step: 1194, cost: 7.837056, mlm loss: 7.837056, speed: 1.101880 steps/s, speed: 8.815040 samples/s, speed: 4513.300463 tokens/s, learning rate: 1.193e-05, loss_scalings: 13421.773438, pp_loss: 7.193387
[INFO] 2021-07-12 18:55:10,868 [run_pretraining.py:  512]:	********exe.run_1194******* 
[INFO] 2021-07-12 18:55:11,788 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:11,788 [run_pretraining.py:  534]:	loss/total_loss, 7.095762729644775, 1195
[INFO] 2021-07-12 18:55:11,788 [run_pretraining.py:  535]:	loss/mlm_loss, 7.095762729644775, 1195
[INFO] 2021-07-12 18:55:11,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1940000149479602e-05, 1195
[INFO] 2021-07-12 18:55:11,789 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1195
[INFO] 2021-07-12 18:55:11,789 [run_pretraining.py:  558]:	worker_index: 7, step: 1195, cost: 7.095763, mlm loss: 7.095763, speed: 1.087200 steps/s, speed: 8.697597 samples/s, speed: 4453.169482 tokens/s, learning rate: 1.194e-05, loss_scalings: 13421.773438, pp_loss: 7.469928
[INFO] 2021-07-12 18:55:11,789 [run_pretraining.py:  512]:	********exe.run_1195******* 
[INFO] 2021-07-12 18:55:12,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:12,708 [run_pretraining.py:  534]:	loss/total_loss, 7.49171781539917, 1196
[INFO] 2021-07-12 18:55:12,708 [run_pretraining.py:  535]:	loss/mlm_loss, 7.49171781539917, 1196
[INFO] 2021-07-12 18:55:12,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1949999134230893e-05, 1196
[INFO] 2021-07-12 18:55:12,708 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1196
[INFO] 2021-07-12 18:55:12,708 [run_pretraining.py:  558]:	worker_index: 7, step: 1196, cost: 7.491718, mlm loss: 7.491718, speed: 1.088638 steps/s, speed: 8.709108 samples/s, speed: 4459.063046 tokens/s, learning rate: 1.195e-05, loss_scalings: 13421.773438, pp_loss: 7.371585
[INFO] 2021-07-12 18:55:12,708 [run_pretraining.py:  512]:	********exe.run_1196******* 
[INFO] 2021-07-12 18:55:13,619 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:13,619 [run_pretraining.py:  534]:	loss/total_loss, 7.215591907501221, 1197
[INFO] 2021-07-12 18:55:13,620 [run_pretraining.py:  535]:	loss/mlm_loss, 7.215591907501221, 1197
[INFO] 2021-07-12 18:55:13,620 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1959999937971588e-05, 1197
[INFO] 2021-07-12 18:55:13,620 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1197
[INFO] 2021-07-12 18:55:13,620 [run_pretraining.py:  558]:	worker_index: 7, step: 1197, cost: 7.215592, mlm loss: 7.215592, speed: 1.097457 steps/s, speed: 8.779656 samples/s, speed: 4495.183911 tokens/s, learning rate: 1.196e-05, loss_scalings: 13421.773438, pp_loss: 7.419793
[INFO] 2021-07-12 18:55:13,620 [run_pretraining.py:  512]:	********exe.run_1197******* 
[INFO] 2021-07-12 18:55:14,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:14,536 [run_pretraining.py:  534]:	loss/total_loss, 7.953177452087402, 1198
[INFO] 2021-07-12 18:55:14,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.953177452087402, 1198
[INFO] 2021-07-12 18:55:14,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1969999832217582e-05, 1198
[INFO] 2021-07-12 18:55:14,537 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1198
[INFO] 2021-07-12 18:55:14,537 [run_pretraining.py:  558]:	worker_index: 7, step: 1198, cost: 7.953177, mlm loss: 7.953177, speed: 1.091382 steps/s, speed: 8.731055 samples/s, speed: 4470.300297 tokens/s, learning rate: 1.197e-05, loss_scalings: 13421.773438, pp_loss: 7.753787
[INFO] 2021-07-12 18:55:14,537 [run_pretraining.py:  512]:	********exe.run_1198******* 
[INFO] 2021-07-12 18:55:15,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:15,487 [run_pretraining.py:  534]:	loss/total_loss, 7.748350620269775, 1199
[INFO] 2021-07-12 18:55:15,487 [run_pretraining.py:  535]:	loss/mlm_loss, 7.748350620269775, 1199
[INFO] 2021-07-12 18:55:15,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1979999726463575e-05, 1199
[INFO] 2021-07-12 18:55:15,487 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1199
[INFO] 2021-07-12 18:55:15,487 [run_pretraining.py:  558]:	worker_index: 7, step: 1199, cost: 7.748351, mlm loss: 7.748351, speed: 1.052870 steps/s, speed: 8.422961 samples/s, speed: 4312.556056 tokens/s, learning rate: 1.198e-05, loss_scalings: 13421.773438, pp_loss: 7.628972
[INFO] 2021-07-12 18:55:15,487 [run_pretraining.py:  512]:	********exe.run_1199******* 
[INFO] 2021-07-12 18:55:16,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:16,416 [run_pretraining.py:  534]:	loss/total_loss, 7.431618690490723, 1200
[INFO] 2021-07-12 18:55:16,416 [run_pretraining.py:  535]:	loss/mlm_loss, 7.431618690490723, 1200
[INFO] 2021-07-12 18:55:16,416 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1989999620709568e-05, 1200
[INFO] 2021-07-12 18:55:16,416 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1200
[INFO] 2021-07-12 18:55:16,416 [run_pretraining.py:  558]:	worker_index: 7, step: 1200, cost: 7.431619, mlm loss: 7.431619, speed: 1.076894 steps/s, speed: 8.615154 samples/s, speed: 4410.958976 tokens/s, learning rate: 1.199e-05, loss_scalings: 13421.773438, pp_loss: 7.707521
[INFO] 2021-07-12 18:55:16,417 [run_pretraining.py:  512]:	********exe.run_1200******* 
[INFO] 2021-07-12 18:55:17,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  534]:	loss/total_loss, 7.162354469299316, 1201
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  535]:	loss/mlm_loss, 7.162354469299316, 1201
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.1999999514955562e-05, 1201
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1201
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  558]:	worker_index: 7, step: 1201, cost: 7.162354, mlm loss: 7.162354, speed: 1.098645 steps/s, speed: 8.789163 samples/s, speed: 4500.051519 tokens/s, learning rate: 1.200e-05, loss_scalings: 13421.773438, pp_loss: 7.724090
[INFO] 2021-07-12 18:55:17,327 [run_pretraining.py:  512]:	********exe.run_1201******* 
[INFO] 2021-07-12 18:55:18,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:18,235 [run_pretraining.py:  534]:	loss/total_loss, 7.192435264587402, 1202
[INFO] 2021-07-12 18:55:18,235 [run_pretraining.py:  535]:	loss/mlm_loss, 7.192435264587402, 1202
[INFO] 2021-07-12 18:55:18,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2009999409201555e-05, 1202
[INFO] 2021-07-12 18:55:18,236 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1202
[INFO] 2021-07-12 18:55:18,236 [run_pretraining.py:  558]:	worker_index: 7, step: 1202, cost: 7.192435, mlm loss: 7.192435, speed: 1.101656 steps/s, speed: 8.813250 samples/s, speed: 4512.384116 tokens/s, learning rate: 1.201e-05, loss_scalings: 13421.773438, pp_loss: 7.494914
[INFO] 2021-07-12 18:55:18,236 [run_pretraining.py:  512]:	********exe.run_1202******* 
[INFO] 2021-07-12 18:55:19,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:19,148 [run_pretraining.py:  534]:	loss/total_loss, 7.2447614669799805, 1203
[INFO] 2021-07-12 18:55:19,148 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2447614669799805, 1203
[INFO] 2021-07-12 18:55:19,148 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.202000021294225e-05, 1203
[INFO] 2021-07-12 18:55:19,148 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1203
[INFO] 2021-07-12 18:55:19,148 [run_pretraining.py:  558]:	worker_index: 7, step: 1203, cost: 7.244761, mlm loss: 7.244761, speed: 1.096868 steps/s, speed: 8.774945 samples/s, speed: 4492.771678 tokens/s, learning rate: 1.202e-05, loss_scalings: 13421.773438, pp_loss: 7.713161
[INFO] 2021-07-12 18:55:19,148 [run_pretraining.py:  512]:	********exe.run_1203******* 
[INFO] 2021-07-12 18:55:20,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:20,060 [run_pretraining.py:  534]:	loss/total_loss, 7.571932315826416, 1204
[INFO] 2021-07-12 18:55:20,060 [run_pretraining.py:  535]:	loss/mlm_loss, 7.571932315826416, 1204
[INFO] 2021-07-12 18:55:20,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2030000107188243e-05, 1204
[INFO] 2021-07-12 18:55:20,060 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1204
[INFO] 2021-07-12 18:55:20,060 [run_pretraining.py:  558]:	worker_index: 7, step: 1204, cost: 7.571932, mlm loss: 7.571932, speed: 1.096831 steps/s, speed: 8.774646 samples/s, speed: 4492.618943 tokens/s, learning rate: 1.203e-05, loss_scalings: 13421.773438, pp_loss: 6.685731
[INFO] 2021-07-12 18:55:20,060 [run_pretraining.py:  512]:	********exe.run_1204******* 
[INFO] 2021-07-12 18:55:20,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:20,972 [run_pretraining.py:  534]:	loss/total_loss, 7.989918231964111, 1205
[INFO] 2021-07-12 18:55:20,972 [run_pretraining.py:  535]:	loss/mlm_loss, 7.989918231964111, 1205
[INFO] 2021-07-12 18:55:20,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2039999091939535e-05, 1205
[INFO] 2021-07-12 18:55:20,972 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1205
[INFO] 2021-07-12 18:55:20,972 [run_pretraining.py:  558]:	worker_index: 7, step: 1205, cost: 7.989918, mlm loss: 7.989918, speed: 1.097600 steps/s, speed: 8.780800 samples/s, speed: 4495.769727 tokens/s, learning rate: 1.204e-05, loss_scalings: 13421.773438, pp_loss: 7.175697
[INFO] 2021-07-12 18:55:20,972 [run_pretraining.py:  512]:	********exe.run_1205******* 
[INFO] 2021-07-12 18:55:21,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:21,882 [run_pretraining.py:  534]:	loss/total_loss, 7.608184814453125, 1206
[INFO] 2021-07-12 18:55:21,882 [run_pretraining.py:  535]:	loss/mlm_loss, 7.608184814453125, 1206
[INFO] 2021-07-12 18:55:21,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.204999989568023e-05, 1206
[INFO] 2021-07-12 18:55:21,882 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1206
[INFO] 2021-07-12 18:55:21,882 [run_pretraining.py:  558]:	worker_index: 7, step: 1206, cost: 7.608185, mlm loss: 7.608185, speed: 1.099292 steps/s, speed: 8.794332 samples/s, speed: 4502.698149 tokens/s, learning rate: 1.205e-05, loss_scalings: 13421.773438, pp_loss: 6.796137
[INFO] 2021-07-12 18:55:21,883 [run_pretraining.py:  512]:	********exe.run_1206******* 
[INFO] 2021-07-12 18:55:22,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:22,790 [run_pretraining.py:  534]:	loss/total_loss, 7.476161956787109, 1207
[INFO] 2021-07-12 18:55:22,790 [run_pretraining.py:  535]:	loss/mlm_loss, 7.476161956787109, 1207
[INFO] 2021-07-12 18:55:22,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2059999789926223e-05, 1207
[INFO] 2021-07-12 18:55:22,791 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1207
[INFO] 2021-07-12 18:55:22,791 [run_pretraining.py:  558]:	worker_index: 7, step: 1207, cost: 7.476162, mlm loss: 7.476162, speed: 1.101838 steps/s, speed: 8.814704 samples/s, speed: 4513.128545 tokens/s, learning rate: 1.206e-05, loss_scalings: 13421.773438, pp_loss: 7.568559
[INFO] 2021-07-12 18:55:22,791 [run_pretraining.py:  512]:	********exe.run_1207******* 
[INFO] 2021-07-12 18:55:23,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:23,701 [run_pretraining.py:  534]:	loss/total_loss, 7.245038032531738, 1208
[INFO] 2021-07-12 18:55:23,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.245038032531738, 1208
[INFO] 2021-07-12 18:55:23,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2069999684172217e-05, 1208
[INFO] 2021-07-12 18:55:23,701 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1208
[INFO] 2021-07-12 18:55:23,701 [run_pretraining.py:  558]:	worker_index: 7, step: 1208, cost: 7.245038, mlm loss: 7.245038, speed: 1.099257 steps/s, speed: 8.794053 samples/s, speed: 4502.555360 tokens/s, learning rate: 1.207e-05, loss_scalings: 13421.773438, pp_loss: 7.597218
[INFO] 2021-07-12 18:55:23,701 [run_pretraining.py:  512]:	********exe.run_1208******* 
[INFO] 2021-07-12 18:55:24,612 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:24,612 [run_pretraining.py:  534]:	loss/total_loss, 7.204890251159668, 1209
[INFO] 2021-07-12 18:55:24,612 [run_pretraining.py:  535]:	loss/mlm_loss, 7.204890251159668, 1209
[INFO] 2021-07-12 18:55:24,613 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2080000487912912e-05, 1209
[INFO] 2021-07-12 18:55:24,613 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1209
[INFO] 2021-07-12 18:55:24,613 [run_pretraining.py:  558]:	worker_index: 7, step: 1209, cost: 7.204890, mlm loss: 7.204890, speed: 1.097604 steps/s, speed: 8.780835 samples/s, speed: 4495.787374 tokens/s, learning rate: 1.208e-05, loss_scalings: 13421.773438, pp_loss: 7.773371
[INFO] 2021-07-12 18:55:24,613 [run_pretraining.py:  512]:	********exe.run_1209******* 
[INFO] 2021-07-12 18:55:25,518 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:25,519 [run_pretraining.py:  534]:	loss/total_loss, 7.959230422973633, 1210
[INFO] 2021-07-12 18:55:25,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.959230422973633, 1210
[INFO] 2021-07-12 18:55:25,519 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2089999472664203e-05, 1210
[INFO] 2021-07-12 18:55:25,519 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1210
[INFO] 2021-07-12 18:55:25,519 [run_pretraining.py:  558]:	worker_index: 7, step: 1210, cost: 7.959230, mlm loss: 7.959230, speed: 1.103987 steps/s, speed: 8.831894 samples/s, speed: 4521.929732 tokens/s, learning rate: 1.209e-05, loss_scalings: 13421.773438, pp_loss: 7.885696
[INFO] 2021-07-12 18:55:25,519 [run_pretraining.py:  512]:	********exe.run_1210******* 
[INFO] 2021-07-12 18:55:26,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:26,452 [run_pretraining.py:  534]:	loss/total_loss, 7.5579986572265625, 1211
[INFO] 2021-07-12 18:55:26,452 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5579986572265625, 1211
[INFO] 2021-07-12 18:55:26,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2099999366910197e-05, 1211
[INFO] 2021-07-12 18:55:26,452 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1211
[INFO] 2021-07-12 18:55:26,452 [run_pretraining.py:  558]:	worker_index: 7, step: 1211, cost: 7.557999, mlm loss: 7.557999, speed: 1.072444 steps/s, speed: 8.579555 samples/s, speed: 4392.731938 tokens/s, learning rate: 1.210e-05, loss_scalings: 13421.773438, pp_loss: 7.493657
[INFO] 2021-07-12 18:55:26,452 [run_pretraining.py:  512]:	********exe.run_1211******* 
[INFO] 2021-07-12 18:55:27,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:27,366 [run_pretraining.py:  534]:	loss/total_loss, 8.163323402404785, 1212
[INFO] 2021-07-12 18:55:27,366 [run_pretraining.py:  535]:	loss/mlm_loss, 8.163323402404785, 1212
[INFO] 2021-07-12 18:55:27,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2110000170650892e-05, 1212
[INFO] 2021-07-12 18:55:27,367 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1212
[INFO] 2021-07-12 18:55:27,367 [run_pretraining.py:  558]:	worker_index: 7, step: 1212, cost: 8.163323, mlm loss: 8.163323, speed: 1.094521 steps/s, speed: 8.756168 samples/s, speed: 4483.157938 tokens/s, learning rate: 1.211e-05, loss_scalings: 13421.773438, pp_loss: 7.660027
[INFO] 2021-07-12 18:55:27,367 [run_pretraining.py:  512]:	********exe.run_1212******* 
[INFO] 2021-07-12 18:55:28,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:28,276 [run_pretraining.py:  534]:	loss/total_loss, 7.355238914489746, 1213
[INFO] 2021-07-12 18:55:28,276 [run_pretraining.py:  535]:	loss/mlm_loss, 7.355238914489746, 1213
[INFO] 2021-07-12 18:55:28,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2120000064896885e-05, 1213
[INFO] 2021-07-12 18:55:28,277 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1213
[INFO] 2021-07-12 18:55:28,277 [run_pretraining.py:  558]:	worker_index: 7, step: 1213, cost: 7.355239, mlm loss: 7.355239, speed: 1.099547 steps/s, speed: 8.796375 samples/s, speed: 4503.743978 tokens/s, learning rate: 1.212e-05, loss_scalings: 13421.773438, pp_loss: 7.403892
[INFO] 2021-07-12 18:55:28,277 [run_pretraining.py:  512]:	********exe.run_1213******* 
[INFO] 2021-07-12 18:55:29,191 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:29,191 [run_pretraining.py:  534]:	loss/total_loss, 7.65757417678833, 1214
[INFO] 2021-07-12 18:55:29,191 [run_pretraining.py:  535]:	loss/mlm_loss, 7.65757417678833, 1214
[INFO] 2021-07-12 18:55:29,191 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2129999049648177e-05, 1214
[INFO] 2021-07-12 18:55:29,191 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1214
[INFO] 2021-07-12 18:55:29,191 [run_pretraining.py:  558]:	worker_index: 7, step: 1214, cost: 7.657574, mlm loss: 7.657574, speed: 1.094001 steps/s, speed: 8.752007 samples/s, speed: 4481.027395 tokens/s, learning rate: 1.213e-05, loss_scalings: 13421.773438, pp_loss: 7.523265
[INFO] 2021-07-12 18:55:29,192 [run_pretraining.py:  512]:	********exe.run_1214******* 
[INFO] 2021-07-12 18:55:30,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:30,099 [run_pretraining.py:  534]:	loss/total_loss, 7.20499324798584, 1215
[INFO] 2021-07-12 18:55:30,099 [run_pretraining.py:  535]:	loss/mlm_loss, 7.20499324798584, 1215
[INFO] 2021-07-12 18:55:30,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2139999853388872e-05, 1215
[INFO] 2021-07-12 18:55:30,100 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1215
[INFO] 2021-07-12 18:55:30,100 [run_pretraining.py:  558]:	worker_index: 7, step: 1215, cost: 7.204993, mlm loss: 7.204993, speed: 1.101822 steps/s, speed: 8.814579 samples/s, speed: 4513.064524 tokens/s, learning rate: 1.214e-05, loss_scalings: 13421.773438, pp_loss: 7.286177
[INFO] 2021-07-12 18:55:30,100 [run_pretraining.py:  512]:	********exe.run_1215******* 
[INFO] 2021-07-12 18:55:31,010 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:31,011 [run_pretraining.py:  534]:	loss/total_loss, 7.637257099151611, 1216
[INFO] 2021-07-12 18:55:31,011 [run_pretraining.py:  535]:	loss/mlm_loss, 7.637257099151611, 1216
[INFO] 2021-07-12 18:55:31,011 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2149999747634865e-05, 1216
[INFO] 2021-07-12 18:55:31,011 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1216
[INFO] 2021-07-12 18:55:31,011 [run_pretraining.py:  558]:	worker_index: 7, step: 1216, cost: 7.637257, mlm loss: 7.637257, speed: 1.097686 steps/s, speed: 8.781485 samples/s, speed: 4496.120348 tokens/s, learning rate: 1.215e-05, loss_scalings: 13421.773438, pp_loss: 7.775833
[INFO] 2021-07-12 18:55:31,011 [run_pretraining.py:  512]:	********exe.run_1216******* 
[INFO] 2021-07-12 18:55:31,921 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:31,921 [run_pretraining.py:  534]:	loss/total_loss, 7.420479774475098, 1217
[INFO] 2021-07-12 18:55:31,921 [run_pretraining.py:  535]:	loss/mlm_loss, 7.420479774475098, 1217
[INFO] 2021-07-12 18:55:31,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2159999641880859e-05, 1217
[INFO] 2021-07-12 18:55:31,921 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1217
[INFO] 2021-07-12 18:55:31,921 [run_pretraining.py:  558]:	worker_index: 7, step: 1217, cost: 7.420480, mlm loss: 7.420480, speed: 1.099599 steps/s, speed: 8.796795 samples/s, speed: 4503.958869 tokens/s, learning rate: 1.216e-05, loss_scalings: 13421.773438, pp_loss: 7.350817
[INFO] 2021-07-12 18:55:31,922 [run_pretraining.py:  512]:	********exe.run_1217******* 
[INFO] 2021-07-12 18:55:32,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:32,825 [run_pretraining.py:  534]:	loss/total_loss, 7.4375481605529785, 1218
[INFO] 2021-07-12 18:55:32,825 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4375481605529785, 1218
[INFO] 2021-07-12 18:55:32,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2169999536126852e-05, 1218
[INFO] 2021-07-12 18:55:32,825 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1218
[INFO] 2021-07-12 18:55:32,825 [run_pretraining.py:  558]:	worker_index: 7, step: 1218, cost: 7.437548, mlm loss: 7.437548, speed: 1.106993 steps/s, speed: 8.855947 samples/s, speed: 4534.245076 tokens/s, learning rate: 1.217e-05, loss_scalings: 13421.773438, pp_loss: 7.924813
[INFO] 2021-07-12 18:55:32,825 [run_pretraining.py:  512]:	********exe.run_1218******* 
[INFO] 2021-07-12 18:55:33,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:33,731 [run_pretraining.py:  534]:	loss/total_loss, 7.892706871032715, 1219
[INFO] 2021-07-12 18:55:33,731 [run_pretraining.py:  535]:	loss/mlm_loss, 7.892706871032715, 1219
[INFO] 2021-07-12 18:55:33,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2179999430372845e-05, 1219
[INFO] 2021-07-12 18:55:33,731 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1219
[INFO] 2021-07-12 18:55:33,731 [run_pretraining.py:  558]:	worker_index: 7, step: 1219, cost: 7.892707, mlm loss: 7.892707, speed: 1.104821 steps/s, speed: 8.838566 samples/s, speed: 4525.345866 tokens/s, learning rate: 1.218e-05, loss_scalings: 13421.773438, pp_loss: 7.262159
[INFO] 2021-07-12 18:55:33,731 [run_pretraining.py:  512]:	********exe.run_1219******* 
[INFO] 2021-07-12 18:55:34,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:34,684 [run_pretraining.py:  534]:	loss/total_loss, 7.749332427978516, 1220
[INFO] 2021-07-12 18:55:34,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.749332427978516, 1220
[INFO] 2021-07-12 18:55:34,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2189999324618839e-05, 1220
[INFO] 2021-07-12 18:55:34,684 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1220
[INFO] 2021-07-12 18:55:34,684 [run_pretraining.py:  558]:	worker_index: 7, step: 1220, cost: 7.749332, mlm loss: 7.749332, speed: 1.050092 steps/s, speed: 8.400739 samples/s, speed: 4301.178197 tokens/s, learning rate: 1.219e-05, loss_scalings: 13421.773438, pp_loss: 7.770440
[INFO] 2021-07-12 18:55:34,684 [run_pretraining.py:  512]:	********exe.run_1220******* 
[INFO] 2021-07-12 18:55:35,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:35,587 [run_pretraining.py:  534]:	loss/total_loss, 7.363232612609863, 1221
[INFO] 2021-07-12 18:55:35,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.363232612609863, 1221
[INFO] 2021-07-12 18:55:35,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2200000128359534e-05, 1221
[INFO] 2021-07-12 18:55:35,587 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1221
[INFO] 2021-07-12 18:55:35,587 [run_pretraining.py:  558]:	worker_index: 7, step: 1221, cost: 7.363233, mlm loss: 7.363233, speed: 1.108073 steps/s, speed: 8.864581 samples/s, speed: 4538.665253 tokens/s, learning rate: 1.220e-05, loss_scalings: 13421.773438, pp_loss: 7.485053
[INFO] 2021-07-12 18:55:35,587 [run_pretraining.py:  512]:	********exe.run_1221******* 
[INFO] 2021-07-12 18:55:36,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:36,488 [run_pretraining.py:  534]:	loss/total_loss, 7.807108402252197, 1222
[INFO] 2021-07-12 18:55:36,488 [run_pretraining.py:  535]:	loss/mlm_loss, 7.807108402252197, 1222
[INFO] 2021-07-12 18:55:36,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2210000022605527e-05, 1222
[INFO] 2021-07-12 18:55:36,488 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1222
[INFO] 2021-07-12 18:55:36,488 [run_pretraining.py:  558]:	worker_index: 7, step: 1222, cost: 7.807108, mlm loss: 7.807108, speed: 1.111027 steps/s, speed: 8.888217 samples/s, speed: 4550.767050 tokens/s, learning rate: 1.221e-05, loss_scalings: 13421.773438, pp_loss: 7.466358
[INFO] 2021-07-12 18:55:36,488 [run_pretraining.py:  512]:	********exe.run_1222******* 
[INFO] 2021-07-12 18:55:37,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:37,385 [run_pretraining.py:  534]:	loss/total_loss, 5.557450294494629, 1223
[INFO] 2021-07-12 18:55:37,386 [run_pretraining.py:  535]:	loss/mlm_loss, 5.557450294494629, 1223
[INFO] 2021-07-12 18:55:37,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2219999007356819e-05, 1223
[INFO] 2021-07-12 18:55:37,386 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1223
[INFO] 2021-07-12 18:55:37,386 [run_pretraining.py:  558]:	worker_index: 7, step: 1223, cost: 5.557450, mlm loss: 5.557450, speed: 1.114625 steps/s, speed: 8.917000 samples/s, speed: 4565.504239 tokens/s, learning rate: 1.222e-05, loss_scalings: 13421.773438, pp_loss: 7.014737
[INFO] 2021-07-12 18:55:37,386 [run_pretraining.py:  512]:	********exe.run_1223******* 
[INFO] 2021-07-12 18:55:38,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:38,402 [run_pretraining.py:  534]:	loss/total_loss, 7.487135887145996, 1224
[INFO] 2021-07-12 18:55:38,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.487135887145996, 1224
[INFO] 2021-07-12 18:55:38,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2229999811097514e-05, 1224
[INFO] 2021-07-12 18:55:38,403 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1224
[INFO] 2021-07-12 18:55:38,403 [run_pretraining.py:  558]:	worker_index: 7, step: 1224, cost: 7.487136, mlm loss: 7.487136, speed: 0.984083 steps/s, speed: 7.872661 samples/s, speed: 4030.802601 tokens/s, learning rate: 1.223e-05, loss_scalings: 13421.773438, pp_loss: 7.039470
[INFO] 2021-07-12 18:55:38,403 [run_pretraining.py:  512]:	********exe.run_1224******* 
[INFO] 2021-07-12 18:55:39,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:39,464 [run_pretraining.py:  534]:	loss/total_loss, 7.852876663208008, 1225
[INFO] 2021-07-12 18:55:39,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.852876663208008, 1225
[INFO] 2021-07-12 18:55:39,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2239999705343507e-05, 1225
[INFO] 2021-07-12 18:55:39,464 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1225
[INFO] 2021-07-12 18:55:39,464 [run_pretraining.py:  558]:	worker_index: 7, step: 1225, cost: 7.852877, mlm loss: 7.852877, speed: 0.942772 steps/s, speed: 7.542174 samples/s, speed: 3861.593237 tokens/s, learning rate: 1.224e-05, loss_scalings: 13421.773438, pp_loss: 7.758854
[INFO] 2021-07-12 18:55:39,464 [run_pretraining.py:  512]:	********exe.run_1225******* 
[INFO] 2021-07-12 18:55:40,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:40,486 [run_pretraining.py:  534]:	loss/total_loss, 7.361441612243652, 1226
[INFO] 2021-07-12 18:55:40,486 [run_pretraining.py:  535]:	loss/mlm_loss, 7.361441612243652, 1226
[INFO] 2021-07-12 18:55:40,486 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.22499995995895e-05, 1226
[INFO] 2021-07-12 18:55:40,486 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1226
[INFO] 2021-07-12 18:55:40,486 [run_pretraining.py:  558]:	worker_index: 7, step: 1226, cost: 7.361442, mlm loss: 7.361442, speed: 0.979044 steps/s, speed: 7.832351 samples/s, speed: 4010.163481 tokens/s, learning rate: 1.225e-05, loss_scalings: 13421.773438, pp_loss: 7.471253
[INFO] 2021-07-12 18:55:40,486 [run_pretraining.py:  512]:	********exe.run_1226******* 
[INFO] 2021-07-12 18:55:41,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:41,545 [run_pretraining.py:  534]:	loss/total_loss, 8.055891036987305, 1227
[INFO] 2021-07-12 18:55:41,546 [run_pretraining.py:  535]:	loss/mlm_loss, 8.055891036987305, 1227
[INFO] 2021-07-12 18:55:41,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2259999493835494e-05, 1227
[INFO] 2021-07-12 18:55:41,546 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1227
[INFO] 2021-07-12 18:55:41,546 [run_pretraining.py:  558]:	worker_index: 7, step: 1227, cost: 8.055891, mlm loss: 8.055891, speed: 0.944206 steps/s, speed: 7.553647 samples/s, speed: 3867.467146 tokens/s, learning rate: 1.226e-05, loss_scalings: 13421.773438, pp_loss: 7.748567
[INFO] 2021-07-12 18:55:41,546 [run_pretraining.py:  512]:	********exe.run_1227******* 
[INFO] 2021-07-12 18:55:42,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  534]:	loss/total_loss, 7.6751508712768555, 1228
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6751508712768555, 1228
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2269999388081487e-05, 1228
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  539]:	lr/loss_scaling, 13421.7734375, 1228
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  558]:	worker_index: 7, step: 1228, cost: 7.675151, mlm loss: 7.675151, speed: 0.942641 steps/s, speed: 7.541125 samples/s, speed: 3861.056028 tokens/s, learning rate: 1.227e-05, loss_scalings: 13421.773438, pp_loss: 7.736303
[INFO] 2021-07-12 18:55:42,607 [run_pretraining.py:  512]:	********exe.run_1228******* 
[INFO] 2021-07-12 18:55:43,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:43,677 [run_pretraining.py:  534]:	loss/total_loss, 8.156530380249023, 1229
[INFO] 2021-07-12 18:55:43,677 [run_pretraining.py:  535]:	loss/mlm_loss, 8.156530380249023, 1229
[INFO] 2021-07-12 18:55:43,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.227999928232748e-05, 1229
[INFO] 2021-07-12 18:55:43,678 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1229
[INFO] 2021-07-12 18:55:43,678 [run_pretraining.py:  558]:	worker_index: 7, step: 1229, cost: 8.156530, mlm loss: 8.156530, speed: 0.934727 steps/s, speed: 7.477819 samples/s, speed: 3828.643325 tokens/s, learning rate: 1.228e-05, loss_scalings: 10737.418945, pp_loss: 7.897398
[INFO] 2021-07-12 18:55:43,678 [run_pretraining.py:  512]:	********exe.run_1229******* 
[INFO] 2021-07-12 18:55:44,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:44,719 [run_pretraining.py:  534]:	loss/total_loss, 6.754690170288086, 1230
[INFO] 2021-07-12 18:55:44,720 [run_pretraining.py:  535]:	loss/mlm_loss, 6.754690170288086, 1230
[INFO] 2021-07-12 18:55:44,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2290000086068176e-05, 1230
[INFO] 2021-07-12 18:55:44,720 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1230
[INFO] 2021-07-12 18:55:44,720 [run_pretraining.py:  558]:	worker_index: 7, step: 1230, cost: 6.754690, mlm loss: 6.754690, speed: 0.960205 steps/s, speed: 7.681640 samples/s, speed: 3932.999579 tokens/s, learning rate: 1.229e-05, loss_scalings: 10737.418945, pp_loss: 6.542490
[INFO] 2021-07-12 18:55:44,720 [run_pretraining.py:  512]:	********exe.run_1230******* 
[INFO] 2021-07-12 18:55:45,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:45,775 [run_pretraining.py:  534]:	loss/total_loss, 7.350172996520996, 1231
[INFO] 2021-07-12 18:55:45,775 [run_pretraining.py:  535]:	loss/mlm_loss, 7.350172996520996, 1231
[INFO] 2021-07-12 18:55:45,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2299999980314169e-05, 1231
[INFO] 2021-07-12 18:55:45,775 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1231
[INFO] 2021-07-12 18:55:45,775 [run_pretraining.py:  558]:	worker_index: 7, step: 1231, cost: 7.350173, mlm loss: 7.350173, speed: 0.948091 steps/s, speed: 7.584727 samples/s, speed: 3883.380426 tokens/s, learning rate: 1.230e-05, loss_scalings: 10737.418945, pp_loss: 7.371478
[INFO] 2021-07-12 18:55:45,775 [run_pretraining.py:  512]:	********exe.run_1231******* 
[INFO] 2021-07-12 18:55:46,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:46,833 [run_pretraining.py:  534]:	loss/total_loss, 7.996541976928711, 1232
[INFO] 2021-07-12 18:55:46,833 [run_pretraining.py:  535]:	loss/mlm_loss, 7.996541976928711, 1232
[INFO] 2021-07-12 18:55:46,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2309999874560162e-05, 1232
[INFO] 2021-07-12 18:55:46,833 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1232
[INFO] 2021-07-12 18:55:46,833 [run_pretraining.py:  558]:	worker_index: 7, step: 1232, cost: 7.996542, mlm loss: 7.996542, speed: 0.945560 steps/s, speed: 7.564479 samples/s, speed: 3873.013163 tokens/s, learning rate: 1.231e-05, loss_scalings: 10737.418945, pp_loss: 7.772226
[INFO] 2021-07-12 18:55:46,834 [run_pretraining.py:  512]:	********exe.run_1232******* 
[INFO] 2021-07-12 18:55:47,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:47,860 [run_pretraining.py:  534]:	loss/total_loss, 8.412848472595215, 1233
[INFO] 2021-07-12 18:55:47,860 [run_pretraining.py:  535]:	loss/mlm_loss, 8.412848472595215, 1233
[INFO] 2021-07-12 18:55:47,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2319999768806156e-05, 1233
[INFO] 2021-07-12 18:55:47,860 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1233
[INFO] 2021-07-12 18:55:47,860 [run_pretraining.py:  558]:	worker_index: 7, step: 1233, cost: 8.412848, mlm loss: 8.412848, speed: 0.974609 steps/s, speed: 7.796876 samples/s, speed: 3992.000413 tokens/s, learning rate: 1.232e-05, loss_scalings: 10737.418945, pp_loss: 7.217487
[INFO] 2021-07-12 18:55:47,860 [run_pretraining.py:  512]:	********exe.run_1233******* 
[INFO] 2021-07-12 18:55:48,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:48,918 [run_pretraining.py:  534]:	loss/total_loss, 7.058343887329102, 1234
[INFO] 2021-07-12 18:55:48,918 [run_pretraining.py:  535]:	loss/mlm_loss, 7.058343887329102, 1234
[INFO] 2021-07-12 18:55:48,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2329999663052149e-05, 1234
[INFO] 2021-07-12 18:55:48,918 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1234
[INFO] 2021-07-12 18:55:48,919 [run_pretraining.py:  558]:	worker_index: 7, step: 1234, cost: 7.058344, mlm loss: 7.058344, speed: 0.945425 steps/s, speed: 7.563403 samples/s, speed: 3872.462297 tokens/s, learning rate: 1.233e-05, loss_scalings: 10737.418945, pp_loss: 7.498149
[INFO] 2021-07-12 18:55:48,919 [run_pretraining.py:  512]:	********exe.run_1234******* 
[INFO] 2021-07-12 18:55:49,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  534]:	loss/total_loss, 7.416598320007324, 1235
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  535]:	loss/mlm_loss, 7.416598320007324, 1235
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2339999557298142e-05, 1235
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1235
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  558]:	worker_index: 7, step: 1235, cost: 7.416598, mlm loss: 7.416598, speed: 0.939762 steps/s, speed: 7.518095 samples/s, speed: 3849.264777 tokens/s, learning rate: 1.234e-05, loss_scalings: 10737.418945, pp_loss: 7.562617
[INFO] 2021-07-12 18:55:49,983 [run_pretraining.py:  512]:	********exe.run_1235******* 
[INFO] 2021-07-12 18:55:50,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:50,898 [run_pretraining.py:  534]:	loss/total_loss, 7.800736427307129, 1236
[INFO] 2021-07-12 18:55:50,898 [run_pretraining.py:  535]:	loss/mlm_loss, 7.800736427307129, 1236
[INFO] 2021-07-12 18:55:50,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2349999451544136e-05, 1236
[INFO] 2021-07-12 18:55:50,898 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1236
[INFO] 2021-07-12 18:55:50,898 [run_pretraining.py:  558]:	worker_index: 7, step: 1236, cost: 7.800736, mlm loss: 7.800736, speed: 1.093582 steps/s, speed: 8.748655 samples/s, speed: 4479.311105 tokens/s, learning rate: 1.235e-05, loss_scalings: 10737.418945, pp_loss: 7.679998
[INFO] 2021-07-12 18:55:50,898 [run_pretraining.py:  512]:	********exe.run_1236******* 
[INFO] 2021-07-12 18:55:51,871 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:51,872 [run_pretraining.py:  534]:	loss/total_loss, 8.078968048095703, 1237
[INFO] 2021-07-12 18:55:51,872 [run_pretraining.py:  535]:	loss/mlm_loss, 8.078968048095703, 1237
[INFO] 2021-07-12 18:55:51,872 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.235999934579013e-05, 1237
[INFO] 2021-07-12 18:55:51,872 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1237
[INFO] 2021-07-12 18:55:51,872 [run_pretraining.py:  558]:	worker_index: 7, step: 1237, cost: 8.078968, mlm loss: 8.078968, speed: 1.027412 steps/s, speed: 8.219299 samples/s, speed: 4208.280917 tokens/s, learning rate: 1.236e-05, loss_scalings: 10737.418945, pp_loss: 7.669946
[INFO] 2021-07-12 18:55:51,872 [run_pretraining.py:  512]:	********exe.run_1237******* 
[INFO] 2021-07-12 18:55:52,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:52,819 [run_pretraining.py:  534]:	loss/total_loss, 6.211639404296875, 1238
[INFO] 2021-07-12 18:55:52,819 [run_pretraining.py:  535]:	loss/mlm_loss, 6.211639404296875, 1238
[INFO] 2021-07-12 18:55:52,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2370000149530824e-05, 1238
[INFO] 2021-07-12 18:55:52,820 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1238
[INFO] 2021-07-12 18:55:52,820 [run_pretraining.py:  558]:	worker_index: 7, step: 1238, cost: 6.211639, mlm loss: 6.211639, speed: 1.056370 steps/s, speed: 8.450957 samples/s, speed: 4326.890009 tokens/s, learning rate: 1.237e-05, loss_scalings: 10737.418945, pp_loss: 7.203593
[INFO] 2021-07-12 18:55:52,820 [run_pretraining.py:  512]:	********exe.run_1238******* 
[INFO] 2021-07-12 18:55:53,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  534]:	loss/total_loss, 7.24785852432251, 1239
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.24785852432251, 1239
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2380000043776818e-05, 1239
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1239
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  558]:	worker_index: 7, step: 1239, cost: 7.247859, mlm loss: 7.247859, speed: 1.096574 steps/s, speed: 8.772593 samples/s, speed: 4491.567706 tokens/s, learning rate: 1.238e-05, loss_scalings: 10737.418945, pp_loss: 6.856113
[INFO] 2021-07-12 18:55:53,732 [run_pretraining.py:  512]:	********exe.run_1239******* 
[INFO] 2021-07-12 18:55:54,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  534]:	loss/total_loss, 7.981627464294434, 1240
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  535]:	loss/mlm_loss, 7.981627464294434, 1240
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.238999902852811e-05, 1240
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1240
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  558]:	worker_index: 7, step: 1240, cost: 7.981627, mlm loss: 7.981627, speed: 1.102636 steps/s, speed: 8.821088 samples/s, speed: 4516.397219 tokens/s, learning rate: 1.239e-05, loss_scalings: 10737.418945, pp_loss: 7.706121
[INFO] 2021-07-12 18:55:54,640 [run_pretraining.py:  512]:	********exe.run_1240******* 
[INFO] 2021-07-12 18:55:55,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:55,546 [run_pretraining.py:  534]:	loss/total_loss, 6.924372673034668, 1241
[INFO] 2021-07-12 18:55:55,546 [run_pretraining.py:  535]:	loss/mlm_loss, 6.924372673034668, 1241
[INFO] 2021-07-12 18:55:55,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2399999832268804e-05, 1241
[INFO] 2021-07-12 18:55:55,547 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1241
[INFO] 2021-07-12 18:55:55,547 [run_pretraining.py:  558]:	worker_index: 7, step: 1241, cost: 6.924373, mlm loss: 6.924373, speed: 1.103624 steps/s, speed: 8.828989 samples/s, speed: 4520.442445 tokens/s, learning rate: 1.240e-05, loss_scalings: 10737.418945, pp_loss: 7.501664
[INFO] 2021-07-12 18:55:55,547 [run_pretraining.py:  512]:	********exe.run_1241******* 
[INFO] 2021-07-12 18:55:56,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:56,461 [run_pretraining.py:  534]:	loss/total_loss, 7.668362617492676, 1242
[INFO] 2021-07-12 18:55:56,461 [run_pretraining.py:  535]:	loss/mlm_loss, 7.668362617492676, 1242
[INFO] 2021-07-12 18:55:56,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2409999726514798e-05, 1242
[INFO] 2021-07-12 18:55:56,461 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1242
[INFO] 2021-07-12 18:55:56,461 [run_pretraining.py:  558]:	worker_index: 7, step: 1242, cost: 7.668363, mlm loss: 7.668363, speed: 1.094239 steps/s, speed: 8.753911 samples/s, speed: 4482.002376 tokens/s, learning rate: 1.241e-05, loss_scalings: 10737.418945, pp_loss: 7.582383
[INFO] 2021-07-12 18:55:56,461 [run_pretraining.py:  512]:	********exe.run_1242******* 
[INFO] 2021-07-12 18:55:57,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:57,369 [run_pretraining.py:  534]:	loss/total_loss, 7.194395542144775, 1243
[INFO] 2021-07-12 18:55:57,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.194395542144775, 1243
[INFO] 2021-07-12 18:55:57,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2419999620760791e-05, 1243
[INFO] 2021-07-12 18:55:57,369 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1243
[INFO] 2021-07-12 18:55:57,369 [run_pretraining.py:  558]:	worker_index: 7, step: 1243, cost: 7.194396, mlm loss: 7.194396, speed: 1.101853 steps/s, speed: 8.814822 samples/s, speed: 4513.189011 tokens/s, learning rate: 1.242e-05, loss_scalings: 10737.418945, pp_loss: 7.566962
[INFO] 2021-07-12 18:55:57,369 [run_pretraining.py:  512]:	********exe.run_1243******* 
[INFO] 2021-07-12 18:55:58,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:58,282 [run_pretraining.py:  534]:	loss/total_loss, 7.718258857727051, 1244
[INFO] 2021-07-12 18:55:58,282 [run_pretraining.py:  535]:	loss/mlm_loss, 7.718258857727051, 1244
[INFO] 2021-07-12 18:55:58,282 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2430000424501486e-05, 1244
[INFO] 2021-07-12 18:55:58,282 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1244
[INFO] 2021-07-12 18:55:58,283 [run_pretraining.py:  558]:	worker_index: 7, step: 1244, cost: 7.718259, mlm loss: 7.718259, speed: 1.095832 steps/s, speed: 8.766659 samples/s, speed: 4488.529521 tokens/s, learning rate: 1.243e-05, loss_scalings: 10737.418945, pp_loss: 7.628088
[INFO] 2021-07-12 18:55:58,283 [run_pretraining.py:  512]:	********exe.run_1244******* 
[INFO] 2021-07-12 18:55:59,199 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:55:59,199 [run_pretraining.py:  534]:	loss/total_loss, 8.022464752197266, 1245
[INFO] 2021-07-12 18:55:59,200 [run_pretraining.py:  535]:	loss/mlm_loss, 8.022464752197266, 1245
[INFO] 2021-07-12 18:55:59,200 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2439999409252778e-05, 1245
[INFO] 2021-07-12 18:55:59,200 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1245
[INFO] 2021-07-12 18:55:59,200 [run_pretraining.py:  558]:	worker_index: 7, step: 1245, cost: 8.022465, mlm loss: 8.022465, speed: 1.090961 steps/s, speed: 8.727687 samples/s, speed: 4468.575940 tokens/s, learning rate: 1.244e-05, loss_scalings: 10737.418945, pp_loss: 7.646292
[INFO] 2021-07-12 18:55:59,200 [run_pretraining.py:  512]:	********exe.run_1245******* 
[INFO] 2021-07-12 18:56:00,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:00,113 [run_pretraining.py:  534]:	loss/total_loss, 5.350057601928711, 1246
[INFO] 2021-07-12 18:56:00,113 [run_pretraining.py:  535]:	loss/mlm_loss, 5.350057601928711, 1246
[INFO] 2021-07-12 18:56:00,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2449999303498771e-05, 1246
[INFO] 2021-07-12 18:56:00,113 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1246
[INFO] 2021-07-12 18:56:00,113 [run_pretraining.py:  558]:	worker_index: 7, step: 1246, cost: 5.350058, mlm loss: 5.350058, speed: 1.095308 steps/s, speed: 8.762467 samples/s, speed: 4486.383327 tokens/s, learning rate: 1.245e-05, loss_scalings: 10737.418945, pp_loss: 7.093652
[INFO] 2021-07-12 18:56:00,114 [run_pretraining.py:  512]:	********exe.run_1246******* 
[INFO] 2021-07-12 18:56:01,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:01,035 [run_pretraining.py:  534]:	loss/total_loss, 7.538689136505127, 1247
[INFO] 2021-07-12 18:56:01,035 [run_pretraining.py:  535]:	loss/mlm_loss, 7.538689136505127, 1247
[INFO] 2021-07-12 18:56:01,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2460000107239466e-05, 1247
[INFO] 2021-07-12 18:56:01,035 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1247
[INFO] 2021-07-12 18:56:01,035 [run_pretraining.py:  558]:	worker_index: 7, step: 1247, cost: 7.538689, mlm loss: 7.538689, speed: 1.085532 steps/s, speed: 8.684259 samples/s, speed: 4446.340743 tokens/s, learning rate: 1.246e-05, loss_scalings: 10737.418945, pp_loss: 7.507277
[INFO] 2021-07-12 18:56:01,035 [run_pretraining.py:  512]:	********exe.run_1247******* 
[INFO] 2021-07-12 18:56:01,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:01,943 [run_pretraining.py:  534]:	loss/total_loss, 7.710411071777344, 1248
[INFO] 2021-07-12 18:56:01,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.710411071777344, 1248
[INFO] 2021-07-12 18:56:01,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.247000000148546e-05, 1248
[INFO] 2021-07-12 18:56:01,943 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1248
[INFO] 2021-07-12 18:56:01,943 [run_pretraining.py:  558]:	worker_index: 7, step: 1248, cost: 7.710411, mlm loss: 7.710411, speed: 1.102611 steps/s, speed: 8.820884 samples/s, speed: 4516.292738 tokens/s, learning rate: 1.247e-05, loss_scalings: 10737.418945, pp_loss: 6.754834
[INFO] 2021-07-12 18:56:01,943 [run_pretraining.py:  512]:	********exe.run_1248******* 
[INFO] 2021-07-12 18:56:02,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:02,858 [run_pretraining.py:  534]:	loss/total_loss, 7.787740707397461, 1249
[INFO] 2021-07-12 18:56:02,858 [run_pretraining.py:  535]:	loss/mlm_loss, 7.787740707397461, 1249
[INFO] 2021-07-12 18:56:02,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2479998986236751e-05, 1249
[INFO] 2021-07-12 18:56:02,858 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1249
[INFO] 2021-07-12 18:56:02,858 [run_pretraining.py:  558]:	worker_index: 7, step: 1249, cost: 7.787741, mlm loss: 7.787741, speed: 1.093361 steps/s, speed: 8.746887 samples/s, speed: 4478.406172 tokens/s, learning rate: 1.248e-05, loss_scalings: 10737.418945, pp_loss: 7.562317
[INFO] 2021-07-12 18:56:02,858 [run_pretraining.py:  512]:	********exe.run_1249******* 
[INFO] 2021-07-12 18:56:03,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:03,772 [run_pretraining.py:  534]:	loss/total_loss, 7.658710479736328, 1250
[INFO] 2021-07-12 18:56:03,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.658710479736328, 1250
[INFO] 2021-07-12 18:56:03,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2489999789977446e-05, 1250
[INFO] 2021-07-12 18:56:03,772 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1250
[INFO] 2021-07-12 18:56:03,772 [run_pretraining.py:  558]:	worker_index: 7, step: 1250, cost: 7.658710, mlm loss: 7.658710, speed: 1.095148 steps/s, speed: 8.761186 samples/s, speed: 4485.727337 tokens/s, learning rate: 1.249e-05, loss_scalings: 10737.418945, pp_loss: 6.805569
[INFO] 2021-07-12 18:56:03,772 [run_pretraining.py:  512]:	********exe.run_1250******* 
[INFO] 2021-07-12 18:56:04,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  534]:	loss/total_loss, 7.876332759857178, 1251
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  535]:	loss/mlm_loss, 7.876332759857178, 1251
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.249999968422344e-05, 1251
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1251
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  558]:	worker_index: 7, step: 1251, cost: 7.876333, mlm loss: 7.876333, speed: 1.100822 steps/s, speed: 8.806572 samples/s, speed: 4508.965031 tokens/s, learning rate: 1.250e-05, loss_scalings: 10737.418945, pp_loss: 7.806243
[INFO] 2021-07-12 18:56:04,681 [run_pretraining.py:  512]:	********exe.run_1251******* 
[INFO] 2021-07-12 18:56:05,614 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:05,615 [run_pretraining.py:  534]:	loss/total_loss, 7.389917373657227, 1252
[INFO] 2021-07-12 18:56:05,615 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389917373657227, 1252
[INFO] 2021-07-12 18:56:05,615 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2509999578469433e-05, 1252
[INFO] 2021-07-12 18:56:05,615 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1252
[INFO] 2021-07-12 18:56:05,615 [run_pretraining.py:  558]:	worker_index: 7, step: 1252, cost: 7.389917, mlm loss: 7.389917, speed: 1.071119 steps/s, speed: 8.568955 samples/s, speed: 4387.304704 tokens/s, learning rate: 1.251e-05, loss_scalings: 10737.418945, pp_loss: 7.564012
[INFO] 2021-07-12 18:56:05,615 [run_pretraining.py:  512]:	********exe.run_1252******* 
[INFO] 2021-07-12 18:56:06,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:06,528 [run_pretraining.py:  534]:	loss/total_loss, 7.599254131317139, 1253
[INFO] 2021-07-12 18:56:06,528 [run_pretraining.py:  535]:	loss/mlm_loss, 7.599254131317139, 1253
[INFO] 2021-07-12 18:56:06,528 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2520000382210128e-05, 1253
[INFO] 2021-07-12 18:56:06,528 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1253
[INFO] 2021-07-12 18:56:06,528 [run_pretraining.py:  558]:	worker_index: 7, step: 1253, cost: 7.599254, mlm loss: 7.599254, speed: 1.096095 steps/s, speed: 8.768760 samples/s, speed: 4489.605148 tokens/s, learning rate: 1.252e-05, loss_scalings: 10737.418945, pp_loss: 7.609563
[INFO] 2021-07-12 18:56:06,528 [run_pretraining.py:  512]:	********exe.run_1253******* 
[INFO] 2021-07-12 18:56:07,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:07,438 [run_pretraining.py:  534]:	loss/total_loss, 7.713366985321045, 1254
[INFO] 2021-07-12 18:56:07,438 [run_pretraining.py:  535]:	loss/mlm_loss, 7.713366985321045, 1254
[INFO] 2021-07-12 18:56:07,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2530000276456121e-05, 1254
[INFO] 2021-07-12 18:56:07,439 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1254
[INFO] 2021-07-12 18:56:07,439 [run_pretraining.py:  558]:	worker_index: 7, step: 1254, cost: 7.713367, mlm loss: 7.713367, speed: 1.099160 steps/s, speed: 8.793277 samples/s, speed: 4502.157720 tokens/s, learning rate: 1.253e-05, loss_scalings: 10737.418945, pp_loss: 7.148770
[INFO] 2021-07-12 18:56:07,439 [run_pretraining.py:  512]:	********exe.run_1254******* 
[INFO] 2021-07-12 18:56:08,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:08,385 [run_pretraining.py:  534]:	loss/total_loss, 7.97747278213501, 1255
[INFO] 2021-07-12 18:56:08,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.97747278213501, 1255
[INFO] 2021-07-12 18:56:08,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2540000170702115e-05, 1255
[INFO] 2021-07-12 18:56:08,385 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1255
[INFO] 2021-07-12 18:56:08,386 [run_pretraining.py:  558]:	worker_index: 7, step: 1255, cost: 7.977473, mlm loss: 7.977473, speed: 1.056838 steps/s, speed: 8.454707 samples/s, speed: 4328.809932 tokens/s, learning rate: 1.254e-05, loss_scalings: 10737.418945, pp_loss: 7.727637
[INFO] 2021-07-12 18:56:08,386 [run_pretraining.py:  512]:	********exe.run_1255******* 
[INFO] 2021-07-12 18:56:09,337 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:09,338 [run_pretraining.py:  534]:	loss/total_loss, 7.884542465209961, 1256
[INFO] 2021-07-12 18:56:09,338 [run_pretraining.py:  535]:	loss/mlm_loss, 7.884542465209961, 1256
[INFO] 2021-07-12 18:56:09,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2549999155453406e-05, 1256
[INFO] 2021-07-12 18:56:09,338 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1256
[INFO] 2021-07-12 18:56:09,338 [run_pretraining.py:  558]:	worker_index: 7, step: 1256, cost: 7.884542, mlm loss: 7.884542, speed: 1.050665 steps/s, speed: 8.405320 samples/s, speed: 4303.523777 tokens/s, learning rate: 1.255e-05, loss_scalings: 10737.418945, pp_loss: 7.690226
[INFO] 2021-07-12 18:56:09,338 [run_pretraining.py:  512]:	********exe.run_1256******* 
[INFO] 2021-07-12 18:56:10,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:10,408 [run_pretraining.py:  534]:	loss/total_loss, 7.9828338623046875, 1257
[INFO] 2021-07-12 18:56:10,408 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9828338623046875, 1257
[INFO] 2021-07-12 18:56:10,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.25599990496994e-05, 1257
[INFO] 2021-07-12 18:56:10,408 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1257
[INFO] 2021-07-12 18:56:10,408 [run_pretraining.py:  558]:	worker_index: 7, step: 1257, cost: 7.982834, mlm loss: 7.982834, speed: 0.934812 steps/s, speed: 7.478496 samples/s, speed: 3828.989771 tokens/s, learning rate: 1.256e-05, loss_scalings: 10737.418945, pp_loss: 7.847235
[INFO] 2021-07-12 18:56:10,408 [run_pretraining.py:  512]:	********exe.run_1257******* 
[INFO] 2021-07-12 18:56:11,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:11,467 [run_pretraining.py:  534]:	loss/total_loss, 8.003239631652832, 1258
[INFO] 2021-07-12 18:56:11,467 [run_pretraining.py:  535]:	loss/mlm_loss, 8.003239631652832, 1258
[INFO] 2021-07-12 18:56:11,467 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2569998943945393e-05, 1258
[INFO] 2021-07-12 18:56:11,467 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1258
[INFO] 2021-07-12 18:56:11,467 [run_pretraining.py:  558]:	worker_index: 7, step: 1258, cost: 8.003240, mlm loss: 8.003240, speed: 0.945084 steps/s, speed: 7.560671 samples/s, speed: 3871.063576 tokens/s, learning rate: 1.257e-05, loss_scalings: 10737.418945, pp_loss: 6.850853
[INFO] 2021-07-12 18:56:11,467 [run_pretraining.py:  512]:	********exe.run_1258******* 
[INFO] 2021-07-12 18:56:12,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:12,520 [run_pretraining.py:  534]:	loss/total_loss, 7.456191539764404, 1259
[INFO] 2021-07-12 18:56:12,520 [run_pretraining.py:  535]:	loss/mlm_loss, 7.456191539764404, 1259
[INFO] 2021-07-12 18:56:12,521 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2579999747686088e-05, 1259
[INFO] 2021-07-12 18:56:12,521 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1259
[INFO] 2021-07-12 18:56:12,521 [run_pretraining.py:  558]:	worker_index: 7, step: 1259, cost: 7.456192, mlm loss: 7.456192, speed: 0.949772 steps/s, speed: 7.598176 samples/s, speed: 3890.265857 tokens/s, learning rate: 1.258e-05, loss_scalings: 10737.418945, pp_loss: 7.387963
[INFO] 2021-07-12 18:56:12,521 [run_pretraining.py:  512]:	********exe.run_1259******* 
[INFO] 2021-07-12 18:56:13,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:13,451 [run_pretraining.py:  534]:	loss/total_loss, 7.458885669708252, 1260
[INFO] 2021-07-12 18:56:13,451 [run_pretraining.py:  535]:	loss/mlm_loss, 7.458885669708252, 1260
[INFO] 2021-07-12 18:56:13,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2589999641932081e-05, 1260
[INFO] 2021-07-12 18:56:13,451 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1260
[INFO] 2021-07-12 18:56:13,451 [run_pretraining.py:  558]:	worker_index: 7, step: 1260, cost: 7.458886, mlm loss: 7.458886, speed: 1.075816 steps/s, speed: 8.606532 samples/s, speed: 4406.544303 tokens/s, learning rate: 1.259e-05, loss_scalings: 10737.418945, pp_loss: 7.746196
[INFO] 2021-07-12 18:56:13,451 [run_pretraining.py:  512]:	********exe.run_1260******* 
[INFO] 2021-07-12 18:56:14,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:14,369 [run_pretraining.py:  534]:	loss/total_loss, 7.9789862632751465, 1261
[INFO] 2021-07-12 18:56:14,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9789862632751465, 1261
[INFO] 2021-07-12 18:56:14,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2599999536178075e-05, 1261
[INFO] 2021-07-12 18:56:14,369 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1261
[INFO] 2021-07-12 18:56:14,370 [run_pretraining.py:  558]:	worker_index: 7, step: 1261, cost: 7.978986, mlm loss: 7.978986, speed: 1.089296 steps/s, speed: 8.714371 samples/s, speed: 4461.757843 tokens/s, learning rate: 1.260e-05, loss_scalings: 10737.418945, pp_loss: 7.421929
[INFO] 2021-07-12 18:56:14,370 [run_pretraining.py:  512]:	********exe.run_1261******* 
[INFO] 2021-07-12 18:56:15,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:15,286 [run_pretraining.py:  534]:	loss/total_loss, 7.69162130355835, 1262
[INFO] 2021-07-12 18:56:15,286 [run_pretraining.py:  535]:	loss/mlm_loss, 7.69162130355835, 1262
[INFO] 2021-07-12 18:56:15,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.261000033991877e-05, 1262
[INFO] 2021-07-12 18:56:15,286 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1262
[INFO] 2021-07-12 18:56:15,286 [run_pretraining.py:  558]:	worker_index: 7, step: 1262, cost: 7.691621, mlm loss: 7.691621, speed: 1.091791 steps/s, speed: 8.734328 samples/s, speed: 4471.975929 tokens/s, learning rate: 1.261e-05, loss_scalings: 10737.418945, pp_loss: 7.532260
[INFO] 2021-07-12 18:56:15,286 [run_pretraining.py:  512]:	********exe.run_1262******* 
[INFO] 2021-07-12 18:56:16,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:16,212 [run_pretraining.py:  534]:	loss/total_loss, 8.05299186706543, 1263
[INFO] 2021-07-12 18:56:16,212 [run_pretraining.py:  535]:	loss/mlm_loss, 8.05299186706543, 1263
[INFO] 2021-07-12 18:56:16,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2620000234164763e-05, 1263
[INFO] 2021-07-12 18:56:16,212 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1263
[INFO] 2021-07-12 18:56:16,212 [run_pretraining.py:  558]:	worker_index: 7, step: 1263, cost: 8.052992, mlm loss: 8.052992, speed: 1.080628 steps/s, speed: 8.645024 samples/s, speed: 4426.252148 tokens/s, learning rate: 1.262e-05, loss_scalings: 10737.418945, pp_loss: 7.701106
[INFO] 2021-07-12 18:56:16,212 [run_pretraining.py:  512]:	********exe.run_1263******* 
[INFO] 2021-07-12 18:56:17,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:17,112 [run_pretraining.py:  534]:	loss/total_loss, 7.902349472045898, 1264
[INFO] 2021-07-12 18:56:17,112 [run_pretraining.py:  535]:	loss/mlm_loss, 7.902349472045898, 1264
[INFO] 2021-07-12 18:56:17,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2630000128410757e-05, 1264
[INFO] 2021-07-12 18:56:17,112 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1264
[INFO] 2021-07-12 18:56:17,112 [run_pretraining.py:  558]:	worker_index: 7, step: 1264, cost: 7.902349, mlm loss: 7.902349, speed: 1.112028 steps/s, speed: 8.896222 samples/s, speed: 4554.865653 tokens/s, learning rate: 1.263e-05, loss_scalings: 10737.418945, pp_loss: 7.679773
[INFO] 2021-07-12 18:56:17,112 [run_pretraining.py:  512]:	********exe.run_1264******* 
[INFO] 2021-07-12 18:56:18,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:18,017 [run_pretraining.py:  534]:	loss/total_loss, 7.5829620361328125, 1265
[INFO] 2021-07-12 18:56:18,017 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5829620361328125, 1265
[INFO] 2021-07-12 18:56:18,017 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2639999113162048e-05, 1265
[INFO] 2021-07-12 18:56:18,017 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1265
[INFO] 2021-07-12 18:56:18,017 [run_pretraining.py:  558]:	worker_index: 7, step: 1265, cost: 7.582962, mlm loss: 7.582962, speed: 1.106041 steps/s, speed: 8.848327 samples/s, speed: 4530.343561 tokens/s, learning rate: 1.264e-05, loss_scalings: 10737.418945, pp_loss: 7.533060
[INFO] 2021-07-12 18:56:18,017 [run_pretraining.py:  512]:	********exe.run_1265******* 
[INFO] 2021-07-12 18:56:18,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:18,943 [run_pretraining.py:  534]:	loss/total_loss, 7.700840950012207, 1266
[INFO] 2021-07-12 18:56:18,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.700840950012207, 1266
[INFO] 2021-07-12 18:56:18,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2649999007408042e-05, 1266
[INFO] 2021-07-12 18:56:18,943 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1266
[INFO] 2021-07-12 18:56:18,943 [run_pretraining.py:  558]:	worker_index: 7, step: 1266, cost: 7.700841, mlm loss: 7.700841, speed: 1.080007 steps/s, speed: 8.640057 samples/s, speed: 4423.709405 tokens/s, learning rate: 1.265e-05, loss_scalings: 10737.418945, pp_loss: 7.736437
[INFO] 2021-07-12 18:56:18,944 [run_pretraining.py:  512]:	********exe.run_1266******* 
[INFO] 2021-07-12 18:56:19,865 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:19,865 [run_pretraining.py:  534]:	loss/total_loss, 7.325278282165527, 1267
[INFO] 2021-07-12 18:56:19,865 [run_pretraining.py:  535]:	loss/mlm_loss, 7.325278282165527, 1267
[INFO] 2021-07-12 18:56:19,866 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2659999811148737e-05, 1267
[INFO] 2021-07-12 18:56:19,866 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1267
[INFO] 2021-07-12 18:56:19,866 [run_pretraining.py:  558]:	worker_index: 7, step: 1267, cost: 7.325278, mlm loss: 7.325278, speed: 1.085006 steps/s, speed: 8.680049 samples/s, speed: 4444.185260 tokens/s, learning rate: 1.266e-05, loss_scalings: 10737.418945, pp_loss: 7.657853
[INFO] 2021-07-12 18:56:19,866 [run_pretraining.py:  512]:	********exe.run_1267******* 
[INFO] 2021-07-12 18:56:20,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:20,810 [run_pretraining.py:  534]:	loss/total_loss, 7.222063064575195, 1268
[INFO] 2021-07-12 18:56:20,810 [run_pretraining.py:  535]:	loss/mlm_loss, 7.222063064575195, 1268
[INFO] 2021-07-12 18:56:20,810 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.266999970539473e-05, 1268
[INFO] 2021-07-12 18:56:20,810 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1268
[INFO] 2021-07-12 18:56:20,810 [run_pretraining.py:  558]:	worker_index: 7, step: 1268, cost: 7.222063, mlm loss: 7.222063, speed: 1.059600 steps/s, speed: 8.476798 samples/s, speed: 4340.120828 tokens/s, learning rate: 1.267e-05, loss_scalings: 10737.418945, pp_loss: 7.765196
[INFO] 2021-07-12 18:56:20,810 [run_pretraining.py:  512]:	********exe.run_1268******* 
[INFO] 2021-07-12 18:56:21,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:21,711 [run_pretraining.py:  534]:	loss/total_loss, 7.357172012329102, 1269
[INFO] 2021-07-12 18:56:21,711 [run_pretraining.py:  535]:	loss/mlm_loss, 7.357172012329102, 1269
[INFO] 2021-07-12 18:56:21,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2679999599640723e-05, 1269
[INFO] 2021-07-12 18:56:21,711 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1269
[INFO] 2021-07-12 18:56:21,711 [run_pretraining.py:  558]:	worker_index: 7, step: 1269, cost: 7.357172, mlm loss: 7.357172, speed: 1.110281 steps/s, speed: 8.882248 samples/s, speed: 4547.710876 tokens/s, learning rate: 1.268e-05, loss_scalings: 10737.418945, pp_loss: 7.527736
[INFO] 2021-07-12 18:56:21,712 [run_pretraining.py:  512]:	********exe.run_1269******* 
[INFO] 2021-07-12 18:56:22,628 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:22,628 [run_pretraining.py:  534]:	loss/total_loss, 7.6957011222839355, 1270
[INFO] 2021-07-12 18:56:22,628 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6957011222839355, 1270
[INFO] 2021-07-12 18:56:22,629 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2689999493886717e-05, 1270
[INFO] 2021-07-12 18:56:22,629 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1270
[INFO] 2021-07-12 18:56:22,629 [run_pretraining.py:  558]:	worker_index: 7, step: 1270, cost: 7.695701, mlm loss: 7.695701, speed: 1.091109 steps/s, speed: 8.728873 samples/s, speed: 4469.182743 tokens/s, learning rate: 1.269e-05, loss_scalings: 10737.418945, pp_loss: 7.789385
[INFO] 2021-07-12 18:56:22,629 [run_pretraining.py:  512]:	********exe.run_1270******* 
[INFO] 2021-07-12 18:56:23,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:23,547 [run_pretraining.py:  534]:	loss/total_loss, 7.331892490386963, 1271
[INFO] 2021-07-12 18:56:23,547 [run_pretraining.py:  535]:	loss/mlm_loss, 7.331892490386963, 1271
[INFO] 2021-07-12 18:56:23,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2700000297627412e-05, 1271
[INFO] 2021-07-12 18:56:23,547 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1271
[INFO] 2021-07-12 18:56:23,547 [run_pretraining.py:  558]:	worker_index: 7, step: 1271, cost: 7.331892, mlm loss: 7.331892, speed: 1.089342 steps/s, speed: 8.714733 samples/s, speed: 4461.943252 tokens/s, learning rate: 1.270e-05, loss_scalings: 10737.418945, pp_loss: 7.618649
[INFO] 2021-07-12 18:56:23,547 [run_pretraining.py:  512]:	********exe.run_1271******* 
[INFO] 2021-07-12 18:56:24,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:24,462 [run_pretraining.py:  534]:	loss/total_loss, 7.605345249176025, 1272
[INFO] 2021-07-12 18:56:24,462 [run_pretraining.py:  535]:	loss/mlm_loss, 7.605345249176025, 1272
[INFO] 2021-07-12 18:56:24,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2710000191873405e-05, 1272
[INFO] 2021-07-12 18:56:24,462 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1272
[INFO] 2021-07-12 18:56:24,462 [run_pretraining.py:  558]:	worker_index: 7, step: 1272, cost: 7.605345, mlm loss: 7.605345, speed: 1.093905 steps/s, speed: 8.751240 samples/s, speed: 4480.634717 tokens/s, learning rate: 1.271e-05, loss_scalings: 10737.418945, pp_loss: 7.474874
[INFO] 2021-07-12 18:56:24,462 [run_pretraining.py:  512]:	********exe.run_1272******* 
[INFO] 2021-07-12 18:56:25,382 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:25,383 [run_pretraining.py:  534]:	loss/total_loss, 7.837994575500488, 1273
[INFO] 2021-07-12 18:56:25,383 [run_pretraining.py:  535]:	loss/mlm_loss, 7.837994575500488, 1273
[INFO] 2021-07-12 18:56:25,383 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2720000086119398e-05, 1273
[INFO] 2021-07-12 18:56:25,383 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1273
[INFO] 2021-07-12 18:56:25,383 [run_pretraining.py:  558]:	worker_index: 7, step: 1273, cost: 7.837995, mlm loss: 7.837995, speed: 1.086707 steps/s, speed: 8.693658 samples/s, speed: 4451.152680 tokens/s, learning rate: 1.272e-05, loss_scalings: 10737.418945, pp_loss: 7.767927
[INFO] 2021-07-12 18:56:25,383 [run_pretraining.py:  512]:	********exe.run_1273******* 
[INFO] 2021-07-12 18:56:26,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:26,300 [run_pretraining.py:  534]:	loss/total_loss, 7.766824722290039, 1274
[INFO] 2021-07-12 18:56:26,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.766824722290039, 1274
[INFO] 2021-07-12 18:56:26,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.272999907087069e-05, 1274
[INFO] 2021-07-12 18:56:26,301 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1274
[INFO] 2021-07-12 18:56:26,301 [run_pretraining.py:  558]:	worker_index: 7, step: 1274, cost: 7.766825, mlm loss: 7.766825, speed: 1.090316 steps/s, speed: 8.722530 samples/s, speed: 4465.935592 tokens/s, learning rate: 1.273e-05, loss_scalings: 10737.418945, pp_loss: 7.679632
[INFO] 2021-07-12 18:56:26,301 [run_pretraining.py:  512]:	********exe.run_1274******* 
[INFO] 2021-07-12 18:56:27,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:27,207 [run_pretraining.py:  534]:	loss/total_loss, 7.5467376708984375, 1275
[INFO] 2021-07-12 18:56:27,207 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5467376708984375, 1275
[INFO] 2021-07-12 18:56:27,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2739998965116683e-05, 1275
[INFO] 2021-07-12 18:56:27,208 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1275
[INFO] 2021-07-12 18:56:27,208 [run_pretraining.py:  558]:	worker_index: 7, step: 1275, cost: 7.546738, mlm loss: 7.546738, speed: 1.103607 steps/s, speed: 8.828859 samples/s, speed: 4520.375837 tokens/s, learning rate: 1.274e-05, loss_scalings: 10737.418945, pp_loss: 7.340919
[INFO] 2021-07-12 18:56:27,208 [run_pretraining.py:  512]:	********exe.run_1275******* 
[INFO] 2021-07-12 18:56:28,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:28,109 [run_pretraining.py:  534]:	loss/total_loss, 7.557888031005859, 1276
[INFO] 2021-07-12 18:56:28,109 [run_pretraining.py:  535]:	loss/mlm_loss, 7.557888031005859, 1276
[INFO] 2021-07-12 18:56:28,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2749999768857379e-05, 1276
[INFO] 2021-07-12 18:56:28,109 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1276
[INFO] 2021-07-12 18:56:28,109 [run_pretraining.py:  558]:	worker_index: 7, step: 1276, cost: 7.557888, mlm loss: 7.557888, speed: 1.110338 steps/s, speed: 8.882706 samples/s, speed: 4547.945635 tokens/s, learning rate: 1.275e-05, loss_scalings: 10737.418945, pp_loss: 7.215031
[INFO] 2021-07-12 18:56:28,109 [run_pretraining.py:  512]:	********exe.run_1276******* 
[INFO] 2021-07-12 18:56:29,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:29,022 [run_pretraining.py:  534]:	loss/total_loss, 7.47630500793457, 1277
[INFO] 2021-07-12 18:56:29,022 [run_pretraining.py:  535]:	loss/mlm_loss, 7.47630500793457, 1277
[INFO] 2021-07-12 18:56:29,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2759999663103372e-05, 1277
[INFO] 2021-07-12 18:56:29,022 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1277
[INFO] 2021-07-12 18:56:29,022 [run_pretraining.py:  558]:	worker_index: 7, step: 1277, cost: 7.476305, mlm loss: 7.476305, speed: 1.095725 steps/s, speed: 8.765798 samples/s, speed: 4488.088628 tokens/s, learning rate: 1.276e-05, loss_scalings: 10737.418945, pp_loss: 7.639616
[INFO] 2021-07-12 18:56:29,022 [run_pretraining.py:  512]:	********exe.run_1277******* 
[INFO] 2021-07-12 18:56:29,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:29,921 [run_pretraining.py:  534]:	loss/total_loss, 7.125266075134277, 1278
[INFO] 2021-07-12 18:56:29,921 [run_pretraining.py:  535]:	loss/mlm_loss, 7.125266075134277, 1278
[INFO] 2021-07-12 18:56:29,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2769999557349365e-05, 1278
[INFO] 2021-07-12 18:56:29,921 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1278
[INFO] 2021-07-12 18:56:29,921 [run_pretraining.py:  558]:	worker_index: 7, step: 1278, cost: 7.125266, mlm loss: 7.125266, speed: 1.112968 steps/s, speed: 8.903748 samples/s, speed: 4558.718811 tokens/s, learning rate: 1.277e-05, loss_scalings: 10737.418945, pp_loss: 7.083026
[INFO] 2021-07-12 18:56:29,921 [run_pretraining.py:  512]:	********exe.run_1278******* 
[INFO] 2021-07-12 18:56:30,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:30,827 [run_pretraining.py:  534]:	loss/total_loss, 4.641786575317383, 1279
[INFO] 2021-07-12 18:56:30,827 [run_pretraining.py:  535]:	loss/mlm_loss, 4.641786575317383, 1279
[INFO] 2021-07-12 18:56:30,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.278000036109006e-05, 1279
[INFO] 2021-07-12 18:56:30,827 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1279
[INFO] 2021-07-12 18:56:30,827 [run_pretraining.py:  558]:	worker_index: 7, step: 1279, cost: 4.641787, mlm loss: 4.641787, speed: 1.105104 steps/s, speed: 8.840830 samples/s, speed: 4526.504807 tokens/s, learning rate: 1.278e-05, loss_scalings: 10737.418945, pp_loss: 6.899503
[INFO] 2021-07-12 18:56:30,827 [run_pretraining.py:  512]:	********exe.run_1279******* 
[INFO] 2021-07-12 18:56:31,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:31,731 [run_pretraining.py:  534]:	loss/total_loss, 7.778351306915283, 1280
[INFO] 2021-07-12 18:56:31,731 [run_pretraining.py:  535]:	loss/mlm_loss, 7.778351306915283, 1280
[INFO] 2021-07-12 18:56:31,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2790000255336054e-05, 1280
[INFO] 2021-07-12 18:56:31,731 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1280
[INFO] 2021-07-12 18:56:31,731 [run_pretraining.py:  558]:	worker_index: 7, step: 1280, cost: 7.778351, mlm loss: 7.778351, speed: 1.106925 steps/s, speed: 8.855398 samples/s, speed: 4533.963866 tokens/s, learning rate: 1.279e-05, loss_scalings: 10737.418945, pp_loss: 7.420769
[INFO] 2021-07-12 18:56:31,731 [run_pretraining.py:  512]:	********exe.run_1280******* 
[INFO] 2021-07-12 18:56:32,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:32,722 [run_pretraining.py:  534]:	loss/total_loss, 7.7375898361206055, 1281
[INFO] 2021-07-12 18:56:32,723 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7375898361206055, 1281
[INFO] 2021-07-12 18:56:32,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2800000149582047e-05, 1281
[INFO] 2021-07-12 18:56:32,723 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1281
[INFO] 2021-07-12 18:56:32,723 [run_pretraining.py:  558]:	worker_index: 7, step: 1281, cost: 7.737590, mlm loss: 7.737590, speed: 1.008906 steps/s, speed: 8.071250 samples/s, speed: 4132.480239 tokens/s, learning rate: 1.280e-05, loss_scalings: 10737.418945, pp_loss: 7.523603
[INFO] 2021-07-12 18:56:32,723 [run_pretraining.py:  512]:	********exe.run_1281******* 
[INFO] 2021-07-12 18:56:33,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:33,776 [run_pretraining.py:  534]:	loss/total_loss, 5.686468124389648, 1282
[INFO] 2021-07-12 18:56:33,776 [run_pretraining.py:  535]:	loss/mlm_loss, 5.686468124389648, 1282
[INFO] 2021-07-12 18:56:33,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2809999134333339e-05, 1282
[INFO] 2021-07-12 18:56:33,777 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1282
[INFO] 2021-07-12 18:56:33,777 [run_pretraining.py:  558]:	worker_index: 7, step: 1282, cost: 5.686468, mlm loss: 5.686468, speed: 0.949360 steps/s, speed: 7.594877 samples/s, speed: 3888.576977 tokens/s, learning rate: 1.281e-05, loss_scalings: 10737.418945, pp_loss: 7.124422
[INFO] 2021-07-12 18:56:33,777 [run_pretraining.py:  512]:	********exe.run_1282******* 
[INFO] 2021-07-12 18:56:34,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:34,833 [run_pretraining.py:  534]:	loss/total_loss, 7.947515964508057, 1283
[INFO] 2021-07-12 18:56:34,833 [run_pretraining.py:  535]:	loss/mlm_loss, 7.947515964508057, 1283
[INFO] 2021-07-12 18:56:34,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2819999028579332e-05, 1283
[INFO] 2021-07-12 18:56:34,833 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1283
[INFO] 2021-07-12 18:56:34,834 [run_pretraining.py:  558]:	worker_index: 7, step: 1283, cost: 7.947516, mlm loss: 7.947516, speed: 0.946840 steps/s, speed: 7.574723 samples/s, speed: 3878.258153 tokens/s, learning rate: 1.282e-05, loss_scalings: 10737.418945, pp_loss: 7.361882
[INFO] 2021-07-12 18:56:34,834 [run_pretraining.py:  512]:	********exe.run_1283******* 
[INFO] 2021-07-12 18:56:35,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:35,886 [run_pretraining.py:  534]:	loss/total_loss, 8.068530082702637, 1284
[INFO] 2021-07-12 18:56:35,887 [run_pretraining.py:  535]:	loss/mlm_loss, 8.068530082702637, 1284
[INFO] 2021-07-12 18:56:35,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2829998922825325e-05, 1284
[INFO] 2021-07-12 18:56:35,887 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1284
[INFO] 2021-07-12 18:56:35,887 [run_pretraining.py:  558]:	worker_index: 7, step: 1284, cost: 8.068530, mlm loss: 8.068530, speed: 0.949966 steps/s, speed: 7.599731 samples/s, speed: 3891.062375 tokens/s, learning rate: 1.283e-05, loss_scalings: 10737.418945, pp_loss: 7.618773
[INFO] 2021-07-12 18:56:35,887 [run_pretraining.py:  512]:	********exe.run_1284******* 
[INFO] 2021-07-12 18:56:36,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:36,933 [run_pretraining.py:  534]:	loss/total_loss, 7.706073760986328, 1285
[INFO] 2021-07-12 18:56:36,933 [run_pretraining.py:  535]:	loss/mlm_loss, 7.706073760986328, 1285
[INFO] 2021-07-12 18:56:36,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.283999972656602e-05, 1285
[INFO] 2021-07-12 18:56:36,934 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1285
[INFO] 2021-07-12 18:56:36,934 [run_pretraining.py:  558]:	worker_index: 7, step: 1285, cost: 7.706074, mlm loss: 7.706074, speed: 0.955928 steps/s, speed: 7.647420 samples/s, speed: 3915.479065 tokens/s, learning rate: 1.284e-05, loss_scalings: 10737.418945, pp_loss: 7.722188
[INFO] 2021-07-12 18:56:36,934 [run_pretraining.py:  512]:	********exe.run_1285******* 
[INFO] 2021-07-12 18:56:37,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  534]:	loss/total_loss, 7.193471431732178, 1286
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  535]:	loss/mlm_loss, 7.193471431732178, 1286
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2849999620812014e-05, 1286
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1286
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  558]:	worker_index: 7, step: 1286, cost: 7.193471, mlm loss: 7.193471, speed: 0.941807 steps/s, speed: 7.534453 samples/s, speed: 3857.640136 tokens/s, learning rate: 1.285e-05, loss_scalings: 10737.418945, pp_loss: 7.052421
[INFO] 2021-07-12 18:56:37,996 [run_pretraining.py:  512]:	********exe.run_1286******* 
[INFO] 2021-07-12 18:56:39,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  534]:	loss/total_loss, 7.7499589920043945, 1287
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7499589920043945, 1287
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2859999515058007e-05, 1287
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1287
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  558]:	worker_index: 7, step: 1287, cost: 7.749959, mlm loss: 7.749959, speed: 0.946578 steps/s, speed: 7.572620 samples/s, speed: 3877.181593 tokens/s, learning rate: 1.286e-05, loss_scalings: 10737.418945, pp_loss: 7.765265
[INFO] 2021-07-12 18:56:39,053 [run_pretraining.py:  512]:	********exe.run_1287******* 
[INFO] 2021-07-12 18:56:40,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:40,101 [run_pretraining.py:  534]:	loss/total_loss, 6.886940002441406, 1288
[INFO] 2021-07-12 18:56:40,101 [run_pretraining.py:  535]:	loss/mlm_loss, 6.886940002441406, 1288
[INFO] 2021-07-12 18:56:40,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2870000318798702e-05, 1288
[INFO] 2021-07-12 18:56:40,101 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1288
[INFO] 2021-07-12 18:56:40,102 [run_pretraining.py:  558]:	worker_index: 7, step: 1288, cost: 6.886940, mlm loss: 6.886940, speed: 0.954389 steps/s, speed: 7.635116 samples/s, speed: 3909.179197 tokens/s, learning rate: 1.287e-05, loss_scalings: 10737.418945, pp_loss: 7.439803
[INFO] 2021-07-12 18:56:40,102 [run_pretraining.py:  512]:	********exe.run_1288******* 
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  534]:	loss/total_loss, 8.037993431091309, 1289
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  535]:	loss/mlm_loss, 8.037993431091309, 1289
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2880000213044696e-05, 1289
[INFO] 2021-07-12 18:56:41,216 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1289
[INFO] 2021-07-12 18:56:41,217 [run_pretraining.py:  558]:	worker_index: 7, step: 1289, cost: 8.037993, mlm loss: 8.037993, speed: 0.897385 steps/s, speed: 7.179082 samples/s, speed: 3675.689830 tokens/s, learning rate: 1.288e-05, loss_scalings: 10737.418945, pp_loss: 7.783428
[INFO] 2021-07-12 18:56:41,217 [run_pretraining.py:  512]:	********exe.run_1289******* 
[INFO] 2021-07-12 18:56:42,115 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:42,116 [run_pretraining.py:  534]:	loss/total_loss, 7.667819499969482, 1290
[INFO] 2021-07-12 18:56:42,116 [run_pretraining.py:  535]:	loss/mlm_loss, 7.667819499969482, 1290
[INFO] 2021-07-12 18:56:42,116 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2890000107290689e-05, 1290
[INFO] 2021-07-12 18:56:42,116 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1290
[INFO] 2021-07-12 18:56:42,116 [run_pretraining.py:  558]:	worker_index: 7, step: 1290, cost: 7.667819, mlm loss: 7.667819, speed: 1.112623 steps/s, speed: 8.900987 samples/s, speed: 4557.305149 tokens/s, learning rate: 1.289e-05, loss_scalings: 10737.418945, pp_loss: 7.512436
[INFO] 2021-07-12 18:56:42,116 [run_pretraining.py:  512]:	********exe.run_1290******* 
[INFO] 2021-07-12 18:56:43,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:43,018 [run_pretraining.py:  534]:	loss/total_loss, 8.443889617919922, 1291
[INFO] 2021-07-12 18:56:43,018 [run_pretraining.py:  535]:	loss/mlm_loss, 8.443889617919922, 1291
[INFO] 2021-07-12 18:56:43,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.289999909204198e-05, 1291
[INFO] 2021-07-12 18:56:43,018 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1291
[INFO] 2021-07-12 18:56:43,018 [run_pretraining.py:  558]:	worker_index: 7, step: 1291, cost: 8.443890, mlm loss: 8.443890, speed: 1.109433 steps/s, speed: 8.875460 samples/s, speed: 4544.235663 tokens/s, learning rate: 1.290e-05, loss_scalings: 10737.418945, pp_loss: 7.710342
[INFO] 2021-07-12 18:56:43,018 [run_pretraining.py:  512]:	********exe.run_1291******* 
[INFO] 2021-07-12 18:56:43,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  534]:	loss/total_loss, 7.5933942794799805, 1292
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5933942794799805, 1292
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2909998986287974e-05, 1292
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1292
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  558]:	worker_index: 7, step: 1292, cost: 7.593394, mlm loss: 7.593394, speed: 1.103324 steps/s, speed: 8.826595 samples/s, speed: 4519.216466 tokens/s, learning rate: 1.291e-05, loss_scalings: 10737.418945, pp_loss: 7.546926
[INFO] 2021-07-12 18:56:43,925 [run_pretraining.py:  512]:	********exe.run_1292******* 
[INFO] 2021-07-12 18:56:44,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:44,829 [run_pretraining.py:  534]:	loss/total_loss, 7.714051246643066, 1293
[INFO] 2021-07-12 18:56:44,829 [run_pretraining.py:  535]:	loss/mlm_loss, 7.714051246643066, 1293
[INFO] 2021-07-12 18:56:44,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2919998880533967e-05, 1293
[INFO] 2021-07-12 18:56:44,829 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1293
[INFO] 2021-07-12 18:56:44,829 [run_pretraining.py:  558]:	worker_index: 7, step: 1293, cost: 7.714051, mlm loss: 7.714051, speed: 1.106389 steps/s, speed: 8.851109 samples/s, speed: 4531.768037 tokens/s, learning rate: 1.292e-05, loss_scalings: 10737.418945, pp_loss: 7.502782
[INFO] 2021-07-12 18:56:44,830 [run_pretraining.py:  512]:	********exe.run_1293******* 
[INFO] 2021-07-12 18:56:45,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:45,742 [run_pretraining.py:  534]:	loss/total_loss, 7.391474723815918, 1294
[INFO] 2021-07-12 18:56:45,742 [run_pretraining.py:  535]:	loss/mlm_loss, 7.391474723815918, 1294
[INFO] 2021-07-12 18:56:45,742 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2929999684274662e-05, 1294
[INFO] 2021-07-12 18:56:45,742 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1294
[INFO] 2021-07-12 18:56:45,743 [run_pretraining.py:  558]:	worker_index: 7, step: 1294, cost: 7.391475, mlm loss: 7.391475, speed: 1.096071 steps/s, speed: 8.768565 samples/s, speed: 4489.505423 tokens/s, learning rate: 1.293e-05, loss_scalings: 10737.418945, pp_loss: 7.520078
[INFO] 2021-07-12 18:56:45,743 [run_pretraining.py:  512]:	********exe.run_1294******* 
[INFO] 2021-07-12 18:56:46,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:46,638 [run_pretraining.py:  534]:	loss/total_loss, 7.9161376953125, 1295
[INFO] 2021-07-12 18:56:46,638 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9161376953125, 1295
[INFO] 2021-07-12 18:56:46,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2939999578520656e-05, 1295
[INFO] 2021-07-12 18:56:46,638 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1295
[INFO] 2021-07-12 18:56:46,638 [run_pretraining.py:  558]:	worker_index: 7, step: 1295, cost: 7.916138, mlm loss: 7.916138, speed: 1.117462 steps/s, speed: 8.939693 samples/s, speed: 4577.122892 tokens/s, learning rate: 1.294e-05, loss_scalings: 10737.418945, pp_loss: 7.765638
[INFO] 2021-07-12 18:56:46,638 [run_pretraining.py:  512]:	********exe.run_1295******* 
[INFO] 2021-07-12 18:56:47,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:47,538 [run_pretraining.py:  534]:	loss/total_loss, 7.46262264251709, 1296
[INFO] 2021-07-12 18:56:47,538 [run_pretraining.py:  535]:	loss/mlm_loss, 7.46262264251709, 1296
[INFO] 2021-07-12 18:56:47,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2949999472766649e-05, 1296
[INFO] 2021-07-12 18:56:47,538 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1296
[INFO] 2021-07-12 18:56:47,538 [run_pretraining.py:  558]:	worker_index: 7, step: 1296, cost: 7.462623, mlm loss: 7.462623, speed: 1.111747 steps/s, speed: 8.893972 samples/s, speed: 4553.713872 tokens/s, learning rate: 1.295e-05, loss_scalings: 10737.418945, pp_loss: 7.472137
[INFO] 2021-07-12 18:56:47,538 [run_pretraining.py:  512]:	********exe.run_1296******* 
[INFO] 2021-07-12 18:56:48,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:48,445 [run_pretraining.py:  534]:	loss/total_loss, 4.412697792053223, 1297
[INFO] 2021-07-12 18:56:48,445 [run_pretraining.py:  535]:	loss/mlm_loss, 4.412697792053223, 1297
[INFO] 2021-07-12 18:56:48,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2960000276507344e-05, 1297
[INFO] 2021-07-12 18:56:48,445 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1297
[INFO] 2021-07-12 18:56:48,445 [run_pretraining.py:  558]:	worker_index: 7, step: 1297, cost: 4.412698, mlm loss: 4.412698, speed: 1.103323 steps/s, speed: 8.826583 samples/s, speed: 4519.210522 tokens/s, learning rate: 1.296e-05, loss_scalings: 10737.418945, pp_loss: 6.584949
[INFO] 2021-07-12 18:56:48,445 [run_pretraining.py:  512]:	********exe.run_1297******* 
[INFO] 2021-07-12 18:56:49,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:49,345 [run_pretraining.py:  534]:	loss/total_loss, 7.728603839874268, 1298
[INFO] 2021-07-12 18:56:49,345 [run_pretraining.py:  535]:	loss/mlm_loss, 7.728603839874268, 1298
[INFO] 2021-07-12 18:56:49,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2970000170753337e-05, 1298
[INFO] 2021-07-12 18:56:49,345 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1298
[INFO] 2021-07-12 18:56:49,345 [run_pretraining.py:  558]:	worker_index: 7, step: 1298, cost: 7.728604, mlm loss: 7.728604, speed: 1.111632 steps/s, speed: 8.893053 samples/s, speed: 4553.243186 tokens/s, learning rate: 1.297e-05, loss_scalings: 10737.418945, pp_loss: 7.713132
[INFO] 2021-07-12 18:56:49,345 [run_pretraining.py:  512]:	********exe.run_1298******* 
[INFO] 2021-07-12 18:56:50,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:50,247 [run_pretraining.py:  534]:	loss/total_loss, 6.52945613861084, 1299
[INFO] 2021-07-12 18:56:50,248 [run_pretraining.py:  535]:	loss/mlm_loss, 6.52945613861084, 1299
[INFO] 2021-07-12 18:56:50,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.298000006499933e-05, 1299
[INFO] 2021-07-12 18:56:50,248 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1299
[INFO] 2021-07-12 18:56:50,248 [run_pretraining.py:  558]:	worker_index: 7, step: 1299, cost: 6.529456, mlm loss: 6.529456, speed: 1.108985 steps/s, speed: 8.871879 samples/s, speed: 4542.402162 tokens/s, learning rate: 1.298e-05, loss_scalings: 10737.418945, pp_loss: 7.348037
[INFO] 2021-07-12 18:56:50,248 [run_pretraining.py:  512]:	********exe.run_1299******* 
[INFO] 2021-07-12 18:56:51,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:51,235 [run_pretraining.py:  534]:	loss/total_loss, 7.315422058105469, 1300
[INFO] 2021-07-12 18:56:51,235 [run_pretraining.py:  535]:	loss/mlm_loss, 7.315422058105469, 1300
[INFO] 2021-07-12 18:56:51,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2989999049750622e-05, 1300
[INFO] 2021-07-12 18:56:51,235 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1300
[INFO] 2021-07-12 18:56:51,235 [run_pretraining.py:  558]:	worker_index: 7, step: 1300, cost: 7.315422, mlm loss: 7.315422, speed: 1.013771 steps/s, speed: 8.110166 samples/s, speed: 4152.404856 tokens/s, learning rate: 1.299e-05, loss_scalings: 10737.418945, pp_loss: 7.661987
[INFO] 2021-07-12 18:56:51,235 [run_pretraining.py:  512]:	********exe.run_1300******* 
[INFO] 2021-07-12 18:56:52,160 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:52,161 [run_pretraining.py:  534]:	loss/total_loss, 7.111245155334473, 1301
[INFO] 2021-07-12 18:56:52,161 [run_pretraining.py:  535]:	loss/mlm_loss, 7.111245155334473, 1301
[INFO] 2021-07-12 18:56:52,161 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.2999998943996616e-05, 1301
[INFO] 2021-07-12 18:56:52,161 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1301
[INFO] 2021-07-12 18:56:52,161 [run_pretraining.py:  558]:	worker_index: 7, step: 1301, cost: 7.111245, mlm loss: 7.111245, speed: 1.080387 steps/s, speed: 8.643095 samples/s, speed: 4425.264793 tokens/s, learning rate: 1.300e-05, loss_scalings: 10737.418945, pp_loss: 7.737698
[INFO] 2021-07-12 18:56:52,161 [run_pretraining.py:  512]:	********exe.run_1301******* 
[INFO] 2021-07-12 18:56:53,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:53,066 [run_pretraining.py:  534]:	loss/total_loss, 4.411172389984131, 1302
[INFO] 2021-07-12 18:56:53,066 [run_pretraining.py:  535]:	loss/mlm_loss, 4.411172389984131, 1302
[INFO] 2021-07-12 18:56:53,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.300999974773731e-05, 1302
[INFO] 2021-07-12 18:56:53,067 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1302
[INFO] 2021-07-12 18:56:53,067 [run_pretraining.py:  558]:	worker_index: 7, step: 1302, cost: 4.411172, mlm loss: 4.411172, speed: 1.105094 steps/s, speed: 8.840751 samples/s, speed: 4526.464258 tokens/s, learning rate: 1.301e-05, loss_scalings: 10737.418945, pp_loss: 6.709286
[INFO] 2021-07-12 18:56:53,067 [run_pretraining.py:  512]:	********exe.run_1302******* 
[INFO] 2021-07-12 18:56:53,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  534]:	loss/total_loss, 7.376218795776367, 1303
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  535]:	loss/mlm_loss, 7.376218795776367, 1303
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3019999641983304e-05, 1303
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1303
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  558]:	worker_index: 7, step: 1303, cost: 7.376219, mlm loss: 7.376219, speed: 1.112783 steps/s, speed: 8.902262 samples/s, speed: 4557.958057 tokens/s, learning rate: 1.302e-05, loss_scalings: 10737.418945, pp_loss: 6.697296
[INFO] 2021-07-12 18:56:53,966 [run_pretraining.py:  512]:	********exe.run_1303******* 
[INFO] 2021-07-12 18:56:54,863 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:54,864 [run_pretraining.py:  534]:	loss/total_loss, 7.043033599853516, 1304
[INFO] 2021-07-12 18:56:54,864 [run_pretraining.py:  535]:	loss/mlm_loss, 7.043033599853516, 1304
[INFO] 2021-07-12 18:56:54,864 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3029999536229298e-05, 1304
[INFO] 2021-07-12 18:56:54,864 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1304
[INFO] 2021-07-12 18:56:54,864 [run_pretraining.py:  558]:	worker_index: 7, step: 1304, cost: 7.043034, mlm loss: 7.043034, speed: 1.113915 steps/s, speed: 8.911319 samples/s, speed: 4562.595458 tokens/s, learning rate: 1.303e-05, loss_scalings: 10737.418945, pp_loss: 7.164588
[INFO] 2021-07-12 18:56:54,864 [run_pretraining.py:  512]:	********exe.run_1304******* 
[INFO] 2021-07-12 18:56:55,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:55,784 [run_pretraining.py:  534]:	loss/total_loss, 7.879110336303711, 1305
[INFO] 2021-07-12 18:56:55,784 [run_pretraining.py:  535]:	loss/mlm_loss, 7.879110336303711, 1305
[INFO] 2021-07-12 18:56:55,784 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3039999430475291e-05, 1305
[INFO] 2021-07-12 18:56:55,784 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1305
[INFO] 2021-07-12 18:56:55,784 [run_pretraining.py:  558]:	worker_index: 7, step: 1305, cost: 7.879110, mlm loss: 7.879110, speed: 1.087761 steps/s, speed: 8.702085 samples/s, speed: 4455.467724 tokens/s, learning rate: 1.304e-05, loss_scalings: 10737.418945, pp_loss: 6.949772
[INFO] 2021-07-12 18:56:55,784 [run_pretraining.py:  512]:	********exe.run_1305******* 
[INFO] 2021-07-12 18:56:56,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:56,679 [run_pretraining.py:  534]:	loss/total_loss, 6.818547248840332, 1306
[INFO] 2021-07-12 18:56:56,679 [run_pretraining.py:  535]:	loss/mlm_loss, 6.818547248840332, 1306
[INFO] 2021-07-12 18:56:56,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3050000234215986e-05, 1306
[INFO] 2021-07-12 18:56:56,679 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1306
[INFO] 2021-07-12 18:56:56,679 [run_pretraining.py:  558]:	worker_index: 7, step: 1306, cost: 6.818547, mlm loss: 6.818547, speed: 1.118386 steps/s, speed: 8.947087 samples/s, speed: 4580.908766 tokens/s, learning rate: 1.305e-05, loss_scalings: 10737.418945, pp_loss: 7.381540
[INFO] 2021-07-12 18:56:56,679 [run_pretraining.py:  512]:	********exe.run_1306******* 
[INFO] 2021-07-12 18:56:57,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:57,608 [run_pretraining.py:  534]:	loss/total_loss, 7.722618579864502, 1307
[INFO] 2021-07-12 18:56:57,608 [run_pretraining.py:  535]:	loss/mlm_loss, 7.722618579864502, 1307
[INFO] 2021-07-12 18:56:57,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.306000012846198e-05, 1307
[INFO] 2021-07-12 18:56:57,608 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1307
[INFO] 2021-07-12 18:56:57,608 [run_pretraining.py:  558]:	worker_index: 7, step: 1307, cost: 7.722619, mlm loss: 7.722619, speed: 1.077322 steps/s, speed: 8.618575 samples/s, speed: 4412.710548 tokens/s, learning rate: 1.306e-05, loss_scalings: 10737.418945, pp_loss: 7.661860
[INFO] 2021-07-12 18:56:57,608 [run_pretraining.py:  512]:	********exe.run_1307******* 
[INFO] 2021-07-12 18:56:58,524 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:58,524 [run_pretraining.py:  534]:	loss/total_loss, 7.623012542724609, 1308
[INFO] 2021-07-12 18:56:58,525 [run_pretraining.py:  535]:	loss/mlm_loss, 7.623012542724609, 1308
[INFO] 2021-07-12 18:56:58,525 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3070000022707973e-05, 1308
[INFO] 2021-07-12 18:56:58,525 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1308
[INFO] 2021-07-12 18:56:58,525 [run_pretraining.py:  558]:	worker_index: 7, step: 1308, cost: 7.623013, mlm loss: 7.623013, speed: 1.091443 steps/s, speed: 8.731546 samples/s, speed: 4470.551561 tokens/s, learning rate: 1.307e-05, loss_scalings: 10737.418945, pp_loss: 7.510625
[INFO] 2021-07-12 18:56:58,525 [run_pretraining.py:  512]:	********exe.run_1308******* 
[INFO] 2021-07-12 18:56:59,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:56:59,502 [run_pretraining.py:  534]:	loss/total_loss, 7.564455986022949, 1309
[INFO] 2021-07-12 18:56:59,502 [run_pretraining.py:  535]:	loss/mlm_loss, 7.564455986022949, 1309
[INFO] 2021-07-12 18:56:59,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3079999007459264e-05, 1309
[INFO] 2021-07-12 18:56:59,502 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1309
[INFO] 2021-07-12 18:56:59,502 [run_pretraining.py:  558]:	worker_index: 7, step: 1309, cost: 7.564456, mlm loss: 7.564456, speed: 1.023699 steps/s, speed: 8.189593 samples/s, speed: 4193.071466 tokens/s, learning rate: 1.308e-05, loss_scalings: 10737.418945, pp_loss: 7.432516
[INFO] 2021-07-12 18:56:59,502 [run_pretraining.py:  512]:	********exe.run_1309******* 
[INFO] 2021-07-12 18:57:00,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:00,563 [run_pretraining.py:  534]:	loss/total_loss, 7.725957870483398, 1310
[INFO] 2021-07-12 18:57:00,563 [run_pretraining.py:  535]:	loss/mlm_loss, 7.725957870483398, 1310
[INFO] 2021-07-12 18:57:00,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3089998901705258e-05, 1310
[INFO] 2021-07-12 18:57:00,563 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1310
[INFO] 2021-07-12 18:57:00,563 [run_pretraining.py:  558]:	worker_index: 7, step: 1310, cost: 7.725958, mlm loss: 7.725958, speed: 0.943391 steps/s, speed: 7.547124 samples/s, speed: 3864.127685 tokens/s, learning rate: 1.309e-05, loss_scalings: 10737.418945, pp_loss: 7.541960
[INFO] 2021-07-12 18:57:00,563 [run_pretraining.py:  512]:	********exe.run_1310******* 
[INFO] 2021-07-12 18:57:28,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:28,156 [run_pretraining.py:  534]:	loss/total_loss, 4.750819206237793, 1311
[INFO] 2021-07-12 18:57:28,156 [run_pretraining.py:  535]:	loss/mlm_loss, 4.750819206237793, 1311
[INFO] 2021-07-12 18:57:28,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3099999705445953e-05, 1311
[INFO] 2021-07-12 18:57:28,156 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1311
[INFO] 2021-07-12 18:57:28,156 [run_pretraining.py:  558]:	worker_index: 7, step: 1311, cost: 4.750819, mlm loss: 4.750819, speed: 0.036242 steps/s, speed: 0.289933 samples/s, speed: 148.445945 tokens/s, learning rate: 1.310e-05, loss_scalings: 10737.418945, pp_loss: 7.065324
[INFO] 2021-07-12 18:57:28,156 [run_pretraining.py:  512]:	********exe.run_1311******* 
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  534]:	loss/total_loss, 7.21536922454834, 1312
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  535]:	loss/mlm_loss, 7.21536922454834, 1312
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3109999599691946e-05, 1312
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1312
[INFO] 2021-07-12 18:57:56,319 [run_pretraining.py:  558]:	worker_index: 7, step: 1312, cost: 7.215369, mlm loss: 7.215369, speed: 0.035508 steps/s, speed: 0.284065 samples/s, speed: 145.441043 tokens/s, learning rate: 1.311e-05, loss_scalings: 10737.418945, pp_loss: 7.575103
[INFO] 2021-07-12 18:57:56,320 [run_pretraining.py:  512]:	********exe.run_1312******* 
[INFO] 2021-07-12 18:57:57,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:57,262 [run_pretraining.py:  534]:	loss/total_loss, 7.432494163513184, 1313
[INFO] 2021-07-12 18:57:57,262 [run_pretraining.py:  535]:	loss/mlm_loss, 7.432494163513184, 1313
[INFO] 2021-07-12 18:57:57,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.311999949393794e-05, 1313
[INFO] 2021-07-12 18:57:57,262 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1313
[INFO] 2021-07-12 18:57:57,262 [run_pretraining.py:  558]:	worker_index: 7, step: 1313, cost: 7.432494, mlm loss: 7.432494, speed: 1.061890 steps/s, speed: 8.495118 samples/s, speed: 4349.500243 tokens/s, learning rate: 1.312e-05, loss_scalings: 10737.418945, pp_loss: 7.528549
[INFO] 2021-07-12 18:57:57,262 [run_pretraining.py:  512]:	********exe.run_1313******* 
[INFO] 2021-07-12 18:57:58,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:58,182 [run_pretraining.py:  534]:	loss/total_loss, 7.178449630737305, 1314
[INFO] 2021-07-12 18:57:58,182 [run_pretraining.py:  535]:	loss/mlm_loss, 7.178449630737305, 1314
[INFO] 2021-07-12 18:57:58,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3130000297678635e-05, 1314
[INFO] 2021-07-12 18:57:58,182 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1314
[INFO] 2021-07-12 18:57:58,182 [run_pretraining.py:  558]:	worker_index: 7, step: 1314, cost: 7.178450, mlm loss: 7.178450, speed: 1.087024 steps/s, speed: 8.696192 samples/s, speed: 4452.450469 tokens/s, learning rate: 1.313e-05, loss_scalings: 10737.418945, pp_loss: 7.526252
[INFO] 2021-07-12 18:57:58,183 [run_pretraining.py:  512]:	********exe.run_1314******* 
[INFO] 2021-07-12 18:57:59,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  534]:	loss/total_loss, 7.052460670471191, 1315
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  535]:	loss/mlm_loss, 7.052460670471191, 1315
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3140000191924628e-05, 1315
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1315
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  558]:	worker_index: 7, step: 1315, cost: 7.052461, mlm loss: 7.052461, speed: 1.045743 steps/s, speed: 8.365947 samples/s, speed: 4283.364732 tokens/s, learning rate: 1.314e-05, loss_scalings: 10737.418945, pp_loss: 7.385815
[INFO] 2021-07-12 18:57:59,139 [run_pretraining.py:  512]:	********exe.run_1315******* 
[INFO] 2021-07-12 18:58:00,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:00,202 [run_pretraining.py:  534]:	loss/total_loss, 7.456424713134766, 1316
[INFO] 2021-07-12 18:58:00,202 [run_pretraining.py:  535]:	loss/mlm_loss, 7.456424713134766, 1316
[INFO] 2021-07-12 18:58:00,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3150000086170621e-05, 1316
[INFO] 2021-07-12 18:58:00,202 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1316
[INFO] 2021-07-12 18:58:00,202 [run_pretraining.py:  558]:	worker_index: 7, step: 1316, cost: 7.456425, mlm loss: 7.456425, speed: 0.941650 steps/s, speed: 7.533203 samples/s, speed: 3857.000112 tokens/s, learning rate: 1.315e-05, loss_scalings: 10737.418945, pp_loss: 7.529744
[INFO] 2021-07-12 18:58:00,202 [run_pretraining.py:  512]:	********exe.run_1316******* 
[INFO] 2021-07-12 18:58:01,260 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:01,261 [run_pretraining.py:  534]:	loss/total_loss, 7.644759178161621, 1317
[INFO] 2021-07-12 18:58:01,261 [run_pretraining.py:  535]:	loss/mlm_loss, 7.644759178161621, 1317
[INFO] 2021-07-12 18:58:01,261 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3159999980416615e-05, 1317
[INFO] 2021-07-12 18:58:01,261 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1317
[INFO] 2021-07-12 18:58:01,261 [run_pretraining.py:  558]:	worker_index: 7, step: 1317, cost: 7.644759, mlm loss: 7.644759, speed: 0.944939 steps/s, speed: 7.559514 samples/s, speed: 3870.471409 tokens/s, learning rate: 1.316e-05, loss_scalings: 10737.418945, pp_loss: 7.654364
[INFO] 2021-07-12 18:58:01,261 [run_pretraining.py:  512]:	********exe.run_1317******* 
[INFO] 2021-07-12 18:58:02,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:02,347 [run_pretraining.py:  534]:	loss/total_loss, 7.428374767303467, 1318
[INFO] 2021-07-12 18:58:02,347 [run_pretraining.py:  535]:	loss/mlm_loss, 7.428374767303467, 1318
[INFO] 2021-07-12 18:58:02,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3169998965167906e-05, 1318
[INFO] 2021-07-12 18:58:02,347 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1318
[INFO] 2021-07-12 18:58:02,347 [run_pretraining.py:  558]:	worker_index: 7, step: 1318, cost: 7.428375, mlm loss: 7.428375, speed: 0.920936 steps/s, speed: 7.367490 samples/s, speed: 3772.155088 tokens/s, learning rate: 1.317e-05, loss_scalings: 10737.418945, pp_loss: 7.588007
[INFO] 2021-07-12 18:58:02,348 [run_pretraining.py:  512]:	********exe.run_1318******* 
[INFO] 2021-07-12 18:58:03,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:03,412 [run_pretraining.py:  534]:	loss/total_loss, 8.49468994140625, 1319
[INFO] 2021-07-12 18:58:03,412 [run_pretraining.py:  535]:	loss/mlm_loss, 8.49468994140625, 1319
[INFO] 2021-07-12 18:58:03,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.31799988594139e-05, 1319
[INFO] 2021-07-12 18:58:03,412 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1319
[INFO] 2021-07-12 18:58:03,412 [run_pretraining.py:  558]:	worker_index: 7, step: 1319, cost: 8.494690, mlm loss: 8.494690, speed: 0.939521 steps/s, speed: 7.516165 samples/s, speed: 3848.276659 tokens/s, learning rate: 1.318e-05, loss_scalings: 10737.418945, pp_loss: 7.873854
[INFO] 2021-07-12 18:58:03,413 [run_pretraining.py:  512]:	********exe.run_1319******* 
[INFO] 2021-07-12 18:58:04,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:04,483 [run_pretraining.py:  534]:	loss/total_loss, 7.713336944580078, 1320
[INFO] 2021-07-12 18:58:04,483 [run_pretraining.py:  535]:	loss/mlm_loss, 7.713336944580078, 1320
[INFO] 2021-07-12 18:58:04,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3189999663154595e-05, 1320
[INFO] 2021-07-12 18:58:04,484 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1320
[INFO] 2021-07-12 18:58:04,484 [run_pretraining.py:  558]:	worker_index: 7, step: 1320, cost: 7.713337, mlm loss: 7.713337, speed: 0.934131 steps/s, speed: 7.473049 samples/s, speed: 3826.201211 tokens/s, learning rate: 1.319e-05, loss_scalings: 10737.418945, pp_loss: 7.630930
[INFO] 2021-07-12 18:58:04,484 [run_pretraining.py:  512]:	********exe.run_1320******* 
[INFO] 2021-07-12 18:58:05,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:05,535 [run_pretraining.py:  534]:	loss/total_loss, 7.490828990936279, 1321
[INFO] 2021-07-12 18:58:05,535 [run_pretraining.py:  535]:	loss/mlm_loss, 7.490828990936279, 1321
[INFO] 2021-07-12 18:58:05,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3199999557400588e-05, 1321
[INFO] 2021-07-12 18:58:05,535 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1321
[INFO] 2021-07-12 18:58:05,535 [run_pretraining.py:  558]:	worker_index: 7, step: 1321, cost: 7.490829, mlm loss: 7.490829, speed: 0.951651 steps/s, speed: 7.613207 samples/s, speed: 3897.961832 tokens/s, learning rate: 1.320e-05, loss_scalings: 10737.418945, pp_loss: 7.431782
[INFO] 2021-07-12 18:58:05,535 [run_pretraining.py:  512]:	********exe.run_1321******* 
[INFO] 2021-07-12 18:58:06,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:06,593 [run_pretraining.py:  534]:	loss/total_loss, 7.940947532653809, 1322
[INFO] 2021-07-12 18:58:06,593 [run_pretraining.py:  535]:	loss/mlm_loss, 7.940947532653809, 1322
[INFO] 2021-07-12 18:58:06,593 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3209999451646581e-05, 1322
[INFO] 2021-07-12 18:58:06,594 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1322
[INFO] 2021-07-12 18:58:06,594 [run_pretraining.py:  558]:	worker_index: 7, step: 1322, cost: 7.940948, mlm loss: 7.940948, speed: 0.945259 steps/s, speed: 7.562072 samples/s, speed: 3871.780698 tokens/s, learning rate: 1.321e-05, loss_scalings: 10737.418945, pp_loss: 7.215353
[INFO] 2021-07-12 18:58:06,594 [run_pretraining.py:  512]:	********exe.run_1322******* 
[INFO] 2021-07-12 18:58:07,657 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:07,657 [run_pretraining.py:  534]:	loss/total_loss, 6.8739118576049805, 1323
[INFO] 2021-07-12 18:58:07,657 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8739118576049805, 1323
[INFO] 2021-07-12 18:58:07,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3220000255387276e-05, 1323
[INFO] 2021-07-12 18:58:07,658 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1323
[INFO] 2021-07-12 18:58:07,658 [run_pretraining.py:  558]:	worker_index: 7, step: 1323, cost: 6.873912, mlm loss: 6.873912, speed: 0.940430 steps/s, speed: 7.523444 samples/s, speed: 3852.003289 tokens/s, learning rate: 1.322e-05, loss_scalings: 10737.418945, pp_loss: 7.196652
[INFO] 2021-07-12 18:58:07,658 [run_pretraining.py:  512]:	********exe.run_1323******* 
[INFO] 2021-07-12 18:58:08,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:08,717 [run_pretraining.py:  534]:	loss/total_loss, 5.960448741912842, 1324
[INFO] 2021-07-12 18:58:08,717 [run_pretraining.py:  535]:	loss/mlm_loss, 5.960448741912842, 1324
[INFO] 2021-07-12 18:58:08,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.323000014963327e-05, 1324
[INFO] 2021-07-12 18:58:08,717 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1324
[INFO] 2021-07-12 18:58:08,717 [run_pretraining.py:  558]:	worker_index: 7, step: 1324, cost: 5.960449, mlm loss: 5.960449, speed: 0.944299 steps/s, speed: 7.554392 samples/s, speed: 3867.848520 tokens/s, learning rate: 1.323e-05, loss_scalings: 10737.418945, pp_loss: 6.878419
[INFO] 2021-07-12 18:58:08,717 [run_pretraining.py:  512]:	********exe.run_1324******* 
[INFO] 2021-07-12 18:58:09,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:09,775 [run_pretraining.py:  534]:	loss/total_loss, 7.059220314025879, 1325
[INFO] 2021-07-12 18:58:09,775 [run_pretraining.py:  535]:	loss/mlm_loss, 7.059220314025879, 1325
[INFO] 2021-07-12 18:58:09,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3240000043879263e-05, 1325
[INFO] 2021-07-12 18:58:09,775 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1325
[INFO] 2021-07-12 18:58:09,775 [run_pretraining.py:  558]:	worker_index: 7, step: 1325, cost: 7.059220, mlm loss: 7.059220, speed: 0.945698 steps/s, speed: 7.565581 samples/s, speed: 3873.577286 tokens/s, learning rate: 1.324e-05, loss_scalings: 10737.418945, pp_loss: 7.412869
[INFO] 2021-07-12 18:58:09,775 [run_pretraining.py:  512]:	********exe.run_1325******* 
[INFO] 2021-07-12 18:58:10,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:10,837 [run_pretraining.py:  534]:	loss/total_loss, 7.617036819458008, 1326
[INFO] 2021-07-12 18:58:10,837 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617036819458008, 1326
[INFO] 2021-07-12 18:58:10,837 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3249999028630555e-05, 1326
[INFO] 2021-07-12 18:58:10,837 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1326
[INFO] 2021-07-12 18:58:10,837 [run_pretraining.py:  558]:	worker_index: 7, step: 1326, cost: 7.617037, mlm loss: 7.617037, speed: 0.942194 steps/s, speed: 7.537552 samples/s, speed: 3859.226820 tokens/s, learning rate: 1.325e-05, loss_scalings: 10737.418945, pp_loss: 7.625592
[INFO] 2021-07-12 18:58:10,837 [run_pretraining.py:  512]:	********exe.run_1326******* 
[INFO] 2021-07-12 18:58:11,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:11,895 [run_pretraining.py:  534]:	loss/total_loss, 8.07829475402832, 1327
[INFO] 2021-07-12 18:58:11,895 [run_pretraining.py:  535]:	loss/mlm_loss, 8.07829475402832, 1327
[INFO] 2021-07-12 18:58:11,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3259998922876548e-05, 1327
[INFO] 2021-07-12 18:58:11,895 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1327
[INFO] 2021-07-12 18:58:11,895 [run_pretraining.py:  558]:	worker_index: 7, step: 1327, cost: 8.078295, mlm loss: 8.078295, speed: 0.946029 steps/s, speed: 7.568231 samples/s, speed: 3874.934124 tokens/s, learning rate: 1.326e-05, loss_scalings: 10737.418945, pp_loss: 7.797238
[INFO] 2021-07-12 18:58:11,895 [run_pretraining.py:  512]:	********exe.run_1327******* 
[INFO] 2021-07-12 18:58:12,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:12,974 [run_pretraining.py:  534]:	loss/total_loss, 7.631850719451904, 1328
[INFO] 2021-07-12 18:58:12,974 [run_pretraining.py:  535]:	loss/mlm_loss, 7.631850719451904, 1328
[INFO] 2021-07-12 18:58:12,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3269999726617243e-05, 1328
[INFO] 2021-07-12 18:58:12,974 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1328
[INFO] 2021-07-12 18:58:12,974 [run_pretraining.py:  558]:	worker_index: 7, step: 1328, cost: 7.631851, mlm loss: 7.631851, speed: 0.927129 steps/s, speed: 7.417036 samples/s, speed: 3797.522260 tokens/s, learning rate: 1.327e-05, loss_scalings: 10737.418945, pp_loss: 7.375474
[INFO] 2021-07-12 18:58:12,974 [run_pretraining.py:  512]:	********exe.run_1328******* 
[INFO] 2021-07-12 18:58:14,055 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:14,056 [run_pretraining.py:  534]:	loss/total_loss, 7.438148498535156, 1329
[INFO] 2021-07-12 18:58:14,056 [run_pretraining.py:  535]:	loss/mlm_loss, 7.438148498535156, 1329
[INFO] 2021-07-12 18:58:14,056 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3279999620863236e-05, 1329
[INFO] 2021-07-12 18:58:14,056 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1329
[INFO] 2021-07-12 18:58:14,056 [run_pretraining.py:  558]:	worker_index: 7, step: 1329, cost: 7.438148, mlm loss: 7.438148, speed: 0.924959 steps/s, speed: 7.399673 samples/s, speed: 3788.632645 tokens/s, learning rate: 1.328e-05, loss_scalings: 10737.418945, pp_loss: 7.511230
[INFO] 2021-07-12 18:58:14,056 [run_pretraining.py:  512]:	********exe.run_1329******* 
[INFO] 2021-07-12 18:58:15,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:15,117 [run_pretraining.py:  534]:	loss/total_loss, 6.607693672180176, 1330
[INFO] 2021-07-12 18:58:15,117 [run_pretraining.py:  535]:	loss/mlm_loss, 6.607693672180176, 1330
[INFO] 2021-07-12 18:58:15,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.328999951510923e-05, 1330
[INFO] 2021-07-12 18:58:15,117 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1330
[INFO] 2021-07-12 18:58:15,117 [run_pretraining.py:  558]:	worker_index: 7, step: 1330, cost: 6.607694, mlm loss: 6.607694, speed: 0.942839 steps/s, speed: 7.542708 samples/s, speed: 3861.866672 tokens/s, learning rate: 1.329e-05, loss_scalings: 10737.418945, pp_loss: 7.264815
[INFO] 2021-07-12 18:58:15,117 [run_pretraining.py:  512]:	********exe.run_1330******* 
[INFO] 2021-07-12 18:58:16,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:16,178 [run_pretraining.py:  534]:	loss/total_loss, 7.276554584503174, 1331
[INFO] 2021-07-12 18:58:16,178 [run_pretraining.py:  535]:	loss/mlm_loss, 7.276554584503174, 1331
[INFO] 2021-07-12 18:58:16,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3299999409355223e-05, 1331
[INFO] 2021-07-12 18:58:16,178 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1331
[INFO] 2021-07-12 18:58:16,178 [run_pretraining.py:  558]:	worker_index: 7, step: 1331, cost: 7.276555, mlm loss: 7.276555, speed: 0.943186 steps/s, speed: 7.545487 samples/s, speed: 3863.289160 tokens/s, learning rate: 1.330e-05, loss_scalings: 10737.418945, pp_loss: 7.403219
[INFO] 2021-07-12 18:58:16,178 [run_pretraining.py:  512]:	********exe.run_1331******* 
[INFO] 2021-07-12 18:58:17,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:17,244 [run_pretraining.py:  534]:	loss/total_loss, 7.484142303466797, 1332
[INFO] 2021-07-12 18:58:17,244 [run_pretraining.py:  535]:	loss/mlm_loss, 7.484142303466797, 1332
[INFO] 2021-07-12 18:58:17,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3310000213095918e-05, 1332
[INFO] 2021-07-12 18:58:17,244 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1332
[INFO] 2021-07-12 18:58:17,244 [run_pretraining.py:  558]:	worker_index: 7, step: 1332, cost: 7.484142, mlm loss: 7.484142, speed: 0.938841 steps/s, speed: 7.510730 samples/s, speed: 3845.493516 tokens/s, learning rate: 1.331e-05, loss_scalings: 10737.418945, pp_loss: 7.420828
[INFO] 2021-07-12 18:58:17,244 [run_pretraining.py:  512]:	********exe.run_1332******* 
[INFO] 2021-07-12 18:58:18,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:18,301 [run_pretraining.py:  534]:	loss/total_loss, 5.781955242156982, 1333
[INFO] 2021-07-12 18:58:18,301 [run_pretraining.py:  535]:	loss/mlm_loss, 5.781955242156982, 1333
[INFO] 2021-07-12 18:58:18,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3320000107341912e-05, 1333
[INFO] 2021-07-12 18:58:18,301 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1333
[INFO] 2021-07-12 18:58:18,302 [run_pretraining.py:  558]:	worker_index: 7, step: 1333, cost: 5.781955, mlm loss: 5.781955, speed: 0.946150 steps/s, speed: 7.569204 samples/s, speed: 3875.432365 tokens/s, learning rate: 1.332e-05, loss_scalings: 10737.418945, pp_loss: 7.200096
[INFO] 2021-07-12 18:58:18,302 [run_pretraining.py:  512]:	********exe.run_1333******* 
[INFO] 2021-07-12 18:58:47,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:47,368 [run_pretraining.py:  534]:	loss/total_loss, 7.7940473556518555, 1334
[INFO] 2021-07-12 18:58:47,368 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7940473556518555, 1334
[INFO] 2021-07-12 18:58:47,368 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3330000001587905e-05, 1334
[INFO] 2021-07-12 18:58:47,368 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1334
[INFO] 2021-07-12 18:58:47,368 [run_pretraining.py:  558]:	worker_index: 7, step: 1334, cost: 7.794047, mlm loss: 7.794047, speed: 0.034404 steps/s, speed: 0.275234 samples/s, speed: 140.919644 tokens/s, learning rate: 1.333e-05, loss_scalings: 10737.418945, pp_loss: 8.047908
[INFO] 2021-07-12 18:58:47,369 [run_pretraining.py:  512]:	********exe.run_1334******* 
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  534]:	loss/total_loss, 9.438514709472656, 1335
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  535]:	loss/mlm_loss, 9.438514709472656, 1335
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3339998986339197e-05, 1335
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1335
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  558]:	worker_index: 7, step: 1335, cost: 9.438515, mlm loss: 9.438515, speed: 1.124480 steps/s, speed: 8.995843 samples/s, speed: 4605.871696 tokens/s, learning rate: 1.334e-05, loss_scalings: 10737.418945, pp_loss: 8.038300
[INFO] 2021-07-12 18:58:48,258 [run_pretraining.py:  512]:	********exe.run_1335******* 
[INFO] 2021-07-12 18:58:49,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:49,157 [run_pretraining.py:  534]:	loss/total_loss, 7.59680700302124, 1336
[INFO] 2021-07-12 18:58:49,157 [run_pretraining.py:  535]:	loss/mlm_loss, 7.59680700302124, 1336
[INFO] 2021-07-12 18:58:49,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.334999888058519e-05, 1336
[INFO] 2021-07-12 18:58:49,157 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1336
[INFO] 2021-07-12 18:58:49,157 [run_pretraining.py:  558]:	worker_index: 7, step: 1336, cost: 7.596807, mlm loss: 7.596807, speed: 1.113213 steps/s, speed: 8.905702 samples/s, speed: 4559.719425 tokens/s, learning rate: 1.335e-05, loss_scalings: 10737.418945, pp_loss: 7.597977
[INFO] 2021-07-12 18:58:49,157 [run_pretraining.py:  512]:	********exe.run_1336******* 
[INFO] 2021-07-12 18:58:50,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:50,061 [run_pretraining.py:  534]:	loss/total_loss, 7.1700544357299805, 1337
[INFO] 2021-07-12 18:58:50,061 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1700544357299805, 1337
[INFO] 2021-07-12 18:58:50,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3359999684325885e-05, 1337
[INFO] 2021-07-12 18:58:50,061 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1337
[INFO] 2021-07-12 18:58:50,061 [run_pretraining.py:  558]:	worker_index: 7, step: 1337, cost: 7.170054, mlm loss: 7.170054, speed: 1.107471 steps/s, speed: 8.859766 samples/s, speed: 4536.200152 tokens/s, learning rate: 1.336e-05, loss_scalings: 10737.418945, pp_loss: 7.328346
[INFO] 2021-07-12 18:58:50,061 [run_pretraining.py:  512]:	********exe.run_1337******* 
[INFO] 2021-07-12 18:58:50,961 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:50,962 [run_pretraining.py:  534]:	loss/total_loss, 7.810788154602051, 1338
[INFO] 2021-07-12 18:58:50,962 [run_pretraining.py:  535]:	loss/mlm_loss, 7.810788154602051, 1338
[INFO] 2021-07-12 18:58:50,962 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3369999578571878e-05, 1338
[INFO] 2021-07-12 18:58:50,962 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1338
[INFO] 2021-07-12 18:58:50,962 [run_pretraining.py:  558]:	worker_index: 7, step: 1338, cost: 7.810788, mlm loss: 7.810788, speed: 1.110662 steps/s, speed: 8.885294 samples/s, speed: 4549.270373 tokens/s, learning rate: 1.337e-05, loss_scalings: 10737.418945, pp_loss: 7.617195
[INFO] 2021-07-12 18:58:50,962 [run_pretraining.py:  512]:	********exe.run_1338******* 
[INFO] 2021-07-12 18:58:51,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:51,858 [run_pretraining.py:  534]:	loss/total_loss, 7.696559906005859, 1339
[INFO] 2021-07-12 18:58:51,859 [run_pretraining.py:  535]:	loss/mlm_loss, 7.696559906005859, 1339
[INFO] 2021-07-12 18:58:51,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3379999472817872e-05, 1339
[INFO] 2021-07-12 18:58:51,859 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1339
[INFO] 2021-07-12 18:58:51,859 [run_pretraining.py:  558]:	worker_index: 7, step: 1339, cost: 7.696560, mlm loss: 7.696560, speed: 1.115873 steps/s, speed: 8.926986 samples/s, speed: 4570.616613 tokens/s, learning rate: 1.338e-05, loss_scalings: 10737.418945, pp_loss: 7.528389
[INFO] 2021-07-12 18:58:51,859 [run_pretraining.py:  512]:	********exe.run_1339******* 
[INFO] 2021-07-12 18:58:52,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:52,776 [run_pretraining.py:  534]:	loss/total_loss, 6.9783430099487305, 1340
[INFO] 2021-07-12 18:58:52,776 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9783430099487305, 1340
[INFO] 2021-07-12 18:58:52,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3390000276558567e-05, 1340
[INFO] 2021-07-12 18:58:52,776 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1340
[INFO] 2021-07-12 18:58:52,776 [run_pretraining.py:  558]:	worker_index: 7, step: 1340, cost: 6.978343, mlm loss: 6.978343, speed: 1.090643 steps/s, speed: 8.725148 samples/s, speed: 4467.275704 tokens/s, learning rate: 1.339e-05, loss_scalings: 10737.418945, pp_loss: 7.428185
[INFO] 2021-07-12 18:58:52,776 [run_pretraining.py:  512]:	********exe.run_1340******* 
[INFO] 2021-07-12 18:58:53,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:53,672 [run_pretraining.py:  534]:	loss/total_loss, 7.65011739730835, 1341
[INFO] 2021-07-12 18:58:53,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.65011739730835, 1341
[INFO] 2021-07-12 18:58:53,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.340000017080456e-05, 1341
[INFO] 2021-07-12 18:58:53,672 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1341
[INFO] 2021-07-12 18:58:53,672 [run_pretraining.py:  558]:	worker_index: 7, step: 1341, cost: 7.650117, mlm loss: 7.650117, speed: 1.117253 steps/s, speed: 8.938024 samples/s, speed: 4576.268215 tokens/s, learning rate: 1.340e-05, loss_scalings: 10737.418945, pp_loss: 7.104032
[INFO] 2021-07-12 18:58:53,672 [run_pretraining.py:  512]:	********exe.run_1341******* 
[INFO] 2021-07-12 18:58:54,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:54,570 [run_pretraining.py:  534]:	loss/total_loss, 7.329977989196777, 1342
[INFO] 2021-07-12 18:58:54,570 [run_pretraining.py:  535]:	loss/mlm_loss, 7.329977989196777, 1342
[INFO] 2021-07-12 18:58:54,570 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3410000065050554e-05, 1342
[INFO] 2021-07-12 18:58:54,570 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1342
[INFO] 2021-07-12 18:58:54,570 [run_pretraining.py:  558]:	worker_index: 7, step: 1342, cost: 7.329978, mlm loss: 7.329978, speed: 1.114078 steps/s, speed: 8.912623 samples/s, speed: 4563.263216 tokens/s, learning rate: 1.341e-05, loss_scalings: 10737.418945, pp_loss: 7.467090
[INFO] 2021-07-12 18:58:54,570 [run_pretraining.py:  512]:	********exe.run_1342******* 
[INFO] 2021-07-12 18:58:55,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:55,478 [run_pretraining.py:  534]:	loss/total_loss, 8.035634994506836, 1343
[INFO] 2021-07-12 18:58:55,478 [run_pretraining.py:  535]:	loss/mlm_loss, 8.035634994506836, 1343
[INFO] 2021-07-12 18:58:55,478 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3419999959296547e-05, 1343
[INFO] 2021-07-12 18:58:55,478 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1343
[INFO] 2021-07-12 18:58:55,479 [run_pretraining.py:  558]:	worker_index: 7, step: 1343, cost: 8.035635, mlm loss: 8.035635, speed: 1.101793 steps/s, speed: 8.814341 samples/s, speed: 4512.942415 tokens/s, learning rate: 1.342e-05, loss_scalings: 10737.418945, pp_loss: 7.740846
[INFO] 2021-07-12 18:58:55,479 [run_pretraining.py:  512]:	********exe.run_1343******* 
[INFO] 2021-07-12 18:58:56,381 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:56,381 [run_pretraining.py:  534]:	loss/total_loss, 7.5067925453186035, 1344
[INFO] 2021-07-12 18:58:56,381 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5067925453186035, 1344
[INFO] 2021-07-12 18:58:56,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3429998944047838e-05, 1344
[INFO] 2021-07-12 18:58:56,382 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1344
[INFO] 2021-07-12 18:58:56,382 [run_pretraining.py:  558]:	worker_index: 7, step: 1344, cost: 7.506793, mlm loss: 7.506793, speed: 1.108085 steps/s, speed: 8.864681 samples/s, speed: 4538.716813 tokens/s, learning rate: 1.343e-05, loss_scalings: 10737.418945, pp_loss: 7.465930
[INFO] 2021-07-12 18:58:56,382 [run_pretraining.py:  512]:	********exe.run_1344******* 
[INFO] 2021-07-12 18:58:57,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:57,284 [run_pretraining.py:  534]:	loss/total_loss, 5.101406574249268, 1345
[INFO] 2021-07-12 18:58:57,284 [run_pretraining.py:  535]:	loss/mlm_loss, 5.101406574249268, 1345
[INFO] 2021-07-12 18:58:57,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3439998838293832e-05, 1345
[INFO] 2021-07-12 18:58:57,284 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1345
[INFO] 2021-07-12 18:58:57,284 [run_pretraining.py:  558]:	worker_index: 7, step: 1345, cost: 5.101407, mlm loss: 5.101407, speed: 1.108393 steps/s, speed: 8.867146 samples/s, speed: 4539.978591 tokens/s, learning rate: 1.344e-05, loss_scalings: 10737.418945, pp_loss: 6.328462
[INFO] 2021-07-12 18:58:57,285 [run_pretraining.py:  512]:	********exe.run_1345******* 
[INFO] 2021-07-12 18:58:58,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:58,248 [run_pretraining.py:  534]:	loss/total_loss, 7.473835468292236, 1346
[INFO] 2021-07-12 18:58:58,249 [run_pretraining.py:  535]:	loss/mlm_loss, 7.473835468292236, 1346
[INFO] 2021-07-12 18:58:58,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3449999642034527e-05, 1346
[INFO] 2021-07-12 18:58:58,249 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1346
[INFO] 2021-07-12 18:58:58,249 [run_pretraining.py:  558]:	worker_index: 7, step: 1346, cost: 7.473835, mlm loss: 7.473835, speed: 1.037688 steps/s, speed: 8.301502 samples/s, speed: 4250.369234 tokens/s, learning rate: 1.345e-05, loss_scalings: 10737.418945, pp_loss: 7.560693
[INFO] 2021-07-12 18:58:58,249 [run_pretraining.py:  512]:	********exe.run_1346******* 
[INFO] 2021-07-12 18:58:59,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:58:59,303 [run_pretraining.py:  534]:	loss/total_loss, 7.2720441818237305, 1347
[INFO] 2021-07-12 18:58:59,303 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2720441818237305, 1347
[INFO] 2021-07-12 18:58:59,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.345999953628052e-05, 1347
[INFO] 2021-07-12 18:58:59,304 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1347
[INFO] 2021-07-12 18:58:59,304 [run_pretraining.py:  558]:	worker_index: 7, step: 1347, cost: 7.272044, mlm loss: 7.272044, speed: 0.948654 steps/s, speed: 7.589234 samples/s, speed: 3885.687800 tokens/s, learning rate: 1.346e-05, loss_scalings: 10737.418945, pp_loss: 7.526608
[INFO] 2021-07-12 18:58:59,304 [run_pretraining.py:  512]:	********exe.run_1347******* 
[INFO] 2021-07-12 18:59:00,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:00,357 [run_pretraining.py:  534]:	loss/total_loss, 7.309192657470703, 1348
[INFO] 2021-07-12 18:59:00,357 [run_pretraining.py:  535]:	loss/mlm_loss, 7.309192657470703, 1348
[INFO] 2021-07-12 18:59:00,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3469999430526514e-05, 1348
[INFO] 2021-07-12 18:59:00,357 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1348
[INFO] 2021-07-12 18:59:00,357 [run_pretraining.py:  558]:	worker_index: 7, step: 1348, cost: 7.309193, mlm loss: 7.309193, speed: 0.949835 steps/s, speed: 7.598683 samples/s, speed: 3890.525747 tokens/s, learning rate: 1.347e-05, loss_scalings: 10737.418945, pp_loss: 7.503404
[INFO] 2021-07-12 18:59:00,357 [run_pretraining.py:  512]:	********exe.run_1348******* 
[INFO] 2021-07-12 18:59:01,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:01,357 [run_pretraining.py:  534]:	loss/total_loss, 8.294443130493164, 1349
[INFO] 2021-07-12 18:59:01,357 [run_pretraining.py:  535]:	loss/mlm_loss, 8.294443130493164, 1349
[INFO] 2021-07-12 18:59:01,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3480000234267209e-05, 1349
[INFO] 2021-07-12 18:59:01,357 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1349
[INFO] 2021-07-12 18:59:01,357 [run_pretraining.py:  558]:	worker_index: 7, step: 1349, cost: 8.294443, mlm loss: 8.294443, speed: 1.000684 steps/s, speed: 8.005472 samples/s, speed: 4098.801720 tokens/s, learning rate: 1.348e-05, loss_scalings: 10737.418945, pp_loss: 7.277905
[INFO] 2021-07-12 18:59:01,357 [run_pretraining.py:  512]:	********exe.run_1349******* 
[INFO] 2021-07-12 18:59:02,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:02,257 [run_pretraining.py:  534]:	loss/total_loss, 7.921404838562012, 1350
[INFO] 2021-07-12 18:59:02,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.921404838562012, 1350
[INFO] 2021-07-12 18:59:02,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3490000128513202e-05, 1350
[INFO] 2021-07-12 18:59:02,257 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1350
[INFO] 2021-07-12 18:59:02,257 [run_pretraining.py:  558]:	worker_index: 7, step: 1350, cost: 7.921405, mlm loss: 7.921405, speed: 1.111539 steps/s, speed: 8.892315 samples/s, speed: 4552.865500 tokens/s, learning rate: 1.349e-05, loss_scalings: 10737.418945, pp_loss: 7.711485
[INFO] 2021-07-12 18:59:02,257 [run_pretraining.py:  512]:	********exe.run_1350******* 
[INFO] 2021-07-12 18:59:03,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:03,158 [run_pretraining.py:  534]:	loss/total_loss, 7.7342376708984375, 1351
[INFO] 2021-07-12 18:59:03,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7342376708984375, 1351
[INFO] 2021-07-12 18:59:03,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3500000022759195e-05, 1351
[INFO] 2021-07-12 18:59:03,158 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1351
[INFO] 2021-07-12 18:59:03,158 [run_pretraining.py:  558]:	worker_index: 7, step: 1351, cost: 7.734238, mlm loss: 7.734238, speed: 1.110905 steps/s, speed: 8.887238 samples/s, speed: 4550.265637 tokens/s, learning rate: 1.350e-05, loss_scalings: 10737.418945, pp_loss: 7.370683
[INFO] 2021-07-12 18:59:03,158 [run_pretraining.py:  512]:	********exe.run_1351******* 
[INFO] 2021-07-12 18:59:04,056 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:04,056 [run_pretraining.py:  534]:	loss/total_loss, 7.499807834625244, 1352
[INFO] 2021-07-12 18:59:04,056 [run_pretraining.py:  535]:	loss/mlm_loss, 7.499807834625244, 1352
[INFO] 2021-07-12 18:59:04,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3509999917005189e-05, 1352
[INFO] 2021-07-12 18:59:04,057 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1352
[INFO] 2021-07-12 18:59:04,057 [run_pretraining.py:  558]:	worker_index: 7, step: 1352, cost: 7.499808, mlm loss: 7.499808, speed: 1.113728 steps/s, speed: 8.909821 samples/s, speed: 4561.828565 tokens/s, learning rate: 1.351e-05, loss_scalings: 10737.418945, pp_loss: 6.870317
[INFO] 2021-07-12 18:59:04,057 [run_pretraining.py:  512]:	********exe.run_1352******* 
[INFO] 2021-07-12 18:59:04,950 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:04,950 [run_pretraining.py:  534]:	loss/total_loss, 8.142290115356445, 1353
[INFO] 2021-07-12 18:59:04,950 [run_pretraining.py:  535]:	loss/mlm_loss, 8.142290115356445, 1353
[INFO] 2021-07-12 18:59:04,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.351999890175648e-05, 1353
[INFO] 2021-07-12 18:59:04,950 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1353
[INFO] 2021-07-12 18:59:04,951 [run_pretraining.py:  558]:	worker_index: 7, step: 1353, cost: 8.142290, mlm loss: 8.142290, speed: 1.119580 steps/s, speed: 8.956643 samples/s, speed: 4585.801094 tokens/s, learning rate: 1.352e-05, loss_scalings: 10737.418945, pp_loss: 7.875432
[INFO] 2021-07-12 18:59:04,951 [run_pretraining.py:  512]:	********exe.run_1353******* 
[INFO] 2021-07-12 18:59:05,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:05,852 [run_pretraining.py:  534]:	loss/total_loss, 7.9281487464904785, 1354
[INFO] 2021-07-12 18:59:05,852 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9281487464904785, 1354
[INFO] 2021-07-12 18:59:05,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3529998796002474e-05, 1354
[INFO] 2021-07-12 18:59:05,852 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1354
[INFO] 2021-07-12 18:59:05,852 [run_pretraining.py:  558]:	worker_index: 7, step: 1354, cost: 7.928149, mlm loss: 7.928149, speed: 1.110334 steps/s, speed: 8.882671 samples/s, speed: 4547.927576 tokens/s, learning rate: 1.353e-05, loss_scalings: 10737.418945, pp_loss: 7.528146
[INFO] 2021-07-12 18:59:05,852 [run_pretraining.py:  512]:	********exe.run_1354******* 
[INFO] 2021-07-12 18:59:06,751 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:06,751 [run_pretraining.py:  534]:	loss/total_loss, 7.324707984924316, 1355
[INFO] 2021-07-12 18:59:06,752 [run_pretraining.py:  535]:	loss/mlm_loss, 7.324707984924316, 1355
[INFO] 2021-07-12 18:59:06,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3539999599743169e-05, 1355
[INFO] 2021-07-12 18:59:06,752 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1355
[INFO] 2021-07-12 18:59:06,752 [run_pretraining.py:  558]:	worker_index: 7, step: 1355, cost: 7.324708, mlm loss: 7.324708, speed: 1.111943 steps/s, speed: 8.895545 samples/s, speed: 4554.519091 tokens/s, learning rate: 1.354e-05, loss_scalings: 10737.418945, pp_loss: 7.672590
[INFO] 2021-07-12 18:59:06,752 [run_pretraining.py:  512]:	********exe.run_1355******* 
[INFO] 2021-07-12 18:59:07,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:07,639 [run_pretraining.py:  534]:	loss/total_loss, 7.630222797393799, 1356
[INFO] 2021-07-12 18:59:07,640 [run_pretraining.py:  535]:	loss/mlm_loss, 7.630222797393799, 1356
[INFO] 2021-07-12 18:59:07,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3549999493989162e-05, 1356
[INFO] 2021-07-12 18:59:07,640 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1356
[INFO] 2021-07-12 18:59:07,640 [run_pretraining.py:  558]:	worker_index: 7, step: 1356, cost: 7.630223, mlm loss: 7.630223, speed: 1.127073 steps/s, speed: 9.016584 samples/s, speed: 4616.490882 tokens/s, learning rate: 1.355e-05, loss_scalings: 10737.418945, pp_loss: 7.649135
[INFO] 2021-07-12 18:59:07,640 [run_pretraining.py:  512]:	********exe.run_1356******* 
[INFO] 2021-07-12 18:59:08,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  534]:	loss/total_loss, 7.996610641479492, 1357
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  535]:	loss/mlm_loss, 7.996610641479492, 1357
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3559999388235155e-05, 1357
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1357
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  558]:	worker_index: 7, step: 1357, cost: 7.996611, mlm loss: 7.996611, speed: 1.103989 steps/s, speed: 8.831910 samples/s, speed: 4521.938064 tokens/s, learning rate: 1.356e-05, loss_scalings: 10737.418945, pp_loss: 7.800816
[INFO] 2021-07-12 18:59:08,546 [run_pretraining.py:  512]:	********exe.run_1357******* 
[INFO] 2021-07-12 18:59:09,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:09,443 [run_pretraining.py:  534]:	loss/total_loss, 7.664985656738281, 1358
[INFO] 2021-07-12 18:59:09,444 [run_pretraining.py:  535]:	loss/mlm_loss, 7.664985656738281, 1358
[INFO] 2021-07-12 18:59:09,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.357000019197585e-05, 1358
[INFO] 2021-07-12 18:59:09,444 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1358
[INFO] 2021-07-12 18:59:09,444 [run_pretraining.py:  558]:	worker_index: 7, step: 1358, cost: 7.664986, mlm loss: 7.664986, speed: 1.114983 steps/s, speed: 8.919866 samples/s, speed: 4566.971555 tokens/s, learning rate: 1.357e-05, loss_scalings: 10737.418945, pp_loss: 7.459885
[INFO] 2021-07-12 18:59:09,444 [run_pretraining.py:  512]:	********exe.run_1358******* 
[INFO] 2021-07-12 18:59:10,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:10,347 [run_pretraining.py:  534]:	loss/total_loss, 7.717972755432129, 1359
[INFO] 2021-07-12 18:59:10,347 [run_pretraining.py:  535]:	loss/mlm_loss, 7.717972755432129, 1359
[INFO] 2021-07-12 18:59:10,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3580000086221844e-05, 1359
[INFO] 2021-07-12 18:59:10,347 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1359
[INFO] 2021-07-12 18:59:10,347 [run_pretraining.py:  558]:	worker_index: 7, step: 1359, cost: 7.717973, mlm loss: 7.717973, speed: 1.107955 steps/s, speed: 8.863639 samples/s, speed: 4538.183287 tokens/s, learning rate: 1.358e-05, loss_scalings: 10737.418945, pp_loss: 7.505814
[INFO] 2021-07-12 18:59:10,347 [run_pretraining.py:  512]:	********exe.run_1359******* 
[INFO] 2021-07-12 18:59:11,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:11,277 [run_pretraining.py:  534]:	loss/total_loss, 7.683645248413086, 1360
[INFO] 2021-07-12 18:59:11,277 [run_pretraining.py:  535]:	loss/mlm_loss, 7.683645248413086, 1360
[INFO] 2021-07-12 18:59:11,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3589999980467837e-05, 1360
[INFO] 2021-07-12 18:59:11,278 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1360
[INFO] 2021-07-12 18:59:11,278 [run_pretraining.py:  558]:	worker_index: 7, step: 1360, cost: 7.683645, mlm loss: 7.683645, speed: 1.075161 steps/s, speed: 8.601290 samples/s, speed: 4403.860452 tokens/s, learning rate: 1.359e-05, loss_scalings: 10737.418945, pp_loss: 7.501786
[INFO] 2021-07-12 18:59:11,278 [run_pretraining.py:  512]:	********exe.run_1360******* 
[INFO] 2021-07-12 18:59:12,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:12,176 [run_pretraining.py:  534]:	loss/total_loss, 7.79649543762207, 1361
[INFO] 2021-07-12 18:59:12,176 [run_pretraining.py:  535]:	loss/mlm_loss, 7.79649543762207, 1361
[INFO] 2021-07-12 18:59:12,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3600000784208532e-05, 1361
[INFO] 2021-07-12 18:59:12,177 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1361
[INFO] 2021-07-12 18:59:12,177 [run_pretraining.py:  558]:	worker_index: 7, step: 1361, cost: 7.796495, mlm loss: 7.796495, speed: 1.113189 steps/s, speed: 8.905511 samples/s, speed: 4559.621401 tokens/s, learning rate: 1.360e-05, loss_scalings: 10737.418945, pp_loss: 7.545883
[INFO] 2021-07-12 18:59:12,177 [run_pretraining.py:  512]:	********exe.run_1361******* 
[INFO] 2021-07-12 18:59:13,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:13,080 [run_pretraining.py:  534]:	loss/total_loss, 7.3955512046813965, 1362
[INFO] 2021-07-12 18:59:13,080 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3955512046813965, 1362
[INFO] 2021-07-12 18:59:13,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3609998859465122e-05, 1362
[INFO] 2021-07-12 18:59:13,080 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1362
[INFO] 2021-07-12 18:59:13,080 [run_pretraining.py:  558]:	worker_index: 7, step: 1362, cost: 7.395551, mlm loss: 7.395551, speed: 1.107444 steps/s, speed: 8.859553 samples/s, speed: 4536.091160 tokens/s, learning rate: 1.361e-05, loss_scalings: 10737.418945, pp_loss: 7.398342
[INFO] 2021-07-12 18:59:13,080 [run_pretraining.py:  512]:	********exe.run_1362******* 
[INFO] 2021-07-12 18:59:13,976 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:13,976 [run_pretraining.py:  534]:	loss/total_loss, 7.388309478759766, 1363
[INFO] 2021-07-12 18:59:13,976 [run_pretraining.py:  535]:	loss/mlm_loss, 7.388309478759766, 1363
[INFO] 2021-07-12 18:59:13,976 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3619999663205817e-05, 1363
[INFO] 2021-07-12 18:59:13,976 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1363
[INFO] 2021-07-12 18:59:13,977 [run_pretraining.py:  558]:	worker_index: 7, step: 1363, cost: 7.388309, mlm loss: 7.388309, speed: 1.116473 steps/s, speed: 8.931781 samples/s, speed: 4573.071798 tokens/s, learning rate: 1.362e-05, loss_scalings: 10737.418945, pp_loss: 7.528274
[INFO] 2021-07-12 18:59:13,977 [run_pretraining.py:  512]:	********exe.run_1363******* 
[INFO] 2021-07-12 18:59:14,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:14,937 [run_pretraining.py:  534]:	loss/total_loss, 4.209793567657471, 1364
[INFO] 2021-07-12 18:59:14,942 [run_pretraining.py:  535]:	loss/mlm_loss, 4.209793567657471, 1364
[INFO] 2021-07-12 18:59:14,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.362999955745181e-05, 1364
[INFO] 2021-07-12 18:59:14,953 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1364
[INFO] 2021-07-12 18:59:14,958 [run_pretraining.py:  558]:	worker_index: 7, step: 1364, cost: 4.209794, mlm loss: 4.209794, speed: 1.041566 steps/s, speed: 8.332528 samples/s, speed: 4266.254338 tokens/s, learning rate: 1.363e-05, loss_scalings: 10737.418945, pp_loss: 6.608633
[INFO] 2021-07-12 18:59:14,963 [run_pretraining.py:  512]:	********exe.run_1364******* 
[INFO] 2021-07-12 18:59:15,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:15,853 [run_pretraining.py:  534]:	loss/total_loss, 7.6458282470703125, 1365
[INFO] 2021-07-12 18:59:15,854 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6458282470703125, 1365
[INFO] 2021-07-12 18:59:15,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3639999451697804e-05, 1365
[INFO] 2021-07-12 18:59:15,854 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1365
[INFO] 2021-07-12 18:59:15,854 [run_pretraining.py:  558]:	worker_index: 7, step: 1365, cost: 7.645828, mlm loss: 7.645828, speed: 1.123535 steps/s, speed: 8.988277 samples/s, speed: 4601.997621 tokens/s, learning rate: 1.364e-05, loss_scalings: 10737.418945, pp_loss: 7.540301
[INFO] 2021-07-12 18:59:15,854 [run_pretraining.py:  512]:	********exe.run_1365******* 
[INFO] 2021-07-12 18:59:16,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:16,751 [run_pretraining.py:  534]:	loss/total_loss, 7.243268966674805, 1366
[INFO] 2021-07-12 18:59:16,751 [run_pretraining.py:  535]:	loss/mlm_loss, 7.243268966674805, 1366
[INFO] 2021-07-12 18:59:16,751 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3649999345943797e-05, 1366
[INFO] 2021-07-12 18:59:16,751 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1366
[INFO] 2021-07-12 18:59:16,751 [run_pretraining.py:  558]:	worker_index: 7, step: 1366, cost: 7.243269, mlm loss: 7.243269, speed: 1.115369 steps/s, speed: 8.922955 samples/s, speed: 4568.552796 tokens/s, learning rate: 1.365e-05, loss_scalings: 10737.418945, pp_loss: 7.096402
[INFO] 2021-07-12 18:59:16,751 [run_pretraining.py:  512]:	********exe.run_1366******* 
[INFO] 2021-07-12 18:59:17,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:17,653 [run_pretraining.py:  534]:	loss/total_loss, 7.5969438552856445, 1367
[INFO] 2021-07-12 18:59:17,653 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5969438552856445, 1367
[INFO] 2021-07-12 18:59:17,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3660000149684492e-05, 1367
[INFO] 2021-07-12 18:59:17,653 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1367
[INFO] 2021-07-12 18:59:17,653 [run_pretraining.py:  558]:	worker_index: 7, step: 1367, cost: 7.596944, mlm loss: 7.596944, speed: 1.109483 steps/s, speed: 8.875862 samples/s, speed: 4544.441213 tokens/s, learning rate: 1.366e-05, loss_scalings: 10737.418945, pp_loss: 7.542990
[INFO] 2021-07-12 18:59:17,653 [run_pretraining.py:  512]:	********exe.run_1367******* 
[INFO] 2021-07-12 18:59:18,553 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:18,553 [run_pretraining.py:  534]:	loss/total_loss, 7.632762432098389, 1368
[INFO] 2021-07-12 18:59:18,553 [run_pretraining.py:  535]:	loss/mlm_loss, 7.632762432098389, 1368
[INFO] 2021-07-12 18:59:18,553 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3670000043930486e-05, 1368
[INFO] 2021-07-12 18:59:18,553 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1368
[INFO] 2021-07-12 18:59:18,553 [run_pretraining.py:  558]:	worker_index: 7, step: 1368, cost: 7.632762, mlm loss: 7.632762, speed: 1.111442 steps/s, speed: 8.891538 samples/s, speed: 4552.467370 tokens/s, learning rate: 1.367e-05, loss_scalings: 10737.418945, pp_loss: 7.401896
[INFO] 2021-07-12 18:59:18,553 [run_pretraining.py:  512]:	********exe.run_1368******* 
[INFO] 2021-07-12 18:59:19,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:19,453 [run_pretraining.py:  534]:	loss/total_loss, 7.840559005737305, 1369
[INFO] 2021-07-12 18:59:19,453 [run_pretraining.py:  535]:	loss/mlm_loss, 7.840559005737305, 1369
[INFO] 2021-07-12 18:59:19,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.367999993817648e-05, 1369
[INFO] 2021-07-12 18:59:19,453 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1369
[INFO] 2021-07-12 18:59:19,453 [run_pretraining.py:  558]:	worker_index: 7, step: 1369, cost: 7.840559, mlm loss: 7.840559, speed: 1.112051 steps/s, speed: 8.896411 samples/s, speed: 4554.962265 tokens/s, learning rate: 1.368e-05, loss_scalings: 10737.418945, pp_loss: 7.577612
[INFO] 2021-07-12 18:59:19,453 [run_pretraining.py:  512]:	********exe.run_1369******* 
[INFO] 2021-07-12 18:59:20,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:20,353 [run_pretraining.py:  534]:	loss/total_loss, 7.0727152824401855, 1370
[INFO] 2021-07-12 18:59:20,353 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0727152824401855, 1370
[INFO] 2021-07-12 18:59:20,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.368999892292777e-05, 1370
[INFO] 2021-07-12 18:59:20,353 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1370
[INFO] 2021-07-12 18:59:20,353 [run_pretraining.py:  558]:	worker_index: 7, step: 1370, cost: 7.072715, mlm loss: 7.072715, speed: 1.112154 steps/s, speed: 8.897229 samples/s, speed: 4555.381366 tokens/s, learning rate: 1.369e-05, loss_scalings: 10737.418945, pp_loss: 7.410361
[INFO] 2021-07-12 18:59:20,353 [run_pretraining.py:  512]:	********exe.run_1370******* 
[INFO] 2021-07-12 18:59:21,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:21,248 [run_pretraining.py:  534]:	loss/total_loss, 6.986183166503906, 1371
[INFO] 2021-07-12 18:59:21,248 [run_pretraining.py:  535]:	loss/mlm_loss, 6.986183166503906, 1371
[INFO] 2021-07-12 18:59:21,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3699998817173764e-05, 1371
[INFO] 2021-07-12 18:59:21,248 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1371
[INFO] 2021-07-12 18:59:21,248 [run_pretraining.py:  558]:	worker_index: 7, step: 1371, cost: 6.986183, mlm loss: 6.986183, speed: 1.117829 steps/s, speed: 8.942628 samples/s, speed: 4578.625753 tokens/s, learning rate: 1.370e-05, loss_scalings: 10737.418945, pp_loss: 7.358288
[INFO] 2021-07-12 18:59:21,248 [run_pretraining.py:  512]:	********exe.run_1371******* 
[INFO] 2021-07-12 18:59:22,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:22,158 [run_pretraining.py:  534]:	loss/total_loss, 7.540520668029785, 1372
[INFO] 2021-07-12 18:59:22,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.540520668029785, 1372
[INFO] 2021-07-12 18:59:22,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.370999962091446e-05, 1372
[INFO] 2021-07-12 18:59:22,158 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1372
[INFO] 2021-07-12 18:59:22,158 [run_pretraining.py:  558]:	worker_index: 7, step: 1372, cost: 7.540521, mlm loss: 7.540521, speed: 1.099750 steps/s, speed: 8.798001 samples/s, speed: 4504.576502 tokens/s, learning rate: 1.371e-05, loss_scalings: 10737.418945, pp_loss: 7.380256
[INFO] 2021-07-12 18:59:22,158 [run_pretraining.py:  512]:	********exe.run_1372******* 
[INFO] 2021-07-12 18:59:23,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:23,070 [run_pretraining.py:  534]:	loss/total_loss, 7.158504486083984, 1373
[INFO] 2021-07-12 18:59:23,070 [run_pretraining.py:  535]:	loss/mlm_loss, 7.158504486083984, 1373
[INFO] 2021-07-12 18:59:23,070 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3719999515160453e-05, 1373
[INFO] 2021-07-12 18:59:23,070 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1373
[INFO] 2021-07-12 18:59:23,070 [run_pretraining.py:  558]:	worker_index: 7, step: 1373, cost: 7.158504, mlm loss: 7.158504, speed: 1.097475 steps/s, speed: 8.779803 samples/s, speed: 4495.259188 tokens/s, learning rate: 1.372e-05, loss_scalings: 10737.418945, pp_loss: 7.449952
[INFO] 2021-07-12 18:59:23,070 [run_pretraining.py:  512]:	********exe.run_1373******* 
[INFO] 2021-07-12 18:59:23,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:23,984 [run_pretraining.py:  534]:	loss/total_loss, 7.650723457336426, 1374
[INFO] 2021-07-12 18:59:23,984 [run_pretraining.py:  535]:	loss/mlm_loss, 7.650723457336426, 1374
[INFO] 2021-07-12 18:59:23,984 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3729999409406446e-05, 1374
[INFO] 2021-07-12 18:59:23,984 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1374
[INFO] 2021-07-12 18:59:23,984 [run_pretraining.py:  558]:	worker_index: 7, step: 1374, cost: 7.650723, mlm loss: 7.650723, speed: 1.094759 steps/s, speed: 8.758072 samples/s, speed: 4484.132675 tokens/s, learning rate: 1.373e-05, loss_scalings: 10737.418945, pp_loss: 7.569741
[INFO] 2021-07-12 18:59:23,984 [run_pretraining.py:  512]:	********exe.run_1374******* 
[INFO] 2021-07-12 18:59:24,897 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:24,898 [run_pretraining.py:  534]:	loss/total_loss, 7.325414180755615, 1375
[INFO] 2021-07-12 18:59:24,898 [run_pretraining.py:  535]:	loss/mlm_loss, 7.325414180755615, 1375
[INFO] 2021-07-12 18:59:24,898 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3740000213147141e-05, 1375
[INFO] 2021-07-12 18:59:24,898 [run_pretraining.py:  539]:	lr/loss_scaling, 10737.4189453125, 1375
[INFO] 2021-07-12 18:59:24,898 [run_pretraining.py:  558]:	worker_index: 7, step: 1375, cost: 7.325414, mlm loss: 7.325414, speed: 1.094662 steps/s, speed: 8.757294 samples/s, speed: 4483.734772 tokens/s, learning rate: 1.374e-05, loss_scalings: 10737.418945, pp_loss: 7.467226
[INFO] 2021-07-12 18:59:24,898 [run_pretraining.py:  512]:	********exe.run_1375******* 
[INFO] 2021-07-12 18:59:25,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:25,843 [run_pretraining.py:  534]:	loss/total_loss, 6.593807220458984, 1376
[INFO] 2021-07-12 18:59:25,843 [run_pretraining.py:  535]:	loss/mlm_loss, 6.593807220458984, 1376
[INFO] 2021-07-12 18:59:25,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3750000107393134e-05, 1376
[INFO] 2021-07-12 18:59:25,843 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1376
[INFO] 2021-07-12 18:59:25,843 [run_pretraining.py:  558]:	worker_index: 7, step: 1376, cost: 6.593807, mlm loss: 6.593807, speed: 1.059053 steps/s, speed: 8.472426 samples/s, speed: 4337.881962 tokens/s, learning rate: 1.375e-05, loss_scalings: 8589.935547, pp_loss: 7.151658
[INFO] 2021-07-12 18:59:25,843 [run_pretraining.py:  512]:	********exe.run_1376******* 
[INFO] 2021-07-12 18:59:26,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:26,743 [run_pretraining.py:  534]:	loss/total_loss, 7.705272674560547, 1377
[INFO] 2021-07-12 18:59:26,744 [run_pretraining.py:  535]:	loss/mlm_loss, 7.705272674560547, 1377
[INFO] 2021-07-12 18:59:26,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3760000001639128e-05, 1377
[INFO] 2021-07-12 18:59:26,744 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1377
[INFO] 2021-07-12 18:59:26,744 [run_pretraining.py:  558]:	worker_index: 7, step: 1377, cost: 7.705273, mlm loss: 7.705273, speed: 1.111221 steps/s, speed: 8.889764 samples/s, speed: 4551.559168 tokens/s, learning rate: 1.376e-05, loss_scalings: 8589.935547, pp_loss: 7.503403
[INFO] 2021-07-12 18:59:26,744 [run_pretraining.py:  512]:	********exe.run_1377******* 
[INFO] 2021-07-12 18:59:27,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:27,640 [run_pretraining.py:  534]:	loss/total_loss, 7.07789421081543, 1378
[INFO] 2021-07-12 18:59:27,640 [run_pretraining.py:  535]:	loss/mlm_loss, 7.07789421081543, 1378
[INFO] 2021-07-12 18:59:27,640 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3769999895885121e-05, 1378
[INFO] 2021-07-12 18:59:27,640 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1378
[INFO] 2021-07-12 18:59:27,640 [run_pretraining.py:  558]:	worker_index: 7, step: 1378, cost: 7.077894, mlm loss: 7.077894, speed: 1.116267 steps/s, speed: 8.930136 samples/s, speed: 4572.229584 tokens/s, learning rate: 1.377e-05, loss_scalings: 8589.935547, pp_loss: 7.593630
[INFO] 2021-07-12 18:59:27,640 [run_pretraining.py:  512]:	********exe.run_1378******* 
[INFO] 2021-07-12 18:59:28,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:28,534 [run_pretraining.py:  534]:	loss/total_loss, 6.734200477600098, 1379
[INFO] 2021-07-12 18:59:28,534 [run_pretraining.py:  535]:	loss/mlm_loss, 6.734200477600098, 1379
[INFO] 2021-07-12 18:59:28,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3779998880636413e-05, 1379
[INFO] 2021-07-12 18:59:28,534 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1379
[INFO] 2021-07-12 18:59:28,534 [run_pretraining.py:  558]:	worker_index: 7, step: 1379, cost: 6.734200, mlm loss: 6.734200, speed: 1.119192 steps/s, speed: 8.953536 samples/s, speed: 4584.210339 tokens/s, learning rate: 1.378e-05, loss_scalings: 8589.935547, pp_loss: 7.094904
[INFO] 2021-07-12 18:59:28,535 [run_pretraining.py:  512]:	********exe.run_1379******* 
[INFO] 2021-07-12 18:59:29,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:29,432 [run_pretraining.py:  534]:	loss/total_loss, 6.949019908905029, 1380
[INFO] 2021-07-12 18:59:29,433 [run_pretraining.py:  535]:	loss/mlm_loss, 6.949019908905029, 1380
[INFO] 2021-07-12 18:59:29,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3789998774882406e-05, 1380
[INFO] 2021-07-12 18:59:29,433 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1380
[INFO] 2021-07-12 18:59:29,433 [run_pretraining.py:  558]:	worker_index: 7, step: 1380, cost: 6.949020, mlm loss: 6.949020, speed: 1.114035 steps/s, speed: 8.912278 samples/s, speed: 4563.086259 tokens/s, learning rate: 1.379e-05, loss_scalings: 8589.935547, pp_loss: 7.310148
[INFO] 2021-07-12 18:59:29,433 [run_pretraining.py:  512]:	********exe.run_1380******* 
[INFO] 2021-07-12 18:59:30,350 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:30,351 [run_pretraining.py:  534]:	loss/total_loss, 7.157315254211426, 1381
[INFO] 2021-07-12 18:59:30,351 [run_pretraining.py:  535]:	loss/mlm_loss, 7.157315254211426, 1381
[INFO] 2021-07-12 18:59:30,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3799999578623101e-05, 1381
[INFO] 2021-07-12 18:59:30,351 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1381
[INFO] 2021-07-12 18:59:30,351 [run_pretraining.py:  558]:	worker_index: 7, step: 1381, cost: 7.157315, mlm loss: 7.157315, speed: 1.089622 steps/s, speed: 8.716977 samples/s, speed: 4463.091971 tokens/s, learning rate: 1.380e-05, loss_scalings: 8589.935547, pp_loss: 7.566483
[INFO] 2021-07-12 18:59:30,351 [run_pretraining.py:  512]:	********exe.run_1381******* 
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  534]:	loss/total_loss, 7.235779285430908, 1382
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  535]:	loss/mlm_loss, 7.235779285430908, 1382
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3809999472869094e-05, 1382
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1382
[INFO] 2021-07-12 18:59:31,250 [run_pretraining.py:  558]:	worker_index: 7, step: 1382, cost: 7.235779, mlm loss: 7.235779, speed: 1.112712 steps/s, speed: 8.901693 samples/s, speed: 4557.666644 tokens/s, learning rate: 1.381e-05, loss_scalings: 8589.935547, pp_loss: 7.372265
[INFO] 2021-07-12 18:59:31,251 [run_pretraining.py:  512]:	********exe.run_1382******* 
[INFO] 2021-07-12 18:59:32,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:32,186 [run_pretraining.py:  534]:	loss/total_loss, 6.999854564666748, 1383
[INFO] 2021-07-12 18:59:32,186 [run_pretraining.py:  535]:	loss/mlm_loss, 6.999854564666748, 1383
[INFO] 2021-07-12 18:59:32,186 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3819999367115088e-05, 1383
[INFO] 2021-07-12 18:59:32,186 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1383
[INFO] 2021-07-12 18:59:32,186 [run_pretraining.py:  558]:	worker_index: 7, step: 1383, cost: 6.999855, mlm loss: 6.999855, speed: 1.069119 steps/s, speed: 8.552951 samples/s, speed: 4379.110816 tokens/s, learning rate: 1.382e-05, loss_scalings: 8589.935547, pp_loss: 7.274309
[INFO] 2021-07-12 18:59:32,187 [run_pretraining.py:  512]:	********exe.run_1383******* 
[INFO] 2021-07-12 18:59:33,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:33,086 [run_pretraining.py:  534]:	loss/total_loss, 7.7981038093566895, 1384
[INFO] 2021-07-12 18:59:33,086 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7981038093566895, 1384
[INFO] 2021-07-12 18:59:33,086 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3830000170855783e-05, 1384
[INFO] 2021-07-12 18:59:33,086 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1384
[INFO] 2021-07-12 18:59:33,086 [run_pretraining.py:  558]:	worker_index: 7, step: 1384, cost: 7.798104, mlm loss: 7.798104, speed: 1.112620 steps/s, speed: 8.900961 samples/s, speed: 4557.291851 tokens/s, learning rate: 1.383e-05, loss_scalings: 8589.935547, pp_loss: 7.477469
[INFO] 2021-07-12 18:59:33,086 [run_pretraining.py:  512]:	********exe.run_1384******* 
[INFO] 2021-07-12 18:59:33,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:33,984 [run_pretraining.py:  534]:	loss/total_loss, 7.109397888183594, 1385
[INFO] 2021-07-12 18:59:33,984 [run_pretraining.py:  535]:	loss/mlm_loss, 7.109397888183594, 1385
[INFO] 2021-07-12 18:59:33,984 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3840000065101776e-05, 1385
[INFO] 2021-07-12 18:59:33,984 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1385
[INFO] 2021-07-12 18:59:33,984 [run_pretraining.py:  558]:	worker_index: 7, step: 1385, cost: 7.109398, mlm loss: 7.109398, speed: 1.114008 steps/s, speed: 8.912062 samples/s, speed: 4562.975971 tokens/s, learning rate: 1.384e-05, loss_scalings: 8589.935547, pp_loss: 7.427882
[INFO] 2021-07-12 18:59:33,984 [run_pretraining.py:  512]:	********exe.run_1385******* 
[INFO] 2021-07-12 18:59:34,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:34,886 [run_pretraining.py:  534]:	loss/total_loss, 7.96781063079834, 1386
[INFO] 2021-07-12 18:59:34,886 [run_pretraining.py:  535]:	loss/mlm_loss, 7.96781063079834, 1386
[INFO] 2021-07-12 18:59:34,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.384999995934777e-05, 1386
[INFO] 2021-07-12 18:59:34,887 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1386
[INFO] 2021-07-12 18:59:34,887 [run_pretraining.py:  558]:	worker_index: 7, step: 1386, cost: 7.967811, mlm loss: 7.967811, speed: 1.109024 steps/s, speed: 8.872196 samples/s, speed: 4542.564306 tokens/s, learning rate: 1.385e-05, loss_scalings: 8589.935547, pp_loss: 7.598947
[INFO] 2021-07-12 18:59:34,887 [run_pretraining.py:  512]:	********exe.run_1386******* 
[INFO] 2021-07-12 18:59:35,798 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:35,798 [run_pretraining.py:  534]:	loss/total_loss, 7.830692291259766, 1387
[INFO] 2021-07-12 18:59:35,798 [run_pretraining.py:  535]:	loss/mlm_loss, 7.830692291259766, 1387
[INFO] 2021-07-12 18:59:35,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3860000763088465e-05, 1387
[INFO] 2021-07-12 18:59:35,799 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1387
[INFO] 2021-07-12 18:59:35,799 [run_pretraining.py:  558]:	worker_index: 7, step: 1387, cost: 7.830692, mlm loss: 7.830692, speed: 1.097137 steps/s, speed: 8.777095 samples/s, speed: 4493.872849 tokens/s, learning rate: 1.386e-05, loss_scalings: 8589.935547, pp_loss: 7.470850
[INFO] 2021-07-12 18:59:35,799 [run_pretraining.py:  512]:	********exe.run_1387******* 
[INFO] 2021-07-12 18:59:36,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:36,694 [run_pretraining.py:  534]:	loss/total_loss, 6.646114826202393, 1388
[INFO] 2021-07-12 18:59:36,694 [run_pretraining.py:  535]:	loss/mlm_loss, 6.646114826202393, 1388
[INFO] 2021-07-12 18:59:36,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3869998838345055e-05, 1388
[INFO] 2021-07-12 18:59:36,695 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1388
[INFO] 2021-07-12 18:59:36,695 [run_pretraining.py:  558]:	worker_index: 7, step: 1388, cost: 6.646115, mlm loss: 6.646115, speed: 1.116968 steps/s, speed: 8.935741 samples/s, speed: 4575.099494 tokens/s, learning rate: 1.387e-05, loss_scalings: 8589.935547, pp_loss: 7.267869
[INFO] 2021-07-12 18:59:36,695 [run_pretraining.py:  512]:	********exe.run_1388******* 
[INFO] 2021-07-12 18:59:37,640 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:37,641 [run_pretraining.py:  534]:	loss/total_loss, 7.733799934387207, 1389
[INFO] 2021-07-12 18:59:37,641 [run_pretraining.py:  535]:	loss/mlm_loss, 7.733799934387207, 1389
[INFO] 2021-07-12 18:59:37,641 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3879998732591048e-05, 1389
[INFO] 2021-07-12 18:59:37,641 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1389
[INFO] 2021-07-12 18:59:37,641 [run_pretraining.py:  558]:	worker_index: 7, step: 1389, cost: 7.733800, mlm loss: 7.733800, speed: 1.056932 steps/s, speed: 8.455455 samples/s, speed: 4329.192812 tokens/s, learning rate: 1.388e-05, loss_scalings: 8589.935547, pp_loss: 7.547578
[INFO] 2021-07-12 18:59:37,642 [run_pretraining.py:  512]:	********exe.run_1389******* 
[INFO] 2021-07-12 18:59:38,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:38,550 [run_pretraining.py:  534]:	loss/total_loss, 7.41535758972168, 1390
[INFO] 2021-07-12 18:59:38,550 [run_pretraining.py:  535]:	loss/mlm_loss, 7.41535758972168, 1390
[INFO] 2021-07-12 18:59:38,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3889999536331743e-05, 1390
[INFO] 2021-07-12 18:59:38,550 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1390
[INFO] 2021-07-12 18:59:38,550 [run_pretraining.py:  558]:	worker_index: 7, step: 1390, cost: 7.415358, mlm loss: 7.415358, speed: 1.101228 steps/s, speed: 8.809821 samples/s, speed: 4510.628330 tokens/s, learning rate: 1.389e-05, loss_scalings: 8589.935547, pp_loss: 7.343303
[INFO] 2021-07-12 18:59:38,550 [run_pretraining.py:  512]:	********exe.run_1390******* 
[INFO] 2021-07-12 18:59:39,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:39,453 [run_pretraining.py:  534]:	loss/total_loss, 7.733197212219238, 1391
[INFO] 2021-07-12 18:59:39,453 [run_pretraining.py:  535]:	loss/mlm_loss, 7.733197212219238, 1391
[INFO] 2021-07-12 18:59:39,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3899999430577736e-05, 1391
[INFO] 2021-07-12 18:59:39,453 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1391
[INFO] 2021-07-12 18:59:39,453 [run_pretraining.py:  558]:	worker_index: 7, step: 1391, cost: 7.733197, mlm loss: 7.733197, speed: 1.108109 steps/s, speed: 8.864876 samples/s, speed: 4538.816338 tokens/s, learning rate: 1.390e-05, loss_scalings: 8589.935547, pp_loss: 7.549644
[INFO] 2021-07-12 18:59:39,453 [run_pretraining.py:  512]:	********exe.run_1391******* 
[INFO] 2021-07-12 18:59:40,346 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:40,346 [run_pretraining.py:  534]:	loss/total_loss, 6.87431001663208, 1392
[INFO] 2021-07-12 18:59:40,347 [run_pretraining.py:  535]:	loss/mlm_loss, 6.87431001663208, 1392
[INFO] 2021-07-12 18:59:40,347 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.390999932482373e-05, 1392
[INFO] 2021-07-12 18:59:40,347 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1392
[INFO] 2021-07-12 18:59:40,347 [run_pretraining.py:  558]:	worker_index: 7, step: 1392, cost: 6.874310, mlm loss: 6.874310, speed: 1.120069 steps/s, speed: 8.960556 samples/s, speed: 4587.804568 tokens/s, learning rate: 1.391e-05, loss_scalings: 8589.935547, pp_loss: 7.547517
[INFO] 2021-07-12 18:59:40,347 [run_pretraining.py:  512]:	********exe.run_1392******* 
[INFO] 2021-07-12 18:59:41,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:41,252 [run_pretraining.py:  534]:	loss/total_loss, 7.5261149406433105, 1393
[INFO] 2021-07-12 18:59:41,252 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5261149406433105, 1393
[INFO] 2021-07-12 18:59:41,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3920000128564425e-05, 1393
[INFO] 2021-07-12 18:59:41,252 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1393
[INFO] 2021-07-12 18:59:41,252 [run_pretraining.py:  558]:	worker_index: 7, step: 1393, cost: 7.526115, mlm loss: 7.526115, speed: 1.105385 steps/s, speed: 8.843083 samples/s, speed: 4527.658375 tokens/s, learning rate: 1.392e-05, loss_scalings: 8589.935547, pp_loss: 7.822232
[INFO] 2021-07-12 18:59:41,252 [run_pretraining.py:  512]:	********exe.run_1393******* 
[INFO] 2021-07-12 18:59:42,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:42,153 [run_pretraining.py:  534]:	loss/total_loss, 7.422976016998291, 1394
[INFO] 2021-07-12 18:59:42,154 [run_pretraining.py:  535]:	loss/mlm_loss, 7.422976016998291, 1394
[INFO] 2021-07-12 18:59:42,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3930000022810418e-05, 1394
[INFO] 2021-07-12 18:59:42,154 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1394
[INFO] 2021-07-12 18:59:42,154 [run_pretraining.py:  558]:	worker_index: 7, step: 1394, cost: 7.422976, mlm loss: 7.422976, speed: 1.109840 steps/s, speed: 8.878722 samples/s, speed: 4545.905845 tokens/s, learning rate: 1.393e-05, loss_scalings: 8589.935547, pp_loss: 7.302545
[INFO] 2021-07-12 18:59:42,154 [run_pretraining.py:  512]:	********exe.run_1394******* 
[INFO] 2021-07-12 18:59:43,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:43,054 [run_pretraining.py:  534]:	loss/total_loss, 6.799010276794434, 1395
[INFO] 2021-07-12 18:59:43,054 [run_pretraining.py:  535]:	loss/mlm_loss, 6.799010276794434, 1395
[INFO] 2021-07-12 18:59:43,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3939999917056412e-05, 1395
[INFO] 2021-07-12 18:59:43,054 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1395
[INFO] 2021-07-12 18:59:43,054 [run_pretraining.py:  558]:	worker_index: 7, step: 1395, cost: 6.799010, mlm loss: 6.799010, speed: 1.111210 steps/s, speed: 8.889682 samples/s, speed: 4551.516963 tokens/s, learning rate: 1.394e-05, loss_scalings: 8589.935547, pp_loss: 7.232195
[INFO] 2021-07-12 18:59:43,054 [run_pretraining.py:  512]:	********exe.run_1395******* 
[INFO] 2021-07-12 18:59:43,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:43,956 [run_pretraining.py:  534]:	loss/total_loss, 7.3271026611328125, 1396
[INFO] 2021-07-12 18:59:43,956 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3271026611328125, 1396
[INFO] 2021-07-12 18:59:43,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3950000720797107e-05, 1396
[INFO] 2021-07-12 18:59:43,956 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1396
[INFO] 2021-07-12 18:59:43,956 [run_pretraining.py:  558]:	worker_index: 7, step: 1396, cost: 7.327103, mlm loss: 7.327103, speed: 1.109543 steps/s, speed: 8.876341 samples/s, speed: 4544.686455 tokens/s, learning rate: 1.395e-05, loss_scalings: 8589.935547, pp_loss: 7.399160
[INFO] 2021-07-12 18:59:43,956 [run_pretraining.py:  512]:	********exe.run_1396******* 
[INFO] 2021-07-12 18:59:44,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:44,858 [run_pretraining.py:  534]:	loss/total_loss, 7.79487419128418, 1397
[INFO] 2021-07-12 18:59:44,858 [run_pretraining.py:  535]:	loss/mlm_loss, 7.79487419128418, 1397
[INFO] 2021-07-12 18:59:44,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3959998796053696e-05, 1397
[INFO] 2021-07-12 18:59:44,859 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1397
[INFO] 2021-07-12 18:59:44,859 [run_pretraining.py:  558]:	worker_index: 7, step: 1397, cost: 7.794874, mlm loss: 7.794874, speed: 1.108959 steps/s, speed: 8.871668 samples/s, speed: 4542.294073 tokens/s, learning rate: 1.396e-05, loss_scalings: 8589.935547, pp_loss: 7.749386
[INFO] 2021-07-12 18:59:44,859 [run_pretraining.py:  512]:	********exe.run_1397******* 
[INFO] 2021-07-12 18:59:45,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:45,755 [run_pretraining.py:  534]:	loss/total_loss, 7.421328067779541, 1398
[INFO] 2021-07-12 18:59:45,755 [run_pretraining.py:  535]:	loss/mlm_loss, 7.421328067779541, 1398
[INFO] 2021-07-12 18:59:45,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3969999599794392e-05, 1398
[INFO] 2021-07-12 18:59:45,755 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1398
[INFO] 2021-07-12 18:59:45,755 [run_pretraining.py:  558]:	worker_index: 7, step: 1398, cost: 7.421328, mlm loss: 7.421328, speed: 1.116292 steps/s, speed: 8.930338 samples/s, speed: 4572.333018 tokens/s, learning rate: 1.397e-05, loss_scalings: 8589.935547, pp_loss: 7.425149
[INFO] 2021-07-12 18:59:45,755 [run_pretraining.py:  512]:	********exe.run_1398******* 
[INFO] 2021-07-12 18:59:46,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:46,657 [run_pretraining.py:  534]:	loss/total_loss, 7.290963172912598, 1399
[INFO] 2021-07-12 18:59:46,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.290963172912598, 1399
[INFO] 2021-07-12 18:59:46,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3979999494040385e-05, 1399
[INFO] 2021-07-12 18:59:46,657 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1399
[INFO] 2021-07-12 18:59:46,657 [run_pretraining.py:  558]:	worker_index: 7, step: 1399, cost: 7.290963, mlm loss: 7.290963, speed: 1.109326 steps/s, speed: 8.874606 samples/s, speed: 4543.798180 tokens/s, learning rate: 1.398e-05, loss_scalings: 8589.935547, pp_loss: 7.472521
[INFO] 2021-07-12 18:59:46,657 [run_pretraining.py:  512]:	********exe.run_1399******* 
[INFO] 2021-07-12 18:59:47,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:47,558 [run_pretraining.py:  534]:	loss/total_loss, 7.590808868408203, 1400
[INFO] 2021-07-12 18:59:47,558 [run_pretraining.py:  535]:	loss/mlm_loss, 7.590808868408203, 1400
[INFO] 2021-07-12 18:59:47,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3989999388286378e-05, 1400
[INFO] 2021-07-12 18:59:47,558 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1400
[INFO] 2021-07-12 18:59:47,558 [run_pretraining.py:  558]:	worker_index: 7, step: 1400, cost: 7.590809, mlm loss: 7.590809, speed: 1.110920 steps/s, speed: 8.887358 samples/s, speed: 4550.327103 tokens/s, learning rate: 1.399e-05, loss_scalings: 8589.935547, pp_loss: 7.249004
[INFO] 2021-07-12 18:59:47,558 [run_pretraining.py:  512]:	********exe.run_1400******* 
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  534]:	loss/total_loss, 7.080974578857422, 1401
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  535]:	loss/mlm_loss, 7.080974578857422, 1401
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.3999999282532372e-05, 1401
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1401
[INFO] 2021-07-12 18:59:48,457 [run_pretraining.py:  558]:	worker_index: 7, step: 1401, cost: 7.080975, mlm loss: 7.080975, speed: 1.112571 steps/s, speed: 8.900571 samples/s, speed: 4557.092390 tokens/s, learning rate: 1.400e-05, loss_scalings: 8589.935547, pp_loss: 7.493407
[INFO] 2021-07-12 18:59:48,458 [run_pretraining.py:  512]:	********exe.run_1401******* 
[INFO] 2021-07-12 18:59:49,361 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:49,362 [run_pretraining.py:  534]:	loss/total_loss, 7.422494888305664, 1402
[INFO] 2021-07-12 18:59:49,362 [run_pretraining.py:  535]:	loss/mlm_loss, 7.422494888305664, 1402
[INFO] 2021-07-12 18:59:49,362 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4010000086273067e-05, 1402
[INFO] 2021-07-12 18:59:49,362 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1402
[INFO] 2021-07-12 18:59:49,362 [run_pretraining.py:  558]:	worker_index: 7, step: 1402, cost: 7.422495, mlm loss: 7.422495, speed: 1.106334 steps/s, speed: 8.850671 samples/s, speed: 4531.543312 tokens/s, learning rate: 1.401e-05, loss_scalings: 8589.935547, pp_loss: 7.110741
[INFO] 2021-07-12 18:59:49,362 [run_pretraining.py:  512]:	********exe.run_1402******* 
[INFO] 2021-07-12 18:59:50,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:50,258 [run_pretraining.py:  534]:	loss/total_loss, 8.036809921264648, 1403
[INFO] 2021-07-12 18:59:50,258 [run_pretraining.py:  535]:	loss/mlm_loss, 8.036809921264648, 1403
[INFO] 2021-07-12 18:59:50,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.401999998051906e-05, 1403
[INFO] 2021-07-12 18:59:50,258 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1403
[INFO] 2021-07-12 18:59:50,258 [run_pretraining.py:  558]:	worker_index: 7, step: 1403, cost: 8.036810, mlm loss: 8.036810, speed: 1.116983 steps/s, speed: 8.935860 samples/s, speed: 4575.160414 tokens/s, learning rate: 1.402e-05, loss_scalings: 8589.935547, pp_loss: 7.684478
[INFO] 2021-07-12 18:59:50,258 [run_pretraining.py:  512]:	********exe.run_1403******* 
[INFO] 2021-07-12 18:59:51,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  534]:	loss/total_loss, 8.17255973815918, 1404
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  535]:	loss/mlm_loss, 8.17255973815918, 1404
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4029999874765053e-05, 1404
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1404
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  558]:	worker_index: 7, step: 1404, cost: 8.172560, mlm loss: 8.172560, speed: 1.116307 steps/s, speed: 8.930459 samples/s, speed: 4572.395081 tokens/s, learning rate: 1.403e-05, loss_scalings: 8589.935547, pp_loss: 7.795714
[INFO] 2021-07-12 18:59:51,154 [run_pretraining.py:  512]:	********exe.run_1404******* 
[INFO] 2021-07-12 18:59:52,047 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:52,048 [run_pretraining.py:  534]:	loss/total_loss, 7.369388580322266, 1405
[INFO] 2021-07-12 18:59:52,048 [run_pretraining.py:  535]:	loss/mlm_loss, 7.369388580322266, 1405
[INFO] 2021-07-12 18:59:52,048 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4040000678505749e-05, 1405
[INFO] 2021-07-12 18:59:52,048 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1405
[INFO] 2021-07-12 18:59:52,048 [run_pretraining.py:  558]:	worker_index: 7, step: 1405, cost: 7.369389, mlm loss: 7.369389, speed: 1.119767 steps/s, speed: 8.958132 samples/s, speed: 4586.563824 tokens/s, learning rate: 1.404e-05, loss_scalings: 8589.935547, pp_loss: 7.530744
[INFO] 2021-07-12 18:59:52,048 [run_pretraining.py:  512]:	********exe.run_1405******* 
[INFO] 2021-07-12 18:59:52,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:52,943 [run_pretraining.py:  534]:	loss/total_loss, 6.969191074371338, 1406
[INFO] 2021-07-12 18:59:52,943 [run_pretraining.py:  535]:	loss/mlm_loss, 6.969191074371338, 1406
[INFO] 2021-07-12 18:59:52,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4049998753762338e-05, 1406
[INFO] 2021-07-12 18:59:52,944 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1406
[INFO] 2021-07-12 18:59:52,944 [run_pretraining.py:  558]:	worker_index: 7, step: 1406, cost: 6.969191, mlm loss: 6.969191, speed: 1.117441 steps/s, speed: 8.939524 samples/s, speed: 4577.036313 tokens/s, learning rate: 1.405e-05, loss_scalings: 8589.935547, pp_loss: 7.420518
[INFO] 2021-07-12 18:59:52,944 [run_pretraining.py:  512]:	********exe.run_1406******* 
[INFO] 2021-07-12 18:59:53,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:53,839 [run_pretraining.py:  534]:	loss/total_loss, 8.204938888549805, 1407
[INFO] 2021-07-12 18:59:53,839 [run_pretraining.py:  535]:	loss/mlm_loss, 8.204938888549805, 1407
[INFO] 2021-07-12 18:59:53,839 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4059999557503033e-05, 1407
[INFO] 2021-07-12 18:59:53,839 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1407
[INFO] 2021-07-12 18:59:53,839 [run_pretraining.py:  558]:	worker_index: 7, step: 1407, cost: 8.204939, mlm loss: 8.204939, speed: 1.117539 steps/s, speed: 8.940315 samples/s, speed: 4577.441192 tokens/s, learning rate: 1.406e-05, loss_scalings: 8589.935547, pp_loss: 7.670441
[INFO] 2021-07-12 18:59:53,839 [run_pretraining.py:  512]:	********exe.run_1407******* 
[INFO] 2021-07-12 18:59:54,740 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:54,741 [run_pretraining.py:  534]:	loss/total_loss, 6.813840866088867, 1408
[INFO] 2021-07-12 18:59:54,741 [run_pretraining.py:  535]:	loss/mlm_loss, 6.813840866088867, 1408
[INFO] 2021-07-12 18:59:54,741 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4069999451749027e-05, 1408
[INFO] 2021-07-12 18:59:54,741 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1408
[INFO] 2021-07-12 18:59:54,741 [run_pretraining.py:  558]:	worker_index: 7, step: 1408, cost: 6.813841, mlm loss: 6.813841, speed: 1.109316 steps/s, speed: 8.874531 samples/s, speed: 4543.759724 tokens/s, learning rate: 1.407e-05, loss_scalings: 8589.935547, pp_loss: 7.147452
[INFO] 2021-07-12 18:59:54,741 [run_pretraining.py:  512]:	********exe.run_1408******* 
[INFO] 2021-07-12 18:59:55,635 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:55,636 [run_pretraining.py:  534]:	loss/total_loss, 7.1485185623168945, 1409
[INFO] 2021-07-12 18:59:55,636 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1485185623168945, 1409
[INFO] 2021-07-12 18:59:55,636 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.407999934599502e-05, 1409
[INFO] 2021-07-12 18:59:55,636 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1409
[INFO] 2021-07-12 18:59:55,636 [run_pretraining.py:  558]:	worker_index: 7, step: 1409, cost: 7.148519, mlm loss: 7.148519, speed: 1.117870 steps/s, speed: 8.942960 samples/s, speed: 4578.795374 tokens/s, learning rate: 1.408e-05, loss_scalings: 8589.935547, pp_loss: 7.559639
[INFO] 2021-07-12 18:59:55,636 [run_pretraining.py:  512]:	********exe.run_1409******* 
[INFO] 2021-07-12 18:59:56,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:56,540 [run_pretraining.py:  534]:	loss/total_loss, 6.8607378005981445, 1410
[INFO] 2021-07-12 18:59:56,541 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8607378005981445, 1410
[INFO] 2021-07-12 18:59:56,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4090000149735715e-05, 1410
[INFO] 2021-07-12 18:59:56,541 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1410
[INFO] 2021-07-12 18:59:56,541 [run_pretraining.py:  558]:	worker_index: 7, step: 1410, cost: 6.860738, mlm loss: 6.860738, speed: 1.106479 steps/s, speed: 8.851836 samples/s, speed: 4532.139839 tokens/s, learning rate: 1.409e-05, loss_scalings: 8589.935547, pp_loss: 7.591190
[INFO] 2021-07-12 18:59:56,541 [run_pretraining.py:  512]:	********exe.run_1410******* 
[INFO] 2021-07-12 18:59:57,523 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  534]:	loss/total_loss, 3.8162930011749268, 1411
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8162930011749268, 1411
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4100000043981709e-05, 1411
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1411
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  558]:	worker_index: 7, step: 1411, cost: 3.816293, mlm loss: 3.816293, speed: 1.017740 steps/s, speed: 8.141924 samples/s, speed: 4168.665081 tokens/s, learning rate: 1.410e-05, loss_scalings: 8589.935547, pp_loss: 6.346802
[INFO] 2021-07-12 18:59:57,524 [run_pretraining.py:  512]:	********exe.run_1411******* 
[INFO] 2021-07-12 18:59:58,467 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 18:59:58,467 [run_pretraining.py:  534]:	loss/total_loss, 7.867952346801758, 1412
[INFO] 2021-07-12 18:59:58,468 [run_pretraining.py:  535]:	loss/mlm_loss, 7.867952346801758, 1412
[INFO] 2021-07-12 18:59:58,468 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4109999938227702e-05, 1412
[INFO] 2021-07-12 18:59:58,468 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1412
[INFO] 2021-07-12 18:59:58,468 [run_pretraining.py:  558]:	worker_index: 7, step: 1412, cost: 7.867952, mlm loss: 7.867952, speed: 1.060225 steps/s, speed: 8.481802 samples/s, speed: 4342.682520 tokens/s, learning rate: 1.411e-05, loss_scalings: 8589.935547, pp_loss: 7.573601
[INFO] 2021-07-12 18:59:58,468 [run_pretraining.py:  512]:	********exe.run_1412******* 
[INFO] 2021-07-12 19:00:23,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:23,928 [run_pretraining.py:  534]:	loss/total_loss, 7.8028435707092285, 1413
[INFO] 2021-07-12 19:00:23,928 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8028435707092285, 1413
[INFO] 2021-07-12 19:00:23,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4119999832473695e-05, 1413
[INFO] 2021-07-12 19:00:23,928 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1413
[INFO] 2021-07-12 19:00:23,928 [run_pretraining.py:  558]:	worker_index: 7, step: 1413, cost: 7.802844, mlm loss: 7.802844, speed: 0.039278 steps/s, speed: 0.314226 samples/s, speed: 160.883769 tokens/s, learning rate: 1.412e-05, loss_scalings: 8589.935547, pp_loss: 7.746274
[INFO] 2021-07-12 19:00:23,928 [run_pretraining.py:  512]:	********exe.run_1413******* 
[INFO] 2021-07-12 19:00:24,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:24,826 [run_pretraining.py:  534]:	loss/total_loss, 7.232269287109375, 1414
[INFO] 2021-07-12 19:00:24,826 [run_pretraining.py:  535]:	loss/mlm_loss, 7.232269287109375, 1414
[INFO] 2021-07-12 19:00:24,826 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4129998817224987e-05, 1414
[INFO] 2021-07-12 19:00:24,826 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1414
[INFO] 2021-07-12 19:00:24,826 [run_pretraining.py:  558]:	worker_index: 7, step: 1414, cost: 7.232269, mlm loss: 7.232269, speed: 1.113982 steps/s, speed: 8.911859 samples/s, speed: 4562.871748 tokens/s, learning rate: 1.413e-05, loss_scalings: 8589.935547, pp_loss: 7.317873
[INFO] 2021-07-12 19:00:24,826 [run_pretraining.py:  512]:	********exe.run_1414******* 
[INFO] 2021-07-12 19:00:25,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:25,730 [run_pretraining.py:  534]:	loss/total_loss, 7.9631781578063965, 1415
[INFO] 2021-07-12 19:00:25,730 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9631781578063965, 1415
[INFO] 2021-07-12 19:00:25,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.413999871147098e-05, 1415
[INFO] 2021-07-12 19:00:25,731 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1415
[INFO] 2021-07-12 19:00:25,731 [run_pretraining.py:  558]:	worker_index: 7, step: 1415, cost: 7.963178, mlm loss: 7.963178, speed: 1.106478 steps/s, speed: 8.851826 samples/s, speed: 4532.135057 tokens/s, learning rate: 1.414e-05, loss_scalings: 8589.935547, pp_loss: 6.953437
[INFO] 2021-07-12 19:00:25,731 [run_pretraining.py:  512]:	********exe.run_1415******* 
[INFO] 2021-07-12 19:00:26,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:26,731 [run_pretraining.py:  534]:	loss/total_loss, 7.516315460205078, 1416
[INFO] 2021-07-12 19:00:26,731 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516315460205078, 1416
[INFO] 2021-07-12 19:00:26,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4149999515211675e-05, 1416
[INFO] 2021-07-12 19:00:26,731 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1416
[INFO] 2021-07-12 19:00:26,731 [run_pretraining.py:  558]:	worker_index: 7, step: 1416, cost: 7.516315, mlm loss: 7.516315, speed: 1.000110 steps/s, speed: 8.000877 samples/s, speed: 4096.449268 tokens/s, learning rate: 1.415e-05, loss_scalings: 8589.935547, pp_loss: 7.701169
[INFO] 2021-07-12 19:00:26,731 [run_pretraining.py:  512]:	********exe.run_1416******* 
[INFO] 2021-07-12 19:00:27,773 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  534]:	loss/total_loss, 7.504086494445801, 1417
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  535]:	loss/mlm_loss, 7.504086494445801, 1417
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4159999409457669e-05, 1417
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1417
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  558]:	worker_index: 7, step: 1417, cost: 7.504086, mlm loss: 7.504086, speed: 0.959475 steps/s, speed: 7.675802 samples/s, speed: 3930.010775 tokens/s, learning rate: 1.416e-05, loss_scalings: 8589.935547, pp_loss: 7.764549
[INFO] 2021-07-12 19:00:27,774 [run_pretraining.py:  512]:	********exe.run_1417******* 
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  534]:	loss/total_loss, 7.578581809997559, 1418
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.578581809997559, 1418
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4169999303703662e-05, 1418
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1418
[INFO] 2021-07-12 19:00:28,831 [run_pretraining.py:  558]:	worker_index: 7, step: 1418, cost: 7.578582, mlm loss: 7.578582, speed: 0.946361 steps/s, speed: 7.570888 samples/s, speed: 3876.294537 tokens/s, learning rate: 1.417e-05, loss_scalings: 8589.935547, pp_loss: 7.589228
[INFO] 2021-07-12 19:00:28,832 [run_pretraining.py:  512]:	********exe.run_1418******* 
[INFO] 2021-07-12 19:00:29,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:29,887 [run_pretraining.py:  534]:	loss/total_loss, 8.026659965515137, 1419
[INFO] 2021-07-12 19:00:29,887 [run_pretraining.py:  535]:	loss/mlm_loss, 8.026659965515137, 1419
[INFO] 2021-07-12 19:00:29,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4180000107444357e-05, 1419
[INFO] 2021-07-12 19:00:29,887 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1419
[INFO] 2021-07-12 19:00:29,888 [run_pretraining.py:  558]:	worker_index: 7, step: 1419, cost: 8.026660, mlm loss: 8.026660, speed: 0.947498 steps/s, speed: 7.579983 samples/s, speed: 3880.951293 tokens/s, learning rate: 1.418e-05, loss_scalings: 8589.935547, pp_loss: 7.464869
[INFO] 2021-07-12 19:00:29,888 [run_pretraining.py:  512]:	********exe.run_1419******* 
[INFO] 2021-07-12 19:00:30,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:30,944 [run_pretraining.py:  534]:	loss/total_loss, 7.535682678222656, 1420
[INFO] 2021-07-12 19:00:30,944 [run_pretraining.py:  535]:	loss/mlm_loss, 7.535682678222656, 1420
[INFO] 2021-07-12 19:00:30,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.419000000169035e-05, 1420
[INFO] 2021-07-12 19:00:30,945 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1420
[INFO] 2021-07-12 19:00:30,945 [run_pretraining.py:  558]:	worker_index: 7, step: 1420, cost: 7.535683, mlm loss: 7.535683, speed: 0.946508 steps/s, speed: 7.572065 samples/s, speed: 3876.897236 tokens/s, learning rate: 1.419e-05, loss_scalings: 8589.935547, pp_loss: 7.645571
[INFO] 2021-07-12 19:00:30,945 [run_pretraining.py:  512]:	********exe.run_1420******* 
[INFO] 2021-07-12 19:00:31,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:31,996 [run_pretraining.py:  534]:	loss/total_loss, 3.7062532901763916, 1421
[INFO] 2021-07-12 19:00:31,996 [run_pretraining.py:  535]:	loss/mlm_loss, 3.7062532901763916, 1421
[INFO] 2021-07-12 19:00:31,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4199999895936344e-05, 1421
[INFO] 2021-07-12 19:00:31,996 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1421
[INFO] 2021-07-12 19:00:31,997 [run_pretraining.py:  558]:	worker_index: 7, step: 1421, cost: 3.706253, mlm loss: 3.706253, speed: 0.951230 steps/s, speed: 7.609838 samples/s, speed: 3896.237105 tokens/s, learning rate: 1.420e-05, loss_scalings: 8589.935547, pp_loss: 6.489093
[INFO] 2021-07-12 19:00:31,997 [run_pretraining.py:  512]:	********exe.run_1421******* 
[INFO] 2021-07-12 19:00:33,049 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:33,049 [run_pretraining.py:  534]:	loss/total_loss, 7.103585720062256, 1422
[INFO] 2021-07-12 19:00:33,049 [run_pretraining.py:  535]:	loss/mlm_loss, 7.103585720062256, 1422
[INFO] 2021-07-12 19:00:33,049 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4210000699677039e-05, 1422
[INFO] 2021-07-12 19:00:33,049 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1422
[INFO] 2021-07-12 19:00:33,050 [run_pretraining.py:  558]:	worker_index: 7, step: 1422, cost: 7.103586, mlm loss: 7.103586, speed: 0.950314 steps/s, speed: 7.602514 samples/s, speed: 3892.487054 tokens/s, learning rate: 1.421e-05, loss_scalings: 8589.935547, pp_loss: 7.624673
[INFO] 2021-07-12 19:00:33,050 [run_pretraining.py:  512]:	********exe.run_1422******* 
[INFO] 2021-07-12 19:00:34,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:34,100 [run_pretraining.py:  534]:	loss/total_loss, 7.418796539306641, 1423
[INFO] 2021-07-12 19:00:34,100 [run_pretraining.py:  535]:	loss/mlm_loss, 7.418796539306641, 1423
[INFO] 2021-07-12 19:00:34,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4219998774933629e-05, 1423
[INFO] 2021-07-12 19:00:34,100 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1423
[INFO] 2021-07-12 19:00:34,100 [run_pretraining.py:  558]:	worker_index: 7, step: 1423, cost: 7.418797, mlm loss: 7.418797, speed: 0.952563 steps/s, speed: 7.620505 samples/s, speed: 3901.698520 tokens/s, learning rate: 1.422e-05, loss_scalings: 8589.935547, pp_loss: 6.583702
[INFO] 2021-07-12 19:00:34,100 [run_pretraining.py:  512]:	********exe.run_1423******* 
[INFO] 2021-07-12 19:00:35,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:35,176 [run_pretraining.py:  534]:	loss/total_loss, 7.409783363342285, 1424
[INFO] 2021-07-12 19:00:35,176 [run_pretraining.py:  535]:	loss/mlm_loss, 7.409783363342285, 1424
[INFO] 2021-07-12 19:00:35,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4229998669179622e-05, 1424
[INFO] 2021-07-12 19:00:35,176 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1424
[INFO] 2021-07-12 19:00:35,176 [run_pretraining.py:  558]:	worker_index: 7, step: 1424, cost: 7.409783, mlm loss: 7.409783, speed: 0.929852 steps/s, speed: 7.438818 samples/s, speed: 3808.674752 tokens/s, learning rate: 1.423e-05, loss_scalings: 8589.935547, pp_loss: 7.371685
[INFO] 2021-07-12 19:00:35,176 [run_pretraining.py:  512]:	********exe.run_1424******* 
[INFO] 2021-07-12 19:00:36,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:36,245 [run_pretraining.py:  534]:	loss/total_loss, 8.127331733703613, 1425
[INFO] 2021-07-12 19:00:36,245 [run_pretraining.py:  535]:	loss/mlm_loss, 8.127331733703613, 1425
[INFO] 2021-07-12 19:00:36,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4239999472920317e-05, 1425
[INFO] 2021-07-12 19:00:36,245 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1425
[INFO] 2021-07-12 19:00:36,245 [run_pretraining.py:  558]:	worker_index: 7, step: 1425, cost: 8.127332, mlm loss: 8.127332, speed: 0.935926 steps/s, speed: 7.487407 samples/s, speed: 3833.552314 tokens/s, learning rate: 1.424e-05, loss_scalings: 8589.935547, pp_loss: 7.734486
[INFO] 2021-07-12 19:00:36,245 [run_pretraining.py:  512]:	********exe.run_1425******* 
[INFO] 2021-07-12 19:00:37,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:37,357 [run_pretraining.py:  534]:	loss/total_loss, 7.147056579589844, 1426
[INFO] 2021-07-12 19:00:37,357 [run_pretraining.py:  535]:	loss/mlm_loss, 7.147056579589844, 1426
[INFO] 2021-07-12 19:00:37,357 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.424999936716631e-05, 1426
[INFO] 2021-07-12 19:00:37,358 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1426
[INFO] 2021-07-12 19:00:37,358 [run_pretraining.py:  558]:	worker_index: 7, step: 1426, cost: 7.147057, mlm loss: 7.147057, speed: 0.899450 steps/s, speed: 7.195604 samples/s, speed: 3684.149178 tokens/s, learning rate: 1.425e-05, loss_scalings: 8589.935547, pp_loss: 7.356515
[INFO] 2021-07-12 19:00:37,358 [run_pretraining.py:  512]:	********exe.run_1426******* 
[INFO] 2021-07-12 19:00:38,331 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  534]:	loss/total_loss, 7.624824523925781, 1427
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  535]:	loss/mlm_loss, 7.624824523925781, 1427
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4259999261412304e-05, 1427
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1427
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  558]:	worker_index: 7, step: 1427, cost: 7.624825, mlm loss: 7.624825, speed: 1.026883 steps/s, speed: 8.215065 samples/s, speed: 4206.113156 tokens/s, learning rate: 1.426e-05, loss_scalings: 8589.935547, pp_loss: 7.290291
[INFO] 2021-07-12 19:00:38,332 [run_pretraining.py:  512]:	********exe.run_1427******* 
[INFO] 2021-07-12 19:00:39,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:39,236 [run_pretraining.py:  534]:	loss/total_loss, 6.846935749053955, 1428
[INFO] 2021-07-12 19:00:39,236 [run_pretraining.py:  535]:	loss/mlm_loss, 6.846935749053955, 1428
[INFO] 2021-07-12 19:00:39,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4270000065152999e-05, 1428
[INFO] 2021-07-12 19:00:39,236 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1428
[INFO] 2021-07-12 19:00:39,236 [run_pretraining.py:  558]:	worker_index: 7, step: 1428, cost: 6.846936, mlm loss: 6.846936, speed: 1.107083 steps/s, speed: 8.856665 samples/s, speed: 4534.612497 tokens/s, learning rate: 1.427e-05, loss_scalings: 8589.935547, pp_loss: 7.099070
[INFO] 2021-07-12 19:00:39,236 [run_pretraining.py:  512]:	********exe.run_1428******* 
[INFO] 2021-07-12 19:00:40,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:40,134 [run_pretraining.py:  534]:	loss/total_loss, 7.1094136238098145, 1429
[INFO] 2021-07-12 19:00:40,134 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1094136238098145, 1429
[INFO] 2021-07-12 19:00:40,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4279999959398992e-05, 1429
[INFO] 2021-07-12 19:00:40,135 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1429
[INFO] 2021-07-12 19:00:40,135 [run_pretraining.py:  558]:	worker_index: 7, step: 1429, cost: 7.109414, mlm loss: 7.109414, speed: 1.113603 steps/s, speed: 8.908826 samples/s, speed: 4561.318657 tokens/s, learning rate: 1.428e-05, loss_scalings: 8589.935547, pp_loss: 7.682789
[INFO] 2021-07-12 19:00:40,135 [run_pretraining.py:  512]:	********exe.run_1429******* 
[INFO] 2021-07-12 19:00:41,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:41,033 [run_pretraining.py:  534]:	loss/total_loss, 7.0114312171936035, 1430
[INFO] 2021-07-12 19:00:41,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0114312171936035, 1430
[INFO] 2021-07-12 19:00:41,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4289999853644986e-05, 1430
[INFO] 2021-07-12 19:00:41,033 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1430
[INFO] 2021-07-12 19:00:41,033 [run_pretraining.py:  558]:	worker_index: 7, step: 1430, cost: 7.011431, mlm loss: 7.011431, speed: 1.113394 steps/s, speed: 8.907149 samples/s, speed: 4560.460186 tokens/s, learning rate: 1.429e-05, loss_scalings: 8589.935547, pp_loss: 7.325085
[INFO] 2021-07-12 19:00:41,033 [run_pretraining.py:  512]:	********exe.run_1430******* 
[INFO] 2021-07-12 19:00:41,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:41,930 [run_pretraining.py:  534]:	loss/total_loss, 4.510444164276123, 1431
[INFO] 2021-07-12 19:00:41,930 [run_pretraining.py:  535]:	loss/mlm_loss, 4.510444164276123, 1431
[INFO] 2021-07-12 19:00:41,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.430000065738568e-05, 1431
[INFO] 2021-07-12 19:00:41,930 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1431
[INFO] 2021-07-12 19:00:41,930 [run_pretraining.py:  558]:	worker_index: 7, step: 1431, cost: 4.510444, mlm loss: 4.510444, speed: 1.115566 steps/s, speed: 8.924526 samples/s, speed: 4569.357196 tokens/s, learning rate: 1.430e-05, loss_scalings: 8589.935547, pp_loss: 6.934940
[INFO] 2021-07-12 19:00:41,931 [run_pretraining.py:  512]:	********exe.run_1431******* 
[INFO] 2021-07-12 19:00:42,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  534]:	loss/total_loss, 7.114866256713867, 1432
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  535]:	loss/mlm_loss, 7.114866256713867, 1432
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.430999873264227e-05, 1432
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1432
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  558]:	worker_index: 7, step: 1432, cost: 7.114866, mlm loss: 7.114866, speed: 1.104905 steps/s, speed: 8.839239 samples/s, speed: 4525.690386 tokens/s, learning rate: 1.431e-05, loss_scalings: 8589.935547, pp_loss: 7.305512
[INFO] 2021-07-12 19:00:42,836 [run_pretraining.py:  512]:	********exe.run_1432******* 
[INFO] 2021-07-12 19:00:43,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:43,734 [run_pretraining.py:  534]:	loss/total_loss, 7.705818176269531, 1433
[INFO] 2021-07-12 19:00:43,734 [run_pretraining.py:  535]:	loss/mlm_loss, 7.705818176269531, 1433
[INFO] 2021-07-12 19:00:43,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4319999536382966e-05, 1433
[INFO] 2021-07-12 19:00:43,734 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1433
[INFO] 2021-07-12 19:00:43,734 [run_pretraining.py:  558]:	worker_index: 7, step: 1433, cost: 7.705818, mlm loss: 7.705818, speed: 1.114230 steps/s, speed: 8.913843 samples/s, speed: 4563.887522 tokens/s, learning rate: 1.432e-05, loss_scalings: 8589.935547, pp_loss: 7.498647
[INFO] 2021-07-12 19:00:43,734 [run_pretraining.py:  512]:	********exe.run_1433******* 
[INFO] 2021-07-12 19:00:44,624 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:44,624 [run_pretraining.py:  534]:	loss/total_loss, 7.984187126159668, 1434
[INFO] 2021-07-12 19:00:44,625 [run_pretraining.py:  535]:	loss/mlm_loss, 7.984187126159668, 1434
[INFO] 2021-07-12 19:00:44,625 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4329999430628959e-05, 1434
[INFO] 2021-07-12 19:00:44,625 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1434
[INFO] 2021-07-12 19:00:44,625 [run_pretraining.py:  558]:	worker_index: 7, step: 1434, cost: 7.984187, mlm loss: 7.984187, speed: 1.123807 steps/s, speed: 8.990459 samples/s, speed: 4603.114758 tokens/s, learning rate: 1.433e-05, loss_scalings: 8589.935547, pp_loss: 8.030876
[INFO] 2021-07-12 19:00:44,625 [run_pretraining.py:  512]:	********exe.run_1434******* 
[INFO] 2021-07-12 19:00:45,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:45,517 [run_pretraining.py:  534]:	loss/total_loss, 7.916733741760254, 1435
[INFO] 2021-07-12 19:00:45,517 [run_pretraining.py:  535]:	loss/mlm_loss, 7.916733741760254, 1435
[INFO] 2021-07-12 19:00:45,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4339999324874952e-05, 1435
[INFO] 2021-07-12 19:00:45,518 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1435
[INFO] 2021-07-12 19:00:45,518 [run_pretraining.py:  558]:	worker_index: 7, step: 1435, cost: 7.916734, mlm loss: 7.916734, speed: 1.120740 steps/s, speed: 8.965921 samples/s, speed: 4590.551777 tokens/s, learning rate: 1.434e-05, loss_scalings: 8589.935547, pp_loss: 7.648309
[INFO] 2021-07-12 19:00:45,518 [run_pretraining.py:  512]:	********exe.run_1435******* 
[INFO] 2021-07-12 19:00:46,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:46,412 [run_pretraining.py:  534]:	loss/total_loss, 7.197251319885254, 1436
[INFO] 2021-07-12 19:00:46,412 [run_pretraining.py:  535]:	loss/mlm_loss, 7.197251319885254, 1436
[INFO] 2021-07-12 19:00:46,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4349999219120946e-05, 1436
[INFO] 2021-07-12 19:00:46,412 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1436
[INFO] 2021-07-12 19:00:46,412 [run_pretraining.py:  558]:	worker_index: 7, step: 1436, cost: 7.197251, mlm loss: 7.197251, speed: 1.118456 steps/s, speed: 8.947646 samples/s, speed: 4581.194609 tokens/s, learning rate: 1.435e-05, loss_scalings: 8589.935547, pp_loss: 7.617031
[INFO] 2021-07-12 19:00:46,412 [run_pretraining.py:  512]:	********exe.run_1436******* 
[INFO] 2021-07-12 19:00:47,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:47,310 [run_pretraining.py:  534]:	loss/total_loss, 7.7252302169799805, 1437
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7252302169799805, 1437
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4360000022861641e-05, 1437
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1437
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  558]:	worker_index: 7, step: 1437, cost: 7.725230, mlm loss: 7.725230, speed: 1.113984 steps/s, speed: 8.911873 samples/s, speed: 4562.879019 tokens/s, learning rate: 1.436e-05, loss_scalings: 8589.935547, pp_loss: 7.816656
[INFO] 2021-07-12 19:00:47,311 [run_pretraining.py:  512]:	********exe.run_1437******* 
[INFO] 2021-07-12 19:00:48,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:48,205 [run_pretraining.py:  534]:	loss/total_loss, 7.908540725708008, 1438
[INFO] 2021-07-12 19:00:48,205 [run_pretraining.py:  535]:	loss/mlm_loss, 7.908540725708008, 1438
[INFO] 2021-07-12 19:00:48,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4369999917107634e-05, 1438
[INFO] 2021-07-12 19:00:48,206 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1438
[INFO] 2021-07-12 19:00:48,206 [run_pretraining.py:  558]:	worker_index: 7, step: 1438, cost: 7.908541, mlm loss: 7.908541, speed: 1.118256 steps/s, speed: 8.946045 samples/s, speed: 4580.375045 tokens/s, learning rate: 1.437e-05, loss_scalings: 8589.935547, pp_loss: 7.655501
[INFO] 2021-07-12 19:00:48,206 [run_pretraining.py:  512]:	********exe.run_1438******* 
[INFO] 2021-07-12 19:00:49,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:49,105 [run_pretraining.py:  534]:	loss/total_loss, 6.72973108291626, 1439
[INFO] 2021-07-12 19:00:49,105 [run_pretraining.py:  535]:	loss/mlm_loss, 6.72973108291626, 1439
[INFO] 2021-07-12 19:00:49,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4379999811353628e-05, 1439
[INFO] 2021-07-12 19:00:49,105 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1439
[INFO] 2021-07-12 19:00:49,105 [run_pretraining.py:  558]:	worker_index: 7, step: 1439, cost: 6.729731, mlm loss: 6.729731, speed: 1.112515 steps/s, speed: 8.900120 samples/s, speed: 4556.861520 tokens/s, learning rate: 1.438e-05, loss_scalings: 8589.935547, pp_loss: 7.552394
[INFO] 2021-07-12 19:00:49,105 [run_pretraining.py:  512]:	********exe.run_1439******* 
[INFO] 2021-07-12 19:00:50,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  534]:	loss/total_loss, 6.946457862854004, 1440
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  535]:	loss/mlm_loss, 6.946457862854004, 1440
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4390000615094323e-05, 1440
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1440
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  558]:	worker_index: 7, step: 1440, cost: 6.946458, mlm loss: 6.946458, speed: 1.114763 steps/s, speed: 8.918105 samples/s, speed: 4566.069693 tokens/s, learning rate: 1.439e-05, loss_scalings: 8589.935547, pp_loss: 7.715931
[INFO] 2021-07-12 19:00:50,003 [run_pretraining.py:  512]:	********exe.run_1440******* 
[INFO] 2021-07-12 19:00:50,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:50,900 [run_pretraining.py:  534]:	loss/total_loss, 8.036498069763184, 1441
[INFO] 2021-07-12 19:00:50,900 [run_pretraining.py:  535]:	loss/mlm_loss, 8.036498069763184, 1441
[INFO] 2021-07-12 19:00:50,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4399998690350913e-05, 1441
[INFO] 2021-07-12 19:00:50,900 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1441
[INFO] 2021-07-12 19:00:50,900 [run_pretraining.py:  558]:	worker_index: 7, step: 1441, cost: 8.036498, mlm loss: 8.036498, speed: 1.115519 steps/s, speed: 8.924151 samples/s, speed: 4569.165183 tokens/s, learning rate: 1.440e-05, loss_scalings: 8589.935547, pp_loss: 7.516910
[INFO] 2021-07-12 19:00:50,900 [run_pretraining.py:  512]:	********exe.run_1441******* 
[INFO] 2021-07-12 19:00:51,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:51,802 [run_pretraining.py:  534]:	loss/total_loss, 7.738976955413818, 1442
[INFO] 2021-07-12 19:00:51,802 [run_pretraining.py:  535]:	loss/mlm_loss, 7.738976955413818, 1442
[INFO] 2021-07-12 19:00:51,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4409999494091608e-05, 1442
[INFO] 2021-07-12 19:00:51,802 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1442
[INFO] 2021-07-12 19:00:51,802 [run_pretraining.py:  558]:	worker_index: 7, step: 1442, cost: 7.738977, mlm loss: 7.738977, speed: 1.109417 steps/s, speed: 8.875336 samples/s, speed: 4544.171958 tokens/s, learning rate: 1.441e-05, loss_scalings: 8589.935547, pp_loss: 7.309721
[INFO] 2021-07-12 19:00:51,802 [run_pretraining.py:  512]:	********exe.run_1442******* 
[INFO] 2021-07-12 19:00:52,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:52,730 [run_pretraining.py:  534]:	loss/total_loss, 6.8060712814331055, 1443
[INFO] 2021-07-12 19:00:52,730 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8060712814331055, 1443
[INFO] 2021-07-12 19:00:52,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4419999388337601e-05, 1443
[INFO] 2021-07-12 19:00:52,730 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1443
[INFO] 2021-07-12 19:00:52,730 [run_pretraining.py:  558]:	worker_index: 7, step: 1443, cost: 6.806071, mlm loss: 6.806071, speed: 1.078097 steps/s, speed: 8.624778 samples/s, speed: 4415.886410 tokens/s, learning rate: 1.442e-05, loss_scalings: 8589.935547, pp_loss: 7.201392
[INFO] 2021-07-12 19:00:52,730 [run_pretraining.py:  512]:	********exe.run_1443******* 
[INFO] 2021-07-12 19:00:53,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:53,628 [run_pretraining.py:  534]:	loss/total_loss, 6.8544464111328125, 1444
[INFO] 2021-07-12 19:00:53,628 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8544464111328125, 1444
[INFO] 2021-07-12 19:00:53,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4429999282583594e-05, 1444
[INFO] 2021-07-12 19:00:53,628 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1444
[INFO] 2021-07-12 19:00:53,628 [run_pretraining.py:  558]:	worker_index: 7, step: 1444, cost: 6.854446, mlm loss: 6.854446, speed: 1.114633 steps/s, speed: 8.917062 samples/s, speed: 4565.535785 tokens/s, learning rate: 1.443e-05, loss_scalings: 8589.935547, pp_loss: 7.384961
[INFO] 2021-07-12 19:00:53,628 [run_pretraining.py:  512]:	********exe.run_1444******* 
[INFO] 2021-07-12 19:00:54,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:54,550 [run_pretraining.py:  534]:	loss/total_loss, 5.346088409423828, 1445
[INFO] 2021-07-12 19:00:54,550 [run_pretraining.py:  535]:	loss/mlm_loss, 5.346088409423828, 1445
[INFO] 2021-07-12 19:00:54,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.444000008632429e-05, 1445
[INFO] 2021-07-12 19:00:54,550 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1445
[INFO] 2021-07-12 19:00:54,550 [run_pretraining.py:  558]:	worker_index: 7, step: 1445, cost: 5.346088, mlm loss: 5.346088, speed: 1.085435 steps/s, speed: 8.683482 samples/s, speed: 4445.942615 tokens/s, learning rate: 1.444e-05, loss_scalings: 8589.935547, pp_loss: 6.150885
[INFO] 2021-07-12 19:00:54,550 [run_pretraining.py:  512]:	********exe.run_1445******* 
[INFO] 2021-07-12 19:00:55,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:55,451 [run_pretraining.py:  534]:	loss/total_loss, 4.6149067878723145, 1446
[INFO] 2021-07-12 19:00:55,451 [run_pretraining.py:  535]:	loss/mlm_loss, 4.6149067878723145, 1446
[INFO] 2021-07-12 19:00:55,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4449999980570283e-05, 1446
[INFO] 2021-07-12 19:00:55,451 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1446
[INFO] 2021-07-12 19:00:55,451 [run_pretraining.py:  558]:	worker_index: 7, step: 1446, cost: 4.614907, mlm loss: 4.614907, speed: 1.110265 steps/s, speed: 8.882123 samples/s, speed: 4547.647073 tokens/s, learning rate: 1.445e-05, loss_scalings: 8589.935547, pp_loss: 6.910063
[INFO] 2021-07-12 19:00:55,451 [run_pretraining.py:  512]:	********exe.run_1446******* 
[INFO] 2021-07-12 19:00:56,352 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:56,352 [run_pretraining.py:  534]:	loss/total_loss, 7.462845325469971, 1447
[INFO] 2021-07-12 19:00:56,352 [run_pretraining.py:  535]:	loss/mlm_loss, 7.462845325469971, 1447
[INFO] 2021-07-12 19:00:56,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4459999874816276e-05, 1447
[INFO] 2021-07-12 19:00:56,353 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1447
[INFO] 2021-07-12 19:00:56,353 [run_pretraining.py:  558]:	worker_index: 7, step: 1447, cost: 7.462845, mlm loss: 7.462845, speed: 1.110279 steps/s, speed: 8.882234 samples/s, speed: 4547.703653 tokens/s, learning rate: 1.446e-05, loss_scalings: 8589.935547, pp_loss: 6.900863
[INFO] 2021-07-12 19:00:56,353 [run_pretraining.py:  512]:	********exe.run_1447******* 
[INFO] 2021-07-12 19:00:57,328 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:57,329 [run_pretraining.py:  534]:	loss/total_loss, 7.161352157592773, 1448
[INFO] 2021-07-12 19:00:57,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.161352157592773, 1448
[INFO] 2021-07-12 19:00:57,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.446999976906227e-05, 1448
[INFO] 2021-07-12 19:00:57,329 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1448
[INFO] 2021-07-12 19:00:57,329 [run_pretraining.py:  558]:	worker_index: 7, step: 1448, cost: 7.161352, mlm loss: 7.161352, speed: 1.024765 steps/s, speed: 8.198121 samples/s, speed: 4197.437732 tokens/s, learning rate: 1.447e-05, loss_scalings: 8589.935547, pp_loss: 7.226661
[INFO] 2021-07-12 19:00:57,329 [run_pretraining.py:  512]:	********exe.run_1448******* 
[INFO] 2021-07-12 19:00:58,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:58,254 [run_pretraining.py:  534]:	loss/total_loss, 7.538854122161865, 1449
[INFO] 2021-07-12 19:00:58,254 [run_pretraining.py:  535]:	loss/mlm_loss, 7.538854122161865, 1449
[INFO] 2021-07-12 19:00:58,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4480000572802965e-05, 1449
[INFO] 2021-07-12 19:00:58,254 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1449
[INFO] 2021-07-12 19:00:58,254 [run_pretraining.py:  558]:	worker_index: 7, step: 1449, cost: 7.538854, mlm loss: 7.538854, speed: 1.081780 steps/s, speed: 8.654239 samples/s, speed: 4430.970394 tokens/s, learning rate: 1.448e-05, loss_scalings: 8589.935547, pp_loss: 7.355688
[INFO] 2021-07-12 19:00:58,254 [run_pretraining.py:  512]:	********exe.run_1449******* 
[INFO] 2021-07-12 19:00:59,163 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:00:59,163 [run_pretraining.py:  534]:	loss/total_loss, 7.566250324249268, 1450
[INFO] 2021-07-12 19:00:59,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.566250324249268, 1450
[INFO] 2021-07-12 19:00:59,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4489998648059554e-05, 1450
[INFO] 2021-07-12 19:00:59,164 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1450
[INFO] 2021-07-12 19:00:59,164 [run_pretraining.py:  558]:	worker_index: 7, step: 1450, cost: 7.566250, mlm loss: 7.566250, speed: 1.100175 steps/s, speed: 8.801398 samples/s, speed: 4506.315758 tokens/s, learning rate: 1.449e-05, loss_scalings: 8589.935547, pp_loss: 7.452739
[INFO] 2021-07-12 19:00:59,164 [run_pretraining.py:  512]:	********exe.run_1450******* 
[INFO] 2021-07-12 19:01:00,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:00,067 [run_pretraining.py:  534]:	loss/total_loss, 7.239427089691162, 1451
[INFO] 2021-07-12 19:01:00,067 [run_pretraining.py:  535]:	loss/mlm_loss, 7.239427089691162, 1451
[INFO] 2021-07-12 19:01:00,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.449999945180025e-05, 1451
[INFO] 2021-07-12 19:01:00,067 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1451
[INFO] 2021-07-12 19:01:00,067 [run_pretraining.py:  558]:	worker_index: 7, step: 1451, cost: 7.239427, mlm loss: 7.239427, speed: 1.107875 steps/s, speed: 8.863000 samples/s, speed: 4537.856041 tokens/s, learning rate: 1.450e-05, loss_scalings: 8589.935547, pp_loss: 6.422007
[INFO] 2021-07-12 19:01:00,067 [run_pretraining.py:  512]:	********exe.run_1451******* 
[INFO] 2021-07-12 19:01:00,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:00,968 [run_pretraining.py:  534]:	loss/total_loss, 7.454518795013428, 1452
[INFO] 2021-07-12 19:01:00,968 [run_pretraining.py:  535]:	loss/mlm_loss, 7.454518795013428, 1452
[INFO] 2021-07-12 19:01:00,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4509999346046243e-05, 1452
[INFO] 2021-07-12 19:01:00,968 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1452
[INFO] 2021-07-12 19:01:00,968 [run_pretraining.py:  558]:	worker_index: 7, step: 1452, cost: 7.454519, mlm loss: 7.454519, speed: 1.110372 steps/s, speed: 8.882979 samples/s, speed: 4548.085298 tokens/s, learning rate: 1.451e-05, loss_scalings: 8589.935547, pp_loss: 7.500523
[INFO] 2021-07-12 19:01:00,968 [run_pretraining.py:  512]:	********exe.run_1452******* 
[INFO] 2021-07-12 19:01:01,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:01,868 [run_pretraining.py:  534]:	loss/total_loss, 7.3699750900268555, 1453
[INFO] 2021-07-12 19:01:01,868 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3699750900268555, 1453
[INFO] 2021-07-12 19:01:01,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4519999240292236e-05, 1453
[INFO] 2021-07-12 19:01:01,868 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1453
[INFO] 2021-07-12 19:01:01,868 [run_pretraining.py:  558]:	worker_index: 7, step: 1453, cost: 7.369975, mlm loss: 7.369975, speed: 1.111923 steps/s, speed: 8.895387 samples/s, speed: 4554.438194 tokens/s, learning rate: 1.452e-05, loss_scalings: 8589.935547, pp_loss: 7.597661
[INFO] 2021-07-12 19:01:01,868 [run_pretraining.py:  512]:	********exe.run_1453******* 
[INFO] 2021-07-12 19:01:02,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:02,771 [run_pretraining.py:  534]:	loss/total_loss, 7.7397942543029785, 1454
[INFO] 2021-07-12 19:01:02,771 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7397942543029785, 1454
[INFO] 2021-07-12 19:01:02,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4530000044032931e-05, 1454
[INFO] 2021-07-12 19:01:02,771 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1454
[INFO] 2021-07-12 19:01:02,771 [run_pretraining.py:  558]:	worker_index: 7, step: 1454, cost: 7.739794, mlm loss: 7.739794, speed: 1.108461 steps/s, speed: 8.867692 samples/s, speed: 4540.258148 tokens/s, learning rate: 1.453e-05, loss_scalings: 8589.935547, pp_loss: 7.103836
[INFO] 2021-07-12 19:01:02,771 [run_pretraining.py:  512]:	********exe.run_1454******* 
[INFO] 2021-07-12 19:01:03,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:03,670 [run_pretraining.py:  534]:	loss/total_loss, 7.920956611633301, 1455
[INFO] 2021-07-12 19:01:03,670 [run_pretraining.py:  535]:	loss/mlm_loss, 7.920956611633301, 1455
[INFO] 2021-07-12 19:01:03,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4539999938278925e-05, 1455
[INFO] 2021-07-12 19:01:03,670 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1455
[INFO] 2021-07-12 19:01:03,670 [run_pretraining.py:  558]:	worker_index: 7, step: 1455, cost: 7.920957, mlm loss: 7.920957, speed: 1.113273 steps/s, speed: 8.906187 samples/s, speed: 4559.967529 tokens/s, learning rate: 1.454e-05, loss_scalings: 8589.935547, pp_loss: 7.609316
[INFO] 2021-07-12 19:01:03,670 [run_pretraining.py:  512]:	********exe.run_1455******* 
[INFO] 2021-07-12 19:01:04,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:04,572 [run_pretraining.py:  534]:	loss/total_loss, 7.865103244781494, 1456
[INFO] 2021-07-12 19:01:04,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.865103244781494, 1456
[INFO] 2021-07-12 19:01:04,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4549999832524918e-05, 1456
[INFO] 2021-07-12 19:01:04,573 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1456
[INFO] 2021-07-12 19:01:04,573 [run_pretraining.py:  558]:	worker_index: 7, step: 1456, cost: 7.865103, mlm loss: 7.865103, speed: 1.108585 steps/s, speed: 8.868678 samples/s, speed: 4540.763357 tokens/s, learning rate: 1.455e-05, loss_scalings: 8589.935547, pp_loss: 7.414672
[INFO] 2021-07-12 19:01:04,573 [run_pretraining.py:  512]:	********exe.run_1456******* 
[INFO] 2021-07-12 19:01:05,471 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:05,471 [run_pretraining.py:  534]:	loss/total_loss, 7.217126846313477, 1457
[INFO] 2021-07-12 19:01:05,471 [run_pretraining.py:  535]:	loss/mlm_loss, 7.217126846313477, 1457
[INFO] 2021-07-12 19:01:05,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4560000636265613e-05, 1457
[INFO] 2021-07-12 19:01:05,472 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1457
[INFO] 2021-07-12 19:01:05,472 [run_pretraining.py:  558]:	worker_index: 7, step: 1457, cost: 7.217127, mlm loss: 7.217127, speed: 1.113222 steps/s, speed: 8.905773 samples/s, speed: 4559.755731 tokens/s, learning rate: 1.456e-05, loss_scalings: 8589.935547, pp_loss: 7.669014
[INFO] 2021-07-12 19:01:05,472 [run_pretraining.py:  512]:	********exe.run_1457******* 
[INFO] 2021-07-12 19:01:31,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:31,550 [run_pretraining.py:  534]:	loss/total_loss, 7.159250736236572, 1458
[INFO] 2021-07-12 19:01:31,550 [run_pretraining.py:  535]:	loss/mlm_loss, 7.159250736236572, 1458
[INFO] 2021-07-12 19:01:31,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4569998711522203e-05, 1458
[INFO] 2021-07-12 19:01:31,550 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1458
[INFO] 2021-07-12 19:01:31,550 [run_pretraining.py:  558]:	worker_index: 7, step: 1458, cost: 7.159251, mlm loss: 7.159251, speed: 0.038347 steps/s, speed: 0.306775 samples/s, speed: 157.069018 tokens/s, learning rate: 1.457e-05, loss_scalings: 8589.935547, pp_loss: 7.380188
[INFO] 2021-07-12 19:01:31,550 [run_pretraining.py:  512]:	********exe.run_1458******* 
[INFO] 2021-07-12 19:01:32,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:32,471 [run_pretraining.py:  534]:	loss/total_loss, 7.385446548461914, 1459
[INFO] 2021-07-12 19:01:32,471 [run_pretraining.py:  535]:	loss/mlm_loss, 7.385446548461914, 1459
[INFO] 2021-07-12 19:01:32,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4579999515262898e-05, 1459
[INFO] 2021-07-12 19:01:32,471 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1459
[INFO] 2021-07-12 19:01:32,471 [run_pretraining.py:  558]:	worker_index: 7, step: 1459, cost: 7.385447, mlm loss: 7.385447, speed: 1.086301 steps/s, speed: 8.690411 samples/s, speed: 4449.490308 tokens/s, learning rate: 1.458e-05, loss_scalings: 8589.935547, pp_loss: 7.142965
[INFO] 2021-07-12 19:01:32,471 [run_pretraining.py:  512]:	********exe.run_1459******* 
[INFO] 2021-07-12 19:01:33,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:33,394 [run_pretraining.py:  534]:	loss/total_loss, 7.0052947998046875, 1460
[INFO] 2021-07-12 19:01:33,394 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0052947998046875, 1460
[INFO] 2021-07-12 19:01:33,394 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4589999409508891e-05, 1460
[INFO] 2021-07-12 19:01:33,394 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1460
[INFO] 2021-07-12 19:01:33,394 [run_pretraining.py:  558]:	worker_index: 7, step: 1460, cost: 7.005295, mlm loss: 7.005295, speed: 1.083980 steps/s, speed: 8.671841 samples/s, speed: 4439.982680 tokens/s, learning rate: 1.459e-05, loss_scalings: 8589.935547, pp_loss: 7.551301
[INFO] 2021-07-12 19:01:33,394 [run_pretraining.py:  512]:	********exe.run_1460******* 
[INFO] 2021-07-12 19:01:34,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:34,302 [run_pretraining.py:  534]:	loss/total_loss, 6.148574352264404, 1461
[INFO] 2021-07-12 19:01:34,302 [run_pretraining.py:  535]:	loss/mlm_loss, 6.148574352264404, 1461
[INFO] 2021-07-12 19:01:34,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4599999303754885e-05, 1461
[INFO] 2021-07-12 19:01:34,302 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1461
[INFO] 2021-07-12 19:01:34,302 [run_pretraining.py:  558]:	worker_index: 7, step: 1461, cost: 6.148574, mlm loss: 6.148574, speed: 1.102504 steps/s, speed: 8.820036 samples/s, speed: 4515.858244 tokens/s, learning rate: 1.460e-05, loss_scalings: 8589.935547, pp_loss: 7.347717
[INFO] 2021-07-12 19:01:34,302 [run_pretraining.py:  512]:	********exe.run_1461******* 
[INFO] 2021-07-12 19:01:35,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:35,206 [run_pretraining.py:  534]:	loss/total_loss, 6.935645580291748, 1462
[INFO] 2021-07-12 19:01:35,207 [run_pretraining.py:  535]:	loss/mlm_loss, 6.935645580291748, 1462
[INFO] 2021-07-12 19:01:35,207 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4609999198000878e-05, 1462
[INFO] 2021-07-12 19:01:35,207 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1462
[INFO] 2021-07-12 19:01:35,207 [run_pretraining.py:  558]:	worker_index: 7, step: 1462, cost: 6.935646, mlm loss: 6.935646, speed: 1.106100 steps/s, speed: 8.848796 samples/s, speed: 4530.583699 tokens/s, learning rate: 1.461e-05, loss_scalings: 8589.935547, pp_loss: 7.204123
[INFO] 2021-07-12 19:01:35,207 [run_pretraining.py:  512]:	********exe.run_1462******* 
[INFO] 2021-07-12 19:01:36,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:36,134 [run_pretraining.py:  534]:	loss/total_loss, 7.5780158042907715, 1463
[INFO] 2021-07-12 19:01:36,135 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5780158042907715, 1463
[INFO] 2021-07-12 19:01:36,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4620000001741573e-05, 1463
[INFO] 2021-07-12 19:01:36,135 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1463
[INFO] 2021-07-12 19:01:36,135 [run_pretraining.py:  558]:	worker_index: 7, step: 1463, cost: 7.578016, mlm loss: 7.578016, speed: 1.078342 steps/s, speed: 8.626734 samples/s, speed: 4416.887753 tokens/s, learning rate: 1.462e-05, loss_scalings: 8589.935547, pp_loss: 7.502262
[INFO] 2021-07-12 19:01:36,135 [run_pretraining.py:  512]:	********exe.run_1463******* 
[INFO] 2021-07-12 19:01:37,053 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:37,053 [run_pretraining.py:  534]:	loss/total_loss, 7.844637870788574, 1464
[INFO] 2021-07-12 19:01:37,054 [run_pretraining.py:  535]:	loss/mlm_loss, 7.844637870788574, 1464
[INFO] 2021-07-12 19:01:37,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4629999895987567e-05, 1464
[INFO] 2021-07-12 19:01:37,054 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1464
[INFO] 2021-07-12 19:01:37,054 [run_pretraining.py:  558]:	worker_index: 7, step: 1464, cost: 7.844638, mlm loss: 7.844638, speed: 1.088926 steps/s, speed: 8.711407 samples/s, speed: 4460.240389 tokens/s, learning rate: 1.463e-05, loss_scalings: 8589.935547, pp_loss: 7.207340
[INFO] 2021-07-12 19:01:37,054 [run_pretraining.py:  512]:	********exe.run_1464******* 
[INFO] 2021-07-12 19:01:37,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:37,974 [run_pretraining.py:  534]:	loss/total_loss, 7.619274616241455, 1465
[INFO] 2021-07-12 19:01:37,974 [run_pretraining.py:  535]:	loss/mlm_loss, 7.619274616241455, 1465
[INFO] 2021-07-12 19:01:37,975 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.463999979023356e-05, 1465
[INFO] 2021-07-12 19:01:37,980 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1465
[INFO] 2021-07-12 19:01:37,985 [run_pretraining.py:  558]:	worker_index: 7, step: 1465, cost: 7.619275, mlm loss: 7.619275, speed: 1.086570 steps/s, speed: 8.692561 samples/s, speed: 4450.591116 tokens/s, learning rate: 1.464e-05, loss_scalings: 8589.935547, pp_loss: 7.080290
[INFO] 2021-07-12 19:01:38,001 [run_pretraining.py:  512]:	********exe.run_1465******* 
[INFO] 2021-07-12 19:01:38,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:38,897 [run_pretraining.py:  534]:	loss/total_loss, 7.774148464202881, 1466
[INFO] 2021-07-12 19:01:38,897 [run_pretraining.py:  535]:	loss/mlm_loss, 7.774148464202881, 1466
[INFO] 2021-07-12 19:01:38,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4650000593974255e-05, 1466
[INFO] 2021-07-12 19:01:38,897 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1466
[INFO] 2021-07-12 19:01:38,897 [run_pretraining.py:  558]:	worker_index: 7, step: 1466, cost: 7.774148, mlm loss: 7.774148, speed: 1.116897 steps/s, speed: 8.935175 samples/s, speed: 4574.809539 tokens/s, learning rate: 1.465e-05, loss_scalings: 8589.935547, pp_loss: 7.376144
[INFO] 2021-07-12 19:01:38,897 [run_pretraining.py:  512]:	********exe.run_1466******* 
[INFO] 2021-07-12 19:01:39,819 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  534]:	loss/total_loss, 7.082325458526611, 1467
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  535]:	loss/mlm_loss, 7.082325458526611, 1467
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4659998669230845e-05, 1467
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1467
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  558]:	worker_index: 7, step: 1467, cost: 7.082325, mlm loss: 7.082325, speed: 1.084145 steps/s, speed: 8.673164 samples/s, speed: 4440.659793 tokens/s, learning rate: 1.466e-05, loss_scalings: 8589.935547, pp_loss: 7.083377
[INFO] 2021-07-12 19:01:39,820 [run_pretraining.py:  512]:	********exe.run_1467******* 
[INFO] 2021-07-12 19:01:40,748 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:40,749 [run_pretraining.py:  534]:	loss/total_loss, 7.238901138305664, 1468
[INFO] 2021-07-12 19:01:40,749 [run_pretraining.py:  535]:	loss/mlm_loss, 7.238901138305664, 1468
[INFO] 2021-07-12 19:01:40,749 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.466999947297154e-05, 1468
[INFO] 2021-07-12 19:01:40,749 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1468
[INFO] 2021-07-12 19:01:40,749 [run_pretraining.py:  558]:	worker_index: 7, step: 1468, cost: 7.238901, mlm loss: 7.238901, speed: 1.077652 steps/s, speed: 8.621215 samples/s, speed: 4414.061999 tokens/s, learning rate: 1.467e-05, loss_scalings: 8589.935547, pp_loss: 7.168671
[INFO] 2021-07-12 19:01:40,749 [run_pretraining.py:  512]:	********exe.run_1468******* 
[INFO] 2021-07-12 19:01:41,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:41,678 [run_pretraining.py:  534]:	loss/total_loss, 7.2615509033203125, 1469
[INFO] 2021-07-12 19:01:41,679 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2615509033203125, 1469
[INFO] 2021-07-12 19:01:41,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4679999367217533e-05, 1469
[INFO] 2021-07-12 19:01:41,679 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1469
[INFO] 2021-07-12 19:01:41,679 [run_pretraining.py:  558]:	worker_index: 7, step: 1469, cost: 7.261551, mlm loss: 7.261551, speed: 1.076246 steps/s, speed: 8.609968 samples/s, speed: 4408.303682 tokens/s, learning rate: 1.468e-05, loss_scalings: 8589.935547, pp_loss: 7.178360
[INFO] 2021-07-12 19:01:41,679 [run_pretraining.py:  512]:	********exe.run_1469******* 
[INFO] 2021-07-12 19:01:42,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:42,600 [run_pretraining.py:  534]:	loss/total_loss, 7.034745216369629, 1470
[INFO] 2021-07-12 19:01:42,600 [run_pretraining.py:  535]:	loss/mlm_loss, 7.034745216369629, 1470
[INFO] 2021-07-12 19:01:42,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4689999261463527e-05, 1470
[INFO] 2021-07-12 19:01:42,600 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1470
[INFO] 2021-07-12 19:01:42,600 [run_pretraining.py:  558]:	worker_index: 7, step: 1470, cost: 7.034745, mlm loss: 7.034745, speed: 1.085706 steps/s, speed: 8.685648 samples/s, speed: 4447.052028 tokens/s, learning rate: 1.469e-05, loss_scalings: 8589.935547, pp_loss: 7.110520
[INFO] 2021-07-12 19:01:42,601 [run_pretraining.py:  512]:	********exe.run_1470******* 
[INFO] 2021-07-12 19:01:43,522 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:43,523 [run_pretraining.py:  534]:	loss/total_loss, 7.762046813964844, 1471
[INFO] 2021-07-12 19:01:43,523 [run_pretraining.py:  535]:	loss/mlm_loss, 7.762046813964844, 1471
[INFO] 2021-07-12 19:01:43,523 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4700000065204222e-05, 1471
[INFO] 2021-07-12 19:01:43,523 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1471
[INFO] 2021-07-12 19:01:43,523 [run_pretraining.py:  558]:	worker_index: 7, step: 1471, cost: 7.762047, mlm loss: 7.762047, speed: 1.084313 steps/s, speed: 8.674502 samples/s, speed: 4441.345149 tokens/s, learning rate: 1.470e-05, loss_scalings: 8589.935547, pp_loss: 7.448815
[INFO] 2021-07-12 19:01:43,523 [run_pretraining.py:  512]:	********exe.run_1471******* 
[INFO] 2021-07-12 19:01:44,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:44,448 [run_pretraining.py:  534]:	loss/total_loss, 7.876112461090088, 1472
[INFO] 2021-07-12 19:01:44,448 [run_pretraining.py:  535]:	loss/mlm_loss, 7.876112461090088, 1472
[INFO] 2021-07-12 19:01:44,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4709999959450215e-05, 1472
[INFO] 2021-07-12 19:01:44,448 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1472
[INFO] 2021-07-12 19:01:44,448 [run_pretraining.py:  558]:	worker_index: 7, step: 1472, cost: 7.876112, mlm loss: 7.876112, speed: 1.081851 steps/s, speed: 8.654810 samples/s, speed: 4431.262975 tokens/s, learning rate: 1.471e-05, loss_scalings: 8589.935547, pp_loss: 7.608094
[INFO] 2021-07-12 19:01:44,448 [run_pretraining.py:  512]:	********exe.run_1472******* 
[INFO] 2021-07-12 19:01:45,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:45,370 [run_pretraining.py:  534]:	loss/total_loss, 8.06954574584961, 1473
[INFO] 2021-07-12 19:01:45,370 [run_pretraining.py:  535]:	loss/mlm_loss, 8.06954574584961, 1473
[INFO] 2021-07-12 19:01:45,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4719999853696208e-05, 1473
[INFO] 2021-07-12 19:01:45,370 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1473
[INFO] 2021-07-12 19:01:45,370 [run_pretraining.py:  558]:	worker_index: 7, step: 1473, cost: 8.069546, mlm loss: 8.069546, speed: 1.085499 steps/s, speed: 8.683992 samples/s, speed: 4446.203807 tokens/s, learning rate: 1.472e-05, loss_scalings: 8589.935547, pp_loss: 7.472031
[INFO] 2021-07-12 19:01:45,370 [run_pretraining.py:  512]:	********exe.run_1473******* 
[INFO] 2021-07-12 19:01:46,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:46,294 [run_pretraining.py:  534]:	loss/total_loss, 7.221872806549072, 1474
[INFO] 2021-07-12 19:01:46,295 [run_pretraining.py:  535]:	loss/mlm_loss, 7.221872806549072, 1474
[INFO] 2021-07-12 19:01:46,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4729999747942202e-05, 1474
[INFO] 2021-07-12 19:01:46,295 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1474
[INFO] 2021-07-12 19:01:46,295 [run_pretraining.py:  558]:	worker_index: 7, step: 1474, cost: 7.221873, mlm loss: 7.221873, speed: 1.082422 steps/s, speed: 8.659376 samples/s, speed: 4433.600440 tokens/s, learning rate: 1.473e-05, loss_scalings: 8589.935547, pp_loss: 6.926818
[INFO] 2021-07-12 19:01:46,295 [run_pretraining.py:  512]:	********exe.run_1474******* 
[INFO] 2021-07-12 19:01:47,222 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:47,223 [run_pretraining.py:  534]:	loss/total_loss, 7.766265869140625, 1475
[INFO] 2021-07-12 19:01:47,223 [run_pretraining.py:  535]:	loss/mlm_loss, 7.766265869140625, 1475
[INFO] 2021-07-12 19:01:47,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4740000551682897e-05, 1475
[INFO] 2021-07-12 19:01:47,223 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1475
[INFO] 2021-07-12 19:01:47,223 [run_pretraining.py:  558]:	worker_index: 7, step: 1475, cost: 7.766266, mlm loss: 7.766266, speed: 1.077881 steps/s, speed: 8.623047 samples/s, speed: 4415.000112 tokens/s, learning rate: 1.474e-05, loss_scalings: 8589.935547, pp_loss: 7.544945
[INFO] 2021-07-12 19:01:47,223 [run_pretraining.py:  512]:	********exe.run_1475******* 
[INFO] 2021-07-12 19:01:48,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:48,139 [run_pretraining.py:  534]:	loss/total_loss, 7.336659908294678, 1476
[INFO] 2021-07-12 19:01:48,139 [run_pretraining.py:  535]:	loss/mlm_loss, 7.336659908294678, 1476
[INFO] 2021-07-12 19:01:48,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4749998626939487e-05, 1476
[INFO] 2021-07-12 19:01:48,139 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1476
[INFO] 2021-07-12 19:01:48,140 [run_pretraining.py:  558]:	worker_index: 7, step: 1476, cost: 7.336660, mlm loss: 7.336660, speed: 1.092009 steps/s, speed: 8.736072 samples/s, speed: 4472.868949 tokens/s, learning rate: 1.475e-05, loss_scalings: 8589.935547, pp_loss: 7.939862
[INFO] 2021-07-12 19:01:48,140 [run_pretraining.py:  512]:	********exe.run_1476******* 
[INFO] 2021-07-12 19:01:49,069 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:49,069 [run_pretraining.py:  534]:	loss/total_loss, 6.990778923034668, 1477
[INFO] 2021-07-12 19:01:49,069 [run_pretraining.py:  535]:	loss/mlm_loss, 6.990778923034668, 1477
[INFO] 2021-07-12 19:01:49,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4759999430680182e-05, 1477
[INFO] 2021-07-12 19:01:49,069 [run_pretraining.py:  539]:	lr/loss_scaling, 8589.935546875, 1477
[INFO] 2021-07-12 19:01:49,069 [run_pretraining.py:  558]:	worker_index: 7, step: 1477, cost: 6.990779, mlm loss: 6.990779, speed: 1.076221 steps/s, speed: 8.609767 samples/s, speed: 4408.200749 tokens/s, learning rate: 1.476e-05, loss_scalings: 8589.935547, pp_loss: 6.797167
[INFO] 2021-07-12 19:01:49,069 [run_pretraining.py:  512]:	********exe.run_1477******* 
[INFO] 2021-07-12 19:01:49,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:49,986 [run_pretraining.py:  534]:	loss/total_loss, 8.057760238647461, 1478
[INFO] 2021-07-12 19:01:49,986 [run_pretraining.py:  535]:	loss/mlm_loss, 8.057760238647461, 1478
[INFO] 2021-07-12 19:01:49,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4769999324926175e-05, 1478
[INFO] 2021-07-12 19:01:49,986 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1478
[INFO] 2021-07-12 19:01:49,986 [run_pretraining.py:  558]:	worker_index: 7, step: 1478, cost: 8.057760, mlm loss: 8.057760, speed: 1.091619 steps/s, speed: 8.732948 samples/s, speed: 4471.269450 tokens/s, learning rate: 1.477e-05, loss_scalings: 6871.948730, pp_loss: 7.444567
[INFO] 2021-07-12 19:01:49,986 [run_pretraining.py:  512]:	********exe.run_1478******* 
[INFO] 2021-07-12 19:01:50,917 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:50,917 [run_pretraining.py:  534]:	loss/total_loss, 7.978757858276367, 1479
[INFO] 2021-07-12 19:01:50,917 [run_pretraining.py:  535]:	loss/mlm_loss, 7.978757858276367, 1479
[INFO] 2021-07-12 19:01:50,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4779999219172169e-05, 1479
[INFO] 2021-07-12 19:01:50,917 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1479
[INFO] 2021-07-12 19:01:50,917 [run_pretraining.py:  558]:	worker_index: 7, step: 1479, cost: 7.978758, mlm loss: 7.978758, speed: 1.074471 steps/s, speed: 8.595770 samples/s, speed: 4401.034426 tokens/s, learning rate: 1.478e-05, loss_scalings: 6871.948730, pp_loss: 7.313435
[INFO] 2021-07-12 19:01:50,918 [run_pretraining.py:  512]:	********exe.run_1479******* 
[INFO] 2021-07-12 19:01:51,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  534]:	loss/total_loss, 7.864099025726318, 1480
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  535]:	loss/mlm_loss, 7.864099025726318, 1480
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4790000022912864e-05, 1480
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1480
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  558]:	worker_index: 7, step: 1480, cost: 7.864099, mlm loss: 7.864099, speed: 1.081106 steps/s, speed: 8.648845 samples/s, speed: 4428.208777 tokens/s, learning rate: 1.479e-05, loss_scalings: 6871.948730, pp_loss: 7.690168
[INFO] 2021-07-12 19:01:51,843 [run_pretraining.py:  512]:	********exe.run_1480******* 
[INFO] 2021-07-12 19:01:52,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:52,774 [run_pretraining.py:  534]:	loss/total_loss, 7.397705554962158, 1481
[INFO] 2021-07-12 19:01:52,774 [run_pretraining.py:  535]:	loss/mlm_loss, 7.397705554962158, 1481
[INFO] 2021-07-12 19:01:52,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4799999917158857e-05, 1481
[INFO] 2021-07-12 19:01:52,775 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1481
[INFO] 2021-07-12 19:01:52,775 [run_pretraining.py:  558]:	worker_index: 7, step: 1481, cost: 7.397706, mlm loss: 7.397706, speed: 1.074148 steps/s, speed: 8.593182 samples/s, speed: 4399.708968 tokens/s, learning rate: 1.480e-05, loss_scalings: 6871.948730, pp_loss: 7.489055
[INFO] 2021-07-12 19:01:52,775 [run_pretraining.py:  512]:	********exe.run_1481******* 
[INFO] 2021-07-12 19:01:53,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:53,701 [run_pretraining.py:  534]:	loss/total_loss, 7.515600204467773, 1482
[INFO] 2021-07-12 19:01:53,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.515600204467773, 1482
[INFO] 2021-07-12 19:01:53,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.480999981140485e-05, 1482
[INFO] 2021-07-12 19:01:53,701 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1482
[INFO] 2021-07-12 19:01:53,701 [run_pretraining.py:  558]:	worker_index: 7, step: 1482, cost: 7.515600, mlm loss: 7.515600, speed: 1.079975 steps/s, speed: 8.639797 samples/s, speed: 4423.576137 tokens/s, learning rate: 1.481e-05, loss_scalings: 6871.948730, pp_loss: 7.553888
[INFO] 2021-07-12 19:01:53,701 [run_pretraining.py:  512]:	********exe.run_1482******* 
[INFO] 2021-07-12 19:01:54,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:54,631 [run_pretraining.py:  534]:	loss/total_loss, 7.490979194641113, 1483
[INFO] 2021-07-12 19:01:54,631 [run_pretraining.py:  535]:	loss/mlm_loss, 7.490979194641113, 1483
[INFO] 2021-07-12 19:01:54,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4819999705650844e-05, 1483
[INFO] 2021-07-12 19:01:54,631 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1483
[INFO] 2021-07-12 19:01:54,631 [run_pretraining.py:  558]:	worker_index: 7, step: 1483, cost: 7.490979, mlm loss: 7.490979, speed: 1.076484 steps/s, speed: 8.611875 samples/s, speed: 4409.280087 tokens/s, learning rate: 1.482e-05, loss_scalings: 6871.948730, pp_loss: 7.315763
[INFO] 2021-07-12 19:01:54,631 [run_pretraining.py:  512]:	********exe.run_1483******* 
[INFO] 2021-07-12 19:01:55,557 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:55,557 [run_pretraining.py:  534]:	loss/total_loss, 7.521854877471924, 1484
[INFO] 2021-07-12 19:01:55,557 [run_pretraining.py:  535]:	loss/mlm_loss, 7.521854877471924, 1484
[INFO] 2021-07-12 19:01:55,558 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4830000509391539e-05, 1484
[INFO] 2021-07-12 19:01:55,558 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1484
[INFO] 2021-07-12 19:01:55,558 [run_pretraining.py:  558]:	worker_index: 7, step: 1484, cost: 7.521855, mlm loss: 7.521855, speed: 1.079688 steps/s, speed: 8.637502 samples/s, speed: 4422.400992 tokens/s, learning rate: 1.483e-05, loss_scalings: 6871.948730, pp_loss: 7.283459
[INFO] 2021-07-12 19:01:55,558 [run_pretraining.py:  512]:	********exe.run_1484******* 
[INFO] 2021-07-12 19:01:56,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:56,482 [run_pretraining.py:  534]:	loss/total_loss, 7.861989974975586, 1485
[INFO] 2021-07-12 19:01:56,482 [run_pretraining.py:  535]:	loss/mlm_loss, 7.861989974975586, 1485
[INFO] 2021-07-12 19:01:56,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4839998584648129e-05, 1485
[INFO] 2021-07-12 19:01:56,483 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1485
[INFO] 2021-07-12 19:01:56,483 [run_pretraining.py:  558]:	worker_index: 7, step: 1485, cost: 7.861990, mlm loss: 7.861990, speed: 1.081906 steps/s, speed: 8.655246 samples/s, speed: 4431.485865 tokens/s, learning rate: 1.484e-05, loss_scalings: 6871.948730, pp_loss: 7.426636
[INFO] 2021-07-12 19:01:56,483 [run_pretraining.py:  512]:	********exe.run_1485******* 
[INFO] 2021-07-12 19:01:57,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:57,408 [run_pretraining.py:  534]:	loss/total_loss, 7.609289169311523, 1486
[INFO] 2021-07-12 19:01:57,408 [run_pretraining.py:  535]:	loss/mlm_loss, 7.609289169311523, 1486
[INFO] 2021-07-12 19:01:57,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4849999388388824e-05, 1486
[INFO] 2021-07-12 19:01:57,408 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1486
[INFO] 2021-07-12 19:01:57,408 [run_pretraining.py:  558]:	worker_index: 7, step: 1486, cost: 7.609289, mlm loss: 7.609289, speed: 1.080812 steps/s, speed: 8.646498 samples/s, speed: 4427.007213 tokens/s, learning rate: 1.485e-05, loss_scalings: 6871.948730, pp_loss: 6.878223
[INFO] 2021-07-12 19:01:57,409 [run_pretraining.py:  512]:	********exe.run_1486******* 
[INFO] 2021-07-12 19:01:58,335 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:58,335 [run_pretraining.py:  534]:	loss/total_loss, 7.902848720550537, 1487
[INFO] 2021-07-12 19:01:58,335 [run_pretraining.py:  535]:	loss/mlm_loss, 7.902848720550537, 1487
[INFO] 2021-07-12 19:01:58,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4859999282634817e-05, 1487
[INFO] 2021-07-12 19:01:58,335 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1487
[INFO] 2021-07-12 19:01:58,335 [run_pretraining.py:  558]:	worker_index: 7, step: 1487, cost: 7.902849, mlm loss: 7.902849, speed: 1.079512 steps/s, speed: 8.636097 samples/s, speed: 4421.681638 tokens/s, learning rate: 1.486e-05, loss_scalings: 6871.948730, pp_loss: 7.607051
[INFO] 2021-07-12 19:01:58,336 [run_pretraining.py:  512]:	********exe.run_1487******* 
[INFO] 2021-07-12 19:01:59,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:01:59,264 [run_pretraining.py:  534]:	loss/total_loss, 7.799500942230225, 1488
[INFO] 2021-07-12 19:01:59,264 [run_pretraining.py:  535]:	loss/mlm_loss, 7.799500942230225, 1488
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.486999917688081e-05, 1488
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1488
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  558]:	worker_index: 7, step: 1488, cost: 7.799501, mlm loss: 7.799501, speed: 1.076911 steps/s, speed: 8.615291 samples/s, speed: 4411.029193 tokens/s, learning rate: 1.487e-05, loss_scalings: 6871.948730, pp_loss: 7.530452
[INFO] 2021-07-12 19:01:59,265 [run_pretraining.py:  512]:	********exe.run_1488******* 
[INFO] 2021-07-12 19:02:00,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:00,202 [run_pretraining.py:  534]:	loss/total_loss, 4.4812541007995605, 1489
[INFO] 2021-07-12 19:02:00,202 [run_pretraining.py:  535]:	loss/mlm_loss, 4.4812541007995605, 1489
[INFO] 2021-07-12 19:02:00,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4879999980621506e-05, 1489
[INFO] 2021-07-12 19:02:00,202 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1489
[INFO] 2021-07-12 19:02:00,202 [run_pretraining.py:  558]:	worker_index: 7, step: 1489, cost: 4.481254, mlm loss: 4.481254, speed: 1.067600 steps/s, speed: 8.540799 samples/s, speed: 4372.888896 tokens/s, learning rate: 1.488e-05, loss_scalings: 6871.948730, pp_loss: 6.740531
[INFO] 2021-07-12 19:02:00,202 [run_pretraining.py:  512]:	********exe.run_1489******* 
[INFO] 2021-07-12 19:02:01,144 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:01,145 [run_pretraining.py:  534]:	loss/total_loss, 7.893692493438721, 1490
[INFO] 2021-07-12 19:02:01,145 [run_pretraining.py:  535]:	loss/mlm_loss, 7.893692493438721, 1490
[INFO] 2021-07-12 19:02:01,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4889999874867499e-05, 1490
[INFO] 2021-07-12 19:02:01,145 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1490
[INFO] 2021-07-12 19:02:01,145 [run_pretraining.py:  558]:	worker_index: 7, step: 1490, cost: 7.893692, mlm loss: 7.893692, speed: 1.061301 steps/s, speed: 8.490410 samples/s, speed: 4347.089992 tokens/s, learning rate: 1.489e-05, loss_scalings: 6871.948730, pp_loss: 7.386515
[INFO] 2021-07-12 19:02:01,145 [run_pretraining.py:  512]:	********exe.run_1490******* 
[INFO] 2021-07-12 19:02:02,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:02,052 [run_pretraining.py:  534]:	loss/total_loss, 7.474667549133301, 1491
[INFO] 2021-07-12 19:02:02,052 [run_pretraining.py:  535]:	loss/mlm_loss, 7.474667549133301, 1491
[INFO] 2021-07-12 19:02:02,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4899999769113492e-05, 1491
[INFO] 2021-07-12 19:02:02,052 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1491
[INFO] 2021-07-12 19:02:02,052 [run_pretraining.py:  558]:	worker_index: 7, step: 1491, cost: 7.474668, mlm loss: 7.474668, speed: 1.103258 steps/s, speed: 8.826061 samples/s, speed: 4518.943060 tokens/s, learning rate: 1.490e-05, loss_scalings: 6871.948730, pp_loss: 7.565548
[INFO] 2021-07-12 19:02:02,052 [run_pretraining.py:  512]:	********exe.run_1491******* 
[INFO] 2021-07-12 19:02:02,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:02,961 [run_pretraining.py:  534]:	loss/total_loss, 7.595883846282959, 1492
[INFO] 2021-07-12 19:02:02,961 [run_pretraining.py:  535]:	loss/mlm_loss, 7.595883846282959, 1492
[INFO] 2021-07-12 19:02:02,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4910000572854187e-05, 1492
[INFO] 2021-07-12 19:02:02,961 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1492
[INFO] 2021-07-12 19:02:02,961 [run_pretraining.py:  558]:	worker_index: 7, step: 1492, cost: 7.595884, mlm loss: 7.595884, speed: 1.100685 steps/s, speed: 8.805477 samples/s, speed: 4508.404166 tokens/s, learning rate: 1.491e-05, loss_scalings: 6871.948730, pp_loss: 7.698350
[INFO] 2021-07-12 19:02:02,961 [run_pretraining.py:  512]:	********exe.run_1492******* 
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  534]:	loss/total_loss, 7.262229919433594, 1493
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  535]:	loss/mlm_loss, 7.262229919433594, 1493
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.492000046710018e-05, 1493
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1493
[INFO] 2021-07-12 19:02:03,869 [run_pretraining.py:  558]:	worker_index: 7, step: 1493, cost: 7.262230, mlm loss: 7.262230, speed: 1.101767 steps/s, speed: 8.814132 samples/s, speed: 4512.835723 tokens/s, learning rate: 1.492e-05, loss_scalings: 6871.948730, pp_loss: 7.335175
[INFO] 2021-07-12 19:02:03,870 [run_pretraining.py:  512]:	********exe.run_1493******* 
[INFO] 2021-07-12 19:02:04,777 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:04,778 [run_pretraining.py:  534]:	loss/total_loss, 7.919154644012451, 1494
[INFO] 2021-07-12 19:02:04,778 [run_pretraining.py:  535]:	loss/mlm_loss, 7.919154644012451, 1494
[INFO] 2021-07-12 19:02:04,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4929999451851472e-05, 1494
[INFO] 2021-07-12 19:02:04,778 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1494
[INFO] 2021-07-12 19:02:04,778 [run_pretraining.py:  558]:	worker_index: 7, step: 1494, cost: 7.919155, mlm loss: 7.919155, speed: 1.101456 steps/s, speed: 8.811646 samples/s, speed: 4511.562920 tokens/s, learning rate: 1.493e-05, loss_scalings: 6871.948730, pp_loss: 7.885634
[INFO] 2021-07-12 19:02:04,778 [run_pretraining.py:  512]:	********exe.run_1494******* 
[INFO] 2021-07-12 19:02:05,687 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:05,688 [run_pretraining.py:  534]:	loss/total_loss, 7.546509265899658, 1495
[INFO] 2021-07-12 19:02:05,688 [run_pretraining.py:  535]:	loss/mlm_loss, 7.546509265899658, 1495
[INFO] 2021-07-12 19:02:05,688 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4939999346097466e-05, 1495
[INFO] 2021-07-12 19:02:05,688 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1495
[INFO] 2021-07-12 19:02:05,688 [run_pretraining.py:  558]:	worker_index: 7, step: 1495, cost: 7.546509, mlm loss: 7.546509, speed: 1.099418 steps/s, speed: 8.795342 samples/s, speed: 4503.215101 tokens/s, learning rate: 1.494e-05, loss_scalings: 6871.948730, pp_loss: 7.578059
[INFO] 2021-07-12 19:02:05,688 [run_pretraining.py:  512]:	********exe.run_1495******* 
[INFO] 2021-07-12 19:02:06,594 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:06,594 [run_pretraining.py:  534]:	loss/total_loss, 7.398758888244629, 1496
[INFO] 2021-07-12 19:02:06,594 [run_pretraining.py:  535]:	loss/mlm_loss, 7.398758888244629, 1496
[INFO] 2021-07-12 19:02:06,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4949999240343459e-05, 1496
[INFO] 2021-07-12 19:02:06,594 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1496
[INFO] 2021-07-12 19:02:06,594 [run_pretraining.py:  558]:	worker_index: 7, step: 1496, cost: 7.398759, mlm loss: 7.398759, speed: 1.104360 steps/s, speed: 8.834880 samples/s, speed: 4523.458493 tokens/s, learning rate: 1.495e-05, loss_scalings: 6871.948730, pp_loss: 7.523600
[INFO] 2021-07-12 19:02:06,594 [run_pretraining.py:  512]:	********exe.run_1496******* 
[INFO] 2021-07-12 19:02:07,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:07,498 [run_pretraining.py:  534]:	loss/total_loss, 7.3359055519104, 1497
[INFO] 2021-07-12 19:02:07,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3359055519104, 1497
[INFO] 2021-07-12 19:02:07,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4959999134589452e-05, 1497
[INFO] 2021-07-12 19:02:07,499 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1497
[INFO] 2021-07-12 19:02:07,499 [run_pretraining.py:  558]:	worker_index: 7, step: 1497, cost: 7.335906, mlm loss: 7.335906, speed: 1.106739 steps/s, speed: 8.853912 samples/s, speed: 4533.202979 tokens/s, learning rate: 1.496e-05, loss_scalings: 6871.948730, pp_loss: 7.515985
[INFO] 2021-07-12 19:02:07,499 [run_pretraining.py:  512]:	********exe.run_1497******* 
[INFO] 2021-07-12 19:02:08,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:08,409 [run_pretraining.py:  534]:	loss/total_loss, 7.6089396476745605, 1498
[INFO] 2021-07-12 19:02:08,409 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6089396476745605, 1498
[INFO] 2021-07-12 19:02:08,409 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4969999938330147e-05, 1498
[INFO] 2021-07-12 19:02:08,409 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1498
[INFO] 2021-07-12 19:02:08,409 [run_pretraining.py:  558]:	worker_index: 7, step: 1498, cost: 7.608940, mlm loss: 7.608940, speed: 1.099214 steps/s, speed: 8.793715 samples/s, speed: 4502.381900 tokens/s, learning rate: 1.497e-05, loss_scalings: 6871.948730, pp_loss: 6.776743
[INFO] 2021-07-12 19:02:08,409 [run_pretraining.py:  512]:	********exe.run_1498******* 
[INFO] 2021-07-12 19:02:09,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:09,318 [run_pretraining.py:  534]:	loss/total_loss, 7.323038101196289, 1499
[INFO] 2021-07-12 19:02:09,318 [run_pretraining.py:  535]:	loss/mlm_loss, 7.323038101196289, 1499
[INFO] 2021-07-12 19:02:09,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.497999983257614e-05, 1499
[INFO] 2021-07-12 19:02:09,318 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1499
[INFO] 2021-07-12 19:02:09,318 [run_pretraining.py:  558]:	worker_index: 7, step: 1499, cost: 7.323038, mlm loss: 7.323038, speed: 1.100955 steps/s, speed: 8.807640 samples/s, speed: 4509.511831 tokens/s, learning rate: 1.498e-05, loss_scalings: 6871.948730, pp_loss: 6.588597
[INFO] 2021-07-12 19:02:09,318 [run_pretraining.py:  512]:	********exe.run_1499******* 
[INFO] 2021-07-12 19:02:10,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:10,227 [run_pretraining.py:  534]:	loss/total_loss, 7.583976745605469, 1500
[INFO] 2021-07-12 19:02:10,227 [run_pretraining.py:  535]:	loss/mlm_loss, 7.583976745605469, 1500
[INFO] 2021-07-12 19:02:10,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.4989999726822134e-05, 1500
[INFO] 2021-07-12 19:02:10,227 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1500
[INFO] 2021-07-12 19:02:10,227 [run_pretraining.py:  558]:	worker_index: 7, step: 1500, cost: 7.583977, mlm loss: 7.583977, speed: 1.100567 steps/s, speed: 8.804537 samples/s, speed: 4507.922691 tokens/s, learning rate: 1.499e-05, loss_scalings: 6871.948730, pp_loss: 7.308063
[INFO] 2021-07-12 19:02:10,227 [run_pretraining.py:  512]:	********exe.run_1500******* 
[INFO] 2021-07-12 19:02:11,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:11,135 [run_pretraining.py:  534]:	loss/total_loss, 7.296102523803711, 1501
[INFO] 2021-07-12 19:02:11,135 [run_pretraining.py:  535]:	loss/mlm_loss, 7.296102523803711, 1501
[INFO] 2021-07-12 19:02:11,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.500000053056283e-05, 1501
[INFO] 2021-07-12 19:02:11,135 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1501
[INFO] 2021-07-12 19:02:11,135 [run_pretraining.py:  558]:	worker_index: 7, step: 1501, cost: 7.296103, mlm loss: 7.296103, speed: 1.101923 steps/s, speed: 8.815385 samples/s, speed: 4513.477136 tokens/s, learning rate: 1.500e-05, loss_scalings: 6871.948730, pp_loss: 7.295490
[INFO] 2021-07-12 19:02:11,135 [run_pretraining.py:  512]:	********exe.run_1501******* 
[INFO] 2021-07-12 19:02:12,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:12,040 [run_pretraining.py:  534]:	loss/total_loss, 7.086097717285156, 1502
[INFO] 2021-07-12 19:02:12,040 [run_pretraining.py:  535]:	loss/mlm_loss, 7.086097717285156, 1502
[INFO] 2021-07-12 19:02:12,040 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5009998605819419e-05, 1502
[INFO] 2021-07-12 19:02:12,040 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1502
[INFO] 2021-07-12 19:02:12,040 [run_pretraining.py:  558]:	worker_index: 7, step: 1502, cost: 7.086098, mlm loss: 7.086098, speed: 1.105859 steps/s, speed: 8.846874 samples/s, speed: 4529.599413 tokens/s, learning rate: 1.501e-05, loss_scalings: 6871.948730, pp_loss: 7.411833
[INFO] 2021-07-12 19:02:12,040 [run_pretraining.py:  512]:	********exe.run_1502******* 
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  534]:	loss/total_loss, 7.183969020843506, 1503
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183969020843506, 1503
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5019999409560114e-05, 1503
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1503
[INFO] 2021-07-12 19:02:12,942 [run_pretraining.py:  558]:	worker_index: 7, step: 1503, cost: 7.183969, mlm loss: 7.183969, speed: 1.109251 steps/s, speed: 8.874005 samples/s, speed: 4543.490550 tokens/s, learning rate: 1.502e-05, loss_scalings: 6871.948730, pp_loss: 7.287517
[INFO] 2021-07-12 19:02:12,943 [run_pretraining.py:  512]:	********exe.run_1503******* 
[INFO] 2021-07-12 19:02:13,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:13,855 [run_pretraining.py:  534]:	loss/total_loss, 7.14941930770874, 1504
[INFO] 2021-07-12 19:02:13,855 [run_pretraining.py:  535]:	loss/mlm_loss, 7.14941930770874, 1504
[INFO] 2021-07-12 19:02:13,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5029999303806107e-05, 1504
[INFO] 2021-07-12 19:02:13,855 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1504
[INFO] 2021-07-12 19:02:13,855 [run_pretraining.py:  558]:	worker_index: 7, step: 1504, cost: 7.149419, mlm loss: 7.149419, speed: 1.096613 steps/s, speed: 8.772907 samples/s, speed: 4491.728590 tokens/s, learning rate: 1.503e-05, loss_scalings: 6871.948730, pp_loss: 7.452747
[INFO] 2021-07-12 19:02:13,855 [run_pretraining.py:  512]:	********exe.run_1504******* 
[INFO] 2021-07-12 19:02:14,766 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:14,766 [run_pretraining.py:  534]:	loss/total_loss, 7.003521919250488, 1505
[INFO] 2021-07-12 19:02:14,766 [run_pretraining.py:  535]:	loss/mlm_loss, 7.003521919250488, 1505
[INFO] 2021-07-12 19:02:14,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.50399991980521e-05, 1505
[INFO] 2021-07-12 19:02:14,766 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1505
[INFO] 2021-07-12 19:02:14,767 [run_pretraining.py:  558]:	worker_index: 7, step: 1505, cost: 7.003522, mlm loss: 7.003522, speed: 1.097841 steps/s, speed: 8.782731 samples/s, speed: 4496.758196 tokens/s, learning rate: 1.504e-05, loss_scalings: 6871.948730, pp_loss: 7.304315
[INFO] 2021-07-12 19:02:14,767 [run_pretraining.py:  512]:	********exe.run_1505******* 
[INFO] 2021-07-12 19:02:15,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:15,675 [run_pretraining.py:  534]:	loss/total_loss, 7.696109771728516, 1506
[INFO] 2021-07-12 19:02:15,675 [run_pretraining.py:  535]:	loss/mlm_loss, 7.696109771728516, 1506
[INFO] 2021-07-12 19:02:15,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5050000001792796e-05, 1506
[INFO] 2021-07-12 19:02:15,676 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1506
[INFO] 2021-07-12 19:02:15,676 [run_pretraining.py:  558]:	worker_index: 7, step: 1506, cost: 7.696110, mlm loss: 7.696110, speed: 1.100714 steps/s, speed: 8.805715 samples/s, speed: 4508.526030 tokens/s, learning rate: 1.505e-05, loss_scalings: 6871.948730, pp_loss: 7.568893
[INFO] 2021-07-12 19:02:15,676 [run_pretraining.py:  512]:	********exe.run_1506******* 
[INFO] 2021-07-12 19:02:16,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  534]:	loss/total_loss, 7.157471179962158, 1507
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  535]:	loss/mlm_loss, 7.157471179962158, 1507
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.505999989603879e-05, 1507
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1507
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  558]:	worker_index: 7, step: 1507, cost: 7.157471, mlm loss: 7.157471, speed: 1.105283 steps/s, speed: 8.842267 samples/s, speed: 4527.240780 tokens/s, learning rate: 1.506e-05, loss_scalings: 6871.948730, pp_loss: 7.038471
[INFO] 2021-07-12 19:02:16,581 [run_pretraining.py:  512]:	********exe.run_1507******* 
[INFO] 2021-07-12 19:02:17,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:17,505 [run_pretraining.py:  534]:	loss/total_loss, 3.9171736240386963, 1508
[INFO] 2021-07-12 19:02:17,505 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9171736240386963, 1508
[INFO] 2021-07-12 19:02:17,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5069999790284783e-05, 1508
[INFO] 2021-07-12 19:02:17,506 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1508
[INFO] 2021-07-12 19:02:17,506 [run_pretraining.py:  558]:	worker_index: 7, step: 1508, cost: 3.917174, mlm loss: 3.917174, speed: 1.082368 steps/s, speed: 8.658947 samples/s, speed: 4433.380769 tokens/s, learning rate: 1.507e-05, loss_scalings: 6871.948730, pp_loss: 4.899175
[INFO] 2021-07-12 19:02:17,506 [run_pretraining.py:  512]:	********exe.run_1508******* 
[INFO] 2021-07-12 19:02:18,432 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:18,433 [run_pretraining.py:  534]:	loss/total_loss, 7.0417022705078125, 1509
[INFO] 2021-07-12 19:02:18,433 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0417022705078125, 1509
[INFO] 2021-07-12 19:02:18,433 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5079999684530776e-05, 1509
[INFO] 2021-07-12 19:02:18,433 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1509
[INFO] 2021-07-12 19:02:18,433 [run_pretraining.py:  558]:	worker_index: 7, step: 1509, cost: 7.041702, mlm loss: 7.041702, speed: 1.078915 steps/s, speed: 8.631323 samples/s, speed: 4419.237355 tokens/s, learning rate: 1.508e-05, loss_scalings: 6871.948730, pp_loss: 6.941134
[INFO] 2021-07-12 19:02:18,433 [run_pretraining.py:  512]:	********exe.run_1509******* 
[INFO] 2021-07-12 19:02:19,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:19,331 [run_pretraining.py:  534]:	loss/total_loss, 7.1072797775268555, 1510
[INFO] 2021-07-12 19:02:19,331 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1072797775268555, 1510
[INFO] 2021-07-12 19:02:19,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5090000488271471e-05, 1510
[INFO] 2021-07-12 19:02:19,331 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1510
[INFO] 2021-07-12 19:02:19,331 [run_pretraining.py:  558]:	worker_index: 7, step: 1510, cost: 7.107280, mlm loss: 7.107280, speed: 1.114481 steps/s, speed: 8.915849 samples/s, speed: 4564.914666 tokens/s, learning rate: 1.509e-05, loss_scalings: 6871.948730, pp_loss: 7.214330
[INFO] 2021-07-12 19:02:19,331 [run_pretraining.py:  512]:	********exe.run_1510******* 
[INFO] 2021-07-12 19:02:20,232 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:20,233 [run_pretraining.py:  534]:	loss/total_loss, 7.597446441650391, 1511
[INFO] 2021-07-12 19:02:20,233 [run_pretraining.py:  535]:	loss/mlm_loss, 7.597446441650391, 1511
[INFO] 2021-07-12 19:02:20,233 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5099998563528061e-05, 1511
[INFO] 2021-07-12 19:02:20,233 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1511
[INFO] 2021-07-12 19:02:20,233 [run_pretraining.py:  558]:	worker_index: 7, step: 1511, cost: 7.597446, mlm loss: 7.597446, speed: 1.109463 steps/s, speed: 8.875707 samples/s, speed: 4544.361876 tokens/s, learning rate: 1.510e-05, loss_scalings: 6871.948730, pp_loss: 7.318568
[INFO] 2021-07-12 19:02:20,233 [run_pretraining.py:  512]:	********exe.run_1511******* 
[INFO] 2021-07-12 19:02:21,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:21,146 [run_pretraining.py:  534]:	loss/total_loss, 6.87064790725708, 1512
[INFO] 2021-07-12 19:02:21,146 [run_pretraining.py:  535]:	loss/mlm_loss, 6.87064790725708, 1512
[INFO] 2021-07-12 19:02:21,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5109999367268756e-05, 1512
[INFO] 2021-07-12 19:02:21,146 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1512
[INFO] 2021-07-12 19:02:21,146 [run_pretraining.py:  558]:	worker_index: 7, step: 1512, cost: 6.870648, mlm loss: 6.870648, speed: 1.095950 steps/s, speed: 8.767596 samples/s, speed: 4489.009208 tokens/s, learning rate: 1.511e-05, loss_scalings: 6871.948730, pp_loss: 7.324427
[INFO] 2021-07-12 19:02:21,146 [run_pretraining.py:  512]:	********exe.run_1512******* 
[INFO] 2021-07-12 19:02:22,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:22,043 [run_pretraining.py:  534]:	loss/total_loss, 6.939035415649414, 1513
[INFO] 2021-07-12 19:02:22,043 [run_pretraining.py:  535]:	loss/mlm_loss, 6.939035415649414, 1513
[INFO] 2021-07-12 19:02:22,043 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.511999926151475e-05, 1513
[INFO] 2021-07-12 19:02:22,044 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1513
[INFO] 2021-07-12 19:02:22,044 [run_pretraining.py:  558]:	worker_index: 7, step: 1513, cost: 6.939035, mlm loss: 6.939035, speed: 1.115126 steps/s, speed: 8.921007 samples/s, speed: 4567.555588 tokens/s, learning rate: 1.512e-05, loss_scalings: 6871.948730, pp_loss: 7.364905
[INFO] 2021-07-12 19:02:22,044 [run_pretraining.py:  512]:	********exe.run_1513******* 
[INFO] 2021-07-12 19:02:22,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:22,972 [run_pretraining.py:  534]:	loss/total_loss, 7.766933917999268, 1514
[INFO] 2021-07-12 19:02:22,972 [run_pretraining.py:  535]:	loss/mlm_loss, 7.766933917999268, 1514
[INFO] 2021-07-12 19:02:22,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5129999155760743e-05, 1514
[INFO] 2021-07-12 19:02:22,972 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1514
[INFO] 2021-07-12 19:02:22,972 [run_pretraining.py:  558]:	worker_index: 7, step: 1514, cost: 7.766934, mlm loss: 7.766934, speed: 1.077971 steps/s, speed: 8.623767 samples/s, speed: 4415.368886 tokens/s, learning rate: 1.513e-05, loss_scalings: 6871.948730, pp_loss: 7.548813
[INFO] 2021-07-12 19:02:22,972 [run_pretraining.py:  512]:	********exe.run_1514******* 
[INFO] 2021-07-12 19:02:23,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:23,899 [run_pretraining.py:  534]:	loss/total_loss, 7.368145942687988, 1515
[INFO] 2021-07-12 19:02:23,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.368145942687988, 1515
[INFO] 2021-07-12 19:02:23,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5139999959501438e-05, 1515
[INFO] 2021-07-12 19:02:23,899 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1515
[INFO] 2021-07-12 19:02:23,900 [run_pretraining.py:  558]:	worker_index: 7, step: 1515, cost: 7.368146, mlm loss: 7.368146, speed: 1.078772 steps/s, speed: 8.630177 samples/s, speed: 4418.650857 tokens/s, learning rate: 1.514e-05, loss_scalings: 6871.948730, pp_loss: 7.581267
[INFO] 2021-07-12 19:02:23,900 [run_pretraining.py:  512]:	********exe.run_1515******* 
[INFO] 2021-07-12 19:02:24,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:24,797 [run_pretraining.py:  534]:	loss/total_loss, 7.680656433105469, 1516
[INFO] 2021-07-12 19:02:24,797 [run_pretraining.py:  535]:	loss/mlm_loss, 7.680656433105469, 1516
[INFO] 2021-07-12 19:02:24,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5149999853747431e-05, 1516
[INFO] 2021-07-12 19:02:24,797 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1516
[INFO] 2021-07-12 19:02:24,797 [run_pretraining.py:  558]:	worker_index: 7, step: 1516, cost: 7.680656, mlm loss: 7.680656, speed: 1.115245 steps/s, speed: 8.921958 samples/s, speed: 4568.042599 tokens/s, learning rate: 1.515e-05, loss_scalings: 6871.948730, pp_loss: 7.087818
[INFO] 2021-07-12 19:02:24,797 [run_pretraining.py:  512]:	********exe.run_1516******* 
[INFO] 2021-07-12 19:02:25,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:25,692 [run_pretraining.py:  534]:	loss/total_loss, 7.648942470550537, 1517
[INFO] 2021-07-12 19:02:25,692 [run_pretraining.py:  535]:	loss/mlm_loss, 7.648942470550537, 1517
[INFO] 2021-07-12 19:02:25,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5159999747993425e-05, 1517
[INFO] 2021-07-12 19:02:25,692 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1517
[INFO] 2021-07-12 19:02:25,692 [run_pretraining.py:  558]:	worker_index: 7, step: 1517, cost: 7.648942, mlm loss: 7.648942, speed: 1.117946 steps/s, speed: 8.943565 samples/s, speed: 4579.105363 tokens/s, learning rate: 1.516e-05, loss_scalings: 6871.948730, pp_loss: 7.145706
[INFO] 2021-07-12 19:02:25,692 [run_pretraining.py:  512]:	********exe.run_1517******* 
[INFO] 2021-07-12 19:02:26,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:26,585 [run_pretraining.py:  534]:	loss/total_loss, 7.692489147186279, 1518
[INFO] 2021-07-12 19:02:26,585 [run_pretraining.py:  535]:	loss/mlm_loss, 7.692489147186279, 1518
[INFO] 2021-07-12 19:02:26,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.517000055173412e-05, 1518
[INFO] 2021-07-12 19:02:26,585 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1518
[INFO] 2021-07-12 19:02:26,585 [run_pretraining.py:  558]:	worker_index: 7, step: 1518, cost: 7.692489, mlm loss: 7.692489, speed: 1.120177 steps/s, speed: 8.961415 samples/s, speed: 4588.244439 tokens/s, learning rate: 1.517e-05, loss_scalings: 6871.948730, pp_loss: 7.421846
[INFO] 2021-07-12 19:02:26,585 [run_pretraining.py:  512]:	********exe.run_1518******* 
[INFO] 2021-07-12 19:02:27,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  534]:	loss/total_loss, 7.5314717292785645, 1519
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5314717292785645, 1519
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5180000445980113e-05, 1519
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1519
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  558]:	worker_index: 7, step: 1519, cost: 7.531472, mlm loss: 7.531472, speed: 1.101286 steps/s, speed: 8.810286 samples/s, speed: 4510.866383 tokens/s, learning rate: 1.518e-05, loss_scalings: 6871.948730, pp_loss: 7.411375
[INFO] 2021-07-12 19:02:27,494 [run_pretraining.py:  512]:	********exe.run_1519******* 
[INFO] 2021-07-12 19:02:28,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  534]:	loss/total_loss, 7.954750061035156, 1520
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.954750061035156, 1520
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5189998521236703e-05, 1520
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1520
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  558]:	worker_index: 7, step: 1520, cost: 7.954750, mlm loss: 7.954750, speed: 1.099948 steps/s, speed: 8.799581 samples/s, speed: 4505.385704 tokens/s, learning rate: 1.519e-05, loss_scalings: 6871.948730, pp_loss: 6.587813
[INFO] 2021-07-12 19:02:28,404 [run_pretraining.py:  512]:	********exe.run_1520******* 
[INFO] 2021-07-12 19:02:29,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  534]:	loss/total_loss, 7.326663494110107, 1521
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  535]:	loss/mlm_loss, 7.326663494110107, 1521
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5199999324977398e-05, 1521
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1521
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  558]:	worker_index: 7, step: 1521, cost: 7.326663, mlm loss: 7.326663, speed: 1.099615 steps/s, speed: 8.796922 samples/s, speed: 4504.023813 tokens/s, learning rate: 1.520e-05, loss_scalings: 6871.948730, pp_loss: 7.522155
[INFO] 2021-07-12 19:02:29,314 [run_pretraining.py:  512]:	********exe.run_1521******* 
[INFO] 2021-07-12 19:02:30,222 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:30,223 [run_pretraining.py:  534]:	loss/total_loss, 6.5357818603515625, 1522
[INFO] 2021-07-12 19:02:30,223 [run_pretraining.py:  535]:	loss/mlm_loss, 6.5357818603515625, 1522
[INFO] 2021-07-12 19:02:30,223 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5209999219223391e-05, 1522
[INFO] 2021-07-12 19:02:30,223 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1522
[INFO] 2021-07-12 19:02:30,223 [run_pretraining.py:  558]:	worker_index: 7, step: 1522, cost: 6.535782, mlm loss: 6.535782, speed: 1.100927 steps/s, speed: 8.807418 samples/s, speed: 4509.398199 tokens/s, learning rate: 1.521e-05, loss_scalings: 6871.948730, pp_loss: 7.150177
[INFO] 2021-07-12 19:02:30,223 [run_pretraining.py:  512]:	********exe.run_1522******* 
[INFO] 2021-07-12 19:02:31,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:31,129 [run_pretraining.py:  534]:	loss/total_loss, 7.390848159790039, 1523
[INFO] 2021-07-12 19:02:31,129 [run_pretraining.py:  535]:	loss/mlm_loss, 7.390848159790039, 1523
[INFO] 2021-07-12 19:02:31,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5219999113469385e-05, 1523
[INFO] 2021-07-12 19:02:31,129 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1523
[INFO] 2021-07-12 19:02:31,129 [run_pretraining.py:  558]:	worker_index: 7, step: 1523, cost: 7.390848, mlm loss: 7.390848, speed: 1.103979 steps/s, speed: 8.831836 samples/s, speed: 4521.899977 tokens/s, learning rate: 1.522e-05, loss_scalings: 6871.948730, pp_loss: 7.577548
[INFO] 2021-07-12 19:02:31,129 [run_pretraining.py:  512]:	********exe.run_1523******* 
[INFO] 2021-07-12 19:02:32,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:32,042 [run_pretraining.py:  534]:	loss/total_loss, 7.259598255157471, 1524
[INFO] 2021-07-12 19:02:32,042 [run_pretraining.py:  535]:	loss/mlm_loss, 7.259598255157471, 1524
[INFO] 2021-07-12 19:02:32,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.522999991721008e-05, 1524
[INFO] 2021-07-12 19:02:32,042 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1524
[INFO] 2021-07-12 19:02:32,042 [run_pretraining.py:  558]:	worker_index: 7, step: 1524, cost: 7.259598, mlm loss: 7.259598, speed: 1.096554 steps/s, speed: 8.772433 samples/s, speed: 4491.485507 tokens/s, learning rate: 1.523e-05, loss_scalings: 6871.948730, pp_loss: 7.478590
[INFO] 2021-07-12 19:02:32,042 [run_pretraining.py:  512]:	********exe.run_1524******* 
[INFO] 2021-07-12 19:02:32,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:32,944 [run_pretraining.py:  534]:	loss/total_loss, 7.276882171630859, 1525
[INFO] 2021-07-12 19:02:32,944 [run_pretraining.py:  535]:	loss/mlm_loss, 7.276882171630859, 1525
[INFO] 2021-07-12 19:02:32,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5239999811456073e-05, 1525
[INFO] 2021-07-12 19:02:32,945 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1525
[INFO] 2021-07-12 19:02:32,945 [run_pretraining.py:  558]:	worker_index: 7, step: 1525, cost: 7.276882, mlm loss: 7.276882, speed: 1.108565 steps/s, speed: 8.868517 samples/s, speed: 4540.680548 tokens/s, learning rate: 1.524e-05, loss_scalings: 6871.948730, pp_loss: 6.545759
[INFO] 2021-07-12 19:02:32,945 [run_pretraining.py:  512]:	********exe.run_1525******* 
[INFO] 2021-07-12 19:02:33,853 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:33,854 [run_pretraining.py:  534]:	loss/total_loss, 6.9781880378723145, 1526
[INFO] 2021-07-12 19:02:33,854 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9781880378723145, 1526
[INFO] 2021-07-12 19:02:33,854 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5249999705702066e-05, 1526
[INFO] 2021-07-12 19:02:33,854 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1526
[INFO] 2021-07-12 19:02:33,854 [run_pretraining.py:  558]:	worker_index: 7, step: 1526, cost: 6.978188, mlm loss: 6.978188, speed: 1.100379 steps/s, speed: 8.803028 samples/s, speed: 4507.150416 tokens/s, learning rate: 1.525e-05, loss_scalings: 6871.948730, pp_loss: 6.315885
[INFO] 2021-07-12 19:02:33,854 [run_pretraining.py:  512]:	********exe.run_1526******* 
[INFO] 2021-07-12 19:02:34,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:34,758 [run_pretraining.py:  534]:	loss/total_loss, 7.349867820739746, 1527
[INFO] 2021-07-12 19:02:34,758 [run_pretraining.py:  535]:	loss/mlm_loss, 7.349867820739746, 1527
[INFO] 2021-07-12 19:02:34,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.526000050944276e-05, 1527
[INFO] 2021-07-12 19:02:34,759 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1527
[INFO] 2021-07-12 19:02:34,759 [run_pretraining.py:  558]:	worker_index: 7, step: 1527, cost: 7.349868, mlm loss: 7.349868, speed: 1.106380 steps/s, speed: 8.851039 samples/s, speed: 4531.732175 tokens/s, learning rate: 1.526e-05, loss_scalings: 6871.948730, pp_loss: 7.336374
[INFO] 2021-07-12 19:02:34,759 [run_pretraining.py:  512]:	********exe.run_1527******* 
[INFO] 2021-07-12 19:02:35,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:35,663 [run_pretraining.py:  534]:	loss/total_loss, 7.541813850402832, 1528
[INFO] 2021-07-12 19:02:35,663 [run_pretraining.py:  535]:	loss/mlm_loss, 7.541813850402832, 1528
[INFO] 2021-07-12 19:02:35,663 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5269999494194053e-05, 1528
[INFO] 2021-07-12 19:02:35,663 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1528
[INFO] 2021-07-12 19:02:35,663 [run_pretraining.py:  558]:	worker_index: 7, step: 1528, cost: 7.541814, mlm loss: 7.541814, speed: 1.105899 steps/s, speed: 8.847196 samples/s, speed: 4529.764227 tokens/s, learning rate: 1.527e-05, loss_scalings: 6871.948730, pp_loss: 7.508090
[INFO] 2021-07-12 19:02:35,664 [run_pretraining.py:  512]:	********exe.run_1528******* 
[INFO] 2021-07-12 19:02:36,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:36,567 [run_pretraining.py:  534]:	loss/total_loss, 7.204719066619873, 1529
[INFO] 2021-07-12 19:02:36,567 [run_pretraining.py:  535]:	loss/mlm_loss, 7.204719066619873, 1529
[INFO] 2021-07-12 19:02:36,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5279998478945345e-05, 1529
[INFO] 2021-07-12 19:02:36,567 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1529
[INFO] 2021-07-12 19:02:36,567 [run_pretraining.py:  558]:	worker_index: 7, step: 1529, cost: 7.204719, mlm loss: 7.204719, speed: 1.107511 steps/s, speed: 8.860091 samples/s, speed: 4536.366645 tokens/s, learning rate: 1.528e-05, loss_scalings: 6871.948730, pp_loss: 7.308880
[INFO] 2021-07-12 19:02:36,567 [run_pretraining.py:  512]:	********exe.run_1529******* 
[INFO] 2021-07-12 19:02:37,470 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:37,471 [run_pretraining.py:  534]:	loss/total_loss, 7.097240447998047, 1530
[INFO] 2021-07-12 19:02:37,471 [run_pretraining.py:  535]:	loss/mlm_loss, 7.097240447998047, 1530
[INFO] 2021-07-12 19:02:37,471 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.528999928268604e-05, 1530
[INFO] 2021-07-12 19:02:37,471 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1530
[INFO] 2021-07-12 19:02:37,471 [run_pretraining.py:  558]:	worker_index: 7, step: 1530, cost: 7.097240, mlm loss: 7.097240, speed: 1.106985 steps/s, speed: 8.855877 samples/s, speed: 4534.209175 tokens/s, learning rate: 1.529e-05, loss_scalings: 6871.948730, pp_loss: 7.256307
[INFO] 2021-07-12 19:02:37,471 [run_pretraining.py:  512]:	********exe.run_1530******* 
[INFO] 2021-07-12 19:02:38,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:38,377 [run_pretraining.py:  534]:	loss/total_loss, 7.086544036865234, 1531
[INFO] 2021-07-12 19:02:38,377 [run_pretraining.py:  535]:	loss/mlm_loss, 7.086544036865234, 1531
[INFO] 2021-07-12 19:02:38,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5300000086426735e-05, 1531
[INFO] 2021-07-12 19:02:38,378 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1531
[INFO] 2021-07-12 19:02:38,378 [run_pretraining.py:  558]:	worker_index: 7, step: 1531, cost: 7.086544, mlm loss: 7.086544, speed: 1.103881 steps/s, speed: 8.831046 samples/s, speed: 4521.495343 tokens/s, learning rate: 1.530e-05, loss_scalings: 6871.948730, pp_loss: 7.408583
[INFO] 2021-07-12 19:02:38,378 [run_pretraining.py:  512]:	********exe.run_1531******* 
[INFO] 2021-07-12 19:02:39,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:39,284 [run_pretraining.py:  534]:	loss/total_loss, 6.873856067657471, 1532
[INFO] 2021-07-12 19:02:39,285 [run_pretraining.py:  535]:	loss/mlm_loss, 6.873856067657471, 1532
[INFO] 2021-07-12 19:02:39,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5309999071178026e-05, 1532
[INFO] 2021-07-12 19:02:39,285 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1532
[INFO] 2021-07-12 19:02:39,285 [run_pretraining.py:  558]:	worker_index: 7, step: 1532, cost: 6.873856, mlm loss: 6.873856, speed: 1.103149 steps/s, speed: 8.825190 samples/s, speed: 4518.497360 tokens/s, learning rate: 1.531e-05, loss_scalings: 6871.948730, pp_loss: 7.447203
[INFO] 2021-07-12 19:02:39,285 [run_pretraining.py:  512]:	********exe.run_1532******* 
[INFO] 2021-07-12 19:02:40,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:40,190 [run_pretraining.py:  534]:	loss/total_loss, 7.132639408111572, 1533
[INFO] 2021-07-12 19:02:40,190 [run_pretraining.py:  535]:	loss/mlm_loss, 7.132639408111572, 1533
[INFO] 2021-07-12 19:02:40,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.531999987491872e-05, 1533
[INFO] 2021-07-12 19:02:40,190 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1533
[INFO] 2021-07-12 19:02:40,190 [run_pretraining.py:  558]:	worker_index: 7, step: 1533, cost: 7.132639, mlm loss: 7.132639, speed: 1.105394 steps/s, speed: 8.843150 samples/s, speed: 4527.692979 tokens/s, learning rate: 1.532e-05, loss_scalings: 6871.948730, pp_loss: 7.398931
[INFO] 2021-07-12 19:02:40,190 [run_pretraining.py:  512]:	********exe.run_1533******* 
[INFO] 2021-07-12 19:02:41,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:41,109 [run_pretraining.py:  534]:	loss/total_loss, 7.617163181304932, 1534
[INFO] 2021-07-12 19:02:41,110 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617163181304932, 1534
[INFO] 2021-07-12 19:02:41,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5330000678659417e-05, 1534
[INFO] 2021-07-12 19:02:41,110 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1534
[INFO] 2021-07-12 19:02:41,110 [run_pretraining.py:  558]:	worker_index: 7, step: 1534, cost: 7.617163, mlm loss: 7.617163, speed: 1.088057 steps/s, speed: 8.704458 samples/s, speed: 4456.682476 tokens/s, learning rate: 1.533e-05, loss_scalings: 6871.948730, pp_loss: 7.580783
[INFO] 2021-07-12 19:02:41,110 [run_pretraining.py:  512]:	********exe.run_1534******* 
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  534]:	loss/total_loss, 7.717843532562256, 1535
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  535]:	loss/mlm_loss, 7.717843532562256, 1535
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.533999966341071e-05, 1535
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1535
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  558]:	worker_index: 7, step: 1535, cost: 7.717844, mlm loss: 7.717844, speed: 1.098947 steps/s, speed: 8.791577 samples/s, speed: 4501.287169 tokens/s, learning rate: 1.534e-05, loss_scalings: 6871.948730, pp_loss: 7.442976
[INFO] 2021-07-12 19:02:42,020 [run_pretraining.py:  512]:	********exe.run_1535******* 
[INFO] 2021-07-12 19:02:42,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  534]:	loss/total_loss, 7.284006595611572, 1536
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  535]:	loss/mlm_loss, 7.284006595611572, 1536
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5350000467151403e-05, 1536
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1536
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  558]:	worker_index: 7, step: 1536, cost: 7.284007, mlm loss: 7.284007, speed: 1.111069 steps/s, speed: 8.888549 samples/s, speed: 4550.937024 tokens/s, learning rate: 1.535e-05, loss_scalings: 6871.948730, pp_loss: 7.465261
[INFO] 2021-07-12 19:02:42,921 [run_pretraining.py:  512]:	********exe.run_1536******* 
[INFO] 2021-07-12 19:02:43,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:43,822 [run_pretraining.py:  534]:	loss/total_loss, 7.350417137145996, 1537
[INFO] 2021-07-12 19:02:43,822 [run_pretraining.py:  535]:	loss/mlm_loss, 7.350417137145996, 1537
[INFO] 2021-07-12 19:02:43,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5359999451902695e-05, 1537
[INFO] 2021-07-12 19:02:43,822 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1537
[INFO] 2021-07-12 19:02:43,822 [run_pretraining.py:  558]:	worker_index: 7, step: 1537, cost: 7.350417, mlm loss: 7.350417, speed: 1.110545 steps/s, speed: 8.884357 samples/s, speed: 4548.790969 tokens/s, learning rate: 1.536e-05, loss_scalings: 6871.948730, pp_loss: 7.462599
[INFO] 2021-07-12 19:02:43,822 [run_pretraining.py:  512]:	********exe.run_1537******* 
[INFO] 2021-07-12 19:02:44,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:44,727 [run_pretraining.py:  534]:	loss/total_loss, 7.1515116691589355, 1538
[INFO] 2021-07-12 19:02:44,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1515116691589355, 1538
[INFO] 2021-07-12 19:02:44,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5369998436653987e-05, 1538
[INFO] 2021-07-12 19:02:44,727 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1538
[INFO] 2021-07-12 19:02:44,727 [run_pretraining.py:  558]:	worker_index: 7, step: 1538, cost: 7.151512, mlm loss: 7.151512, speed: 1.106030 steps/s, speed: 8.848239 samples/s, speed: 4530.298164 tokens/s, learning rate: 1.537e-05, loss_scalings: 6871.948730, pp_loss: 7.469195
[INFO] 2021-07-12 19:02:44,727 [run_pretraining.py:  512]:	********exe.run_1538******* 
[INFO] 2021-07-12 19:02:45,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:45,634 [run_pretraining.py:  534]:	loss/total_loss, 6.680784225463867, 1539
[INFO] 2021-07-12 19:02:45,634 [run_pretraining.py:  535]:	loss/mlm_loss, 6.680784225463867, 1539
[INFO] 2021-07-12 19:02:45,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.537999924039468e-05, 1539
[INFO] 2021-07-12 19:02:45,635 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1539
[INFO] 2021-07-12 19:02:45,635 [run_pretraining.py:  558]:	worker_index: 7, step: 1539, cost: 6.680784, mlm loss: 6.680784, speed: 1.102440 steps/s, speed: 8.819521 samples/s, speed: 4515.594739 tokens/s, learning rate: 1.538e-05, loss_scalings: 6871.948730, pp_loss: 7.387421
[INFO] 2021-07-12 19:02:45,635 [run_pretraining.py:  512]:	********exe.run_1539******* 
[INFO] 2021-07-12 19:02:46,544 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:46,545 [run_pretraining.py:  534]:	loss/total_loss, 7.151519298553467, 1540
[INFO] 2021-07-12 19:02:46,545 [run_pretraining.py:  535]:	loss/mlm_loss, 7.151519298553467, 1540
[INFO] 2021-07-12 19:02:46,545 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5390000044135377e-05, 1540
[INFO] 2021-07-12 19:02:46,545 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1540
[INFO] 2021-07-12 19:02:46,545 [run_pretraining.py:  558]:	worker_index: 7, step: 1540, cost: 7.151519, mlm loss: 7.151519, speed: 1.099253 steps/s, speed: 8.794021 samples/s, speed: 4502.538839 tokens/s, learning rate: 1.539e-05, loss_scalings: 6871.948730, pp_loss: 7.432379
[INFO] 2021-07-12 19:02:46,545 [run_pretraining.py:  512]:	********exe.run_1540******* 
[INFO] 2021-07-12 19:02:47,452 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:47,453 [run_pretraining.py:  534]:	loss/total_loss, 7.3955817222595215, 1541
[INFO] 2021-07-12 19:02:47,453 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3955817222595215, 1541
[INFO] 2021-07-12 19:02:47,453 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.539999902888667e-05, 1541
[INFO] 2021-07-12 19:02:47,453 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1541
[INFO] 2021-07-12 19:02:47,453 [run_pretraining.py:  558]:	worker_index: 7, step: 1541, cost: 7.395582, mlm loss: 7.395582, speed: 1.101915 steps/s, speed: 8.815318 samples/s, speed: 4513.442749 tokens/s, learning rate: 1.540e-05, loss_scalings: 6871.948730, pp_loss: 7.356972
[INFO] 2021-07-12 19:02:47,453 [run_pretraining.py:  512]:	********exe.run_1541******* 
[INFO] 2021-07-12 19:02:48,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:48,356 [run_pretraining.py:  534]:	loss/total_loss, 6.919192790985107, 1542
[INFO] 2021-07-12 19:02:48,356 [run_pretraining.py:  535]:	loss/mlm_loss, 6.919192790985107, 1542
[INFO] 2021-07-12 19:02:48,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5409999832627364e-05, 1542
[INFO] 2021-07-12 19:02:48,356 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1542
[INFO] 2021-07-12 19:02:48,356 [run_pretraining.py:  558]:	worker_index: 7, step: 1542, cost: 6.919193, mlm loss: 6.919193, speed: 1.108093 steps/s, speed: 8.864745 samples/s, speed: 4538.749188 tokens/s, learning rate: 1.541e-05, loss_scalings: 6871.948730, pp_loss: 7.185676
[INFO] 2021-07-12 19:02:48,356 [run_pretraining.py:  512]:	********exe.run_1542******* 
[INFO] 2021-07-12 19:02:49,398 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:49,399 [run_pretraining.py:  534]:	loss/total_loss, 8.571916580200195, 1543
[INFO] 2021-07-12 19:02:49,399 [run_pretraining.py:  535]:	loss/mlm_loss, 8.571916580200195, 1543
[INFO] 2021-07-12 19:02:49,399 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.542000063636806e-05, 1543
[INFO] 2021-07-12 19:02:49,399 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1543
[INFO] 2021-07-12 19:02:49,399 [run_pretraining.py:  558]:	worker_index: 7, step: 1543, cost: 8.571917, mlm loss: 8.571917, speed: 0.959621 steps/s, speed: 7.676972 samples/s, speed: 3930.609612 tokens/s, learning rate: 1.542e-05, loss_scalings: 6871.948730, pp_loss: 7.560059
[INFO] 2021-07-12 19:02:49,399 [run_pretraining.py:  512]:	********exe.run_1543******* 
[INFO] 2021-07-12 19:02:50,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:50,454 [run_pretraining.py:  534]:	loss/total_loss, 7.011434555053711, 1544
[INFO] 2021-07-12 19:02:50,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.011434555053711, 1544
[INFO] 2021-07-12 19:02:50,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.542999962111935e-05, 1544
[INFO] 2021-07-12 19:02:50,455 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1544
[INFO] 2021-07-12 19:02:50,455 [run_pretraining.py:  558]:	worker_index: 7, step: 1544, cost: 7.011435, mlm loss: 7.011435, speed: 0.947759 steps/s, speed: 7.582069 samples/s, speed: 3882.019421 tokens/s, learning rate: 1.543e-05, loss_scalings: 6871.948730, pp_loss: 7.188407
[INFO] 2021-07-12 19:02:50,455 [run_pretraining.py:  512]:	********exe.run_1544******* 
[INFO] 2021-07-12 19:02:51,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:51,510 [run_pretraining.py:  534]:	loss/total_loss, 6.691286087036133, 1545
[INFO] 2021-07-12 19:02:51,510 [run_pretraining.py:  535]:	loss/mlm_loss, 6.691286087036133, 1545
[INFO] 2021-07-12 19:02:51,510 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5440000424860045e-05, 1545
[INFO] 2021-07-12 19:02:51,510 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1545
[INFO] 2021-07-12 19:02:51,510 [run_pretraining.py:  558]:	worker_index: 7, step: 1545, cost: 6.691286, mlm loss: 6.691286, speed: 0.948340 steps/s, speed: 7.586724 samples/s, speed: 3884.402464 tokens/s, learning rate: 1.544e-05, loss_scalings: 6871.948730, pp_loss: 7.538040
[INFO] 2021-07-12 19:02:51,510 [run_pretraining.py:  512]:	********exe.run_1545******* 
[INFO] 2021-07-12 19:02:52,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:52,571 [run_pretraining.py:  534]:	loss/total_loss, 7.669743537902832, 1546
[INFO] 2021-07-12 19:02:52,571 [run_pretraining.py:  535]:	loss/mlm_loss, 7.669743537902832, 1546
[INFO] 2021-07-12 19:02:52,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5449999409611337e-05, 1546
[INFO] 2021-07-12 19:02:52,571 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1546
[INFO] 2021-07-12 19:02:52,571 [run_pretraining.py:  558]:	worker_index: 7, step: 1546, cost: 7.669744, mlm loss: 7.669744, speed: 0.943109 steps/s, speed: 7.544874 samples/s, speed: 3862.975567 tokens/s, learning rate: 1.545e-05, loss_scalings: 6871.948730, pp_loss: 7.701812
[INFO] 2021-07-12 19:02:52,571 [run_pretraining.py:  512]:	********exe.run_1546******* 
[INFO] 2021-07-12 19:02:53,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:53,657 [run_pretraining.py:  534]:	loss/total_loss, 7.4880828857421875, 1547
[INFO] 2021-07-12 19:02:53,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4880828857421875, 1547
[INFO] 2021-07-12 19:02:53,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.545999839436263e-05, 1547
[INFO] 2021-07-12 19:02:53,657 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1547
[INFO] 2021-07-12 19:02:53,657 [run_pretraining.py:  558]:	worker_index: 7, step: 1547, cost: 7.488083, mlm loss: 7.488083, speed: 0.921137 steps/s, speed: 7.369099 samples/s, speed: 3772.978544 tokens/s, learning rate: 1.546e-05, loss_scalings: 6871.948730, pp_loss: 7.641701
[INFO] 2021-07-12 19:02:53,657 [run_pretraining.py:  512]:	********exe.run_1547******* 
[INFO] 2021-07-12 19:02:54,714 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:54,714 [run_pretraining.py:  534]:	loss/total_loss, 7.055260181427002, 1548
[INFO] 2021-07-12 19:02:54,714 [run_pretraining.py:  535]:	loss/mlm_loss, 7.055260181427002, 1548
[INFO] 2021-07-12 19:02:54,715 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5469999198103324e-05, 1548
[INFO] 2021-07-12 19:02:54,715 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1548
[INFO] 2021-07-12 19:02:54,715 [run_pretraining.py:  558]:	worker_index: 7, step: 1548, cost: 7.055260, mlm loss: 7.055260, speed: 0.946229 steps/s, speed: 7.569831 samples/s, speed: 3875.753230 tokens/s, learning rate: 1.547e-05, loss_scalings: 6871.948730, pp_loss: 7.287302
[INFO] 2021-07-12 19:02:54,715 [run_pretraining.py:  512]:	********exe.run_1548******* 
[INFO] 2021-07-12 19:02:55,778 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:55,778 [run_pretraining.py:  534]:	loss/total_loss, 7.558141231536865, 1549
[INFO] 2021-07-12 19:02:55,778 [run_pretraining.py:  535]:	loss/mlm_loss, 7.558141231536865, 1549
[INFO] 2021-07-12 19:02:55,779 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.548000000184402e-05, 1549
[INFO] 2021-07-12 19:02:55,779 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1549
[INFO] 2021-07-12 19:02:55,779 [run_pretraining.py:  558]:	worker_index: 7, step: 1549, cost: 7.558141, mlm loss: 7.558141, speed: 0.940427 steps/s, speed: 7.523419 samples/s, speed: 3851.990334 tokens/s, learning rate: 1.548e-05, loss_scalings: 6871.948730, pp_loss: 7.534560
[INFO] 2021-07-12 19:02:55,779 [run_pretraining.py:  512]:	********exe.run_1549******* 
[INFO] 2021-07-12 19:02:56,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:56,752 [run_pretraining.py:  534]:	loss/total_loss, 7.81501579284668, 1550
[INFO] 2021-07-12 19:02:56,752 [run_pretraining.py:  535]:	loss/mlm_loss, 7.81501579284668, 1550
[INFO] 2021-07-12 19:02:56,752 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.548999898659531e-05, 1550
[INFO] 2021-07-12 19:02:56,753 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1550
[INFO] 2021-07-12 19:02:56,753 [run_pretraining.py:  558]:	worker_index: 7, step: 1550, cost: 7.815016, mlm loss: 7.815016, speed: 1.027447 steps/s, speed: 8.219579 samples/s, speed: 4208.424208 tokens/s, learning rate: 1.549e-05, loss_scalings: 6871.948730, pp_loss: 7.391752
[INFO] 2021-07-12 19:02:56,753 [run_pretraining.py:  512]:	********exe.run_1550******* 
[INFO] 2021-07-12 19:02:57,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:57,713 [run_pretraining.py:  534]:	loss/total_loss, 7.019865036010742, 1551
[INFO] 2021-07-12 19:02:57,713 [run_pretraining.py:  535]:	loss/mlm_loss, 7.019865036010742, 1551
[INFO] 2021-07-12 19:02:57,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5499999790336005e-05, 1551
[INFO] 2021-07-12 19:02:57,713 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1551
[INFO] 2021-07-12 19:02:57,713 [run_pretraining.py:  558]:	worker_index: 7, step: 1551, cost: 7.019865, mlm loss: 7.019865, speed: 1.041725 steps/s, speed: 8.333797 samples/s, speed: 4266.903869 tokens/s, learning rate: 1.550e-05, loss_scalings: 6871.948730, pp_loss: 7.283182
[INFO] 2021-07-12 19:02:57,713 [run_pretraining.py:  512]:	********exe.run_1551******* 
[INFO] 2021-07-12 19:02:58,674 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:58,674 [run_pretraining.py:  534]:	loss/total_loss, 7.7659406661987305, 1552
[INFO] 2021-07-12 19:02:58,674 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7659406661987305, 1552
[INFO] 2021-07-12 19:02:58,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.55100005940767e-05, 1552
[INFO] 2021-07-12 19:02:58,674 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1552
[INFO] 2021-07-12 19:02:58,675 [run_pretraining.py:  558]:	worker_index: 7, step: 1552, cost: 7.765941, mlm loss: 7.765941, speed: 1.040949 steps/s, speed: 8.327596 samples/s, speed: 4263.729085 tokens/s, learning rate: 1.551e-05, loss_scalings: 6871.948730, pp_loss: 7.557887
[INFO] 2021-07-12 19:02:58,675 [run_pretraining.py:  512]:	********exe.run_1552******* 
[INFO] 2021-07-12 19:02:59,631 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:02:59,631 [run_pretraining.py:  534]:	loss/total_loss, 7.852069854736328, 1553
[INFO] 2021-07-12 19:02:59,631 [run_pretraining.py:  535]:	loss/mlm_loss, 7.852069854736328, 1553
[INFO] 2021-07-12 19:02:59,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5519999578827992e-05, 1553
[INFO] 2021-07-12 19:02:59,631 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1553
[INFO] 2021-07-12 19:02:59,631 [run_pretraining.py:  558]:	worker_index: 7, step: 1553, cost: 7.852070, mlm loss: 7.852070, speed: 1.045756 steps/s, speed: 8.366047 samples/s, speed: 4283.415994 tokens/s, learning rate: 1.552e-05, loss_scalings: 6871.948730, pp_loss: 7.594008
[INFO] 2021-07-12 19:02:59,631 [run_pretraining.py:  512]:	********exe.run_1553******* 
[INFO] 2021-07-12 19:03:00,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  534]:	loss/total_loss, 7.2475199699401855, 1554
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2475199699401855, 1554
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5530000382568687e-05, 1554
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1554
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  558]:	worker_index: 7, step: 1554, cost: 7.247520, mlm loss: 7.247520, speed: 1.044887 steps/s, speed: 8.359094 samples/s, speed: 4279.856194 tokens/s, learning rate: 1.553e-05, loss_scalings: 6871.948730, pp_loss: 6.159413
[INFO] 2021-07-12 19:03:00,589 [run_pretraining.py:  512]:	********exe.run_1554******* 
[INFO] 2021-07-12 19:03:01,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:01,500 [run_pretraining.py:  534]:	loss/total_loss, 6.935075759887695, 1555
[INFO] 2021-07-12 19:03:01,500 [run_pretraining.py:  535]:	loss/mlm_loss, 6.935075759887695, 1555
[INFO] 2021-07-12 19:03:01,500 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.553999936731998e-05, 1555
[INFO] 2021-07-12 19:03:01,500 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1555
[INFO] 2021-07-12 19:03:01,500 [run_pretraining.py:  558]:	worker_index: 7, step: 1555, cost: 6.935076, mlm loss: 6.935076, speed: 1.098324 steps/s, speed: 8.786590 samples/s, speed: 4498.734082 tokens/s, learning rate: 1.554e-05, loss_scalings: 6871.948730, pp_loss: 6.889761
[INFO] 2021-07-12 19:03:01,500 [run_pretraining.py:  512]:	********exe.run_1555******* 
[INFO] 2021-07-12 19:03:02,431 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:02,432 [run_pretraining.py:  534]:	loss/total_loss, 7.223288536071777, 1556
[INFO] 2021-07-12 19:03:02,432 [run_pretraining.py:  535]:	loss/mlm_loss, 7.223288536071777, 1556
[INFO] 2021-07-12 19:03:02,432 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.554999835207127e-05, 1556
[INFO] 2021-07-12 19:03:02,432 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1556
[INFO] 2021-07-12 19:03:02,432 [run_pretraining.py:  558]:	worker_index: 7, step: 1556, cost: 7.223289, mlm loss: 7.223289, speed: 1.074128 steps/s, speed: 8.593028 samples/s, speed: 4399.630096 tokens/s, learning rate: 1.555e-05, loss_scalings: 6871.948730, pp_loss: 7.340469
[INFO] 2021-07-12 19:03:02,432 [run_pretraining.py:  512]:	********exe.run_1556******* 
[INFO] 2021-07-12 19:03:03,343 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:03,343 [run_pretraining.py:  534]:	loss/total_loss, 6.913677215576172, 1557
[INFO] 2021-07-12 19:03:03,343 [run_pretraining.py:  535]:	loss/mlm_loss, 6.913677215576172, 1557
[INFO] 2021-07-12 19:03:03,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5559999155811965e-05, 1557
[INFO] 2021-07-12 19:03:03,343 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1557
[INFO] 2021-07-12 19:03:03,344 [run_pretraining.py:  558]:	worker_index: 7, step: 1557, cost: 6.913677, mlm loss: 6.913677, speed: 1.097740 steps/s, speed: 8.781922 samples/s, speed: 4496.343927 tokens/s, learning rate: 1.556e-05, loss_scalings: 6871.948730, pp_loss: 7.236977
[INFO] 2021-07-12 19:03:03,344 [run_pretraining.py:  512]:	********exe.run_1557******* 
[INFO] 2021-07-12 19:03:04,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:04,252 [run_pretraining.py:  534]:	loss/total_loss, 7.689560890197754, 1558
[INFO] 2021-07-12 19:03:04,253 [run_pretraining.py:  535]:	loss/mlm_loss, 7.689560890197754, 1558
[INFO] 2021-07-12 19:03:04,253 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.556999995955266e-05, 1558
[INFO] 2021-07-12 19:03:04,253 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1558
[INFO] 2021-07-12 19:03:04,253 [run_pretraining.py:  558]:	worker_index: 7, step: 1558, cost: 7.689561, mlm loss: 7.689561, speed: 1.100570 steps/s, speed: 8.804560 samples/s, speed: 4507.934520 tokens/s, learning rate: 1.557e-05, loss_scalings: 6871.948730, pp_loss: 6.768648
[INFO] 2021-07-12 19:03:04,253 [run_pretraining.py:  512]:	********exe.run_1558******* 
[INFO] 2021-07-12 19:03:05,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:05,159 [run_pretraining.py:  534]:	loss/total_loss, 6.763447284698486, 1559
[INFO] 2021-07-12 19:03:05,159 [run_pretraining.py:  535]:	loss/mlm_loss, 6.763447284698486, 1559
[INFO] 2021-07-12 19:03:05,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5579998944303952e-05, 1559
[INFO] 2021-07-12 19:03:05,159 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1559
[INFO] 2021-07-12 19:03:05,159 [run_pretraining.py:  558]:	worker_index: 7, step: 1559, cost: 6.763447, mlm loss: 6.763447, speed: 1.103828 steps/s, speed: 8.830620 samples/s, speed: 4521.277585 tokens/s, learning rate: 1.558e-05, loss_scalings: 6871.948730, pp_loss: 7.174221
[INFO] 2021-07-12 19:03:05,159 [run_pretraining.py:  512]:	********exe.run_1559******* 
[INFO] 2021-07-12 19:03:06,093 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:06,093 [run_pretraining.py:  534]:	loss/total_loss, 6.990266799926758, 1560
[INFO] 2021-07-12 19:03:06,093 [run_pretraining.py:  535]:	loss/mlm_loss, 6.990266799926758, 1560
[INFO] 2021-07-12 19:03:06,093 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5589999748044647e-05, 1560
[INFO] 2021-07-12 19:03:06,094 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1560
[INFO] 2021-07-12 19:03:06,094 [run_pretraining.py:  558]:	worker_index: 7, step: 1560, cost: 6.990267, mlm loss: 6.990267, speed: 1.071107 steps/s, speed: 8.568854 samples/s, speed: 4387.253166 tokens/s, learning rate: 1.559e-05, loss_scalings: 6871.948730, pp_loss: 7.418623
[INFO] 2021-07-12 19:03:06,094 [run_pretraining.py:  512]:	********exe.run_1560******* 
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  534]:	loss/total_loss, 7.299232482910156, 1561
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  535]:	loss/mlm_loss, 7.299232482910156, 1561
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5600000551785342e-05, 1561
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1561
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  558]:	worker_index: 7, step: 1561, cost: 7.299232, mlm loss: 7.299232, speed: 1.085669 steps/s, speed: 8.685352 samples/s, speed: 4446.900084 tokens/s, learning rate: 1.560e-05, loss_scalings: 6871.948730, pp_loss: 6.949998
[INFO] 2021-07-12 19:03:07,015 [run_pretraining.py:  512]:	********exe.run_1561******* 
[INFO] 2021-07-12 19:03:07,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:07,923 [run_pretraining.py:  534]:	loss/total_loss, 7.457056999206543, 1562
[INFO] 2021-07-12 19:03:07,923 [run_pretraining.py:  535]:	loss/mlm_loss, 7.457056999206543, 1562
[INFO] 2021-07-12 19:03:07,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5609999536536634e-05, 1562
[INFO] 2021-07-12 19:03:07,923 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1562
[INFO] 2021-07-12 19:03:07,923 [run_pretraining.py:  558]:	worker_index: 7, step: 1562, cost: 7.457057, mlm loss: 7.457057, speed: 1.102139 steps/s, speed: 8.817113 samples/s, speed: 4514.361898 tokens/s, learning rate: 1.561e-05, loss_scalings: 6871.948730, pp_loss: 7.450437
[INFO] 2021-07-12 19:03:07,923 [run_pretraining.py:  512]:	********exe.run_1562******* 
[INFO] 2021-07-12 19:03:08,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:08,821 [run_pretraining.py:  534]:	loss/total_loss, 7.277011871337891, 1563
[INFO] 2021-07-12 19:03:08,821 [run_pretraining.py:  535]:	loss/mlm_loss, 7.277011871337891, 1563
[INFO] 2021-07-12 19:03:08,821 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.562000034027733e-05, 1563
[INFO] 2021-07-12 19:03:08,821 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1563
[INFO] 2021-07-12 19:03:08,821 [run_pretraining.py:  558]:	worker_index: 7, step: 1563, cost: 7.277012, mlm loss: 7.277012, speed: 1.114604 steps/s, speed: 8.916835 samples/s, speed: 4565.419312 tokens/s, learning rate: 1.562e-05, loss_scalings: 6871.948730, pp_loss: 6.950510
[INFO] 2021-07-12 19:03:08,821 [run_pretraining.py:  512]:	********exe.run_1563******* 
[INFO] 2021-07-12 19:03:09,730 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:09,731 [run_pretraining.py:  534]:	loss/total_loss, 7.0465850830078125, 1564
[INFO] 2021-07-12 19:03:09,731 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0465850830078125, 1564
[INFO] 2021-07-12 19:03:09,731 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.562999932502862e-05, 1564
[INFO] 2021-07-12 19:03:09,731 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1564
[INFO] 2021-07-12 19:03:09,731 [run_pretraining.py:  558]:	worker_index: 7, step: 1564, cost: 7.046585, mlm loss: 7.046585, speed: 1.099836 steps/s, speed: 8.798691 samples/s, speed: 4504.929680 tokens/s, learning rate: 1.563e-05, loss_scalings: 6871.948730, pp_loss: 7.536120
[INFO] 2021-07-12 19:03:09,731 [run_pretraining.py:  512]:	********exe.run_1564******* 
[INFO] 2021-07-12 19:03:10,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:10,638 [run_pretraining.py:  534]:	loss/total_loss, 7.722474575042725, 1565
[INFO] 2021-07-12 19:03:10,638 [run_pretraining.py:  535]:	loss/mlm_loss, 7.722474575042725, 1565
[INFO] 2021-07-12 19:03:10,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5639998309779912e-05, 1565
[INFO] 2021-07-12 19:03:10,638 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1565
[INFO] 2021-07-12 19:03:10,638 [run_pretraining.py:  558]:	worker_index: 7, step: 1565, cost: 7.722475, mlm loss: 7.722475, speed: 1.103130 steps/s, speed: 8.825044 samples/s, speed: 4518.422492 tokens/s, learning rate: 1.564e-05, loss_scalings: 6871.948730, pp_loss: 7.596200
[INFO] 2021-07-12 19:03:10,638 [run_pretraining.py:  512]:	********exe.run_1565******* 
[INFO] 2021-07-12 19:03:11,545 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:11,545 [run_pretraining.py:  534]:	loss/total_loss, 6.905879020690918, 1566
[INFO] 2021-07-12 19:03:11,545 [run_pretraining.py:  535]:	loss/mlm_loss, 6.905879020690918, 1566
[INFO] 2021-07-12 19:03:11,545 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5649999113520607e-05, 1566
[INFO] 2021-07-12 19:03:11,545 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1566
[INFO] 2021-07-12 19:03:11,545 [run_pretraining.py:  558]:	worker_index: 7, step: 1566, cost: 6.905879, mlm loss: 6.905879, speed: 1.103203 steps/s, speed: 8.825624 samples/s, speed: 4518.719605 tokens/s, learning rate: 1.565e-05, loss_scalings: 6871.948730, pp_loss: 7.076056
[INFO] 2021-07-12 19:03:11,545 [run_pretraining.py:  512]:	********exe.run_1566******* 
[INFO] 2021-07-12 19:03:12,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:12,450 [run_pretraining.py:  534]:	loss/total_loss, 7.637981414794922, 1567
[INFO] 2021-07-12 19:03:12,450 [run_pretraining.py:  535]:	loss/mlm_loss, 7.637981414794922, 1567
[INFO] 2021-07-12 19:03:12,450 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5659999917261302e-05, 1567
[INFO] 2021-07-12 19:03:12,450 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1567
[INFO] 2021-07-12 19:03:12,450 [run_pretraining.py:  558]:	worker_index: 7, step: 1567, cost: 7.637981, mlm loss: 7.637981, speed: 1.105755 steps/s, speed: 8.846039 samples/s, speed: 4529.171908 tokens/s, learning rate: 1.566e-05, loss_scalings: 6871.948730, pp_loss: 7.386861
[INFO] 2021-07-12 19:03:12,450 [run_pretraining.py:  512]:	********exe.run_1567******* 
[INFO] 2021-07-12 19:03:13,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:13,358 [run_pretraining.py:  534]:	loss/total_loss, 7.616619110107422, 1568
[INFO] 2021-07-12 19:03:13,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.616619110107422, 1568
[INFO] 2021-07-12 19:03:13,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5669998902012594e-05, 1568
[INFO] 2021-07-12 19:03:13,358 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1568
[INFO] 2021-07-12 19:03:13,358 [run_pretraining.py:  558]:	worker_index: 7, step: 1568, cost: 7.616619, mlm loss: 7.616619, speed: 1.102287 steps/s, speed: 8.818299 samples/s, speed: 4514.969336 tokens/s, learning rate: 1.567e-05, loss_scalings: 6871.948730, pp_loss: 7.240033
[INFO] 2021-07-12 19:03:13,358 [run_pretraining.py:  512]:	********exe.run_1568******* 
[INFO] 2021-07-12 19:03:14,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:14,268 [run_pretraining.py:  534]:	loss/total_loss, 7.401304244995117, 1569
[INFO] 2021-07-12 19:03:14,269 [run_pretraining.py:  535]:	loss/mlm_loss, 7.401304244995117, 1569
[INFO] 2021-07-12 19:03:14,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.567999970575329e-05, 1569
[INFO] 2021-07-12 19:03:14,269 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1569
[INFO] 2021-07-12 19:03:14,269 [run_pretraining.py:  558]:	worker_index: 7, step: 1569, cost: 7.401304, mlm loss: 7.401304, speed: 1.099038 steps/s, speed: 8.792304 samples/s, speed: 4501.659884 tokens/s, learning rate: 1.568e-05, loss_scalings: 6871.948730, pp_loss: 7.594724
[INFO] 2021-07-12 19:03:14,269 [run_pretraining.py:  512]:	********exe.run_1569******* 
[INFO] 2021-07-12 19:03:15,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:15,169 [run_pretraining.py:  534]:	loss/total_loss, 7.1157121658325195, 1570
[INFO] 2021-07-12 19:03:15,169 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1157121658325195, 1570
[INFO] 2021-07-12 19:03:15,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5690000509493984e-05, 1570
[INFO] 2021-07-12 19:03:15,169 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1570
[INFO] 2021-07-12 19:03:15,169 [run_pretraining.py:  558]:	worker_index: 7, step: 1570, cost: 7.115712, mlm loss: 7.115712, speed: 1.111669 steps/s, speed: 8.893355 samples/s, speed: 4553.397657 tokens/s, learning rate: 1.569e-05, loss_scalings: 6871.948730, pp_loss: 6.410386
[INFO] 2021-07-12 19:03:15,169 [run_pretraining.py:  512]:	********exe.run_1570******* 
[INFO] 2021-07-12 19:03:16,078 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:16,079 [run_pretraining.py:  534]:	loss/total_loss, 7.987435340881348, 1571
[INFO] 2021-07-12 19:03:16,079 [run_pretraining.py:  535]:	loss/mlm_loss, 7.987435340881348, 1571
[INFO] 2021-07-12 19:03:16,079 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5699999494245276e-05, 1571
[INFO] 2021-07-12 19:03:16,079 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1571
[INFO] 2021-07-12 19:03:16,079 [run_pretraining.py:  558]:	worker_index: 7, step: 1571, cost: 7.987435, mlm loss: 7.987435, speed: 1.099556 steps/s, speed: 8.796449 samples/s, speed: 4503.781759 tokens/s, learning rate: 1.570e-05, loss_scalings: 6871.948730, pp_loss: 7.487804
[INFO] 2021-07-12 19:03:16,079 [run_pretraining.py:  512]:	********exe.run_1571******* 
[INFO] 2021-07-12 19:03:16,985 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:16,986 [run_pretraining.py:  534]:	loss/total_loss, 7.8462982177734375, 1572
[INFO] 2021-07-12 19:03:16,986 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8462982177734375, 1572
[INFO] 2021-07-12 19:03:16,986 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.571000029798597e-05, 1572
[INFO] 2021-07-12 19:03:16,986 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1572
[INFO] 2021-07-12 19:03:16,986 [run_pretraining.py:  558]:	worker_index: 7, step: 1572, cost: 7.846298, mlm loss: 7.846298, speed: 1.103435 steps/s, speed: 8.827482 samples/s, speed: 4519.670631 tokens/s, learning rate: 1.571e-05, loss_scalings: 6871.948730, pp_loss: 6.537586
[INFO] 2021-07-12 19:03:16,986 [run_pretraining.py:  512]:	********exe.run_1572******* 
[INFO] 2021-07-12 19:03:17,916 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:17,916 [run_pretraining.py:  534]:	loss/total_loss, 6.416049480438232, 1573
[INFO] 2021-07-12 19:03:17,916 [run_pretraining.py:  535]:	loss/mlm_loss, 6.416049480438232, 1573
[INFO] 2021-07-12 19:03:17,917 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5719999282737263e-05, 1573
[INFO] 2021-07-12 19:03:17,917 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1573
[INFO] 2021-07-12 19:03:17,917 [run_pretraining.py:  558]:	worker_index: 7, step: 1573, cost: 6.416049, mlm loss: 6.416049, speed: 1.075222 steps/s, speed: 8.601779 samples/s, speed: 4404.111078 tokens/s, learning rate: 1.572e-05, loss_scalings: 6871.948730, pp_loss: 7.097759
[INFO] 2021-07-12 19:03:17,917 [run_pretraining.py:  512]:	********exe.run_1573******* 
[INFO] 2021-07-12 19:03:18,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:18,825 [run_pretraining.py:  534]:	loss/total_loss, 6.66530704498291, 1574
[INFO] 2021-07-12 19:03:18,825 [run_pretraining.py:  535]:	loss/mlm_loss, 6.66530704498291, 1574
[INFO] 2021-07-12 19:03:18,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5729998267488554e-05, 1574
[INFO] 2021-07-12 19:03:18,825 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1574
[INFO] 2021-07-12 19:03:18,825 [run_pretraining.py:  558]:	worker_index: 7, step: 1574, cost: 6.665307, mlm loss: 6.665307, speed: 1.101581 steps/s, speed: 8.812646 samples/s, speed: 4512.074799 tokens/s, learning rate: 1.573e-05, loss_scalings: 6871.948730, pp_loss: 6.962051
[INFO] 2021-07-12 19:03:18,825 [run_pretraining.py:  512]:	********exe.run_1574******* 
[INFO] 2021-07-12 19:03:19,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:19,734 [run_pretraining.py:  534]:	loss/total_loss, 7.511019706726074, 1575
[INFO] 2021-07-12 19:03:19,734 [run_pretraining.py:  535]:	loss/mlm_loss, 7.511019706726074, 1575
[INFO] 2021-07-12 19:03:19,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.573999907122925e-05, 1575
[INFO] 2021-07-12 19:03:19,734 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1575
[INFO] 2021-07-12 19:03:19,734 [run_pretraining.py:  558]:	worker_index: 7, step: 1575, cost: 7.511020, mlm loss: 7.511020, speed: 1.101156 steps/s, speed: 8.809245 samples/s, speed: 4510.333464 tokens/s, learning rate: 1.574e-05, loss_scalings: 6871.948730, pp_loss: 7.692202
[INFO] 2021-07-12 19:03:19,734 [run_pretraining.py:  512]:	********exe.run_1575******* 
[INFO] 2021-07-12 19:03:20,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:20,647 [run_pretraining.py:  534]:	loss/total_loss, 7.233135223388672, 1576
[INFO] 2021-07-12 19:03:20,647 [run_pretraining.py:  535]:	loss/mlm_loss, 7.233135223388672, 1576
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5749999874969944e-05, 1576
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1576
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  558]:	worker_index: 7, step: 1576, cost: 7.233135, mlm loss: 7.233135, speed: 1.095138 steps/s, speed: 8.761104 samples/s, speed: 4485.685172 tokens/s, learning rate: 1.575e-05, loss_scalings: 6871.948730, pp_loss: 7.362164
[INFO] 2021-07-12 19:03:20,648 [run_pretraining.py:  512]:	********exe.run_1576******* 
[INFO] 2021-07-12 19:03:21,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:21,563 [run_pretraining.py:  534]:	loss/total_loss, 7.533921241760254, 1577
[INFO] 2021-07-12 19:03:21,563 [run_pretraining.py:  535]:	loss/mlm_loss, 7.533921241760254, 1577
[INFO] 2021-07-12 19:03:21,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5759998859721236e-05, 1577
[INFO] 2021-07-12 19:03:21,563 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1577
[INFO] 2021-07-12 19:03:21,563 [run_pretraining.py:  558]:	worker_index: 7, step: 1577, cost: 7.533921, mlm loss: 7.533921, speed: 1.093489 steps/s, speed: 8.747911 samples/s, speed: 4478.930405 tokens/s, learning rate: 1.576e-05, loss_scalings: 6871.948730, pp_loss: 7.271869
[INFO] 2021-07-12 19:03:21,563 [run_pretraining.py:  512]:	********exe.run_1577******* 
[INFO] 2021-07-12 19:03:22,467 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:22,468 [run_pretraining.py:  534]:	loss/total_loss, 7.401195526123047, 1578
[INFO] 2021-07-12 19:03:22,468 [run_pretraining.py:  535]:	loss/mlm_loss, 7.401195526123047, 1578
[INFO] 2021-07-12 19:03:22,468 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.576999966346193e-05, 1578
[INFO] 2021-07-12 19:03:22,468 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1578
[INFO] 2021-07-12 19:03:22,468 [run_pretraining.py:  558]:	worker_index: 7, step: 1578, cost: 7.401196, mlm loss: 7.401196, speed: 1.105485 steps/s, speed: 8.843882 samples/s, speed: 4528.067693 tokens/s, learning rate: 1.577e-05, loss_scalings: 6871.948730, pp_loss: 7.152899
[INFO] 2021-07-12 19:03:22,468 [run_pretraining.py:  512]:	********exe.run_1578******* 
[INFO] 2021-07-12 19:03:47,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:47,819 [run_pretraining.py:  534]:	loss/total_loss, 7.080782890319824, 1579
[INFO] 2021-07-12 19:03:47,819 [run_pretraining.py:  535]:	loss/mlm_loss, 7.080782890319824, 1579
[INFO] 2021-07-12 19:03:47,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5780000467202626e-05, 1579
[INFO] 2021-07-12 19:03:47,819 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1579
[INFO] 2021-07-12 19:03:47,819 [run_pretraining.py:  558]:	worker_index: 7, step: 1579, cost: 7.080783, mlm loss: 7.080783, speed: 0.039447 steps/s, speed: 0.315579 samples/s, speed: 161.576431 tokens/s, learning rate: 1.578e-05, loss_scalings: 6871.948730, pp_loss: 6.478968
[INFO] 2021-07-12 19:03:47,819 [run_pretraining.py:  512]:	********exe.run_1579******* 
[INFO] 2021-07-12 19:03:48,760 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:48,761 [run_pretraining.py:  534]:	loss/total_loss, 7.149385452270508, 1580
[INFO] 2021-07-12 19:03:48,761 [run_pretraining.py:  535]:	loss/mlm_loss, 7.149385452270508, 1580
[INFO] 2021-07-12 19:03:48,761 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5789999451953918e-05, 1580
[INFO] 2021-07-12 19:03:48,761 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1580
[INFO] 2021-07-12 19:03:48,761 [run_pretraining.py:  558]:	worker_index: 7, step: 1580, cost: 7.149385, mlm loss: 7.149385, speed: 1.062291 steps/s, speed: 8.498326 samples/s, speed: 4351.142724 tokens/s, learning rate: 1.579e-05, loss_scalings: 6871.948730, pp_loss: 7.090360
[INFO] 2021-07-12 19:03:48,761 [run_pretraining.py:  512]:	********exe.run_1580******* 
[INFO] 2021-07-12 19:03:49,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:49,687 [run_pretraining.py:  534]:	loss/total_loss, 7.43202543258667, 1581
[INFO] 2021-07-12 19:03:49,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.43202543258667, 1581
[INFO] 2021-07-12 19:03:49,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5800000255694613e-05, 1581
[INFO] 2021-07-12 19:03:49,687 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1581
[INFO] 2021-07-12 19:03:49,687 [run_pretraining.py:  558]:	worker_index: 7, step: 1581, cost: 7.432025, mlm loss: 7.432025, speed: 1.080304 steps/s, speed: 8.642430 samples/s, speed: 4424.923995 tokens/s, learning rate: 1.580e-05, loss_scalings: 6871.948730, pp_loss: 7.778038
[INFO] 2021-07-12 19:03:49,687 [run_pretraining.py:  512]:	********exe.run_1581******* 
[INFO] 2021-07-12 19:03:50,641 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:50,642 [run_pretraining.py:  534]:	loss/total_loss, 7.346307754516602, 1582
[INFO] 2021-07-12 19:03:50,642 [run_pretraining.py:  535]:	loss/mlm_loss, 7.346307754516602, 1582
[INFO] 2021-07-12 19:03:50,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5809999240445904e-05, 1582
[INFO] 2021-07-12 19:03:50,642 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1582
[INFO] 2021-07-12 19:03:50,642 [run_pretraining.py:  558]:	worker_index: 7, step: 1582, cost: 7.346308, mlm loss: 7.346308, speed: 1.048241 steps/s, speed: 8.385929 samples/s, speed: 4293.595492 tokens/s, learning rate: 1.581e-05, loss_scalings: 6871.948730, pp_loss: 7.475494
[INFO] 2021-07-12 19:03:50,642 [run_pretraining.py:  512]:	********exe.run_1582******* 
[INFO] 2021-07-12 19:03:51,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:51,574 [run_pretraining.py:  534]:	loss/total_loss, 6.898393630981445, 1583
[INFO] 2021-07-12 19:03:51,574 [run_pretraining.py:  535]:	loss/mlm_loss, 6.898393630981445, 1583
[INFO] 2021-07-12 19:03:51,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.58200000441866e-05, 1583
[INFO] 2021-07-12 19:03:51,574 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1583
[INFO] 2021-07-12 19:03:51,574 [run_pretraining.py:  558]:	worker_index: 7, step: 1583, cost: 6.898394, mlm loss: 6.898394, speed: 1.073556 steps/s, speed: 8.588451 samples/s, speed: 4397.286660 tokens/s, learning rate: 1.582e-05, loss_scalings: 6871.948730, pp_loss: 7.302250
[INFO] 2021-07-12 19:03:51,574 [run_pretraining.py:  512]:	********exe.run_1583******* 
[INFO] 2021-07-12 19:03:52,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:52,494 [run_pretraining.py:  534]:	loss/total_loss, 7.37710428237915, 1584
[INFO] 2021-07-12 19:03:52,494 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37710428237915, 1584
[INFO] 2021-07-12 19:03:52,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.582999902893789e-05, 1584
[INFO] 2021-07-12 19:03:52,494 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1584
[INFO] 2021-07-12 19:03:52,494 [run_pretraining.py:  558]:	worker_index: 7, step: 1584, cost: 7.377104, mlm loss: 7.377104, speed: 1.087924 steps/s, speed: 8.703392 samples/s, speed: 4456.136854 tokens/s, learning rate: 1.583e-05, loss_scalings: 6871.948730, pp_loss: 7.275242
[INFO] 2021-07-12 19:03:52,494 [run_pretraining.py:  512]:	********exe.run_1584******* 
[INFO] 2021-07-12 19:03:53,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:53,412 [run_pretraining.py:  534]:	loss/total_loss, 7.287591934204102, 1585
[INFO] 2021-07-12 19:03:53,412 [run_pretraining.py:  535]:	loss/mlm_loss, 7.287591934204102, 1585
[INFO] 2021-07-12 19:03:53,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5839999832678586e-05, 1585
[INFO] 2021-07-12 19:03:53,412 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1585
[INFO] 2021-07-12 19:03:53,412 [run_pretraining.py:  558]:	worker_index: 7, step: 1585, cost: 7.287592, mlm loss: 7.287592, speed: 1.089735 steps/s, speed: 8.717880 samples/s, speed: 4463.554639 tokens/s, learning rate: 1.584e-05, loss_scalings: 6871.948730, pp_loss: 7.128454
[INFO] 2021-07-12 19:03:53,412 [run_pretraining.py:  512]:	********exe.run_1585******* 
[INFO] 2021-07-12 19:03:54,379 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:54,379 [run_pretraining.py:  534]:	loss/total_loss, 7.935023307800293, 1586
[INFO] 2021-07-12 19:03:54,379 [run_pretraining.py:  535]:	loss/mlm_loss, 7.935023307800293, 1586
[INFO] 2021-07-12 19:03:54,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5849998817429878e-05, 1586
[INFO] 2021-07-12 19:03:54,379 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1586
[INFO] 2021-07-12 19:03:54,380 [run_pretraining.py:  558]:	worker_index: 7, step: 1586, cost: 7.935023, mlm loss: 7.935023, speed: 1.034432 steps/s, speed: 8.275458 samples/s, speed: 4237.034326 tokens/s, learning rate: 1.585e-05, loss_scalings: 6871.948730, pp_loss: 7.493723
[INFO] 2021-07-12 19:03:54,380 [run_pretraining.py:  512]:	********exe.run_1586******* 
[INFO] 2021-07-12 19:03:55,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:55,308 [run_pretraining.py:  534]:	loss/total_loss, 7.468510627746582, 1587
[INFO] 2021-07-12 19:03:55,308 [run_pretraining.py:  535]:	loss/mlm_loss, 7.468510627746582, 1587
[INFO] 2021-07-12 19:03:55,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5859999621170573e-05, 1587
[INFO] 2021-07-12 19:03:55,308 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1587
[INFO] 2021-07-12 19:03:55,308 [run_pretraining.py:  558]:	worker_index: 7, step: 1587, cost: 7.468511, mlm loss: 7.468511, speed: 1.077639 steps/s, speed: 8.621113 samples/s, speed: 4414.009831 tokens/s, learning rate: 1.586e-05, loss_scalings: 6871.948730, pp_loss: 7.268221
[INFO] 2021-07-12 19:03:55,308 [run_pretraining.py:  512]:	********exe.run_1587******* 
[INFO] 2021-07-12 19:03:56,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:56,239 [run_pretraining.py:  534]:	loss/total_loss, 7.412059783935547, 1588
[INFO] 2021-07-12 19:03:56,244 [run_pretraining.py:  535]:	loss/mlm_loss, 7.412059783935547, 1588
[INFO] 2021-07-12 19:03:56,249 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5870000424911268e-05, 1588
[INFO] 2021-07-12 19:03:56,254 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1588
[INFO] 2021-07-12 19:03:56,259 [run_pretraining.py:  558]:	worker_index: 7, step: 1588, cost: 7.412060, mlm loss: 7.412060, speed: 1.074983 steps/s, speed: 8.599864 samples/s, speed: 4403.130189 tokens/s, learning rate: 1.587e-05, loss_scalings: 6871.948730, pp_loss: 7.642122
[INFO] 2021-07-12 19:03:56,265 [run_pretraining.py:  512]:	********exe.run_1588******* 
[INFO] 2021-07-12 19:03:57,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:57,167 [run_pretraining.py:  534]:	loss/total_loss, 7.306328773498535, 1589
[INFO] 2021-07-12 19:03:57,167 [run_pretraining.py:  535]:	loss/mlm_loss, 7.306328773498535, 1589
[INFO] 2021-07-12 19:03:57,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.587999940966256e-05, 1589
[INFO] 2021-07-12 19:03:57,167 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1589
[INFO] 2021-07-12 19:03:57,167 [run_pretraining.py:  558]:	worker_index: 7, step: 1589, cost: 7.306329, mlm loss: 7.306329, speed: 1.108359 steps/s, speed: 8.866872 samples/s, speed: 4539.838225 tokens/s, learning rate: 1.588e-05, loss_scalings: 6871.948730, pp_loss: 7.467056
[INFO] 2021-07-12 19:03:57,168 [run_pretraining.py:  512]:	********exe.run_1589******* 
[INFO] 2021-07-12 19:03:58,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:58,075 [run_pretraining.py:  534]:	loss/total_loss, 7.928248405456543, 1590
[INFO] 2021-07-12 19:03:58,075 [run_pretraining.py:  535]:	loss/mlm_loss, 7.928248405456543, 1590
[INFO] 2021-07-12 19:03:58,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.588999839441385e-05, 1590
[INFO] 2021-07-12 19:03:58,076 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1590
[INFO] 2021-07-12 19:03:58,076 [run_pretraining.py:  558]:	worker_index: 7, step: 1590, cost: 7.928248, mlm loss: 7.928248, speed: 1.101887 steps/s, speed: 8.815093 samples/s, speed: 4513.327733 tokens/s, learning rate: 1.589e-05, loss_scalings: 6871.948730, pp_loss: 7.571187
[INFO] 2021-07-12 19:03:58,076 [run_pretraining.py:  512]:	********exe.run_1590******* 
[INFO] 2021-07-12 19:03:58,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:58,995 [run_pretraining.py:  534]:	loss/total_loss, 7.470695495605469, 1591
[INFO] 2021-07-12 19:03:58,995 [run_pretraining.py:  535]:	loss/mlm_loss, 7.470695495605469, 1591
[INFO] 2021-07-12 19:03:58,995 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5899999198154546e-05, 1591
[INFO] 2021-07-12 19:03:58,995 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1591
[INFO] 2021-07-12 19:03:58,995 [run_pretraining.py:  558]:	worker_index: 7, step: 1591, cost: 7.470695, mlm loss: 7.470695, speed: 1.088011 steps/s, speed: 8.704085 samples/s, speed: 4456.491724 tokens/s, learning rate: 1.590e-05, loss_scalings: 6871.948730, pp_loss: 7.410725
[INFO] 2021-07-12 19:03:58,996 [run_pretraining.py:  512]:	********exe.run_1591******* 
[INFO] 2021-07-12 19:03:59,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:03:59,911 [run_pretraining.py:  534]:	loss/total_loss, 8.075130462646484, 1592
[INFO] 2021-07-12 19:03:59,911 [run_pretraining.py:  535]:	loss/mlm_loss, 8.075130462646484, 1592
[INFO] 2021-07-12 19:03:59,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.591000000189524e-05, 1592
[INFO] 2021-07-12 19:03:59,911 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1592
[INFO] 2021-07-12 19:03:59,911 [run_pretraining.py:  558]:	worker_index: 7, step: 1592, cost: 8.075130, mlm loss: 8.075130, speed: 1.092546 steps/s, speed: 8.740366 samples/s, speed: 4475.067507 tokens/s, learning rate: 1.591e-05, loss_scalings: 6871.948730, pp_loss: 7.827376
[INFO] 2021-07-12 19:03:59,911 [run_pretraining.py:  512]:	********exe.run_1592******* 
[INFO] 2021-07-12 19:04:00,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:00,825 [run_pretraining.py:  534]:	loss/total_loss, 7.223560810089111, 1593
[INFO] 2021-07-12 19:04:00,825 [run_pretraining.py:  535]:	loss/mlm_loss, 7.223560810089111, 1593
[INFO] 2021-07-12 19:04:00,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5919998986646533e-05, 1593
[INFO] 2021-07-12 19:04:00,825 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1593
[INFO] 2021-07-12 19:04:00,825 [run_pretraining.py:  558]:	worker_index: 7, step: 1593, cost: 7.223561, mlm loss: 7.223561, speed: 1.095393 steps/s, speed: 8.763145 samples/s, speed: 4486.730142 tokens/s, learning rate: 1.592e-05, loss_scalings: 6871.948730, pp_loss: 6.828129
[INFO] 2021-07-12 19:04:00,825 [run_pretraining.py:  512]:	********exe.run_1593******* 
[INFO] 2021-07-12 19:04:01,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:01,737 [run_pretraining.py:  534]:	loss/total_loss, 7.693885803222656, 1594
[INFO] 2021-07-12 19:04:01,737 [run_pretraining.py:  535]:	loss/mlm_loss, 7.693885803222656, 1594
[INFO] 2021-07-12 19:04:01,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5929999790387228e-05, 1594
[INFO] 2021-07-12 19:04:01,738 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1594
[INFO] 2021-07-12 19:04:01,738 [run_pretraining.py:  558]:	worker_index: 7, step: 1594, cost: 7.693886, mlm loss: 7.693886, speed: 1.096461 steps/s, speed: 8.771690 samples/s, speed: 4491.105083 tokens/s, learning rate: 1.593e-05, loss_scalings: 6871.948730, pp_loss: 7.480329
[INFO] 2021-07-12 19:04:01,738 [run_pretraining.py:  512]:	********exe.run_1594******* 
[INFO] 2021-07-12 19:04:02,643 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:02,644 [run_pretraining.py:  534]:	loss/total_loss, 7.480984687805176, 1595
[INFO] 2021-07-12 19:04:02,644 [run_pretraining.py:  535]:	loss/mlm_loss, 7.480984687805176, 1595
[INFO] 2021-07-12 19:04:02,644 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5940000594127923e-05, 1595
[INFO] 2021-07-12 19:04:02,644 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1595
[INFO] 2021-07-12 19:04:02,644 [run_pretraining.py:  558]:	worker_index: 7, step: 1595, cost: 7.480985, mlm loss: 7.480985, speed: 1.104013 steps/s, speed: 8.832103 samples/s, speed: 4522.036855 tokens/s, learning rate: 1.594e-05, loss_scalings: 6871.948730, pp_loss: 7.206407
[INFO] 2021-07-12 19:04:02,644 [run_pretraining.py:  512]:	********exe.run_1595******* 
[INFO] 2021-07-12 19:04:03,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:03,547 [run_pretraining.py:  534]:	loss/total_loss, 7.914191246032715, 1596
[INFO] 2021-07-12 19:04:03,547 [run_pretraining.py:  535]:	loss/mlm_loss, 7.914191246032715, 1596
[INFO] 2021-07-12 19:04:03,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5949999578879215e-05, 1596
[INFO] 2021-07-12 19:04:03,547 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1596
[INFO] 2021-07-12 19:04:03,547 [run_pretraining.py:  558]:	worker_index: 7, step: 1596, cost: 7.914191, mlm loss: 7.914191, speed: 1.108297 steps/s, speed: 8.866375 samples/s, speed: 4539.583910 tokens/s, learning rate: 1.595e-05, loss_scalings: 6871.948730, pp_loss: 7.666572
[INFO] 2021-07-12 19:04:03,547 [run_pretraining.py:  512]:	********exe.run_1596******* 
[INFO] 2021-07-12 19:04:04,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:04,458 [run_pretraining.py:  534]:	loss/total_loss, 7.227475166320801, 1597
[INFO] 2021-07-12 19:04:04,458 [run_pretraining.py:  535]:	loss/mlm_loss, 7.227475166320801, 1597
[INFO] 2021-07-12 19:04:04,459 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.596000038261991e-05, 1597
[INFO] 2021-07-12 19:04:04,459 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1597
[INFO] 2021-07-12 19:04:04,459 [run_pretraining.py:  558]:	worker_index: 7, step: 1597, cost: 7.227475, mlm loss: 7.227475, speed: 1.097699 steps/s, speed: 8.781591 samples/s, speed: 4496.174476 tokens/s, learning rate: 1.596e-05, loss_scalings: 6871.948730, pp_loss: 7.463407
[INFO] 2021-07-12 19:04:04,459 [run_pretraining.py:  512]:	********exe.run_1597******* 
[INFO] 2021-07-12 19:04:05,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:05,372 [run_pretraining.py:  534]:	loss/total_loss, 7.393496513366699, 1598
[INFO] 2021-07-12 19:04:05,372 [run_pretraining.py:  535]:	loss/mlm_loss, 7.393496513366699, 1598
[INFO] 2021-07-12 19:04:05,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.59699993673712e-05, 1598
[INFO] 2021-07-12 19:04:05,373 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1598
[INFO] 2021-07-12 19:04:05,373 [run_pretraining.py:  558]:	worker_index: 7, step: 1598, cost: 7.393497, mlm loss: 7.393497, speed: 1.094887 steps/s, speed: 8.759096 samples/s, speed: 4484.657079 tokens/s, learning rate: 1.597e-05, loss_scalings: 6871.948730, pp_loss: 7.384557
[INFO] 2021-07-12 19:04:05,373 [run_pretraining.py:  512]:	********exe.run_1598******* 
[INFO] 2021-07-12 19:04:06,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:06,286 [run_pretraining.py:  534]:	loss/total_loss, 7.02060604095459, 1599
[INFO] 2021-07-12 19:04:06,286 [run_pretraining.py:  535]:	loss/mlm_loss, 7.02060604095459, 1599
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5979998352122493e-05, 1599
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1599
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  558]:	worker_index: 7, step: 1599, cost: 7.020606, mlm loss: 7.020606, speed: 1.094815 steps/s, speed: 8.758517 samples/s, speed: 4484.360916 tokens/s, learning rate: 1.598e-05, loss_scalings: 6871.948730, pp_loss: 7.347358
[INFO] 2021-07-12 19:04:06,287 [run_pretraining.py:  512]:	********exe.run_1599******* 
[INFO] 2021-07-12 19:04:07,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:07,192 [run_pretraining.py:  534]:	loss/total_loss, 7.382095813751221, 1600
[INFO] 2021-07-12 19:04:07,192 [run_pretraining.py:  535]:	loss/mlm_loss, 7.382095813751221, 1600
[INFO] 2021-07-12 19:04:07,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5989999155863188e-05, 1600
[INFO] 2021-07-12 19:04:07,193 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1600
[INFO] 2021-07-12 19:04:07,193 [run_pretraining.py:  558]:	worker_index: 7, step: 1600, cost: 7.382096, mlm loss: 7.382096, speed: 1.104593 steps/s, speed: 8.836744 samples/s, speed: 4524.412706 tokens/s, learning rate: 1.599e-05, loss_scalings: 6871.948730, pp_loss: 7.279296
[INFO] 2021-07-12 19:04:07,193 [run_pretraining.py:  512]:	********exe.run_1600******* 
[INFO] 2021-07-12 19:04:08,108 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:08,108 [run_pretraining.py:  534]:	loss/total_loss, 6.30853271484375, 1601
[INFO] 2021-07-12 19:04:08,109 [run_pretraining.py:  535]:	loss/mlm_loss, 6.30853271484375, 1601
[INFO] 2021-07-12 19:04:08,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.5999999959603883e-05, 1601
[INFO] 2021-07-12 19:04:08,109 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1601
[INFO] 2021-07-12 19:04:08,109 [run_pretraining.py:  558]:	worker_index: 7, step: 1601, cost: 6.308533, mlm loss: 6.308533, speed: 1.092398 steps/s, speed: 8.739182 samples/s, speed: 4474.461435 tokens/s, learning rate: 1.600e-05, loss_scalings: 6871.948730, pp_loss: 7.020390
[INFO] 2021-07-12 19:04:08,109 [run_pretraining.py:  512]:	********exe.run_1601******* 
[INFO] 2021-07-12 19:04:09,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:09,098 [run_pretraining.py:  534]:	loss/total_loss, 7.775259971618652, 1602
[INFO] 2021-07-12 19:04:09,098 [run_pretraining.py:  535]:	loss/mlm_loss, 7.775259971618652, 1602
[INFO] 2021-07-12 19:04:09,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6009998944355175e-05, 1602
[INFO] 2021-07-12 19:04:09,098 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1602
[INFO] 2021-07-12 19:04:09,098 [run_pretraining.py:  558]:	worker_index: 7, step: 1602, cost: 7.775260, mlm loss: 7.775260, speed: 1.011318 steps/s, speed: 8.090546 samples/s, speed: 4142.359659 tokens/s, learning rate: 1.601e-05, loss_scalings: 6871.948730, pp_loss: 7.399173
[INFO] 2021-07-12 19:04:09,098 [run_pretraining.py:  512]:	********exe.run_1602******* 
[INFO] 2021-07-12 19:04:10,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:10,162 [run_pretraining.py:  534]:	loss/total_loss, 7.3583269119262695, 1603
[INFO] 2021-07-12 19:04:10,162 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3583269119262695, 1603
[INFO] 2021-07-12 19:04:10,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.601999974809587e-05, 1603
[INFO] 2021-07-12 19:04:10,162 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1603
[INFO] 2021-07-12 19:04:10,162 [run_pretraining.py:  558]:	worker_index: 7, step: 1603, cost: 7.358327, mlm loss: 7.358327, speed: 0.940619 steps/s, speed: 7.524952 samples/s, speed: 3852.775575 tokens/s, learning rate: 1.602e-05, loss_scalings: 6871.948730, pp_loss: 7.211676
[INFO] 2021-07-12 19:04:10,162 [run_pretraining.py:  512]:	********exe.run_1603******* 
[INFO] 2021-07-12 19:04:11,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:11,235 [run_pretraining.py:  534]:	loss/total_loss, 6.959856986999512, 1604
[INFO] 2021-07-12 19:04:11,235 [run_pretraining.py:  535]:	loss/mlm_loss, 6.959856986999512, 1604
[INFO] 2021-07-12 19:04:11,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6030000551836565e-05, 1604
[INFO] 2021-07-12 19:04:11,235 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1604
[INFO] 2021-07-12 19:04:11,235 [run_pretraining.py:  558]:	worker_index: 7, step: 1604, cost: 6.959857, mlm loss: 6.959857, speed: 0.932268 steps/s, speed: 7.458145 samples/s, speed: 3818.570124 tokens/s, learning rate: 1.603e-05, loss_scalings: 6871.948730, pp_loss: 7.121389
[INFO] 2021-07-12 19:04:11,235 [run_pretraining.py:  512]:	********exe.run_1604******* 
[INFO] 2021-07-12 19:04:12,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:12,299 [run_pretraining.py:  534]:	loss/total_loss, 7.018567085266113, 1605
[INFO] 2021-07-12 19:04:12,299 [run_pretraining.py:  535]:	loss/mlm_loss, 7.018567085266113, 1605
[INFO] 2021-07-12 19:04:12,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6039999536587857e-05, 1605
[INFO] 2021-07-12 19:04:12,299 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1605
[INFO] 2021-07-12 19:04:12,299 [run_pretraining.py:  558]:	worker_index: 7, step: 1605, cost: 7.018567, mlm loss: 7.018567, speed: 0.940642 steps/s, speed: 7.525136 samples/s, speed: 3852.869756 tokens/s, learning rate: 1.604e-05, loss_scalings: 6871.948730, pp_loss: 7.325912
[INFO] 2021-07-12 19:04:12,299 [run_pretraining.py:  512]:	********exe.run_1605******* 
[INFO] 2021-07-12 19:04:13,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:13,353 [run_pretraining.py:  534]:	loss/total_loss, 7.88908576965332, 1606
[INFO] 2021-07-12 19:04:13,353 [run_pretraining.py:  535]:	loss/mlm_loss, 7.88908576965332, 1606
[INFO] 2021-07-12 19:04:13,353 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6050000340328552e-05, 1606
[INFO] 2021-07-12 19:04:13,353 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1606
[INFO] 2021-07-12 19:04:13,353 [run_pretraining.py:  558]:	worker_index: 7, step: 1606, cost: 7.889086, mlm loss: 7.889086, speed: 0.948986 steps/s, speed: 7.591885 samples/s, speed: 3887.045222 tokens/s, learning rate: 1.605e-05, loss_scalings: 6871.948730, pp_loss: 7.464341
[INFO] 2021-07-12 19:04:13,354 [run_pretraining.py:  512]:	********exe.run_1606******* 
[INFO] 2021-07-12 19:04:14,422 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:14,422 [run_pretraining.py:  534]:	loss/total_loss, 7.890955448150635, 1607
[INFO] 2021-07-12 19:04:14,422 [run_pretraining.py:  535]:	loss/mlm_loss, 7.890955448150635, 1607
[INFO] 2021-07-12 19:04:14,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6060001144069247e-05, 1607
[INFO] 2021-07-12 19:04:14,423 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1607
[INFO] 2021-07-12 19:04:14,423 [run_pretraining.py:  558]:	worker_index: 7, step: 1607, cost: 7.890955, mlm loss: 7.890955, speed: 0.935799 steps/s, speed: 7.486395 samples/s, speed: 3833.033995 tokens/s, learning rate: 1.606e-05, loss_scalings: 6871.948730, pp_loss: 7.408320
[INFO] 2021-07-12 19:04:14,423 [run_pretraining.py:  512]:	********exe.run_1607******* 
[INFO] 2021-07-12 19:04:15,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:15,501 [run_pretraining.py:  534]:	loss/total_loss, 6.533963203430176, 1608
[INFO] 2021-07-12 19:04:15,501 [run_pretraining.py:  535]:	loss/mlm_loss, 6.533963203430176, 1608
[INFO] 2021-07-12 19:04:15,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6069998309831135e-05, 1608
[INFO] 2021-07-12 19:04:15,501 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1608
[INFO] 2021-07-12 19:04:15,501 [run_pretraining.py:  558]:	worker_index: 7, step: 1608, cost: 6.533963, mlm loss: 6.533963, speed: 0.928057 steps/s, speed: 7.424455 samples/s, speed: 3801.321087 tokens/s, learning rate: 1.607e-05, loss_scalings: 6871.948730, pp_loss: 6.822234
[INFO] 2021-07-12 19:04:15,501 [run_pretraining.py:  512]:	********exe.run_1608******* 
[INFO] 2021-07-12 19:04:16,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:16,570 [run_pretraining.py:  534]:	loss/total_loss, 6.961535930633545, 1609
[INFO] 2021-07-12 19:04:16,570 [run_pretraining.py:  535]:	loss/mlm_loss, 6.961535930633545, 1609
[INFO] 2021-07-12 19:04:16,570 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.607999911357183e-05, 1609
[INFO] 2021-07-12 19:04:16,570 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1609
[INFO] 2021-07-12 19:04:16,570 [run_pretraining.py:  558]:	worker_index: 7, step: 1609, cost: 6.961536, mlm loss: 6.961536, speed: 0.935610 steps/s, speed: 7.484880 samples/s, speed: 3832.258490 tokens/s, learning rate: 1.608e-05, loss_scalings: 6871.948730, pp_loss: 6.876884
[INFO] 2021-07-12 19:04:16,570 [run_pretraining.py:  512]:	********exe.run_1609******* 
[INFO] 2021-07-12 19:04:17,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:17,716 [run_pretraining.py:  534]:	loss/total_loss, 7.473556995391846, 1610
[INFO] 2021-07-12 19:04:17,716 [run_pretraining.py:  535]:	loss/mlm_loss, 7.473556995391846, 1610
[INFO] 2021-07-12 19:04:17,716 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6089999917312525e-05, 1610
[INFO] 2021-07-12 19:04:17,716 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1610
[INFO] 2021-07-12 19:04:17,716 [run_pretraining.py:  558]:	worker_index: 7, step: 1610, cost: 7.473557, mlm loss: 7.473557, speed: 0.873111 steps/s, speed: 6.984888 samples/s, speed: 3576.262757 tokens/s, learning rate: 1.609e-05, loss_scalings: 6871.948730, pp_loss: 7.162723
[INFO] 2021-07-12 19:04:17,716 [run_pretraining.py:  512]:	********exe.run_1610******* 
[INFO] 2021-07-12 19:04:18,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  534]:	loss/total_loss, 6.931886672973633, 1611
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  535]:	loss/mlm_loss, 6.931886672973633, 1611
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6099998902063817e-05, 1611
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1611
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  558]:	worker_index: 7, step: 1611, cost: 6.931887, mlm loss: 6.931887, speed: 0.898525 steps/s, speed: 7.188202 samples/s, speed: 3680.359261 tokens/s, learning rate: 1.610e-05, loss_scalings: 6871.948730, pp_loss: 7.343882
[INFO] 2021-07-12 19:04:18,830 [run_pretraining.py:  512]:	********exe.run_1611******* 
[INFO] 2021-07-12 19:04:19,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  534]:	loss/total_loss, 6.616632461547852, 1612
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  535]:	loss/mlm_loss, 6.616632461547852, 1612
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6109999705804512e-05, 1612
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1612
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  558]:	worker_index: 7, step: 1612, cost: 6.616632, mlm loss: 6.616632, speed: 0.913512 steps/s, speed: 7.308097 samples/s, speed: 3741.745541 tokens/s, learning rate: 1.611e-05, loss_scalings: 6871.948730, pp_loss: 7.128491
[INFO] 2021-07-12 19:04:19,925 [run_pretraining.py:  512]:	********exe.run_1612******* 
[INFO] 2021-07-12 19:04:21,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:21,026 [run_pretraining.py:  534]:	loss/total_loss, 6.769137382507324, 1613
[INFO] 2021-07-12 19:04:21,026 [run_pretraining.py:  535]:	loss/mlm_loss, 6.769137382507324, 1613
[INFO] 2021-07-12 19:04:21,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6120000509545207e-05, 1613
[INFO] 2021-07-12 19:04:21,026 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1613
[INFO] 2021-07-12 19:04:21,026 [run_pretraining.py:  558]:	worker_index: 7, step: 1613, cost: 6.769137, mlm loss: 6.769137, speed: 0.909020 steps/s, speed: 7.272160 samples/s, speed: 3723.346162 tokens/s, learning rate: 1.612e-05, loss_scalings: 6871.948730, pp_loss: 7.152869
[INFO] 2021-07-12 19:04:21,026 [run_pretraining.py:  512]:	********exe.run_1613******* 
[INFO] 2021-07-12 19:04:22,119 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:22,120 [run_pretraining.py:  534]:	loss/total_loss, 7.072568893432617, 1614
[INFO] 2021-07-12 19:04:22,120 [run_pretraining.py:  535]:	loss/mlm_loss, 7.072568893432617, 1614
[INFO] 2021-07-12 19:04:22,120 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.61299994942965e-05, 1614
[INFO] 2021-07-12 19:04:22,120 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1614
[INFO] 2021-07-12 19:04:22,120 [run_pretraining.py:  558]:	worker_index: 7, step: 1614, cost: 7.072569, mlm loss: 7.072569, speed: 0.914465 steps/s, speed: 7.315719 samples/s, speed: 3745.648307 tokens/s, learning rate: 1.613e-05, loss_scalings: 6871.948730, pp_loss: 6.502250
[INFO] 2021-07-12 19:04:22,120 [run_pretraining.py:  512]:	********exe.run_1614******* 
[INFO] 2021-07-12 19:04:23,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:23,209 [run_pretraining.py:  534]:	loss/total_loss, 7.38082218170166, 1615
[INFO] 2021-07-12 19:04:23,209 [run_pretraining.py:  535]:	loss/mlm_loss, 7.38082218170166, 1615
[INFO] 2021-07-12 19:04:23,210 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6140000298037194e-05, 1615
[INFO] 2021-07-12 19:04:23,210 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1615
[INFO] 2021-07-12 19:04:23,210 [run_pretraining.py:  558]:	worker_index: 7, step: 1615, cost: 7.380822, mlm loss: 7.380822, speed: 0.918412 steps/s, speed: 7.347294 samples/s, speed: 3761.814703 tokens/s, learning rate: 1.614e-05, loss_scalings: 6871.948730, pp_loss: 7.298291
[INFO] 2021-07-12 19:04:23,210 [run_pretraining.py:  512]:	********exe.run_1615******* 
[INFO] 2021-07-12 19:04:24,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:24,313 [run_pretraining.py:  534]:	loss/total_loss, 7.857553958892822, 1616
[INFO] 2021-07-12 19:04:24,314 [run_pretraining.py:  535]:	loss/mlm_loss, 7.857553958892822, 1616
[INFO] 2021-07-12 19:04:24,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.615000110177789e-05, 1616
[INFO] 2021-07-12 19:04:24,314 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1616
[INFO] 2021-07-12 19:04:24,314 [run_pretraining.py:  558]:	worker_index: 7, step: 1616, cost: 7.857554, mlm loss: 7.857554, speed: 0.906275 steps/s, speed: 7.250201 samples/s, speed: 3712.103079 tokens/s, learning rate: 1.615e-05, loss_scalings: 6871.948730, pp_loss: 7.598331
[INFO] 2021-07-12 19:04:24,314 [run_pretraining.py:  512]:	********exe.run_1616******* 
[INFO] 2021-07-12 19:04:25,407 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:25,407 [run_pretraining.py:  534]:	loss/total_loss, 6.979272365570068, 1617
[INFO] 2021-07-12 19:04:25,407 [run_pretraining.py:  535]:	loss/mlm_loss, 6.979272365570068, 1617
[INFO] 2021-07-12 19:04:25,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6159998267539777e-05, 1617
[INFO] 2021-07-12 19:04:25,408 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1617
[INFO] 2021-07-12 19:04:25,408 [run_pretraining.py:  558]:	worker_index: 7, step: 1617, cost: 6.979272, mlm loss: 6.979272, speed: 0.914740 steps/s, speed: 7.317918 samples/s, speed: 3746.773984 tokens/s, learning rate: 1.616e-05, loss_scalings: 6871.948730, pp_loss: 7.247241
[INFO] 2021-07-12 19:04:25,408 [run_pretraining.py:  512]:	********exe.run_1617******* 
[INFO] 2021-07-12 19:04:26,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:26,455 [run_pretraining.py:  534]:	loss/total_loss, 7.478308200836182, 1618
[INFO] 2021-07-12 19:04:26,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.478308200836182, 1618
[INFO] 2021-07-12 19:04:26,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6169999071280472e-05, 1618
[INFO] 2021-07-12 19:04:26,455 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1618
[INFO] 2021-07-12 19:04:26,455 [run_pretraining.py:  558]:	worker_index: 7, step: 1618, cost: 7.478308, mlm loss: 7.478308, speed: 0.955080 steps/s, speed: 7.640641 samples/s, speed: 3912.008108 tokens/s, learning rate: 1.617e-05, loss_scalings: 6871.948730, pp_loss: 7.203925
[INFO] 2021-07-12 19:04:26,455 [run_pretraining.py:  512]:	********exe.run_1618******* 
[INFO] 2021-07-12 19:04:27,365 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:27,365 [run_pretraining.py:  534]:	loss/total_loss, 7.7205095291137695, 1619
[INFO] 2021-07-12 19:04:27,365 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7205095291137695, 1619
[INFO] 2021-07-12 19:04:27,366 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6179999875021167e-05, 1619
[INFO] 2021-07-12 19:04:27,366 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1619
[INFO] 2021-07-12 19:04:27,366 [run_pretraining.py:  558]:	worker_index: 7, step: 1619, cost: 7.720510, mlm loss: 7.720510, speed: 1.099200 steps/s, speed: 8.793599 samples/s, speed: 4502.322903 tokens/s, learning rate: 1.618e-05, loss_scalings: 6871.948730, pp_loss: 7.296153
[INFO] 2021-07-12 19:04:27,366 [run_pretraining.py:  512]:	********exe.run_1619******* 
[INFO] 2021-07-12 19:04:28,280 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:28,280 [run_pretraining.py:  534]:	loss/total_loss, 7.218354225158691, 1620
[INFO] 2021-07-12 19:04:28,280 [run_pretraining.py:  535]:	loss/mlm_loss, 7.218354225158691, 1620
[INFO] 2021-07-12 19:04:28,281 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.618999885977246e-05, 1620
[INFO] 2021-07-12 19:04:28,281 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1620
[INFO] 2021-07-12 19:04:28,281 [run_pretraining.py:  558]:	worker_index: 7, step: 1620, cost: 7.218354, mlm loss: 7.218354, speed: 1.093740 steps/s, speed: 8.749923 samples/s, speed: 4479.960547 tokens/s, learning rate: 1.619e-05, loss_scalings: 6871.948730, pp_loss: 7.222528
[INFO] 2021-07-12 19:04:28,281 [run_pretraining.py:  512]:	********exe.run_1620******* 
[INFO] 2021-07-12 19:04:29,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:29,194 [run_pretraining.py:  534]:	loss/total_loss, 6.775341987609863, 1621
[INFO] 2021-07-12 19:04:29,194 [run_pretraining.py:  535]:	loss/mlm_loss, 6.775341987609863, 1621
[INFO] 2021-07-12 19:04:29,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6199999663513154e-05, 1621
[INFO] 2021-07-12 19:04:29,194 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1621
[INFO] 2021-07-12 19:04:29,194 [run_pretraining.py:  558]:	worker_index: 7, step: 1621, cost: 6.775342, mlm loss: 6.775342, speed: 1.095869 steps/s, speed: 8.766950 samples/s, speed: 4488.678459 tokens/s, learning rate: 1.620e-05, loss_scalings: 6871.948730, pp_loss: 7.219633
[INFO] 2021-07-12 19:04:29,194 [run_pretraining.py:  512]:	********exe.run_1621******* 
[INFO] 2021-07-12 19:04:30,104 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:30,105 [run_pretraining.py:  534]:	loss/total_loss, 7.772123336791992, 1622
[INFO] 2021-07-12 19:04:30,105 [run_pretraining.py:  535]:	loss/mlm_loss, 7.772123336791992, 1622
[INFO] 2021-07-12 19:04:30,105 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.621000046725385e-05, 1622
[INFO] 2021-07-12 19:04:30,105 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1622
[INFO] 2021-07-12 19:04:30,105 [run_pretraining.py:  558]:	worker_index: 7, step: 1622, cost: 7.772123, mlm loss: 7.772123, speed: 1.097896 steps/s, speed: 8.783170 samples/s, speed: 4496.983016 tokens/s, learning rate: 1.621e-05, loss_scalings: 6871.948730, pp_loss: 7.485296
[INFO] 2021-07-12 19:04:30,105 [run_pretraining.py:  512]:	********exe.run_1622******* 
[INFO] 2021-07-12 19:04:31,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:31,021 [run_pretraining.py:  534]:	loss/total_loss, 7.223581790924072, 1623
[INFO] 2021-07-12 19:04:31,021 [run_pretraining.py:  535]:	loss/mlm_loss, 7.223581790924072, 1623
[INFO] 2021-07-12 19:04:31,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.621999945200514e-05, 1623
[INFO] 2021-07-12 19:04:31,022 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1623
[INFO] 2021-07-12 19:04:31,022 [run_pretraining.py:  558]:	worker_index: 7, step: 1623, cost: 7.223582, mlm loss: 7.223582, speed: 1.092166 steps/s, speed: 8.737326 samples/s, speed: 4473.510700 tokens/s, learning rate: 1.622e-05, loss_scalings: 6871.948730, pp_loss: 7.331191
[INFO] 2021-07-12 19:04:31,022 [run_pretraining.py:  512]:	********exe.run_1623******* 
[INFO] 2021-07-12 19:04:31,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:31,931 [run_pretraining.py:  534]:	loss/total_loss, 7.118948936462402, 1624
[INFO] 2021-07-12 19:04:31,932 [run_pretraining.py:  535]:	loss/mlm_loss, 7.118948936462402, 1624
[INFO] 2021-07-12 19:04:31,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6230000255745836e-05, 1624
[INFO] 2021-07-12 19:04:31,932 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1624
[INFO] 2021-07-12 19:04:31,932 [run_pretraining.py:  558]:	worker_index: 7, step: 1624, cost: 7.118949, mlm loss: 7.118949, speed: 1.099415 steps/s, speed: 8.795319 samples/s, speed: 4503.203297 tokens/s, learning rate: 1.623e-05, loss_scalings: 6871.948730, pp_loss: 7.312485
[INFO] 2021-07-12 19:04:31,932 [run_pretraining.py:  512]:	********exe.run_1624******* 
[INFO] 2021-07-12 19:04:32,845 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:32,845 [run_pretraining.py:  534]:	loss/total_loss, 7.062618255615234, 1625
[INFO] 2021-07-12 19:04:32,845 [run_pretraining.py:  535]:	loss/mlm_loss, 7.062618255615234, 1625
[INFO] 2021-07-12 19:04:32,846 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.624000105948653e-05, 1625
[INFO] 2021-07-12 19:04:32,846 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1625
[INFO] 2021-07-12 19:04:32,846 [run_pretraining.py:  558]:	worker_index: 7, step: 1625, cost: 7.062618, mlm loss: 7.062618, speed: 1.095040 steps/s, speed: 8.760319 samples/s, speed: 4485.283481 tokens/s, learning rate: 1.624e-05, loss_scalings: 6871.948730, pp_loss: 7.051394
[INFO] 2021-07-12 19:04:32,846 [run_pretraining.py:  512]:	********exe.run_1625******* 
[INFO] 2021-07-12 19:04:33,762 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:33,763 [run_pretraining.py:  534]:	loss/total_loss, 7.7489914894104, 1626
[INFO] 2021-07-12 19:04:33,763 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7489914894104, 1626
[INFO] 2021-07-12 19:04:33,763 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.624999822524842e-05, 1626
[INFO] 2021-07-12 19:04:33,763 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1626
[INFO] 2021-07-12 19:04:33,763 [run_pretraining.py:  558]:	worker_index: 7, step: 1626, cost: 7.748991, mlm loss: 7.748991, speed: 1.090621 steps/s, speed: 8.724969 samples/s, speed: 4467.183938 tokens/s, learning rate: 1.625e-05, loss_scalings: 6871.948730, pp_loss: 7.372985
[INFO] 2021-07-12 19:04:33,763 [run_pretraining.py:  512]:	********exe.run_1626******* 
[INFO] 2021-07-12 19:04:34,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  534]:	loss/total_loss, 7.239657402038574, 1627
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  535]:	loss/mlm_loss, 7.239657402038574, 1627
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6259999028989114e-05, 1627
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1627
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  558]:	worker_index: 7, step: 1627, cost: 7.239657, mlm loss: 7.239657, speed: 1.086830 steps/s, speed: 8.694640 samples/s, speed: 4451.655555 tokens/s, learning rate: 1.626e-05, loss_scalings: 6871.948730, pp_loss: 7.337322
[INFO] 2021-07-12 19:04:34,684 [run_pretraining.py:  512]:	********exe.run_1627******* 
[INFO] 2021-07-12 19:04:35,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  534]:	loss/total_loss, 7.578431606292725, 1628
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  535]:	loss/mlm_loss, 7.578431606292725, 1628
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.626999983272981e-05, 1628
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1628
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  558]:	worker_index: 7, step: 1628, cost: 7.578432, mlm loss: 7.578432, speed: 1.082704 steps/s, speed: 8.661629 samples/s, speed: 4434.754070 tokens/s, learning rate: 1.627e-05, loss_scalings: 6871.948730, pp_loss: 7.505771
[INFO] 2021-07-12 19:04:35,608 [run_pretraining.py:  512]:	********exe.run_1628******* 
[INFO] 2021-07-12 19:04:36,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:36,521 [run_pretraining.py:  534]:	loss/total_loss, 7.466825008392334, 1629
[INFO] 2021-07-12 19:04:36,521 [run_pretraining.py:  535]:	loss/mlm_loss, 7.466825008392334, 1629
[INFO] 2021-07-12 19:04:36,521 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.62799988174811e-05, 1629
[INFO] 2021-07-12 19:04:36,521 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1629
[INFO] 2021-07-12 19:04:36,521 [run_pretraining.py:  558]:	worker_index: 7, step: 1629, cost: 7.466825, mlm loss: 7.466825, speed: 1.096236 steps/s, speed: 8.769888 samples/s, speed: 4490.182469 tokens/s, learning rate: 1.628e-05, loss_scalings: 6871.948730, pp_loss: 7.607814
[INFO] 2021-07-12 19:04:36,521 [run_pretraining.py:  512]:	********exe.run_1629******* 
[INFO] 2021-07-12 19:04:37,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:37,439 [run_pretraining.py:  534]:	loss/total_loss, 7.389163970947266, 1630
[INFO] 2021-07-12 19:04:37,439 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389163970947266, 1630
[INFO] 2021-07-12 19:04:37,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6289999621221796e-05, 1630
[INFO] 2021-07-12 19:04:37,439 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1630
[INFO] 2021-07-12 19:04:37,439 [run_pretraining.py:  558]:	worker_index: 7, step: 1630, cost: 7.389164, mlm loss: 7.389164, speed: 1.090128 steps/s, speed: 8.721025 samples/s, speed: 4465.164869 tokens/s, learning rate: 1.629e-05, loss_scalings: 6871.948730, pp_loss: 7.625778
[INFO] 2021-07-12 19:04:37,439 [run_pretraining.py:  512]:	********exe.run_1630******* 
[INFO] 2021-07-12 19:04:38,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:38,358 [run_pretraining.py:  534]:	loss/total_loss, 7.214165687561035, 1631
[INFO] 2021-07-12 19:04:38,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.214165687561035, 1631
[INFO] 2021-07-12 19:04:38,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.630000042496249e-05, 1631
[INFO] 2021-07-12 19:04:38,358 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1631
[INFO] 2021-07-12 19:04:38,358 [run_pretraining.py:  558]:	worker_index: 7, step: 1631, cost: 7.214166, mlm loss: 7.214166, speed: 1.089161 steps/s, speed: 8.713287 samples/s, speed: 4461.202868 tokens/s, learning rate: 1.630e-05, loss_scalings: 6871.948730, pp_loss: 7.492162
[INFO] 2021-07-12 19:04:38,358 [run_pretraining.py:  512]:	********exe.run_1631******* 
[INFO] 2021-07-12 19:04:39,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:39,283 [run_pretraining.py:  534]:	loss/total_loss, 7.208438873291016, 1632
[INFO] 2021-07-12 19:04:39,283 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208438873291016, 1632
[INFO] 2021-07-12 19:04:39,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6309999409713782e-05, 1632
[INFO] 2021-07-12 19:04:39,283 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1632
[INFO] 2021-07-12 19:04:39,283 [run_pretraining.py:  558]:	worker_index: 7, step: 1632, cost: 7.208439, mlm loss: 7.208439, speed: 1.081421 steps/s, speed: 8.651365 samples/s, speed: 4429.498930 tokens/s, learning rate: 1.631e-05, loss_scalings: 6871.948730, pp_loss: 6.642154
[INFO] 2021-07-12 19:04:39,283 [run_pretraining.py:  512]:	********exe.run_1632******* 
[INFO] 2021-07-12 19:04:40,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:40,196 [run_pretraining.py:  534]:	loss/total_loss, 7.331289768218994, 1633
[INFO] 2021-07-12 19:04:40,196 [run_pretraining.py:  535]:	loss/mlm_loss, 7.331289768218994, 1633
[INFO] 2021-07-12 19:04:40,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6320000213454477e-05, 1633
[INFO] 2021-07-12 19:04:40,197 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1633
[INFO] 2021-07-12 19:04:40,197 [run_pretraining.py:  558]:	worker_index: 7, step: 1633, cost: 7.331290, mlm loss: 7.331290, speed: 1.095552 steps/s, speed: 8.764420 samples/s, speed: 4487.382910 tokens/s, learning rate: 1.632e-05, loss_scalings: 6871.948730, pp_loss: 7.078134
[INFO] 2021-07-12 19:04:40,197 [run_pretraining.py:  512]:	********exe.run_1633******* 
[INFO] 2021-07-12 19:04:41,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:41,107 [run_pretraining.py:  534]:	loss/total_loss, 7.2655558586120605, 1634
[INFO] 2021-07-12 19:04:41,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2655558586120605, 1634
[INFO] 2021-07-12 19:04:41,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.632999919820577e-05, 1634
[INFO] 2021-07-12 19:04:41,107 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1634
[INFO] 2021-07-12 19:04:41,107 [run_pretraining.py:  558]:	worker_index: 7, step: 1634, cost: 7.265556, mlm loss: 7.265556, speed: 1.099067 steps/s, speed: 8.792537 samples/s, speed: 4501.779024 tokens/s, learning rate: 1.633e-05, loss_scalings: 6871.948730, pp_loss: 7.346294
[INFO] 2021-07-12 19:04:41,107 [run_pretraining.py:  512]:	********exe.run_1634******* 
[INFO] 2021-07-12 19:04:42,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:42,019 [run_pretraining.py:  534]:	loss/total_loss, 7.080141067504883, 1635
[INFO] 2021-07-12 19:04:42,019 [run_pretraining.py:  535]:	loss/mlm_loss, 7.080141067504883, 1635
[INFO] 2021-07-12 19:04:42,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.633999818295706e-05, 1635
[INFO] 2021-07-12 19:04:42,019 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1635
[INFO] 2021-07-12 19:04:42,019 [run_pretraining.py:  558]:	worker_index: 7, step: 1635, cost: 7.080141, mlm loss: 7.080141, speed: 1.097657 steps/s, speed: 8.781255 samples/s, speed: 4496.002684 tokens/s, learning rate: 1.634e-05, loss_scalings: 6871.948730, pp_loss: 7.300488
[INFO] 2021-07-12 19:04:42,019 [run_pretraining.py:  512]:	********exe.run_1635******* 
[INFO] 2021-07-12 19:04:42,931 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:42,932 [run_pretraining.py:  534]:	loss/total_loss, 7.992551326751709, 1636
[INFO] 2021-07-12 19:04:42,932 [run_pretraining.py:  535]:	loss/mlm_loss, 7.992551326751709, 1636
[INFO] 2021-07-12 19:04:42,932 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6349998986697756e-05, 1636
[INFO] 2021-07-12 19:04:42,932 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1636
[INFO] 2021-07-12 19:04:42,932 [run_pretraining.py:  558]:	worker_index: 7, step: 1636, cost: 7.992551, mlm loss: 7.992551, speed: 1.095633 steps/s, speed: 8.765061 samples/s, speed: 4487.711123 tokens/s, learning rate: 1.635e-05, loss_scalings: 6871.948730, pp_loss: 7.467935
[INFO] 2021-07-12 19:04:42,932 [run_pretraining.py:  512]:	********exe.run_1636******* 
[INFO] 2021-07-12 19:04:43,849 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:43,849 [run_pretraining.py:  534]:	loss/total_loss, 8.16468620300293, 1637
[INFO] 2021-07-12 19:04:43,849 [run_pretraining.py:  535]:	loss/mlm_loss, 8.16468620300293, 1637
[INFO] 2021-07-12 19:04:43,850 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.635999979043845e-05, 1637
[INFO] 2021-07-12 19:04:43,850 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1637
[INFO] 2021-07-12 19:04:43,850 [run_pretraining.py:  558]:	worker_index: 7, step: 1637, cost: 8.164686, mlm loss: 8.164686, speed: 1.090796 steps/s, speed: 8.726364 samples/s, speed: 4467.898421 tokens/s, learning rate: 1.636e-05, loss_scalings: 6871.948730, pp_loss: 7.520114
[INFO] 2021-07-12 19:04:43,850 [run_pretraining.py:  512]:	********exe.run_1637******* 
[INFO] 2021-07-12 19:04:44,765 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:44,766 [run_pretraining.py:  534]:	loss/total_loss, 7.487776756286621, 1638
[INFO] 2021-07-12 19:04:44,766 [run_pretraining.py:  535]:	loss/mlm_loss, 7.487776756286621, 1638
[INFO] 2021-07-12 19:04:44,766 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6369998775189742e-05, 1638
[INFO] 2021-07-12 19:04:44,766 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1638
[INFO] 2021-07-12 19:04:44,766 [run_pretraining.py:  558]:	worker_index: 7, step: 1638, cost: 7.487777, mlm loss: 7.487777, speed: 1.092135 steps/s, speed: 8.737078 samples/s, speed: 4473.383733 tokens/s, learning rate: 1.637e-05, loss_scalings: 6871.948730, pp_loss: 7.304117
[INFO] 2021-07-12 19:04:44,766 [run_pretraining.py:  512]:	********exe.run_1638******* 
[INFO] 2021-07-12 19:04:45,696 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:45,697 [run_pretraining.py:  534]:	loss/total_loss, 7.103219985961914, 1639
[INFO] 2021-07-12 19:04:45,697 [run_pretraining.py:  535]:	loss/mlm_loss, 7.103219985961914, 1639
[INFO] 2021-07-12 19:04:45,697 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6379999578930438e-05, 1639
[INFO] 2021-07-12 19:04:45,697 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1639
[INFO] 2021-07-12 19:04:45,697 [run_pretraining.py:  558]:	worker_index: 7, step: 1639, cost: 7.103220, mlm loss: 7.103220, speed: 1.074760 steps/s, speed: 8.598083 samples/s, speed: 4402.218546 tokens/s, learning rate: 1.638e-05, loss_scalings: 6871.948730, pp_loss: 7.195333
[INFO] 2021-07-12 19:04:45,697 [run_pretraining.py:  512]:	********exe.run_1639******* 
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  534]:	loss/total_loss, 6.720053672790527, 1640
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  535]:	loss/mlm_loss, 6.720053672790527, 1640
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6390000382671133e-05, 1640
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1640
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  558]:	worker_index: 7, step: 1640, cost: 6.720054, mlm loss: 6.720054, speed: 1.096946 steps/s, speed: 8.775571 samples/s, speed: 4493.092454 tokens/s, learning rate: 1.639e-05, loss_scalings: 6871.948730, pp_loss: 7.144674
[INFO] 2021-07-12 19:04:46,609 [run_pretraining.py:  512]:	********exe.run_1640******* 
[INFO] 2021-07-12 19:04:47,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:47,515 [run_pretraining.py:  534]:	loss/total_loss, 7.66626501083374, 1641
[INFO] 2021-07-12 19:04:47,515 [run_pretraining.py:  535]:	loss/mlm_loss, 7.66626501083374, 1641
[INFO] 2021-07-12 19:04:47,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6399999367422424e-05, 1641
[INFO] 2021-07-12 19:04:47,516 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1641
[INFO] 2021-07-12 19:04:47,516 [run_pretraining.py:  558]:	worker_index: 7, step: 1641, cost: 7.666265, mlm loss: 7.666265, speed: 1.104305 steps/s, speed: 8.834440 samples/s, speed: 4523.233400 tokens/s, learning rate: 1.640e-05, loss_scalings: 6871.948730, pp_loss: 7.424836
[INFO] 2021-07-12 19:04:47,516 [run_pretraining.py:  512]:	********exe.run_1641******* 
[INFO] 2021-07-12 19:04:48,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:48,426 [run_pretraining.py:  534]:	loss/total_loss, 7.99361515045166, 1642
[INFO] 2021-07-12 19:04:48,426 [run_pretraining.py:  535]:	loss/mlm_loss, 7.99361515045166, 1642
[INFO] 2021-07-12 19:04:48,426 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.641000017116312e-05, 1642
[INFO] 2021-07-12 19:04:48,426 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1642
[INFO] 2021-07-12 19:04:48,426 [run_pretraining.py:  558]:	worker_index: 7, step: 1642, cost: 7.993615, mlm loss: 7.993615, speed: 1.098737 steps/s, speed: 8.789900 samples/s, speed: 4500.428745 tokens/s, learning rate: 1.641e-05, loss_scalings: 6871.948730, pp_loss: 7.598478
[INFO] 2021-07-12 19:04:48,426 [run_pretraining.py:  512]:	********exe.run_1642******* 
[INFO] 2021-07-12 19:04:49,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:49,342 [run_pretraining.py:  534]:	loss/total_loss, 7.386160850524902, 1643
[INFO] 2021-07-12 19:04:49,342 [run_pretraining.py:  535]:	loss/mlm_loss, 7.386160850524902, 1643
[INFO] 2021-07-12 19:04:49,342 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.641999915591441e-05, 1643
[INFO] 2021-07-12 19:04:49,342 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1643
[INFO] 2021-07-12 19:04:49,342 [run_pretraining.py:  558]:	worker_index: 7, step: 1643, cost: 7.386161, mlm loss: 7.386161, speed: 1.092778 steps/s, speed: 8.742227 samples/s, speed: 4476.020070 tokens/s, learning rate: 1.642e-05, loss_scalings: 6871.948730, pp_loss: 7.218346
[INFO] 2021-07-12 19:04:49,342 [run_pretraining.py:  512]:	********exe.run_1643******* 
[INFO] 2021-07-12 19:04:50,258 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:50,258 [run_pretraining.py:  534]:	loss/total_loss, 7.377560615539551, 1644
[INFO] 2021-07-12 19:04:50,258 [run_pretraining.py:  535]:	loss/mlm_loss, 7.377560615539551, 1644
[INFO] 2021-07-12 19:04:50,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6429999959655106e-05, 1644
[INFO] 2021-07-12 19:04:50,258 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1644
[INFO] 2021-07-12 19:04:50,259 [run_pretraining.py:  558]:	worker_index: 7, step: 1644, cost: 7.377561, mlm loss: 7.377561, speed: 1.091993 steps/s, speed: 8.735945 samples/s, speed: 4472.803736 tokens/s, learning rate: 1.643e-05, loss_scalings: 6871.948730, pp_loss: 6.459144
[INFO] 2021-07-12 19:04:50,259 [run_pretraining.py:  512]:	********exe.run_1644******* 
[INFO] 2021-07-12 19:04:51,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:51,320 [run_pretraining.py:  534]:	loss/total_loss, 7.328971862792969, 1645
[INFO] 2021-07-12 19:04:51,320 [run_pretraining.py:  535]:	loss/mlm_loss, 7.328971862792969, 1645
[INFO] 2021-07-12 19:04:51,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6439998944406398e-05, 1645
[INFO] 2021-07-12 19:04:51,321 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1645
[INFO] 2021-07-12 19:04:51,321 [run_pretraining.py:  558]:	worker_index: 7, step: 1645, cost: 7.328972, mlm loss: 7.328972, speed: 0.942092 steps/s, speed: 7.536733 samples/s, speed: 3858.807274 tokens/s, learning rate: 1.644e-05, loss_scalings: 6871.948730, pp_loss: 7.345795
[INFO] 2021-07-12 19:04:51,321 [run_pretraining.py:  512]:	********exe.run_1645******* 
[INFO] 2021-07-12 19:04:52,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:52,233 [run_pretraining.py:  534]:	loss/total_loss, 7.379092693328857, 1646
[INFO] 2021-07-12 19:04:52,234 [run_pretraining.py:  535]:	loss/mlm_loss, 7.379092693328857, 1646
[INFO] 2021-07-12 19:04:52,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6449999748147093e-05, 1646
[INFO] 2021-07-12 19:04:52,234 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1646
[INFO] 2021-07-12 19:04:52,234 [run_pretraining.py:  558]:	worker_index: 7, step: 1646, cost: 7.379093, mlm loss: 7.379093, speed: 1.095874 steps/s, speed: 8.766996 samples/s, speed: 4488.701915 tokens/s, learning rate: 1.645e-05, loss_scalings: 6871.948730, pp_loss: 7.578010
[INFO] 2021-07-12 19:04:52,234 [run_pretraining.py:  512]:	********exe.run_1646******* 
[INFO] 2021-07-12 19:04:53,134 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:53,134 [run_pretraining.py:  534]:	loss/total_loss, 7.281856060028076, 1647
[INFO] 2021-07-12 19:04:53,134 [run_pretraining.py:  535]:	loss/mlm_loss, 7.281856060028076, 1647
[INFO] 2021-07-12 19:04:53,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6459998732898384e-05, 1647
[INFO] 2021-07-12 19:04:53,134 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1647
[INFO] 2021-07-12 19:04:53,135 [run_pretraining.py:  558]:	worker_index: 7, step: 1647, cost: 7.281856, mlm loss: 7.281856, speed: 1.110995 steps/s, speed: 8.887963 samples/s, speed: 4550.636865 tokens/s, learning rate: 1.646e-05, loss_scalings: 6871.948730, pp_loss: 7.502225
[INFO] 2021-07-12 19:04:53,135 [run_pretraining.py:  512]:	********exe.run_1647******* 
[INFO] 2021-07-12 19:04:54,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  534]:	loss/total_loss, 6.723363876342773, 1648
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  535]:	loss/mlm_loss, 6.723363876342773, 1648
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.646999953663908e-05, 1648
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1648
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  558]:	worker_index: 7, step: 1648, cost: 6.723364, mlm loss: 6.723364, speed: 1.091931 steps/s, speed: 8.735449 samples/s, speed: 4472.549889 tokens/s, learning rate: 1.647e-05, loss_scalings: 6871.948730, pp_loss: 7.391151
[INFO] 2021-07-12 19:04:54,051 [run_pretraining.py:  512]:	********exe.run_1648******* 
[INFO] 2021-07-12 19:04:55,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:55,109 [run_pretraining.py:  534]:	loss/total_loss, 7.583868980407715, 1649
[INFO] 2021-07-12 19:04:55,109 [run_pretraining.py:  535]:	loss/mlm_loss, 7.583868980407715, 1649
[INFO] 2021-07-12 19:04:55,109 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6480000340379775e-05, 1649
[INFO] 2021-07-12 19:04:55,109 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1649
[INFO] 2021-07-12 19:04:55,109 [run_pretraining.py:  558]:	worker_index: 7, step: 1649, cost: 7.583869, mlm loss: 7.583869, speed: 0.945352 steps/s, speed: 7.562817 samples/s, speed: 3872.162050 tokens/s, learning rate: 1.648e-05, loss_scalings: 6871.948730, pp_loss: 7.265910
[INFO] 2021-07-12 19:04:55,110 [run_pretraining.py:  512]:	********exe.run_1649******* 
[INFO] 2021-07-12 19:04:56,190 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:56,190 [run_pretraining.py:  534]:	loss/total_loss, 7.305115222930908, 1650
[INFO] 2021-07-12 19:04:56,190 [run_pretraining.py:  535]:	loss/mlm_loss, 7.305115222930908, 1650
[INFO] 2021-07-12 19:04:56,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6489999325131066e-05, 1650
[INFO] 2021-07-12 19:04:56,190 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1650
[INFO] 2021-07-12 19:04:56,190 [run_pretraining.py:  558]:	worker_index: 7, step: 1650, cost: 7.305115, mlm loss: 7.305115, speed: 0.925647 steps/s, speed: 7.405175 samples/s, speed: 3791.449529 tokens/s, learning rate: 1.649e-05, loss_scalings: 6871.948730, pp_loss: 7.138957
[INFO] 2021-07-12 19:04:56,190 [run_pretraining.py:  512]:	********exe.run_1650******* 
[INFO] 2021-07-12 19:04:57,251 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:57,252 [run_pretraining.py:  534]:	loss/total_loss, 6.701298713684082, 1651
[INFO] 2021-07-12 19:04:57,252 [run_pretraining.py:  535]:	loss/mlm_loss, 6.701298713684082, 1651
[INFO] 2021-07-12 19:04:57,252 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.650000012887176e-05, 1651
[INFO] 2021-07-12 19:04:57,252 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1651
[INFO] 2021-07-12 19:04:57,252 [run_pretraining.py:  558]:	worker_index: 7, step: 1651, cost: 6.701299, mlm loss: 6.701299, speed: 0.942634 steps/s, speed: 7.541073 samples/s, speed: 3861.029128 tokens/s, learning rate: 1.650e-05, loss_scalings: 6871.948730, pp_loss: 7.622054
[INFO] 2021-07-12 19:04:57,252 [run_pretraining.py:  512]:	********exe.run_1651******* 
[INFO] 2021-07-12 19:04:58,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:58,318 [run_pretraining.py:  534]:	loss/total_loss, 6.899723052978516, 1652
[INFO] 2021-07-12 19:04:58,318 [run_pretraining.py:  535]:	loss/mlm_loss, 6.899723052978516, 1652
[INFO] 2021-07-12 19:04:58,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6509999113623053e-05, 1652
[INFO] 2021-07-12 19:04:58,319 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1652
[INFO] 2021-07-12 19:04:58,319 [run_pretraining.py:  558]:	worker_index: 7, step: 1652, cost: 6.899723, mlm loss: 6.899723, speed: 0.938027 steps/s, speed: 7.504216 samples/s, speed: 3842.158367 tokens/s, learning rate: 1.651e-05, loss_scalings: 6871.948730, pp_loss: 7.066864
[INFO] 2021-07-12 19:04:58,319 [run_pretraining.py:  512]:	********exe.run_1652******* 
[INFO] 2021-07-12 19:04:59,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:04:59,376 [run_pretraining.py:  534]:	loss/total_loss, 7.914846420288086, 1653
[INFO] 2021-07-12 19:04:59,376 [run_pretraining.py:  535]:	loss/mlm_loss, 7.914846420288086, 1653
[INFO] 2021-07-12 19:04:59,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6519999917363748e-05, 1653
[INFO] 2021-07-12 19:04:59,376 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1653
[INFO] 2021-07-12 19:04:59,376 [run_pretraining.py:  558]:	worker_index: 7, step: 1653, cost: 7.914846, mlm loss: 7.914846, speed: 0.946162 steps/s, speed: 7.569296 samples/s, speed: 3875.479574 tokens/s, learning rate: 1.652e-05, loss_scalings: 6871.948730, pp_loss: 6.891425
[INFO] 2021-07-12 19:04:59,376 [run_pretraining.py:  512]:	********exe.run_1653******* 
[INFO] 2021-07-12 19:05:00,375 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:00,376 [run_pretraining.py:  534]:	loss/total_loss, 7.469943046569824, 1654
[INFO] 2021-07-12 19:05:00,376 [run_pretraining.py:  535]:	loss/mlm_loss, 7.469943046569824, 1654
[INFO] 2021-07-12 19:05:00,376 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.652999890211504e-05, 1654
[INFO] 2021-07-12 19:05:00,376 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1654
[INFO] 2021-07-12 19:05:00,376 [run_pretraining.py:  558]:	worker_index: 7, step: 1654, cost: 7.469943, mlm loss: 7.469943, speed: 1.000650 steps/s, speed: 8.005197 samples/s, speed: 4098.660907 tokens/s, learning rate: 1.653e-05, loss_scalings: 6871.948730, pp_loss: 7.408048
[INFO] 2021-07-12 19:05:00,376 [run_pretraining.py:  512]:	********exe.run_1654******* 
[INFO] 2021-07-12 19:05:01,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:01,305 [run_pretraining.py:  534]:	loss/total_loss, 6.609087944030762, 1655
[INFO] 2021-07-12 19:05:01,306 [run_pretraining.py:  535]:	loss/mlm_loss, 6.609087944030762, 1655
[INFO] 2021-07-12 19:05:01,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6539999705855735e-05, 1655
[INFO] 2021-07-12 19:05:01,306 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1655
[INFO] 2021-07-12 19:05:01,306 [run_pretraining.py:  558]:	worker_index: 7, step: 1655, cost: 6.609088, mlm loss: 6.609088, speed: 1.076520 steps/s, speed: 8.612158 samples/s, speed: 4409.424944 tokens/s, learning rate: 1.654e-05, loss_scalings: 6871.948730, pp_loss: 7.248743
[INFO] 2021-07-12 19:05:01,306 [run_pretraining.py:  512]:	********exe.run_1655******* 
[INFO] 2021-07-12 19:05:02,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:02,212 [run_pretraining.py:  534]:	loss/total_loss, 6.993879318237305, 1656
[INFO] 2021-07-12 19:05:02,212 [run_pretraining.py:  535]:	loss/mlm_loss, 6.993879318237305, 1656
[INFO] 2021-07-12 19:05:02,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6549998690607026e-05, 1656
[INFO] 2021-07-12 19:05:02,212 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1656
[INFO] 2021-07-12 19:05:02,213 [run_pretraining.py:  558]:	worker_index: 7, step: 1656, cost: 6.993879, mlm loss: 6.993879, speed: 1.103632 steps/s, speed: 8.829054 samples/s, speed: 4520.475749 tokens/s, learning rate: 1.655e-05, loss_scalings: 6871.948730, pp_loss: 7.520061
[INFO] 2021-07-12 19:05:02,213 [run_pretraining.py:  512]:	********exe.run_1656******* 
[INFO] 2021-07-12 19:05:03,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:03,128 [run_pretraining.py:  534]:	loss/total_loss, 7.357014179229736, 1657
[INFO] 2021-07-12 19:05:03,128 [run_pretraining.py:  535]:	loss/mlm_loss, 7.357014179229736, 1657
[INFO] 2021-07-12 19:05:03,128 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.655999949434772e-05, 1657
[INFO] 2021-07-12 19:05:03,128 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1657
[INFO] 2021-07-12 19:05:03,128 [run_pretraining.py:  558]:	worker_index: 7, step: 1657, cost: 7.357014, mlm loss: 7.357014, speed: 1.093002 steps/s, speed: 8.744015 samples/s, speed: 4476.935705 tokens/s, learning rate: 1.656e-05, loss_scalings: 6871.948730, pp_loss: 7.400195
[INFO] 2021-07-12 19:05:03,128 [run_pretraining.py:  512]:	********exe.run_1657******* 
[INFO] 2021-07-12 19:05:04,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:04,076 [run_pretraining.py:  534]:	loss/total_loss, 7.312518119812012, 1658
[INFO] 2021-07-12 19:05:04,076 [run_pretraining.py:  535]:	loss/mlm_loss, 7.312518119812012, 1658
[INFO] 2021-07-12 19:05:04,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6570000298088416e-05, 1658
[INFO] 2021-07-12 19:05:04,077 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1658
[INFO] 2021-07-12 19:05:04,077 [run_pretraining.py:  558]:	worker_index: 7, step: 1658, cost: 7.312518, mlm loss: 7.312518, speed: 1.054825 steps/s, speed: 8.438596 samples/s, speed: 4320.561221 tokens/s, learning rate: 1.657e-05, loss_scalings: 6871.948730, pp_loss: 7.265977
[INFO] 2021-07-12 19:05:04,077 [run_pretraining.py:  512]:	********exe.run_1658******* 
[INFO] 2021-07-12 19:05:04,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:04,961 [run_pretraining.py:  534]:	loss/total_loss, 8.283743858337402, 1659
[INFO] 2021-07-12 19:05:04,961 [run_pretraining.py:  535]:	loss/mlm_loss, 8.283743858337402, 1659
[INFO] 2021-07-12 19:05:04,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6579999282839708e-05, 1659
[INFO] 2021-07-12 19:05:04,961 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1659
[INFO] 2021-07-12 19:05:04,961 [run_pretraining.py:  558]:	worker_index: 7, step: 1659, cost: 8.283744, mlm loss: 8.283744, speed: 1.131389 steps/s, speed: 9.051108 samples/s, speed: 4634.167504 tokens/s, learning rate: 1.658e-05, loss_scalings: 6871.948730, pp_loss: 7.116805
[INFO] 2021-07-12 19:05:04,961 [run_pretraining.py:  512]:	********exe.run_1659******* 
[INFO] 2021-07-12 19:05:05,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:05,869 [run_pretraining.py:  534]:	loss/total_loss, 7.877758026123047, 1660
[INFO] 2021-07-12 19:05:05,869 [run_pretraining.py:  535]:	loss/mlm_loss, 7.877758026123047, 1660
[INFO] 2021-07-12 19:05:05,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6590000086580403e-05, 1660
[INFO] 2021-07-12 19:05:05,869 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1660
[INFO] 2021-07-12 19:05:05,869 [run_pretraining.py:  558]:	worker_index: 7, step: 1660, cost: 7.877758, mlm loss: 7.877758, speed: 1.102478 steps/s, speed: 8.819820 samples/s, speed: 4515.747853 tokens/s, learning rate: 1.659e-05, loss_scalings: 6871.948730, pp_loss: 7.374588
[INFO] 2021-07-12 19:05:05,869 [run_pretraining.py:  512]:	********exe.run_1660******* 
[INFO] 2021-07-12 19:05:06,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:06,776 [run_pretraining.py:  534]:	loss/total_loss, 7.39936637878418, 1661
[INFO] 2021-07-12 19:05:06,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.39936637878418, 1661
[INFO] 2021-07-12 19:05:06,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6599999071331695e-05, 1661
[INFO] 2021-07-12 19:05:06,777 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1661
[INFO] 2021-07-12 19:05:06,777 [run_pretraining.py:  558]:	worker_index: 7, step: 1661, cost: 7.399366, mlm loss: 7.399366, speed: 1.102399 steps/s, speed: 8.819194 samples/s, speed: 4515.427394 tokens/s, learning rate: 1.660e-05, loss_scalings: 6871.948730, pp_loss: 7.534587
[INFO] 2021-07-12 19:05:06,777 [run_pretraining.py:  512]:	********exe.run_1661******* 
[INFO] 2021-07-12 19:05:07,802 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:07,803 [run_pretraining.py:  534]:	loss/total_loss, 7.551009178161621, 1662
[INFO] 2021-07-12 19:05:07,803 [run_pretraining.py:  535]:	loss/mlm_loss, 7.551009178161621, 1662
[INFO] 2021-07-12 19:05:07,803 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.660999987507239e-05, 1662
[INFO] 2021-07-12 19:05:07,803 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1662
[INFO] 2021-07-12 19:05:07,803 [run_pretraining.py:  558]:	worker_index: 7, step: 1662, cost: 7.551009, mlm loss: 7.551009, speed: 0.974908 steps/s, speed: 7.799261 samples/s, speed: 3993.221509 tokens/s, learning rate: 1.661e-05, loss_scalings: 6871.948730, pp_loss: 6.879318
[INFO] 2021-07-12 19:05:07,803 [run_pretraining.py:  512]:	********exe.run_1662******* 
[INFO] 2021-07-12 19:05:08,882 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:08,882 [run_pretraining.py:  534]:	loss/total_loss, 7.876174449920654, 1663
[INFO] 2021-07-12 19:05:08,882 [run_pretraining.py:  535]:	loss/mlm_loss, 7.876174449920654, 1663
[INFO] 2021-07-12 19:05:08,883 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.661999885982368e-05, 1663
[INFO] 2021-07-12 19:05:08,883 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1663
[INFO] 2021-07-12 19:05:08,883 [run_pretraining.py:  558]:	worker_index: 7, step: 1663, cost: 7.876174, mlm loss: 7.876174, speed: 0.926883 steps/s, speed: 7.415064 samples/s, speed: 3796.512703 tokens/s, learning rate: 1.662e-05, loss_scalings: 6871.948730, pp_loss: 7.498208
[INFO] 2021-07-12 19:05:08,883 [run_pretraining.py:  512]:	********exe.run_1663******* 
[INFO] 2021-07-12 19:05:09,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:09,945 [run_pretraining.py:  534]:	loss/total_loss, 7.076490879058838, 1664
[INFO] 2021-07-12 19:05:09,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.076490879058838, 1664
[INFO] 2021-07-12 19:05:09,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6629999663564377e-05, 1664
[INFO] 2021-07-12 19:05:09,945 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1664
[INFO] 2021-07-12 19:05:09,945 [run_pretraining.py:  558]:	worker_index: 7, step: 1664, cost: 7.076491, mlm loss: 7.076491, speed: 0.941868 steps/s, speed: 7.534944 samples/s, speed: 3857.891353 tokens/s, learning rate: 1.663e-05, loss_scalings: 6871.948730, pp_loss: 7.097571
[INFO] 2021-07-12 19:05:09,945 [run_pretraining.py:  512]:	********exe.run_1664******* 
[INFO] 2021-07-12 19:05:11,005 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:11,006 [run_pretraining.py:  534]:	loss/total_loss, 7.288766384124756, 1665
[INFO] 2021-07-12 19:05:11,006 [run_pretraining.py:  535]:	loss/mlm_loss, 7.288766384124756, 1665
[INFO] 2021-07-12 19:05:11,006 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.664000046730507e-05, 1665
[INFO] 2021-07-12 19:05:11,006 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1665
[INFO] 2021-07-12 19:05:11,006 [run_pretraining.py:  558]:	worker_index: 7, step: 1665, cost: 7.288766, mlm loss: 7.288766, speed: 0.942873 steps/s, speed: 7.542985 samples/s, speed: 3862.008180 tokens/s, learning rate: 1.664e-05, loss_scalings: 6871.948730, pp_loss: 7.288841
[INFO] 2021-07-12 19:05:11,006 [run_pretraining.py:  512]:	********exe.run_1665******* 
[INFO] 2021-07-12 19:05:12,062 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:12,063 [run_pretraining.py:  534]:	loss/total_loss, 7.840318202972412, 1666
[INFO] 2021-07-12 19:05:12,063 [run_pretraining.py:  535]:	loss/mlm_loss, 7.840318202972412, 1666
[INFO] 2021-07-12 19:05:12,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6649999452056363e-05, 1666
[INFO] 2021-07-12 19:05:12,063 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1666
[INFO] 2021-07-12 19:05:12,063 [run_pretraining.py:  558]:	worker_index: 7, step: 1666, cost: 7.840318, mlm loss: 7.840318, speed: 0.946560 steps/s, speed: 7.572477 samples/s, speed: 3877.108094 tokens/s, learning rate: 1.665e-05, loss_scalings: 6871.948730, pp_loss: 7.440104
[INFO] 2021-07-12 19:05:12,063 [run_pretraining.py:  512]:	********exe.run_1666******* 
[INFO] 2021-07-12 19:05:13,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:13,123 [run_pretraining.py:  534]:	loss/total_loss, 6.826695919036865, 1667
[INFO] 2021-07-12 19:05:13,123 [run_pretraining.py:  535]:	loss/mlm_loss, 6.826695919036865, 1667
[INFO] 2021-07-12 19:05:13,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.666000025579706e-05, 1667
[INFO] 2021-07-12 19:05:13,123 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1667
[INFO] 2021-07-12 19:05:13,123 [run_pretraining.py:  558]:	worker_index: 7, step: 1667, cost: 6.826696, mlm loss: 6.826696, speed: 0.944330 steps/s, speed: 7.554638 samples/s, speed: 3867.974790 tokens/s, learning rate: 1.666e-05, loss_scalings: 6871.948730, pp_loss: 6.896254
[INFO] 2021-07-12 19:05:13,123 [run_pretraining.py:  512]:	********exe.run_1667******* 
[INFO] 2021-07-12 19:05:14,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:14,177 [run_pretraining.py:  534]:	loss/total_loss, 7.044066429138184, 1668
[INFO] 2021-07-12 19:05:14,177 [run_pretraining.py:  535]:	loss/mlm_loss, 7.044066429138184, 1668
[INFO] 2021-07-12 19:05:14,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.666999924054835e-05, 1668
[INFO] 2021-07-12 19:05:14,177 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1668
[INFO] 2021-07-12 19:05:14,177 [run_pretraining.py:  558]:	worker_index: 7, step: 1668, cost: 7.044066, mlm loss: 7.044066, speed: 0.949431 steps/s, speed: 7.595449 samples/s, speed: 3888.870092 tokens/s, learning rate: 1.667e-05, loss_scalings: 6871.948730, pp_loss: 7.237898
[INFO] 2021-07-12 19:05:14,177 [run_pretraining.py:  512]:	********exe.run_1668******* 
[INFO] 2021-07-12 19:05:15,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:15,256 [run_pretraining.py:  534]:	loss/total_loss, 6.56546688079834, 1669
[INFO] 2021-07-12 19:05:15,256 [run_pretraining.py:  535]:	loss/mlm_loss, 6.56546688079834, 1669
[INFO] 2021-07-12 19:05:15,256 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6680000044289045e-05, 1669
[INFO] 2021-07-12 19:05:15,257 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1669
[INFO] 2021-07-12 19:05:15,257 [run_pretraining.py:  558]:	worker_index: 7, step: 1669, cost: 6.565467, mlm loss: 6.565467, speed: 0.926746 steps/s, speed: 7.413971 samples/s, speed: 3795.953188 tokens/s, learning rate: 1.668e-05, loss_scalings: 6871.948730, pp_loss: 7.379992
[INFO] 2021-07-12 19:05:15,257 [run_pretraining.py:  512]:	********exe.run_1669******* 
[INFO] 2021-07-12 19:05:40,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:40,463 [run_pretraining.py:  534]:	loss/total_loss, 7.1133856773376465, 1670
[INFO] 2021-07-12 19:05:40,463 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1133856773376465, 1670
[INFO] 2021-07-12 19:05:40,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6689999029040337e-05, 1670
[INFO] 2021-07-12 19:05:40,463 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1670
[INFO] 2021-07-12 19:05:40,463 [run_pretraining.py:  558]:	worker_index: 7, step: 1670, cost: 7.113386, mlm loss: 7.113386, speed: 0.039673 steps/s, speed: 0.317383 samples/s, speed: 162.500303 tokens/s, learning rate: 1.669e-05, loss_scalings: 6871.948730, pp_loss: 7.080691
[INFO] 2021-07-12 19:05:40,463 [run_pretraining.py:  512]:	********exe.run_1670******* 
[INFO] 2021-07-12 19:05:41,374 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  534]:	loss/total_loss, 6.050216197967529, 1671
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  535]:	loss/mlm_loss, 6.050216197967529, 1671
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6699999832781032e-05, 1671
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1671
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  558]:	worker_index: 7, step: 1671, cost: 6.050216, mlm loss: 6.050216, speed: 1.097561 steps/s, speed: 8.780490 samples/s, speed: 4495.610906 tokens/s, learning rate: 1.670e-05, loss_scalings: 6871.948730, pp_loss: 7.023186
[INFO] 2021-07-12 19:05:41,375 [run_pretraining.py:  512]:	********exe.run_1671******* 
[INFO] 2021-07-12 19:05:42,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:42,280 [run_pretraining.py:  534]:	loss/total_loss, 7.216603755950928, 1672
[INFO] 2021-07-12 19:05:42,280 [run_pretraining.py:  535]:	loss/mlm_loss, 7.216603755950928, 1672
[INFO] 2021-07-12 19:05:42,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6709998817532323e-05, 1672
[INFO] 2021-07-12 19:05:42,280 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1672
[INFO] 2021-07-12 19:05:42,280 [run_pretraining.py:  558]:	worker_index: 7, step: 1672, cost: 7.216604, mlm loss: 7.216604, speed: 1.105729 steps/s, speed: 8.845829 samples/s, speed: 4529.064447 tokens/s, learning rate: 1.671e-05, loss_scalings: 6871.948730, pp_loss: 6.627874
[INFO] 2021-07-12 19:05:42,280 [run_pretraining.py:  512]:	********exe.run_1672******* 
[INFO] 2021-07-12 19:05:43,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:43,193 [run_pretraining.py:  534]:	loss/total_loss, 7.685245037078857, 1673
[INFO] 2021-07-12 19:05:43,193 [run_pretraining.py:  535]:	loss/mlm_loss, 7.685245037078857, 1673
[INFO] 2021-07-12 19:05:43,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.671999962127302e-05, 1673
[INFO] 2021-07-12 19:05:43,193 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1673
[INFO] 2021-07-12 19:05:43,193 [run_pretraining.py:  558]:	worker_index: 7, step: 1673, cost: 7.685245, mlm loss: 7.685245, speed: 1.096421 steps/s, speed: 8.771369 samples/s, speed: 4490.940722 tokens/s, learning rate: 1.672e-05, loss_scalings: 6871.948730, pp_loss: 7.269722
[INFO] 2021-07-12 19:05:43,193 [run_pretraining.py:  512]:	********exe.run_1673******* 
[INFO] 2021-07-12 19:05:44,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:44,175 [run_pretraining.py:  534]:	loss/total_loss, 6.442493438720703, 1674
[INFO] 2021-07-12 19:05:44,175 [run_pretraining.py:  535]:	loss/mlm_loss, 6.442493438720703, 1674
[INFO] 2021-07-12 19:05:44,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6730000425013714e-05, 1674
[INFO] 2021-07-12 19:05:44,175 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1674
[INFO] 2021-07-12 19:05:44,175 [run_pretraining.py:  558]:	worker_index: 7, step: 1674, cost: 6.442493, mlm loss: 6.442493, speed: 1.018397 steps/s, speed: 8.147175 samples/s, speed: 4171.353409 tokens/s, learning rate: 1.673e-05, loss_scalings: 6871.948730, pp_loss: 6.680348
[INFO] 2021-07-12 19:05:44,176 [run_pretraining.py:  512]:	********exe.run_1674******* 
[INFO] 2021-07-12 19:05:45,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:45,082 [run_pretraining.py:  534]:	loss/total_loss, 7.197308540344238, 1675
[INFO] 2021-07-12 19:05:45,082 [run_pretraining.py:  535]:	loss/mlm_loss, 7.197308540344238, 1675
[INFO] 2021-07-12 19:05:45,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6739999409765005e-05, 1675
[INFO] 2021-07-12 19:05:45,082 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1675
[INFO] 2021-07-12 19:05:45,082 [run_pretraining.py:  558]:	worker_index: 7, step: 1675, cost: 7.197309, mlm loss: 7.197309, speed: 1.103729 steps/s, speed: 8.829833 samples/s, speed: 4520.874252 tokens/s, learning rate: 1.674e-05, loss_scalings: 6871.948730, pp_loss: 7.288086
[INFO] 2021-07-12 19:05:45,082 [run_pretraining.py:  512]:	********exe.run_1675******* 
[INFO] 2021-07-12 19:05:45,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:45,996 [run_pretraining.py:  534]:	loss/total_loss, 7.311558246612549, 1676
[INFO] 2021-07-12 19:05:45,996 [run_pretraining.py:  535]:	loss/mlm_loss, 7.311558246612549, 1676
[INFO] 2021-07-12 19:05:45,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.67500002135057e-05, 1676
[INFO] 2021-07-12 19:05:45,996 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1676
[INFO] 2021-07-12 19:05:45,996 [run_pretraining.py:  558]:	worker_index: 7, step: 1676, cost: 7.311558, mlm loss: 7.311558, speed: 1.095044 steps/s, speed: 8.760351 samples/s, speed: 4485.299875 tokens/s, learning rate: 1.675e-05, loss_scalings: 6871.948730, pp_loss: 7.478031
[INFO] 2021-07-12 19:05:45,996 [run_pretraining.py:  512]:	********exe.run_1676******* 
[INFO] 2021-07-12 19:05:46,903 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:46,903 [run_pretraining.py:  534]:	loss/total_loss, 7.788601398468018, 1677
[INFO] 2021-07-12 19:05:46,903 [run_pretraining.py:  535]:	loss/mlm_loss, 7.788601398468018, 1677
[INFO] 2021-07-12 19:05:46,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6760001017246395e-05, 1677
[INFO] 2021-07-12 19:05:46,903 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1677
[INFO] 2021-07-12 19:05:46,903 [run_pretraining.py:  558]:	worker_index: 7, step: 1677, cost: 7.788601, mlm loss: 7.788601, speed: 1.102744 steps/s, speed: 8.821956 samples/s, speed: 4516.841317 tokens/s, learning rate: 1.676e-05, loss_scalings: 6871.948730, pp_loss: 7.604005
[INFO] 2021-07-12 19:05:46,904 [run_pretraining.py:  512]:	********exe.run_1677******* 
[INFO] 2021-07-12 19:05:47,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:47,809 [run_pretraining.py:  534]:	loss/total_loss, 7.061259746551514, 1678
[INFO] 2021-07-12 19:05:47,809 [run_pretraining.py:  535]:	loss/mlm_loss, 7.061259746551514, 1678
[INFO] 2021-07-12 19:05:47,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6769998183008283e-05, 1678
[INFO] 2021-07-12 19:05:47,809 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1678
[INFO] 2021-07-12 19:05:47,809 [run_pretraining.py:  558]:	worker_index: 7, step: 1678, cost: 7.061260, mlm loss: 7.061260, speed: 1.104881 steps/s, speed: 8.839048 samples/s, speed: 4525.592628 tokens/s, learning rate: 1.677e-05, loss_scalings: 6871.948730, pp_loss: 7.369742
[INFO] 2021-07-12 19:05:47,809 [run_pretraining.py:  512]:	********exe.run_1678******* 
[INFO] 2021-07-12 19:05:48,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:48,724 [run_pretraining.py:  534]:	loss/total_loss, 7.120279312133789, 1679
[INFO] 2021-07-12 19:05:48,724 [run_pretraining.py:  535]:	loss/mlm_loss, 7.120279312133789, 1679
[INFO] 2021-07-12 19:05:48,724 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.677999898674898e-05, 1679
[INFO] 2021-07-12 19:05:48,725 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1679
[INFO] 2021-07-12 19:05:48,725 [run_pretraining.py:  558]:	worker_index: 7, step: 1679, cost: 7.120279, mlm loss: 7.120279, speed: 1.093264 steps/s, speed: 8.746112 samples/s, speed: 4478.009284 tokens/s, learning rate: 1.678e-05, loss_scalings: 6871.948730, pp_loss: 7.077111
[INFO] 2021-07-12 19:05:48,725 [run_pretraining.py:  512]:	********exe.run_1679******* 
[INFO] 2021-07-12 19:05:49,634 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:49,635 [run_pretraining.py:  534]:	loss/total_loss, 7.393698692321777, 1680
[INFO] 2021-07-12 19:05:49,635 [run_pretraining.py:  535]:	loss/mlm_loss, 7.393698692321777, 1680
[INFO] 2021-07-12 19:05:49,635 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6789999790489674e-05, 1680
[INFO] 2021-07-12 19:05:49,635 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1680
[INFO] 2021-07-12 19:05:49,635 [run_pretraining.py:  558]:	worker_index: 7, step: 1680, cost: 7.393699, mlm loss: 7.393699, speed: 1.099326 steps/s, speed: 8.794609 samples/s, speed: 4502.839768 tokens/s, learning rate: 1.679e-05, loss_scalings: 6871.948730, pp_loss: 7.128995
[INFO] 2021-07-12 19:05:49,635 [run_pretraining.py:  512]:	********exe.run_1680******* 
[INFO] 2021-07-12 19:05:50,554 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:50,555 [run_pretraining.py:  534]:	loss/total_loss, 7.385140419006348, 1681
[INFO] 2021-07-12 19:05:50,555 [run_pretraining.py:  535]:	loss/mlm_loss, 7.385140419006348, 1681
[INFO] 2021-07-12 19:05:50,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6799998775240965e-05, 1681
[INFO] 2021-07-12 19:05:50,555 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1681
[INFO] 2021-07-12 19:05:50,555 [run_pretraining.py:  558]:	worker_index: 7, step: 1681, cost: 7.385140, mlm loss: 7.385140, speed: 1.087632 steps/s, speed: 8.701059 samples/s, speed: 4454.942037 tokens/s, learning rate: 1.680e-05, loss_scalings: 6871.948730, pp_loss: 7.597969
[INFO] 2021-07-12 19:05:50,555 [run_pretraining.py:  512]:	********exe.run_1681******* 
[INFO] 2021-07-12 19:05:51,468 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  534]:	loss/total_loss, 8.112339973449707, 1682
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  535]:	loss/mlm_loss, 8.112339973449707, 1682
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.680999957898166e-05, 1682
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1682
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  558]:	worker_index: 7, step: 1682, cost: 8.112340, mlm loss: 8.112340, speed: 1.094755 steps/s, speed: 8.758040 samples/s, speed: 4484.116289 tokens/s, learning rate: 1.681e-05, loss_scalings: 6871.948730, pp_loss: 7.930754
[INFO] 2021-07-12 19:05:51,469 [run_pretraining.py:  512]:	********exe.run_1682******* 
[INFO] 2021-07-12 19:05:52,377 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:52,377 [run_pretraining.py:  534]:	loss/total_loss, 6.971073150634766, 1683
[INFO] 2021-07-12 19:05:52,377 [run_pretraining.py:  535]:	loss/mlm_loss, 6.971073150634766, 1683
[INFO] 2021-07-12 19:05:52,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6820000382722355e-05, 1683
[INFO] 2021-07-12 19:05:52,378 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1683
[INFO] 2021-07-12 19:05:52,378 [run_pretraining.py:  558]:	worker_index: 7, step: 1683, cost: 6.971073, mlm loss: 6.971073, speed: 1.101416 steps/s, speed: 8.811329 samples/s, speed: 4511.400613 tokens/s, learning rate: 1.682e-05, loss_scalings: 6871.948730, pp_loss: 7.078400
[INFO] 2021-07-12 19:05:52,378 [run_pretraining.py:  512]:	********exe.run_1683******* 
[INFO] 2021-07-12 19:05:53,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:53,294 [run_pretraining.py:  534]:	loss/total_loss, 6.89109992980957, 1684
[INFO] 2021-07-12 19:05:53,295 [run_pretraining.py:  535]:	loss/mlm_loss, 6.89109992980957, 1684
[INFO] 2021-07-12 19:05:53,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6829999367473647e-05, 1684
[INFO] 2021-07-12 19:05:53,295 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1684
[INFO] 2021-07-12 19:05:53,295 [run_pretraining.py:  558]:	worker_index: 7, step: 1684, cost: 6.891100, mlm loss: 6.891100, speed: 1.091085 steps/s, speed: 8.728677 samples/s, speed: 4469.082760 tokens/s, learning rate: 1.683e-05, loss_scalings: 6871.948730, pp_loss: 7.261775
[INFO] 2021-07-12 19:05:53,295 [run_pretraining.py:  512]:	********exe.run_1684******* 
[INFO] 2021-07-12 19:05:54,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:54,214 [run_pretraining.py:  534]:	loss/total_loss, 7.653493881225586, 1685
[INFO] 2021-07-12 19:05:54,215 [run_pretraining.py:  535]:	loss/mlm_loss, 7.653493881225586, 1685
[INFO] 2021-07-12 19:05:54,215 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6840000171214342e-05, 1685
[INFO] 2021-07-12 19:05:54,215 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1685
[INFO] 2021-07-12 19:05:54,215 [run_pretraining.py:  558]:	worker_index: 7, step: 1685, cost: 7.653494, mlm loss: 7.653494, speed: 1.087778 steps/s, speed: 8.702221 samples/s, speed: 4455.537054 tokens/s, learning rate: 1.684e-05, loss_scalings: 6871.948730, pp_loss: 7.621849
[INFO] 2021-07-12 19:05:54,215 [run_pretraining.py:  512]:	********exe.run_1685******* 
[INFO] 2021-07-12 19:05:55,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:55,126 [run_pretraining.py:  534]:	loss/total_loss, 7.409700870513916, 1686
[INFO] 2021-07-12 19:05:55,126 [run_pretraining.py:  535]:	loss/mlm_loss, 7.409700870513916, 1686
[INFO] 2021-07-12 19:05:55,126 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6850000974955037e-05, 1686
[INFO] 2021-07-12 19:05:55,127 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1686
[INFO] 2021-07-12 19:05:55,127 [run_pretraining.py:  558]:	worker_index: 7, step: 1686, cost: 7.409701, mlm loss: 7.409701, speed: 1.097455 steps/s, speed: 8.779642 samples/s, speed: 4495.176854 tokens/s, learning rate: 1.685e-05, loss_scalings: 6871.948730, pp_loss: 7.385112
[INFO] 2021-07-12 19:05:55,127 [run_pretraining.py:  512]:	********exe.run_1686******* 
[INFO] 2021-07-12 19:05:56,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:56,036 [run_pretraining.py:  534]:	loss/total_loss, 7.20571231842041, 1687
[INFO] 2021-07-12 19:05:56,036 [run_pretraining.py:  535]:	loss/mlm_loss, 7.20571231842041, 1687
[INFO] 2021-07-12 19:05:56,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6859998140716925e-05, 1687
[INFO] 2021-07-12 19:05:56,036 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1687
[INFO] 2021-07-12 19:05:56,036 [run_pretraining.py:  558]:	worker_index: 7, step: 1687, cost: 7.205712, mlm loss: 7.205712, speed: 1.100209 steps/s, speed: 8.801670 samples/s, speed: 4506.455240 tokens/s, learning rate: 1.686e-05, loss_scalings: 6871.948730, pp_loss: 7.563161
[INFO] 2021-07-12 19:05:56,036 [run_pretraining.py:  512]:	********exe.run_1687******* 
[INFO] 2021-07-12 19:05:56,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:56,949 [run_pretraining.py:  534]:	loss/total_loss, 6.742604732513428, 1688
[INFO] 2021-07-12 19:05:56,949 [run_pretraining.py:  535]:	loss/mlm_loss, 6.742604732513428, 1688
[INFO] 2021-07-12 19:05:56,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.686999894445762e-05, 1688
[INFO] 2021-07-12 19:05:56,949 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1688
[INFO] 2021-07-12 19:05:56,949 [run_pretraining.py:  558]:	worker_index: 7, step: 1688, cost: 6.742605, mlm loss: 6.742605, speed: 1.096302 steps/s, speed: 8.770417 samples/s, speed: 4490.453580 tokens/s, learning rate: 1.687e-05, loss_scalings: 6871.948730, pp_loss: 7.235343
[INFO] 2021-07-12 19:05:56,949 [run_pretraining.py:  512]:	********exe.run_1688******* 
[INFO] 2021-07-12 19:05:57,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:57,901 [run_pretraining.py:  534]:	loss/total_loss, 7.565064907073975, 1689
[INFO] 2021-07-12 19:05:57,901 [run_pretraining.py:  535]:	loss/mlm_loss, 7.565064907073975, 1689
[INFO] 2021-07-12 19:05:57,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6879999748198316e-05, 1689
[INFO] 2021-07-12 19:05:57,901 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1689
[INFO] 2021-07-12 19:05:57,901 [run_pretraining.py:  558]:	worker_index: 7, step: 1689, cost: 7.565065, mlm loss: 7.565065, speed: 1.051216 steps/s, speed: 8.409727 samples/s, speed: 4305.780186 tokens/s, learning rate: 1.688e-05, loss_scalings: 6871.948730, pp_loss: 7.362800
[INFO] 2021-07-12 19:05:57,901 [run_pretraining.py:  512]:	********exe.run_1689******* 
[INFO] 2021-07-12 19:05:58,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:58,818 [run_pretraining.py:  534]:	loss/total_loss, 7.3582072257995605, 1690
[INFO] 2021-07-12 19:05:58,818 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3582072257995605, 1690
[INFO] 2021-07-12 19:05:58,818 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6889998732949607e-05, 1690
[INFO] 2021-07-12 19:05:58,818 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1690
[INFO] 2021-07-12 19:05:58,819 [run_pretraining.py:  558]:	worker_index: 7, step: 1690, cost: 7.358207, mlm loss: 7.358207, speed: 1.090577 steps/s, speed: 8.724612 samples/s, speed: 4467.001578 tokens/s, learning rate: 1.689e-05, loss_scalings: 6871.948730, pp_loss: 6.934962
[INFO] 2021-07-12 19:05:58,819 [run_pretraining.py:  512]:	********exe.run_1690******* 
[INFO] 2021-07-12 19:05:59,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  534]:	loss/total_loss, 7.17529821395874, 1691
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  535]:	loss/mlm_loss, 7.17529821395874, 1691
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6899999536690302e-05, 1691
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1691
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  558]:	worker_index: 7, step: 1691, cost: 7.175298, mlm loss: 7.175298, speed: 1.092674 steps/s, speed: 8.741389 samples/s, speed: 4475.590958 tokens/s, learning rate: 1.690e-05, loss_scalings: 6871.948730, pp_loss: 7.144221
[INFO] 2021-07-12 19:05:59,734 [run_pretraining.py:  512]:	********exe.run_1691******* 
[INFO] 2021-07-12 19:06:00,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:00,653 [run_pretraining.py:  534]:	loss/total_loss, 8.092031478881836, 1692
[INFO] 2021-07-12 19:06:00,653 [run_pretraining.py:  535]:	loss/mlm_loss, 8.092031478881836, 1692
[INFO] 2021-07-12 19:06:00,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6910000340430997e-05, 1692
[INFO] 2021-07-12 19:06:00,653 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1692
[INFO] 2021-07-12 19:06:00,653 [run_pretraining.py:  558]:	worker_index: 7, step: 1692, cost: 8.092031, mlm loss: 8.092031, speed: 1.088891 steps/s, speed: 8.711124 samples/s, speed: 4460.095647 tokens/s, learning rate: 1.691e-05, loss_scalings: 6871.948730, pp_loss: 7.468440
[INFO] 2021-07-12 19:06:00,653 [run_pretraining.py:  512]:	********exe.run_1692******* 
[INFO] 2021-07-12 19:06:01,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:01,572 [run_pretraining.py:  534]:	loss/total_loss, 7.042041301727295, 1693
[INFO] 2021-07-12 19:06:01,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.042041301727295, 1693
[INFO] 2021-07-12 19:06:01,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.691999932518229e-05, 1693
[INFO] 2021-07-12 19:06:01,572 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1693
[INFO] 2021-07-12 19:06:01,572 [run_pretraining.py:  558]:	worker_index: 7, step: 1693, cost: 7.042041, mlm loss: 7.042041, speed: 1.089264 steps/s, speed: 8.714111 samples/s, speed: 4461.624590 tokens/s, learning rate: 1.692e-05, loss_scalings: 6871.948730, pp_loss: 7.232858
[INFO] 2021-07-12 19:06:01,572 [run_pretraining.py:  512]:	********exe.run_1693******* 
[INFO] 2021-07-12 19:06:02,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:02,482 [run_pretraining.py:  534]:	loss/total_loss, 7.0910539627075195, 1694
[INFO] 2021-07-12 19:06:02,482 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0910539627075195, 1694
[INFO] 2021-07-12 19:06:02,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6930000128922984e-05, 1694
[INFO] 2021-07-12 19:06:02,483 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1694
[INFO] 2021-07-12 19:06:02,483 [run_pretraining.py:  558]:	worker_index: 7, step: 1694, cost: 7.091054, mlm loss: 7.091054, speed: 1.098969 steps/s, speed: 8.791749 samples/s, speed: 4501.375625 tokens/s, learning rate: 1.693e-05, loss_scalings: 6871.948730, pp_loss: 7.232726
[INFO] 2021-07-12 19:06:02,483 [run_pretraining.py:  512]:	********exe.run_1694******* 
[INFO] 2021-07-12 19:06:03,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:03,393 [run_pretraining.py:  534]:	loss/total_loss, 7.155849456787109, 1695
[INFO] 2021-07-12 19:06:03,393 [run_pretraining.py:  535]:	loss/mlm_loss, 7.155849456787109, 1695
[INFO] 2021-07-12 19:06:03,393 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.694000093266368e-05, 1695
[INFO] 2021-07-12 19:06:03,394 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1695
[INFO] 2021-07-12 19:06:03,394 [run_pretraining.py:  558]:	worker_index: 7, step: 1695, cost: 7.155849, mlm loss: 7.155849, speed: 1.098497 steps/s, speed: 8.787975 samples/s, speed: 4499.443375 tokens/s, learning rate: 1.694e-05, loss_scalings: 6871.948730, pp_loss: 7.173633
[INFO] 2021-07-12 19:06:03,394 [run_pretraining.py:  512]:	********exe.run_1695******* 
[INFO] 2021-07-12 19:06:04,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:04,311 [run_pretraining.py:  534]:	loss/total_loss, 6.930858612060547, 1696
[INFO] 2021-07-12 19:06:04,311 [run_pretraining.py:  535]:	loss/mlm_loss, 6.930858612060547, 1696
[INFO] 2021-07-12 19:06:04,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6949998098425567e-05, 1696
[INFO] 2021-07-12 19:06:04,311 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1696
[INFO] 2021-07-12 19:06:04,311 [run_pretraining.py:  558]:	worker_index: 7, step: 1696, cost: 6.930859, mlm loss: 6.930859, speed: 1.090592 steps/s, speed: 8.724733 samples/s, speed: 4467.063137 tokens/s, learning rate: 1.695e-05, loss_scalings: 6871.948730, pp_loss: 6.796510
[INFO] 2021-07-12 19:06:04,311 [run_pretraining.py:  512]:	********exe.run_1696******* 
[INFO] 2021-07-12 19:06:05,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:05,226 [run_pretraining.py:  534]:	loss/total_loss, 7.085024833679199, 1697
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  535]:	loss/mlm_loss, 7.085024833679199, 1697
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6959998902166262e-05, 1697
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1697
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  558]:	worker_index: 7, step: 1697, cost: 7.085025, mlm loss: 7.085025, speed: 1.092990 steps/s, speed: 8.743919 samples/s, speed: 4476.886707 tokens/s, learning rate: 1.696e-05, loss_scalings: 6871.948730, pp_loss: 7.216260
[INFO] 2021-07-12 19:06:05,227 [run_pretraining.py:  512]:	********exe.run_1697******* 
[INFO] 2021-07-12 19:06:06,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:06,147 [run_pretraining.py:  534]:	loss/total_loss, 7.050762176513672, 1698
[INFO] 2021-07-12 19:06:06,147 [run_pretraining.py:  535]:	loss/mlm_loss, 7.050762176513672, 1698
[INFO] 2021-07-12 19:06:06,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6969999705906957e-05, 1698
[INFO] 2021-07-12 19:06:06,147 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1698
[INFO] 2021-07-12 19:06:06,147 [run_pretraining.py:  558]:	worker_index: 7, step: 1698, cost: 7.050762, mlm loss: 7.050762, speed: 1.087628 steps/s, speed: 8.701025 samples/s, speed: 4454.924709 tokens/s, learning rate: 1.697e-05, loss_scalings: 6871.948730, pp_loss: 7.394042
[INFO] 2021-07-12 19:06:06,147 [run_pretraining.py:  512]:	********exe.run_1698******* 
[INFO] 2021-07-12 19:06:07,079 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:07,079 [run_pretraining.py:  534]:	loss/total_loss, 7.300621032714844, 1699
[INFO] 2021-07-12 19:06:07,079 [run_pretraining.py:  535]:	loss/mlm_loss, 7.300621032714844, 1699
[INFO] 2021-07-12 19:06:07,079 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.697999869065825e-05, 1699
[INFO] 2021-07-12 19:06:07,079 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1699
[INFO] 2021-07-12 19:06:07,080 [run_pretraining.py:  558]:	worker_index: 7, step: 1699, cost: 7.300621, mlm loss: 7.300621, speed: 1.072957 steps/s, speed: 8.583652 samples/s, speed: 4394.829918 tokens/s, learning rate: 1.698e-05, loss_scalings: 6871.948730, pp_loss: 7.593572
[INFO] 2021-07-12 19:06:07,080 [run_pretraining.py:  512]:	********exe.run_1699******* 
[INFO] 2021-07-12 19:06:08,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:08,008 [run_pretraining.py:  534]:	loss/total_loss, 6.883824348449707, 1700
[INFO] 2021-07-12 19:06:08,008 [run_pretraining.py:  535]:	loss/mlm_loss, 6.883824348449707, 1700
[INFO] 2021-07-12 19:06:08,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.6989999494398944e-05, 1700
[INFO] 2021-07-12 19:06:08,008 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1700
[INFO] 2021-07-12 19:06:08,008 [run_pretraining.py:  558]:	worker_index: 7, step: 1700, cost: 6.883824, mlm loss: 6.883824, speed: 1.077744 steps/s, speed: 8.621950 samples/s, speed: 4414.438558 tokens/s, learning rate: 1.699e-05, loss_scalings: 6871.948730, pp_loss: 7.286736
[INFO] 2021-07-12 19:06:08,008 [run_pretraining.py:  512]:	********exe.run_1700******* 
[INFO] 2021-07-12 19:06:08,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:08,939 [run_pretraining.py:  534]:	loss/total_loss, 6.454495906829834, 1701
[INFO] 2021-07-12 19:06:08,939 [run_pretraining.py:  535]:	loss/mlm_loss, 6.454495906829834, 1701
[INFO] 2021-07-12 19:06:08,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.700000029813964e-05, 1701
[INFO] 2021-07-12 19:06:08,939 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1701
[INFO] 2021-07-12 19:06:08,939 [run_pretraining.py:  558]:	worker_index: 7, step: 1701, cost: 6.454496, mlm loss: 6.454496, speed: 1.074351 steps/s, speed: 8.594810 samples/s, speed: 4400.542922 tokens/s, learning rate: 1.700e-05, loss_scalings: 6871.948730, pp_loss: 7.087118
[INFO] 2021-07-12 19:06:08,940 [run_pretraining.py:  512]:	********exe.run_1701******* 
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  534]:	loss/total_loss, 7.192872047424316, 1702
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  535]:	loss/mlm_loss, 7.192872047424316, 1702
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.700999928289093e-05, 1702
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1702
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  558]:	worker_index: 7, step: 1702, cost: 7.192872, mlm loss: 7.192872, speed: 1.077332 steps/s, speed: 8.618655 samples/s, speed: 4412.751352 tokens/s, learning rate: 1.701e-05, loss_scalings: 6871.948730, pp_loss: 7.248510
[INFO] 2021-07-12 19:06:09,868 [run_pretraining.py:  512]:	********exe.run_1702******* 
[INFO] 2021-07-12 19:06:10,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:10,799 [run_pretraining.py:  534]:	loss/total_loss, 7.797272682189941, 1703
[INFO] 2021-07-12 19:06:10,800 [run_pretraining.py:  535]:	loss/mlm_loss, 7.797272682189941, 1703
[INFO] 2021-07-12 19:06:10,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7020000086631626e-05, 1703
[INFO] 2021-07-12 19:06:10,800 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1703
[INFO] 2021-07-12 19:06:10,800 [run_pretraining.py:  558]:	worker_index: 7, step: 1703, cost: 7.797273, mlm loss: 7.797273, speed: 1.074426 steps/s, speed: 8.595407 samples/s, speed: 4400.848408 tokens/s, learning rate: 1.702e-05, loss_scalings: 6871.948730, pp_loss: 7.442234
[INFO] 2021-07-12 19:06:10,800 [run_pretraining.py:  512]:	********exe.run_1703******* 
[INFO] 2021-07-12 19:06:11,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  534]:	loss/total_loss, 7.239997863769531, 1704
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  535]:	loss/mlm_loss, 7.239997863769531, 1704
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.703000089037232e-05, 1704
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1704
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  558]:	worker_index: 7, step: 1704, cost: 7.239998, mlm loss: 7.239998, speed: 1.083986 steps/s, speed: 8.671886 samples/s, speed: 4440.005630 tokens/s, learning rate: 1.703e-05, loss_scalings: 6871.948730, pp_loss: 7.400661
[INFO] 2021-07-12 19:06:11,723 [run_pretraining.py:  512]:	********exe.run_1704******* 
[INFO] 2021-07-12 19:06:12,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:12,647 [run_pretraining.py:  534]:	loss/total_loss, 6.784926891326904, 1705
[INFO] 2021-07-12 19:06:12,647 [run_pretraining.py:  535]:	loss/mlm_loss, 6.784926891326904, 1705
[INFO] 2021-07-12 19:06:12,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.703999805613421e-05, 1705
[INFO] 2021-07-12 19:06:12,647 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1705
[INFO] 2021-07-12 19:06:12,647 [run_pretraining.py:  558]:	worker_index: 7, step: 1705, cost: 6.784927, mlm loss: 6.784927, speed: 1.082630 steps/s, speed: 8.661043 samples/s, speed: 4434.454160 tokens/s, learning rate: 1.704e-05, loss_scalings: 6871.948730, pp_loss: 7.097047
[INFO] 2021-07-12 19:06:12,647 [run_pretraining.py:  512]:	********exe.run_1705******* 
[INFO] 2021-07-12 19:06:13,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:13,572 [run_pretraining.py:  534]:	loss/total_loss, 7.483813762664795, 1706
[INFO] 2021-07-12 19:06:13,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.483813762664795, 1706
[INFO] 2021-07-12 19:06:13,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7049998859874904e-05, 1706
[INFO] 2021-07-12 19:06:13,572 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1706
[INFO] 2021-07-12 19:06:13,572 [run_pretraining.py:  558]:	worker_index: 7, step: 1706, cost: 7.483814, mlm loss: 7.483814, speed: 1.081750 steps/s, speed: 8.654000 samples/s, speed: 4430.848115 tokens/s, learning rate: 1.705e-05, loss_scalings: 6871.948730, pp_loss: 7.182993
[INFO] 2021-07-12 19:06:13,572 [run_pretraining.py:  512]:	********exe.run_1706******* 
[INFO] 2021-07-12 19:06:14,492 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:14,492 [run_pretraining.py:  534]:	loss/total_loss, 7.305452823638916, 1707
[INFO] 2021-07-12 19:06:14,492 [run_pretraining.py:  535]:	loss/mlm_loss, 7.305452823638916, 1707
[INFO] 2021-07-12 19:06:14,493 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.70599996636156e-05, 1707
[INFO] 2021-07-12 19:06:14,493 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1707
[INFO] 2021-07-12 19:06:14,493 [run_pretraining.py:  558]:	worker_index: 7, step: 1707, cost: 7.305453, mlm loss: 7.305453, speed: 1.087406 steps/s, speed: 8.699247 samples/s, speed: 4454.014589 tokens/s, learning rate: 1.706e-05, loss_scalings: 6871.948730, pp_loss: 7.242730
[INFO] 2021-07-12 19:06:14,493 [run_pretraining.py:  512]:	********exe.run_1707******* 
[INFO] 2021-07-12 19:06:15,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:15,412 [run_pretraining.py:  534]:	loss/total_loss, 7.020813941955566, 1708
[INFO] 2021-07-12 19:06:15,412 [run_pretraining.py:  535]:	loss/mlm_loss, 7.020813941955566, 1708
[INFO] 2021-07-12 19:06:15,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.706999864836689e-05, 1708
[INFO] 2021-07-12 19:06:15,412 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1708
[INFO] 2021-07-12 19:06:15,412 [run_pretraining.py:  558]:	worker_index: 7, step: 1708, cost: 7.020814, mlm loss: 7.020814, speed: 1.088626 steps/s, speed: 8.709010 samples/s, speed: 4459.013280 tokens/s, learning rate: 1.707e-05, loss_scalings: 6871.948730, pp_loss: 6.957992
[INFO] 2021-07-12 19:06:15,412 [run_pretraining.py:  512]:	********exe.run_1708******* 
[INFO] 2021-07-12 19:06:16,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:16,339 [run_pretraining.py:  534]:	loss/total_loss, 7.382240295410156, 1709
[INFO] 2021-07-12 19:06:16,339 [run_pretraining.py:  535]:	loss/mlm_loss, 7.382240295410156, 1709
[INFO] 2021-07-12 19:06:16,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7079999452107586e-05, 1709
[INFO] 2021-07-12 19:06:16,339 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1709
[INFO] 2021-07-12 19:06:16,339 [run_pretraining.py:  558]:	worker_index: 7, step: 1709, cost: 7.382240, mlm loss: 7.382240, speed: 1.079446 steps/s, speed: 8.635570 samples/s, speed: 4421.411940 tokens/s, learning rate: 1.708e-05, loss_scalings: 6871.948730, pp_loss: 7.460926
[INFO] 2021-07-12 19:06:16,339 [run_pretraining.py:  512]:	********exe.run_1709******* 
[INFO] 2021-07-12 19:06:17,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:17,262 [run_pretraining.py:  534]:	loss/total_loss, 7.05714225769043, 1710
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  535]:	loss/mlm_loss, 7.05714225769043, 1710
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.709000025584828e-05, 1710
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1710
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  558]:	worker_index: 7, step: 1710, cost: 7.057142, mlm loss: 7.057142, speed: 1.083163 steps/s, speed: 8.665304 samples/s, speed: 4436.635730 tokens/s, learning rate: 1.709e-05, loss_scalings: 6871.948730, pp_loss: 7.427856
[INFO] 2021-07-12 19:06:17,263 [run_pretraining.py:  512]:	********exe.run_1710******* 
[INFO] 2021-07-12 19:06:18,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  534]:	loss/total_loss, 8.033573150634766, 1711
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  535]:	loss/mlm_loss, 8.033573150634766, 1711
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7099999240599573e-05, 1711
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1711
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  558]:	worker_index: 7, step: 1711, cost: 8.033573, mlm loss: 8.033573, speed: 1.089657 steps/s, speed: 8.717257 samples/s, speed: 4463.235747 tokens/s, learning rate: 1.710e-05, loss_scalings: 6871.948730, pp_loss: 7.599882
[INFO] 2021-07-12 19:06:18,181 [run_pretraining.py:  512]:	********exe.run_1711******* 
[INFO] 2021-07-12 19:06:19,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:19,103 [run_pretraining.py:  534]:	loss/total_loss, 7.049431324005127, 1712
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.049431324005127, 1712
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7110000044340268e-05, 1712
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1712
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  558]:	worker_index: 7, step: 1712, cost: 7.049431, mlm loss: 7.049431, speed: 1.084671 steps/s, speed: 8.677365 samples/s, speed: 4442.810708 tokens/s, learning rate: 1.711e-05, loss_scalings: 6871.948730, pp_loss: 7.417771
[INFO] 2021-07-12 19:06:19,104 [run_pretraining.py:  512]:	********exe.run_1712******* 
[INFO] 2021-07-12 19:06:20,056 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:20,057 [run_pretraining.py:  534]:	loss/total_loss, 6.898785591125488, 1713
[INFO] 2021-07-12 19:06:20,057 [run_pretraining.py:  535]:	loss/mlm_loss, 6.898785591125488, 1713
[INFO] 2021-07-12 19:06:20,057 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7120000848080963e-05, 1713
[INFO] 2021-07-12 19:06:20,057 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1713
[INFO] 2021-07-12 19:06:20,057 [run_pretraining.py:  558]:	worker_index: 7, step: 1713, cost: 6.898786, mlm loss: 6.898786, speed: 1.049498 steps/s, speed: 8.395986 samples/s, speed: 4298.744818 tokens/s, learning rate: 1.712e-05, loss_scalings: 6871.948730, pp_loss: 7.349560
[INFO] 2021-07-12 19:06:20,057 [run_pretraining.py:  512]:	********exe.run_1713******* 
[INFO] 2021-07-12 19:06:20,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:20,988 [run_pretraining.py:  534]:	loss/total_loss, 6.791504859924316, 1714
[INFO] 2021-07-12 19:06:20,988 [run_pretraining.py:  535]:	loss/mlm_loss, 6.791504859924316, 1714
[INFO] 2021-07-12 19:06:20,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7129999832832254e-05, 1714
[INFO] 2021-07-12 19:06:20,989 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1714
[INFO] 2021-07-12 19:06:20,989 [run_pretraining.py:  558]:	worker_index: 7, step: 1714, cost: 6.791505, mlm loss: 6.791505, speed: 1.074477 steps/s, speed: 8.595817 samples/s, speed: 4401.058102 tokens/s, learning rate: 1.713e-05, loss_scalings: 6871.948730, pp_loss: 7.424545
[INFO] 2021-07-12 19:06:20,989 [run_pretraining.py:  512]:	********exe.run_1714******* 
[INFO] 2021-07-12 19:06:21,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:21,913 [run_pretraining.py:  534]:	loss/total_loss, 7.4032511711120605, 1715
[INFO] 2021-07-12 19:06:21,913 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4032511711120605, 1715
[INFO] 2021-07-12 19:06:21,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7139998817583546e-05, 1715
[INFO] 2021-07-12 19:06:21,913 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1715
[INFO] 2021-07-12 19:06:21,913 [run_pretraining.py:  558]:	worker_index: 7, step: 1715, cost: 7.403251, mlm loss: 7.403251, speed: 1.082726 steps/s, speed: 8.661806 samples/s, speed: 4434.844509 tokens/s, learning rate: 1.714e-05, loss_scalings: 6871.948730, pp_loss: 7.498486
[INFO] 2021-07-12 19:06:21,913 [run_pretraining.py:  512]:	********exe.run_1715******* 
[INFO] 2021-07-12 19:06:22,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:22,831 [run_pretraining.py:  534]:	loss/total_loss, 6.604405403137207, 1716
[INFO] 2021-07-12 19:06:22,831 [run_pretraining.py:  535]:	loss/mlm_loss, 6.604405403137207, 1716
[INFO] 2021-07-12 19:06:22,831 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.714999962132424e-05, 1716
[INFO] 2021-07-12 19:06:22,831 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1716
[INFO] 2021-07-12 19:06:22,831 [run_pretraining.py:  558]:	worker_index: 7, step: 1716, cost: 6.604405, mlm loss: 6.604405, speed: 1.089496 steps/s, speed: 8.715964 samples/s, speed: 4462.573757 tokens/s, learning rate: 1.715e-05, loss_scalings: 6871.948730, pp_loss: 7.009368
[INFO] 2021-07-12 19:06:22,831 [run_pretraining.py:  512]:	********exe.run_1716******* 
[INFO] 2021-07-12 19:06:23,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:23,881 [run_pretraining.py:  534]:	loss/total_loss, 7.454784870147705, 1717
[INFO] 2021-07-12 19:06:23,881 [run_pretraining.py:  535]:	loss/mlm_loss, 7.454784870147705, 1717
[INFO] 2021-07-12 19:06:23,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7159998606075533e-05, 1717
[INFO] 2021-07-12 19:06:23,881 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1717
[INFO] 2021-07-12 19:06:23,881 [run_pretraining.py:  558]:	worker_index: 7, step: 1717, cost: 7.454785, mlm loss: 7.454785, speed: 0.953460 steps/s, speed: 7.627680 samples/s, speed: 3905.372243 tokens/s, learning rate: 1.716e-05, loss_scalings: 6871.948730, pp_loss: 7.060825
[INFO] 2021-07-12 19:06:23,881 [run_pretraining.py:  512]:	********exe.run_1717******* 
[INFO] 2021-07-12 19:06:24,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:24,945 [run_pretraining.py:  534]:	loss/total_loss, 7.4324116706848145, 1718
[INFO] 2021-07-12 19:06:24,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4324116706848145, 1718
[INFO] 2021-07-12 19:06:24,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7169999409816228e-05, 1718
[INFO] 2021-07-12 19:06:24,945 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1718
[INFO] 2021-07-12 19:06:24,945 [run_pretraining.py:  558]:	worker_index: 7, step: 1718, cost: 7.432412, mlm loss: 7.432412, speed: 0.940062 steps/s, speed: 7.520493 samples/s, speed: 3850.492440 tokens/s, learning rate: 1.717e-05, loss_scalings: 6871.948730, pp_loss: 7.184203
[INFO] 2021-07-12 19:06:24,945 [run_pretraining.py:  512]:	********exe.run_1718******* 
[INFO] 2021-07-12 19:06:26,017 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  534]:	loss/total_loss, 6.913769721984863, 1719
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  535]:	loss/mlm_loss, 6.913769721984863, 1719
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7180000213556923e-05, 1719
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1719
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  558]:	worker_index: 7, step: 1719, cost: 6.913770, mlm loss: 6.913770, speed: 0.932506 steps/s, speed: 7.460050 samples/s, speed: 3819.545592 tokens/s, learning rate: 1.718e-05, loss_scalings: 6871.948730, pp_loss: 7.161795
[INFO] 2021-07-12 19:06:26,018 [run_pretraining.py:  512]:	********exe.run_1719******* 
[INFO] 2021-07-12 19:06:27,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:27,073 [run_pretraining.py:  534]:	loss/total_loss, 7.000229835510254, 1720
[INFO] 2021-07-12 19:06:27,073 [run_pretraining.py:  535]:	loss/mlm_loss, 7.000229835510254, 1720
[INFO] 2021-07-12 19:06:27,073 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7189999198308215e-05, 1720
[INFO] 2021-07-12 19:06:27,073 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1720
[INFO] 2021-07-12 19:06:27,074 [run_pretraining.py:  558]:	worker_index: 7, step: 1720, cost: 7.000230, mlm loss: 7.000230, speed: 0.948223 steps/s, speed: 7.585787 samples/s, speed: 3883.922987 tokens/s, learning rate: 1.719e-05, loss_scalings: 6871.948730, pp_loss: 7.245592
[INFO] 2021-07-12 19:06:27,074 [run_pretraining.py:  512]:	********exe.run_1720******* 
[INFO] 2021-07-12 19:06:28,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:28,143 [run_pretraining.py:  534]:	loss/total_loss, 6.949347019195557, 1721
[INFO] 2021-07-12 19:06:28,143 [run_pretraining.py:  535]:	loss/mlm_loss, 6.949347019195557, 1721
[INFO] 2021-07-12 19:06:28,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.720000000204891e-05, 1721
[INFO] 2021-07-12 19:06:28,143 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1721
[INFO] 2021-07-12 19:06:28,143 [run_pretraining.py:  558]:	worker_index: 7, step: 1721, cost: 6.949347, mlm loss: 6.949347, speed: 0.935617 steps/s, speed: 7.484937 samples/s, speed: 3832.287555 tokens/s, learning rate: 1.720e-05, loss_scalings: 6871.948730, pp_loss: 7.261723
[INFO] 2021-07-12 19:06:28,143 [run_pretraining.py:  512]:	********exe.run_1721******* 
[INFO] 2021-07-12 19:06:29,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:29,055 [run_pretraining.py:  534]:	loss/total_loss, 6.900345802307129, 1722
[INFO] 2021-07-12 19:06:29,055 [run_pretraining.py:  535]:	loss/mlm_loss, 6.900345802307129, 1722
[INFO] 2021-07-12 19:06:29,055 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.72099989868002e-05, 1722
[INFO] 2021-07-12 19:06:29,055 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1722
[INFO] 2021-07-12 19:06:29,055 [run_pretraining.py:  558]:	worker_index: 7, step: 1722, cost: 6.900346, mlm loss: 6.900346, speed: 1.096979 steps/s, speed: 8.775831 samples/s, speed: 4493.225243 tokens/s, learning rate: 1.721e-05, loss_scalings: 6871.948730, pp_loss: 7.406521
[INFO] 2021-07-12 19:06:29,055 [run_pretraining.py:  512]:	********exe.run_1722******* 
[INFO] 2021-07-12 19:06:29,967 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:29,968 [run_pretraining.py:  534]:	loss/total_loss, 7.188508033752441, 1723
[INFO] 2021-07-12 19:06:29,968 [run_pretraining.py:  535]:	loss/mlm_loss, 7.188508033752441, 1723
[INFO] 2021-07-12 19:06:29,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7219999790540896e-05, 1723
[INFO] 2021-07-12 19:06:29,968 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1723
[INFO] 2021-07-12 19:06:29,968 [run_pretraining.py:  558]:	worker_index: 7, step: 1723, cost: 7.188508, mlm loss: 7.188508, speed: 1.096356 steps/s, speed: 8.770850 samples/s, speed: 4490.675422 tokens/s, learning rate: 1.722e-05, loss_scalings: 6871.948730, pp_loss: 7.043211
[INFO] 2021-07-12 19:06:29,968 [run_pretraining.py:  512]:	********exe.run_1723******* 
[INFO] 2021-07-12 19:06:30,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:30,880 [run_pretraining.py:  534]:	loss/total_loss, 7.232624530792236, 1724
[INFO] 2021-07-12 19:06:30,880 [run_pretraining.py:  535]:	loss/mlm_loss, 7.232624530792236, 1724
[INFO] 2021-07-12 19:06:30,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7229998775292188e-05, 1724
[INFO] 2021-07-12 19:06:30,880 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1724
[INFO] 2021-07-12 19:06:30,880 [run_pretraining.py:  558]:	worker_index: 7, step: 1724, cost: 7.232625, mlm loss: 7.232625, speed: 1.096744 steps/s, speed: 8.773949 samples/s, speed: 4492.261820 tokens/s, learning rate: 1.723e-05, loss_scalings: 6871.948730, pp_loss: 7.347849
[INFO] 2021-07-12 19:06:30,880 [run_pretraining.py:  512]:	********exe.run_1724******* 
[INFO] 2021-07-12 19:06:31,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:31,789 [run_pretraining.py:  534]:	loss/total_loss, 7.905043601989746, 1725
[INFO] 2021-07-12 19:06:31,789 [run_pretraining.py:  535]:	loss/mlm_loss, 7.905043601989746, 1725
[INFO] 2021-07-12 19:06:31,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7239999579032883e-05, 1725
[INFO] 2021-07-12 19:06:31,790 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1725
[INFO] 2021-07-12 19:06:31,790 [run_pretraining.py:  558]:	worker_index: 7, step: 1725, cost: 7.905044, mlm loss: 7.905044, speed: 1.100509 steps/s, speed: 8.804074 samples/s, speed: 4507.686131 tokens/s, learning rate: 1.724e-05, loss_scalings: 6871.948730, pp_loss: 7.476516
[INFO] 2021-07-12 19:06:31,790 [run_pretraining.py:  512]:	********exe.run_1725******* 
[INFO] 2021-07-12 19:06:32,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:32,702 [run_pretraining.py:  534]:	loss/total_loss, 6.577482223510742, 1726
[INFO] 2021-07-12 19:06:32,702 [run_pretraining.py:  535]:	loss/mlm_loss, 6.577482223510742, 1726
[INFO] 2021-07-12 19:06:32,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7250000382773578e-05, 1726
[INFO] 2021-07-12 19:06:32,703 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1726
[INFO] 2021-07-12 19:06:32,703 [run_pretraining.py:  558]:	worker_index: 7, step: 1726, cost: 6.577482, mlm loss: 6.577482, speed: 1.096139 steps/s, speed: 8.769113 samples/s, speed: 4489.785838 tokens/s, learning rate: 1.725e-05, loss_scalings: 6871.948730, pp_loss: 7.242057
[INFO] 2021-07-12 19:06:32,703 [run_pretraining.py:  512]:	********exe.run_1726******* 
[INFO] 2021-07-12 19:06:33,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:33,611 [run_pretraining.py:  534]:	loss/total_loss, 7.431273937225342, 1727
[INFO] 2021-07-12 19:06:33,612 [run_pretraining.py:  535]:	loss/mlm_loss, 7.431273937225342, 1727
[INFO] 2021-07-12 19:06:33,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.725999936752487e-05, 1727
[INFO] 2021-07-12 19:06:33,612 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1727
[INFO] 2021-07-12 19:06:33,612 [run_pretraining.py:  558]:	worker_index: 7, step: 1727, cost: 7.431274, mlm loss: 7.431274, speed: 1.100832 steps/s, speed: 8.806656 samples/s, speed: 4509.007634 tokens/s, learning rate: 1.726e-05, loss_scalings: 6871.948730, pp_loss: 7.363970
[INFO] 2021-07-12 19:06:33,612 [run_pretraining.py:  512]:	********exe.run_1727******* 
[INFO] 2021-07-12 19:06:34,563 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:34,564 [run_pretraining.py:  534]:	loss/total_loss, 7.278743267059326, 1728
[INFO] 2021-07-12 19:06:34,564 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278743267059326, 1728
[INFO] 2021-07-12 19:06:34,564 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7270000171265565e-05, 1728
[INFO] 2021-07-12 19:06:34,564 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1728
[INFO] 2021-07-12 19:06:34,564 [run_pretraining.py:  558]:	worker_index: 7, step: 1728, cost: 7.278743, mlm loss: 7.278743, speed: 1.050533 steps/s, speed: 8.404263 samples/s, speed: 4302.982677 tokens/s, learning rate: 1.727e-05, loss_scalings: 6871.948730, pp_loss: 6.988295
[INFO] 2021-07-12 19:06:34,564 [run_pretraining.py:  512]:	********exe.run_1728******* 
[INFO] 2021-07-12 19:06:35,619 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:35,619 [run_pretraining.py:  534]:	loss/total_loss, 7.07843017578125, 1729
[INFO] 2021-07-12 19:06:35,619 [run_pretraining.py:  535]:	loss/mlm_loss, 7.07843017578125, 1729
[INFO] 2021-07-12 19:06:35,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7279999156016856e-05, 1729
[INFO] 2021-07-12 19:06:35,619 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1729
[INFO] 2021-07-12 19:06:35,620 [run_pretraining.py:  558]:	worker_index: 7, step: 1729, cost: 7.078430, mlm loss: 7.078430, speed: 0.948266 steps/s, speed: 7.586128 samples/s, speed: 3884.097728 tokens/s, learning rate: 1.728e-05, loss_scalings: 6871.948730, pp_loss: 7.126126
[INFO] 2021-07-12 19:06:35,620 [run_pretraining.py:  512]:	********exe.run_1729******* 
[INFO] 2021-07-12 19:06:36,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:36,672 [run_pretraining.py:  534]:	loss/total_loss, 7.355207920074463, 1730
[INFO] 2021-07-12 19:06:36,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.355207920074463, 1730
[INFO] 2021-07-12 19:06:36,673 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.728999995975755e-05, 1730
[INFO] 2021-07-12 19:06:36,673 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1730
[INFO] 2021-07-12 19:06:36,673 [run_pretraining.py:  558]:	worker_index: 7, step: 1730, cost: 7.355208, mlm loss: 7.355208, speed: 0.950036 steps/s, speed: 7.600285 samples/s, speed: 3891.346170 tokens/s, learning rate: 1.729e-05, loss_scalings: 6871.948730, pp_loss: 7.241625
[INFO] 2021-07-12 19:06:36,673 [run_pretraining.py:  512]:	********exe.run_1730******* 
[INFO] 2021-07-12 19:06:37,733 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:37,733 [run_pretraining.py:  534]:	loss/total_loss, 7.50686502456665, 1731
[INFO] 2021-07-12 19:06:37,733 [run_pretraining.py:  535]:	loss/mlm_loss, 7.50686502456665, 1731
[INFO] 2021-07-12 19:06:37,733 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7299998944508843e-05, 1731
[INFO] 2021-07-12 19:06:37,733 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1731
[INFO] 2021-07-12 19:06:37,734 [run_pretraining.py:  558]:	worker_index: 7, step: 1731, cost: 7.506865, mlm loss: 7.506865, speed: 0.943287 steps/s, speed: 7.546294 samples/s, speed: 3863.702729 tokens/s, learning rate: 1.730e-05, loss_scalings: 6871.948730, pp_loss: 7.569896
[INFO] 2021-07-12 19:06:37,734 [run_pretraining.py:  512]:	********exe.run_1731******* 
[INFO] 2021-07-12 19:06:38,787 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  534]:	loss/total_loss, 7.142047882080078, 1732
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  535]:	loss/mlm_loss, 7.142047882080078, 1732
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7309999748249538e-05, 1732
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1732
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  558]:	worker_index: 7, step: 1732, cost: 7.142048, mlm loss: 7.142048, speed: 0.948982 steps/s, speed: 7.591858 samples/s, speed: 3887.031151 tokens/s, learning rate: 1.731e-05, loss_scalings: 6871.948730, pp_loss: 6.563026
[INFO] 2021-07-12 19:06:38,788 [run_pretraining.py:  512]:	********exe.run_1732******* 
[INFO] 2021-07-12 19:06:39,848 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:39,849 [run_pretraining.py:  534]:	loss/total_loss, 6.891468524932861, 1733
[INFO] 2021-07-12 19:06:39,849 [run_pretraining.py:  535]:	loss/mlm_loss, 6.891468524932861, 1733
[INFO] 2021-07-12 19:06:39,849 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.731999873300083e-05, 1733
[INFO] 2021-07-12 19:06:39,849 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1733
[INFO] 2021-07-12 19:06:39,849 [run_pretraining.py:  558]:	worker_index: 7, step: 1733, cost: 6.891469, mlm loss: 6.891469, speed: 0.942769 steps/s, speed: 7.542156 samples/s, speed: 3861.583689 tokens/s, learning rate: 1.732e-05, loss_scalings: 6871.948730, pp_loss: 7.236080
[INFO] 2021-07-12 19:06:39,849 [run_pretraining.py:  512]:	********exe.run_1733******* 
[INFO] 2021-07-12 19:06:40,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:40,911 [run_pretraining.py:  534]:	loss/total_loss, 6.563175678253174, 1734
[INFO] 2021-07-12 19:06:40,911 [run_pretraining.py:  535]:	loss/mlm_loss, 6.563175678253174, 1734
[INFO] 2021-07-12 19:06:40,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7329999536741525e-05, 1734
[INFO] 2021-07-12 19:06:40,911 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1734
[INFO] 2021-07-12 19:06:40,911 [run_pretraining.py:  558]:	worker_index: 7, step: 1734, cost: 6.563176, mlm loss: 6.563176, speed: 0.942386 steps/s, speed: 7.539085 samples/s, speed: 3860.011545 tokens/s, learning rate: 1.733e-05, loss_scalings: 6871.948730, pp_loss: 6.649378
[INFO] 2021-07-12 19:06:40,911 [run_pretraining.py:  512]:	********exe.run_1734******* 
[INFO] 2021-07-12 19:06:41,966 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:41,967 [run_pretraining.py:  534]:	loss/total_loss, 6.197353839874268, 1735
[INFO] 2021-07-12 19:06:41,967 [run_pretraining.py:  535]:	loss/mlm_loss, 6.197353839874268, 1735
[INFO] 2021-07-12 19:06:41,967 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.734000034048222e-05, 1735
[INFO] 2021-07-12 19:06:41,967 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1735
[INFO] 2021-07-12 19:06:41,967 [run_pretraining.py:  558]:	worker_index: 7, step: 1735, cost: 6.197354, mlm loss: 6.197354, speed: 0.947685 steps/s, speed: 7.581480 samples/s, speed: 3881.717690 tokens/s, learning rate: 1.734e-05, loss_scalings: 6871.948730, pp_loss: 6.970183
[INFO] 2021-07-12 19:06:41,967 [run_pretraining.py:  512]:	********exe.run_1735******* 
[INFO] 2021-07-12 19:06:43,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:43,025 [run_pretraining.py:  534]:	loss/total_loss, 6.68910026550293, 1736
[INFO] 2021-07-12 19:06:43,025 [run_pretraining.py:  535]:	loss/mlm_loss, 6.68910026550293, 1736
[INFO] 2021-07-12 19:06:43,025 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.734999932523351e-05, 1736
[INFO] 2021-07-12 19:06:43,025 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1736
[INFO] 2021-07-12 19:06:43,025 [run_pretraining.py:  558]:	worker_index: 7, step: 1736, cost: 6.689100, mlm loss: 6.689100, speed: 0.945475 steps/s, speed: 7.563802 samples/s, speed: 3872.666562 tokens/s, learning rate: 1.735e-05, loss_scalings: 6871.948730, pp_loss: 7.289801
[INFO] 2021-07-12 19:06:43,025 [run_pretraining.py:  512]:	********exe.run_1736******* 
[INFO] 2021-07-12 19:06:44,087 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:44,088 [run_pretraining.py:  534]:	loss/total_loss, 6.144320487976074, 1737
[INFO] 2021-07-12 19:06:44,088 [run_pretraining.py:  535]:	loss/mlm_loss, 6.144320487976074, 1737
[INFO] 2021-07-12 19:06:44,088 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7360000128974207e-05, 1737
[INFO] 2021-07-12 19:06:44,088 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1737
[INFO] 2021-07-12 19:06:44,088 [run_pretraining.py:  558]:	worker_index: 7, step: 1737, cost: 6.144320, mlm loss: 6.144320, speed: 0.941703 steps/s, speed: 7.533626 samples/s, speed: 3857.216605 tokens/s, learning rate: 1.736e-05, loss_scalings: 6871.948730, pp_loss: 7.066581
[INFO] 2021-07-12 19:06:44,088 [run_pretraining.py:  512]:	********exe.run_1737******* 
[INFO] 2021-07-12 19:06:45,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:45,146 [run_pretraining.py:  534]:	loss/total_loss, 7.113335609436035, 1738
[INFO] 2021-07-12 19:06:45,147 [run_pretraining.py:  535]:	loss/mlm_loss, 7.113335609436035, 1738
[INFO] 2021-07-12 19:06:45,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7370000932714902e-05, 1738
[INFO] 2021-07-12 19:06:45,147 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1738
[INFO] 2021-07-12 19:06:45,147 [run_pretraining.py:  558]:	worker_index: 7, step: 1738, cost: 7.113336, mlm loss: 7.113336, speed: 0.944901 steps/s, speed: 7.559205 samples/s, speed: 3870.312715 tokens/s, learning rate: 1.737e-05, loss_scalings: 6871.948730, pp_loss: 7.527665
[INFO] 2021-07-12 19:06:45,147 [run_pretraining.py:  512]:	********exe.run_1738******* 
[INFO] 2021-07-12 19:06:46,201 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:46,201 [run_pretraining.py:  534]:	loss/total_loss, 7.9013671875, 1739
[INFO] 2021-07-12 19:06:46,201 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9013671875, 1739
[INFO] 2021-07-12 19:06:46,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7379999917466193e-05, 1739
[INFO] 2021-07-12 19:06:46,202 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1739
[INFO] 2021-07-12 19:06:46,202 [run_pretraining.py:  558]:	worker_index: 7, step: 1739, cost: 7.901367, mlm loss: 7.901367, speed: 0.948506 steps/s, speed: 7.588048 samples/s, speed: 3885.080608 tokens/s, learning rate: 1.738e-05, loss_scalings: 6871.948730, pp_loss: 7.447917
[INFO] 2021-07-12 19:06:46,202 [run_pretraining.py:  512]:	********exe.run_1739******* 
[INFO] 2021-07-12 19:06:47,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:47,262 [run_pretraining.py:  534]:	loss/total_loss, 7.419547080993652, 1740
[INFO] 2021-07-12 19:06:47,263 [run_pretraining.py:  535]:	loss/mlm_loss, 7.419547080993652, 1740
[INFO] 2021-07-12 19:06:47,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7389998902217485e-05, 1740
[INFO] 2021-07-12 19:06:47,263 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1740
[INFO] 2021-07-12 19:06:47,263 [run_pretraining.py:  558]:	worker_index: 7, step: 1740, cost: 7.419547, mlm loss: 7.419547, speed: 0.942980 steps/s, speed: 7.543836 samples/s, speed: 3862.444052 tokens/s, learning rate: 1.739e-05, loss_scalings: 6871.948730, pp_loss: 7.401350
[INFO] 2021-07-12 19:06:47,263 [run_pretraining.py:  512]:	********exe.run_1740******* 
[INFO] 2021-07-12 19:06:48,316 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:06:48,317 [run_pretraining.py:  534]:	loss/total_loss, 6.85918664932251, 1741
[INFO] 2021-07-12 19:06:48,317 [run_pretraining.py:  535]:	loss/mlm_loss, 6.85918664932251, 1741
[INFO] 2021-07-12 19:06:48,317 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.739999970595818e-05, 1741
[INFO] 2021-07-12 19:06:48,317 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1741
[INFO] 2021-07-12 19:06:48,317 [run_pretraining.py:  558]:	worker_index: 7, step: 1741, cost: 6.859187, mlm loss: 6.859187, speed: 0.949314 steps/s, speed: 7.594514 samples/s, speed: 3888.391272 tokens/s, learning rate: 1.740e-05, loss_scalings: 6871.948730, pp_loss: 7.333014
[INFO] 2021-07-12 19:06:48,317 [run_pretraining.py:  512]:	********exe.run_1741******* 
[INFO] 2021-07-12 19:07:13,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:13,835 [run_pretraining.py:  534]:	loss/total_loss, 8.307743072509766, 1742
[INFO] 2021-07-12 19:07:13,835 [run_pretraining.py:  535]:	loss/mlm_loss, 8.307743072509766, 1742
[INFO] 2021-07-12 19:07:13,835 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7409998690709472e-05, 1742
[INFO] 2021-07-12 19:07:13,836 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1742
[INFO] 2021-07-12 19:07:13,836 [run_pretraining.py:  558]:	worker_index: 7, step: 1742, cost: 8.307743, mlm loss: 8.307743, speed: 0.039188 steps/s, speed: 0.313504 samples/s, speed: 160.514041 tokens/s, learning rate: 1.741e-05, loss_scalings: 6871.948730, pp_loss: 7.578628
[INFO] 2021-07-12 19:07:13,836 [run_pretraining.py:  512]:	********exe.run_1742******* 
[INFO] 2021-07-12 19:07:14,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:14,845 [run_pretraining.py:  534]:	loss/total_loss, 7.30334997177124, 1743
[INFO] 2021-07-12 19:07:14,845 [run_pretraining.py:  535]:	loss/mlm_loss, 7.30334997177124, 1743
[INFO] 2021-07-12 19:07:14,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7419999494450167e-05, 1743
[INFO] 2021-07-12 19:07:14,845 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1743
[INFO] 2021-07-12 19:07:14,845 [run_pretraining.py:  558]:	worker_index: 7, step: 1743, cost: 7.303350, mlm loss: 7.303350, speed: 0.991276 steps/s, speed: 7.930210 samples/s, speed: 4060.267588 tokens/s, learning rate: 1.742e-05, loss_scalings: 6871.948730, pp_loss: 7.286596
[INFO] 2021-07-12 19:07:14,845 [run_pretraining.py:  512]:	********exe.run_1743******* 
[INFO] 2021-07-12 19:07:15,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:15,802 [run_pretraining.py:  534]:	loss/total_loss, 6.994258403778076, 1744
[INFO] 2021-07-12 19:07:15,802 [run_pretraining.py:  535]:	loss/mlm_loss, 6.994258403778076, 1744
[INFO] 2021-07-12 19:07:15,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7430000298190862e-05, 1744
[INFO] 2021-07-12 19:07:15,802 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1744
[INFO] 2021-07-12 19:07:15,802 [run_pretraining.py:  558]:	worker_index: 7, step: 1744, cost: 6.994258, mlm loss: 6.994258, speed: 1.045795 steps/s, speed: 8.366364 samples/s, speed: 4283.578332 tokens/s, learning rate: 1.743e-05, loss_scalings: 6871.948730, pp_loss: 7.503383
[INFO] 2021-07-12 19:07:15,802 [run_pretraining.py:  512]:	********exe.run_1744******* 
[INFO] 2021-07-12 19:07:16,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:16,771 [run_pretraining.py:  534]:	loss/total_loss, 7.925448417663574, 1745
[INFO] 2021-07-12 19:07:16,771 [run_pretraining.py:  535]:	loss/mlm_loss, 7.925448417663574, 1745
[INFO] 2021-07-12 19:07:16,771 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7439999282942154e-05, 1745
[INFO] 2021-07-12 19:07:16,771 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1745
[INFO] 2021-07-12 19:07:16,771 [run_pretraining.py:  558]:	worker_index: 7, step: 1745, cost: 7.925448, mlm loss: 7.925448, speed: 1.032407 steps/s, speed: 8.259260 samples/s, speed: 4228.740983 tokens/s, learning rate: 1.744e-05, loss_scalings: 6871.948730, pp_loss: 7.443463
[INFO] 2021-07-12 19:07:16,771 [run_pretraining.py:  512]:	********exe.run_1745******* 
[INFO] 2021-07-12 19:07:17,794 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:17,795 [run_pretraining.py:  534]:	loss/total_loss, 7.597927093505859, 1746
[INFO] 2021-07-12 19:07:17,795 [run_pretraining.py:  535]:	loss/mlm_loss, 7.597927093505859, 1746
[INFO] 2021-07-12 19:07:17,795 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.745000008668285e-05, 1746
[INFO] 2021-07-12 19:07:17,795 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1746
[INFO] 2021-07-12 19:07:17,795 [run_pretraining.py:  558]:	worker_index: 7, step: 1746, cost: 7.597927, mlm loss: 7.597927, speed: 0.977031 steps/s, speed: 7.816248 samples/s, speed: 4001.918789 tokens/s, learning rate: 1.745e-05, loss_scalings: 6871.948730, pp_loss: 6.881849
[INFO] 2021-07-12 19:07:17,795 [run_pretraining.py:  512]:	********exe.run_1746******* 
[INFO] 2021-07-12 19:07:18,736 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:18,737 [run_pretraining.py:  534]:	loss/total_loss, 8.069145202636719, 1747
[INFO] 2021-07-12 19:07:18,737 [run_pretraining.py:  535]:	loss/mlm_loss, 8.069145202636719, 1747
[INFO] 2021-07-12 19:07:18,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7460000890423544e-05, 1747
[INFO] 2021-07-12 19:07:18,737 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1747
[INFO] 2021-07-12 19:07:18,737 [run_pretraining.py:  558]:	worker_index: 7, step: 1747, cost: 8.069145, mlm loss: 8.069145, speed: 1.062621 steps/s, speed: 8.500972 samples/s, speed: 4352.497520 tokens/s, learning rate: 1.746e-05, loss_scalings: 6871.948730, pp_loss: 7.415550
[INFO] 2021-07-12 19:07:18,737 [run_pretraining.py:  512]:	********exe.run_1747******* 
[INFO] 2021-07-12 19:07:19,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:19,677 [run_pretraining.py:  534]:	loss/total_loss, 7.134297847747803, 1748
[INFO] 2021-07-12 19:07:19,677 [run_pretraining.py:  535]:	loss/mlm_loss, 7.134297847747803, 1748
[INFO] 2021-07-12 19:07:19,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7469999875174835e-05, 1748
[INFO] 2021-07-12 19:07:19,677 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1748
[INFO] 2021-07-12 19:07:19,677 [run_pretraining.py:  558]:	worker_index: 7, step: 1748, cost: 7.134298, mlm loss: 7.134298, speed: 1.064397 steps/s, speed: 8.515180 samples/s, speed: 4359.772038 tokens/s, learning rate: 1.747e-05, loss_scalings: 6871.948730, pp_loss: 6.402231
[INFO] 2021-07-12 19:07:19,677 [run_pretraining.py:  512]:	********exe.run_1748******* 
[INFO] 2021-07-12 19:07:20,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:20,608 [run_pretraining.py:  534]:	loss/total_loss, 7.86578369140625, 1749
[INFO] 2021-07-12 19:07:20,608 [run_pretraining.py:  535]:	loss/mlm_loss, 7.86578369140625, 1749
[INFO] 2021-07-12 19:07:20,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7479998859926127e-05, 1749
[INFO] 2021-07-12 19:07:20,608 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1749
[INFO] 2021-07-12 19:07:20,608 [run_pretraining.py:  558]:	worker_index: 7, step: 1749, cost: 7.865784, mlm loss: 7.865784, speed: 1.075332 steps/s, speed: 8.602653 samples/s, speed: 4404.558210 tokens/s, learning rate: 1.748e-05, loss_scalings: 6871.948730, pp_loss: 6.974825
[INFO] 2021-07-12 19:07:20,608 [run_pretraining.py:  512]:	********exe.run_1749******* 
[INFO] 2021-07-12 19:07:21,544 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:21,544 [run_pretraining.py:  534]:	loss/total_loss, 7.186206817626953, 1750
[INFO] 2021-07-12 19:07:21,544 [run_pretraining.py:  535]:	loss/mlm_loss, 7.186206817626953, 1750
[INFO] 2021-07-12 19:07:21,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7489999663666822e-05, 1750
[INFO] 2021-07-12 19:07:21,544 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1750
[INFO] 2021-07-12 19:07:21,545 [run_pretraining.py:  558]:	worker_index: 7, step: 1750, cost: 7.186207, mlm loss: 7.186207, speed: 1.068325 steps/s, speed: 8.546598 samples/s, speed: 4375.858319 tokens/s, learning rate: 1.749e-05, loss_scalings: 6871.948730, pp_loss: 7.215619
[INFO] 2021-07-12 19:07:21,545 [run_pretraining.py:  512]:	********exe.run_1750******* 
[INFO] 2021-07-12 19:07:22,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:22,470 [run_pretraining.py:  534]:	loss/total_loss, 7.68995475769043, 1751
[INFO] 2021-07-12 19:07:22,470 [run_pretraining.py:  535]:	loss/mlm_loss, 7.68995475769043, 1751
[INFO] 2021-07-12 19:07:22,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7499998648418114e-05, 1751
[INFO] 2021-07-12 19:07:22,470 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1751
[INFO] 2021-07-12 19:07:22,470 [run_pretraining.py:  558]:	worker_index: 7, step: 1751, cost: 7.689955, mlm loss: 7.689955, speed: 1.081176 steps/s, speed: 8.649409 samples/s, speed: 4428.497569 tokens/s, learning rate: 1.750e-05, loss_scalings: 6871.948730, pp_loss: 7.289080
[INFO] 2021-07-12 19:07:22,470 [run_pretraining.py:  512]:	********exe.run_1751******* 
[INFO] 2021-07-12 19:07:23,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:23,398 [run_pretraining.py:  534]:	loss/total_loss, 7.512267112731934, 1752
[INFO] 2021-07-12 19:07:23,398 [run_pretraining.py:  535]:	loss/mlm_loss, 7.512267112731934, 1752
[INFO] 2021-07-12 19:07:23,398 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.750999945215881e-05, 1752
[INFO] 2021-07-12 19:07:23,398 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1752
[INFO] 2021-07-12 19:07:23,398 [run_pretraining.py:  558]:	worker_index: 7, step: 1752, cost: 7.512267, mlm loss: 7.512267, speed: 1.078290 steps/s, speed: 8.626317 samples/s, speed: 4416.674277 tokens/s, learning rate: 1.751e-05, loss_scalings: 6871.948730, pp_loss: 7.864191
[INFO] 2021-07-12 19:07:23,398 [run_pretraining.py:  512]:	********exe.run_1752******* 
[INFO] 2021-07-12 19:07:24,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:24,335 [run_pretraining.py:  534]:	loss/total_loss, 7.747426986694336, 1753
[INFO] 2021-07-12 19:07:24,335 [run_pretraining.py:  535]:	loss/mlm_loss, 7.747426986694336, 1753
[INFO] 2021-07-12 19:07:24,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7520000255899504e-05, 1753
[INFO] 2021-07-12 19:07:24,335 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1753
[INFO] 2021-07-12 19:07:24,335 [run_pretraining.py:  558]:	worker_index: 7, step: 1753, cost: 7.747427, mlm loss: 7.747427, speed: 1.068334 steps/s, speed: 8.546672 samples/s, speed: 4375.896215 tokens/s, learning rate: 1.752e-05, loss_scalings: 6871.948730, pp_loss: 7.600479
[INFO] 2021-07-12 19:07:24,335 [run_pretraining.py:  512]:	********exe.run_1753******* 
[INFO] 2021-07-12 19:07:25,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:25,272 [run_pretraining.py:  534]:	loss/total_loss, 7.9187188148498535, 1754
[INFO] 2021-07-12 19:07:25,272 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9187188148498535, 1754
[INFO] 2021-07-12 19:07:25,272 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7529999240650795e-05, 1754
[INFO] 2021-07-12 19:07:25,272 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1754
[INFO] 2021-07-12 19:07:25,273 [run_pretraining.py:  558]:	worker_index: 7, step: 1754, cost: 7.918719, mlm loss: 7.918719, speed: 1.067237 steps/s, speed: 8.537895 samples/s, speed: 4371.402359 tokens/s, learning rate: 1.753e-05, loss_scalings: 6871.948730, pp_loss: 7.263739
[INFO] 2021-07-12 19:07:25,273 [run_pretraining.py:  512]:	********exe.run_1754******* 
[INFO] 2021-07-12 19:07:26,202 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:26,202 [run_pretraining.py:  534]:	loss/total_loss, 6.970260143280029, 1755
[INFO] 2021-07-12 19:07:26,202 [run_pretraining.py:  535]:	loss/mlm_loss, 6.970260143280029, 1755
[INFO] 2021-07-12 19:07:26,202 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.754000004439149e-05, 1755
[INFO] 2021-07-12 19:07:26,202 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1755
[INFO] 2021-07-12 19:07:26,202 [run_pretraining.py:  558]:	worker_index: 7, step: 1755, cost: 6.970260, mlm loss: 6.970260, speed: 1.076090 steps/s, speed: 8.608718 samples/s, speed: 4407.663539 tokens/s, learning rate: 1.754e-05, loss_scalings: 6871.948730, pp_loss: 7.266909
[INFO] 2021-07-12 19:07:26,203 [run_pretraining.py:  512]:	********exe.run_1755******* 
[INFO] 2021-07-12 19:07:27,127 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:27,127 [run_pretraining.py:  534]:	loss/total_loss, 7.295609474182129, 1756
[INFO] 2021-07-12 19:07:27,128 [run_pretraining.py:  535]:	loss/mlm_loss, 7.295609474182129, 1756
[INFO] 2021-07-12 19:07:27,128 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7550000848132186e-05, 1756
[INFO] 2021-07-12 19:07:27,128 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1756
[INFO] 2021-07-12 19:07:27,128 [run_pretraining.py:  558]:	worker_index: 7, step: 1756, cost: 7.295609, mlm loss: 7.295609, speed: 1.081510 steps/s, speed: 8.652081 samples/s, speed: 4429.865562 tokens/s, learning rate: 1.755e-05, loss_scalings: 6871.948730, pp_loss: 7.547645
[INFO] 2021-07-12 19:07:27,128 [run_pretraining.py:  512]:	********exe.run_1756******* 
[INFO] 2021-07-12 19:07:28,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:28,064 [run_pretraining.py:  534]:	loss/total_loss, 7.828520774841309, 1757
[INFO] 2021-07-12 19:07:28,064 [run_pretraining.py:  535]:	loss/mlm_loss, 7.828520774841309, 1757
[INFO] 2021-07-12 19:07:28,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7559999832883477e-05, 1757
[INFO] 2021-07-12 19:07:28,064 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1757
[INFO] 2021-07-12 19:07:28,064 [run_pretraining.py:  558]:	worker_index: 7, step: 1757, cost: 7.828521, mlm loss: 7.828521, speed: 1.068646 steps/s, speed: 8.549166 samples/s, speed: 4377.172790 tokens/s, learning rate: 1.756e-05, loss_scalings: 6871.948730, pp_loss: 7.596271
[INFO] 2021-07-12 19:07:28,064 [run_pretraining.py:  512]:	********exe.run_1757******* 
[INFO] 2021-07-12 19:07:28,994 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:28,994 [run_pretraining.py:  534]:	loss/total_loss, 6.761724472045898, 1758
[INFO] 2021-07-12 19:07:28,994 [run_pretraining.py:  535]:	loss/mlm_loss, 6.761724472045898, 1758
[INFO] 2021-07-12 19:07:28,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.756999881763477e-05, 1758
[INFO] 2021-07-12 19:07:28,994 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1758
[INFO] 2021-07-12 19:07:28,995 [run_pretraining.py:  558]:	worker_index: 7, step: 1758, cost: 6.761724, mlm loss: 6.761724, speed: 1.075643 steps/s, speed: 8.605144 samples/s, speed: 4405.833487 tokens/s, learning rate: 1.757e-05, loss_scalings: 6871.948730, pp_loss: 6.919050
[INFO] 2021-07-12 19:07:28,995 [run_pretraining.py:  512]:	********exe.run_1758******* 
[INFO] 2021-07-12 19:07:29,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:29,918 [run_pretraining.py:  534]:	loss/total_loss, 6.252778053283691, 1759
[INFO] 2021-07-12 19:07:29,918 [run_pretraining.py:  535]:	loss/mlm_loss, 6.252778053283691, 1759
[INFO] 2021-07-12 19:07:29,918 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7579999621375464e-05, 1759
[INFO] 2021-07-12 19:07:29,918 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1759
[INFO] 2021-07-12 19:07:29,919 [run_pretraining.py:  558]:	worker_index: 7, step: 1759, cost: 6.252778, mlm loss: 6.252778, speed: 1.083049 steps/s, speed: 8.664393 samples/s, speed: 4436.169461 tokens/s, learning rate: 1.758e-05, loss_scalings: 6871.948730, pp_loss: 7.147001
[INFO] 2021-07-12 19:07:29,919 [run_pretraining.py:  512]:	********exe.run_1759******* 
[INFO] 2021-07-12 19:07:30,838 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:30,838 [run_pretraining.py:  534]:	loss/total_loss, 4.771358013153076, 1760
[INFO] 2021-07-12 19:07:30,838 [run_pretraining.py:  535]:	loss/mlm_loss, 4.771358013153076, 1760
[INFO] 2021-07-12 19:07:30,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7589998606126755e-05, 1760
[INFO] 2021-07-12 19:07:30,839 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1760
[INFO] 2021-07-12 19:07:30,839 [run_pretraining.py:  558]:	worker_index: 7, step: 1760, cost: 4.771358, mlm loss: 4.771358, speed: 1.087599 steps/s, speed: 8.700795 samples/s, speed: 4454.806881 tokens/s, learning rate: 1.759e-05, loss_scalings: 6871.948730, pp_loss: 6.626162
[INFO] 2021-07-12 19:07:30,839 [run_pretraining.py:  512]:	********exe.run_1760******* 
[INFO] 2021-07-12 19:07:31,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:31,821 [run_pretraining.py:  534]:	loss/total_loss, 7.668935775756836, 1761
[INFO] 2021-07-12 19:07:31,822 [run_pretraining.py:  535]:	loss/mlm_loss, 7.668935775756836, 1761
[INFO] 2021-07-12 19:07:31,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.759999940986745e-05, 1761
[INFO] 2021-07-12 19:07:31,822 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1761
[INFO] 2021-07-12 19:07:31,822 [run_pretraining.py:  558]:	worker_index: 7, step: 1761, cost: 7.668936, mlm loss: 7.668936, speed: 1.017834 steps/s, speed: 8.142675 samples/s, speed: 4169.049494 tokens/s, learning rate: 1.760e-05, loss_scalings: 6871.948730, pp_loss: 7.346699
[INFO] 2021-07-12 19:07:31,822 [run_pretraining.py:  512]:	********exe.run_1761******* 
[INFO] 2021-07-12 19:07:32,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:32,920 [run_pretraining.py:  534]:	loss/total_loss, 7.315187454223633, 1762
[INFO] 2021-07-12 19:07:32,920 [run_pretraining.py:  535]:	loss/mlm_loss, 7.315187454223633, 1762
[INFO] 2021-07-12 19:07:32,920 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7610000213608146e-05, 1762
[INFO] 2021-07-12 19:07:32,920 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1762
[INFO] 2021-07-12 19:07:32,920 [run_pretraining.py:  558]:	worker_index: 7, step: 1762, cost: 7.315187, mlm loss: 7.315187, speed: 0.910727 steps/s, speed: 7.285816 samples/s, speed: 3730.337775 tokens/s, learning rate: 1.761e-05, loss_scalings: 6871.948730, pp_loss: 7.045091
[INFO] 2021-07-12 19:07:32,920 [run_pretraining.py:  512]:	********exe.run_1762******* 
[INFO] 2021-07-12 19:07:34,014 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:34,014 [run_pretraining.py:  534]:	loss/total_loss, 8.240604400634766, 1763
[INFO] 2021-07-12 19:07:34,014 [run_pretraining.py:  535]:	loss/mlm_loss, 8.240604400634766, 1763
[INFO] 2021-07-12 19:07:34,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7619999198359437e-05, 1763
[INFO] 2021-07-12 19:07:34,015 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1763
[INFO] 2021-07-12 19:07:34,015 [run_pretraining.py:  558]:	worker_index: 7, step: 1763, cost: 8.240604, mlm loss: 8.240604, speed: 0.914437 steps/s, speed: 7.315496 samples/s, speed: 3745.533980 tokens/s, learning rate: 1.762e-05, loss_scalings: 6871.948730, pp_loss: 7.431800
[INFO] 2021-07-12 19:07:34,015 [run_pretraining.py:  512]:	********exe.run_1763******* 
[INFO] 2021-07-12 19:07:35,111 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:35,112 [run_pretraining.py:  534]:	loss/total_loss, 7.581061363220215, 1764
[INFO] 2021-07-12 19:07:35,112 [run_pretraining.py:  535]:	loss/mlm_loss, 7.581061363220215, 1764
[INFO] 2021-07-12 19:07:35,112 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7630000002100132e-05, 1764
[INFO] 2021-07-12 19:07:35,112 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1764
[INFO] 2021-07-12 19:07:35,112 [run_pretraining.py:  558]:	worker_index: 7, step: 1764, cost: 7.581061, mlm loss: 7.581061, speed: 0.911807 steps/s, speed: 7.294453 samples/s, speed: 3734.759854 tokens/s, learning rate: 1.763e-05, loss_scalings: 6871.948730, pp_loss: 7.395637
[INFO] 2021-07-12 19:07:35,112 [run_pretraining.py:  512]:	********exe.run_1764******* 
[INFO] 2021-07-12 19:07:36,120 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:36,121 [run_pretraining.py:  534]:	loss/total_loss, 8.115279197692871, 1765
[INFO] 2021-07-12 19:07:36,121 [run_pretraining.py:  535]:	loss/mlm_loss, 8.115279197692871, 1765
[INFO] 2021-07-12 19:07:36,121 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7640000805840828e-05, 1765
[INFO] 2021-07-12 19:07:36,121 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1765
[INFO] 2021-07-12 19:07:36,121 [run_pretraining.py:  558]:	worker_index: 7, step: 1765, cost: 8.115279, mlm loss: 8.115279, speed: 0.991777 steps/s, speed: 7.934219 samples/s, speed: 4062.320247 tokens/s, learning rate: 1.764e-05, loss_scalings: 6871.948730, pp_loss: 6.517607
[INFO] 2021-07-12 19:07:36,121 [run_pretraining.py:  512]:	********exe.run_1765******* 
[INFO] 2021-07-12 19:07:37,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:07:37,037 [run_pretraining.py:  534]:	loss/total_loss, 7.1758623123168945, 1766
[INFO] 2021-07-12 19:07:37,037 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1758623123168945, 1766
[INFO] 2021-07-12 19:07:37,037 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7649997971602716e-05, 1766
[INFO] 2021-07-12 19:07:37,037 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1766
[INFO] 2021-07-12 19:07:37,037 [run_pretraining.py:  558]:	worker_index: 7, step: 1766, cost: 7.175862, mlm loss: 7.175862, speed: 1.092301 steps/s, speed: 8.738409 samples/s, speed: 4474.065246 tokens/s, learning rate: 1.765e-05, loss_scalings: 6871.948730, pp_loss: 7.495308
[INFO] 2021-07-12 19:07:37,037 [run_pretraining.py:  512]:	********exe.run_1766******* 
[INFO] 2021-07-12 19:08:03,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:03,476 [run_pretraining.py:  534]:	loss/total_loss, 7.143633842468262, 1767
[INFO] 2021-07-12 19:08:03,476 [run_pretraining.py:  535]:	loss/mlm_loss, 7.143633842468262, 1767
[INFO] 2021-07-12 19:08:03,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.765999877534341e-05, 1767
[INFO] 2021-07-12 19:08:03,476 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1767
[INFO] 2021-07-12 19:08:03,477 [run_pretraining.py:  558]:	worker_index: 7, step: 1767, cost: 7.143634, mlm loss: 7.143634, speed: 0.037823 steps/s, speed: 0.302586 samples/s, speed: 154.924174 tokens/s, learning rate: 1.766e-05, loss_scalings: 6871.948730, pp_loss: 7.204558
[INFO] 2021-07-12 19:08:03,477 [run_pretraining.py:  512]:	********exe.run_1767******* 
[INFO] 2021-07-12 19:08:04,434 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:04,435 [run_pretraining.py:  534]:	loss/total_loss, 7.382138729095459, 1768
[INFO] 2021-07-12 19:08:04,435 [run_pretraining.py:  535]:	loss/mlm_loss, 7.382138729095459, 1768
[INFO] 2021-07-12 19:08:04,435 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7669999579084106e-05, 1768
[INFO] 2021-07-12 19:08:04,435 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1768
[INFO] 2021-07-12 19:08:04,435 [run_pretraining.py:  558]:	worker_index: 7, step: 1768, cost: 7.382139, mlm loss: 7.382139, speed: 1.044104 steps/s, speed: 8.352831 samples/s, speed: 4276.649338 tokens/s, learning rate: 1.767e-05, loss_scalings: 6871.948730, pp_loss: 7.123353
[INFO] 2021-07-12 19:08:04,435 [run_pretraining.py:  512]:	********exe.run_1768******* 
[INFO] 2021-07-12 19:08:05,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:05,389 [run_pretraining.py:  534]:	loss/total_loss, 7.424380779266357, 1769
[INFO] 2021-07-12 19:08:05,389 [run_pretraining.py:  535]:	loss/mlm_loss, 7.424380779266357, 1769
[INFO] 2021-07-12 19:08:05,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7679998563835397e-05, 1769
[INFO] 2021-07-12 19:08:05,389 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1769
[INFO] 2021-07-12 19:08:05,389 [run_pretraining.py:  558]:	worker_index: 7, step: 1769, cost: 7.424381, mlm loss: 7.424381, speed: 1.048472 steps/s, speed: 8.387773 samples/s, speed: 4294.539989 tokens/s, learning rate: 1.768e-05, loss_scalings: 6871.948730, pp_loss: 6.969788
[INFO] 2021-07-12 19:08:05,389 [run_pretraining.py:  512]:	********exe.run_1769******* 
[INFO] 2021-07-12 19:08:06,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:06,348 [run_pretraining.py:  534]:	loss/total_loss, 7.578988075256348, 1770
[INFO] 2021-07-12 19:08:06,349 [run_pretraining.py:  535]:	loss/mlm_loss, 7.578988075256348, 1770
[INFO] 2021-07-12 19:08:06,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7689999367576092e-05, 1770
[INFO] 2021-07-12 19:08:06,349 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1770
[INFO] 2021-07-12 19:08:06,349 [run_pretraining.py:  558]:	worker_index: 7, step: 1770, cost: 7.578988, mlm loss: 7.578988, speed: 1.042958 steps/s, speed: 8.343661 samples/s, speed: 4271.954278 tokens/s, learning rate: 1.769e-05, loss_scalings: 6871.948730, pp_loss: 7.210301
[INFO] 2021-07-12 19:08:06,349 [run_pretraining.py:  512]:	********exe.run_1770******* 
[INFO] 2021-07-12 19:08:07,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:07,308 [run_pretraining.py:  534]:	loss/total_loss, 7.606983661651611, 1771
[INFO] 2021-07-12 19:08:07,308 [run_pretraining.py:  535]:	loss/mlm_loss, 7.606983661651611, 1771
[INFO] 2021-07-12 19:08:07,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7700000171316788e-05, 1771
[INFO] 2021-07-12 19:08:07,308 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1771
[INFO] 2021-07-12 19:08:07,308 [run_pretraining.py:  558]:	worker_index: 7, step: 1771, cost: 7.606984, mlm loss: 7.606984, speed: 1.043085 steps/s, speed: 8.344684 samples/s, speed: 4272.478040 tokens/s, learning rate: 1.770e-05, loss_scalings: 6871.948730, pp_loss: 7.354108
[INFO] 2021-07-12 19:08:07,308 [run_pretraining.py:  512]:	********exe.run_1771******* 
[INFO] 2021-07-12 19:08:08,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:08,265 [run_pretraining.py:  534]:	loss/total_loss, 7.2167887687683105, 1772
[INFO] 2021-07-12 19:08:08,265 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2167887687683105, 1772
[INFO] 2021-07-12 19:08:08,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.770999915606808e-05, 1772
[INFO] 2021-07-12 19:08:08,265 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1772
[INFO] 2021-07-12 19:08:08,265 [run_pretraining.py:  558]:	worker_index: 7, step: 1772, cost: 7.216789, mlm loss: 7.216789, speed: 1.045963 steps/s, speed: 8.367708 samples/s, speed: 4284.266270 tokens/s, learning rate: 1.771e-05, loss_scalings: 6871.948730, pp_loss: 7.172381
[INFO] 2021-07-12 19:08:08,265 [run_pretraining.py:  512]:	********exe.run_1772******* 
[INFO] 2021-07-12 19:08:09,209 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:09,209 [run_pretraining.py:  534]:	loss/total_loss, 7.958895683288574, 1773
[INFO] 2021-07-12 19:08:09,209 [run_pretraining.py:  535]:	loss/mlm_loss, 7.958895683288574, 1773
[INFO] 2021-07-12 19:08:09,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7719999959808774e-05, 1773
[INFO] 2021-07-12 19:08:09,210 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1773
[INFO] 2021-07-12 19:08:09,210 [run_pretraining.py:  558]:	worker_index: 7, step: 1773, cost: 7.958896, mlm loss: 7.958896, speed: 1.059221 steps/s, speed: 8.473769 samples/s, speed: 4338.569924 tokens/s, learning rate: 1.772e-05, loss_scalings: 6871.948730, pp_loss: 7.166866
[INFO] 2021-07-12 19:08:09,210 [run_pretraining.py:  512]:	********exe.run_1773******* 
[INFO] 2021-07-12 19:08:10,144 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:10,144 [run_pretraining.py:  534]:	loss/total_loss, 6.625453948974609, 1774
[INFO] 2021-07-12 19:08:10,145 [run_pretraining.py:  535]:	loss/mlm_loss, 6.625453948974609, 1774
[INFO] 2021-07-12 19:08:10,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.773000076354947e-05, 1774
[INFO] 2021-07-12 19:08:10,145 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1774
[INFO] 2021-07-12 19:08:10,145 [run_pretraining.py:  558]:	worker_index: 7, step: 1774, cost: 6.625454, mlm loss: 6.625454, speed: 1.070040 steps/s, speed: 8.560317 samples/s, speed: 4382.882439 tokens/s, learning rate: 1.773e-05, loss_scalings: 6871.948730, pp_loss: 7.048605
[INFO] 2021-07-12 19:08:10,145 [run_pretraining.py:  512]:	********exe.run_1774******* 
[INFO] 2021-07-12 19:08:11,082 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:11,082 [run_pretraining.py:  534]:	loss/total_loss, 6.957275390625, 1775
[INFO] 2021-07-12 19:08:11,082 [run_pretraining.py:  535]:	loss/mlm_loss, 6.957275390625, 1775
[INFO] 2021-07-12 19:08:11,083 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.773999974830076e-05, 1775
[INFO] 2021-07-12 19:08:11,083 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1775
[INFO] 2021-07-12 19:08:11,083 [run_pretraining.py:  558]:	worker_index: 7, step: 1775, cost: 6.957275, mlm loss: 6.957275, speed: 1.066991 steps/s, speed: 8.535925 samples/s, speed: 4370.393736 tokens/s, learning rate: 1.774e-05, loss_scalings: 6871.948730, pp_loss: 7.197499
[INFO] 2021-07-12 19:08:11,083 [run_pretraining.py:  512]:	********exe.run_1775******* 
[INFO] 2021-07-12 19:08:12,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:12,026 [run_pretraining.py:  534]:	loss/total_loss, 7.112638473510742, 1776
[INFO] 2021-07-12 19:08:12,026 [run_pretraining.py:  535]:	loss/mlm_loss, 7.112638473510742, 1776
[INFO] 2021-07-12 19:08:12,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7749998733052053e-05, 1776
[INFO] 2021-07-12 19:08:12,026 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1776
[INFO] 2021-07-12 19:08:12,026 [run_pretraining.py:  558]:	worker_index: 7, step: 1776, cost: 7.112638, mlm loss: 7.112638, speed: 1.060468 steps/s, speed: 8.483740 samples/s, speed: 4343.675097 tokens/s, learning rate: 1.775e-05, loss_scalings: 6871.948730, pp_loss: 6.872162
[INFO] 2021-07-12 19:08:12,026 [run_pretraining.py:  512]:	********exe.run_1776******* 
[INFO] 2021-07-12 19:08:12,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:12,965 [run_pretraining.py:  534]:	loss/total_loss, 7.345964431762695, 1777
[INFO] 2021-07-12 19:08:12,965 [run_pretraining.py:  535]:	loss/mlm_loss, 7.345964431762695, 1777
[INFO] 2021-07-12 19:08:12,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7759999536792748e-05, 1777
[INFO] 2021-07-12 19:08:12,965 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1777
[INFO] 2021-07-12 19:08:12,965 [run_pretraining.py:  558]:	worker_index: 7, step: 1777, cost: 7.345964, mlm loss: 7.345964, speed: 1.065735 steps/s, speed: 8.525877 samples/s, speed: 4365.248895 tokens/s, learning rate: 1.776e-05, loss_scalings: 6871.948730, pp_loss: 7.252688
[INFO] 2021-07-12 19:08:12,965 [run_pretraining.py:  512]:	********exe.run_1777******* 
[INFO] 2021-07-12 19:08:13,907 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:13,908 [run_pretraining.py:  534]:	loss/total_loss, 7.4945831298828125, 1778
[INFO] 2021-07-12 19:08:13,908 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4945831298828125, 1778
[INFO] 2021-07-12 19:08:13,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.776999852154404e-05, 1778
[INFO] 2021-07-12 19:08:13,908 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1778
[INFO] 2021-07-12 19:08:13,908 [run_pretraining.py:  558]:	worker_index: 7, step: 1778, cost: 7.494583, mlm loss: 7.494583, speed: 1.061578 steps/s, speed: 8.492621 samples/s, speed: 4348.222147 tokens/s, learning rate: 1.777e-05, loss_scalings: 6871.948730, pp_loss: 7.219785
[INFO] 2021-07-12 19:08:13,908 [run_pretraining.py:  512]:	********exe.run_1778******* 
[INFO] 2021-07-12 19:08:14,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:14,905 [run_pretraining.py:  534]:	loss/total_loss, 7.248589992523193, 1779
[INFO] 2021-07-12 19:08:14,905 [run_pretraining.py:  535]:	loss/mlm_loss, 7.248589992523193, 1779
[INFO] 2021-07-12 19:08:14,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7779999325284734e-05, 1779
[INFO] 2021-07-12 19:08:14,905 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1779
[INFO] 2021-07-12 19:08:14,905 [run_pretraining.py:  558]:	worker_index: 7, step: 1779, cost: 7.248590, mlm loss: 7.248590, speed: 1.003337 steps/s, speed: 8.026698 samples/s, speed: 4109.669491 tokens/s, learning rate: 1.778e-05, loss_scalings: 6871.948730, pp_loss: 7.193985
[INFO] 2021-07-12 19:08:14,905 [run_pretraining.py:  512]:	********exe.run_1779******* 
[INFO] 2021-07-12 19:08:15,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  534]:	loss/total_loss, 7.105399131774902, 1780
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  535]:	loss/mlm_loss, 7.105399131774902, 1780
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.779000012902543e-05, 1780
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1780
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  558]:	worker_index: 7, step: 1780, cost: 7.105399, mlm loss: 7.105399, speed: 0.989757 steps/s, speed: 7.918059 samples/s, speed: 4054.046463 tokens/s, learning rate: 1.779e-05, loss_scalings: 6871.948730, pp_loss: 7.226105
[INFO] 2021-07-12 19:08:15,916 [run_pretraining.py:  512]:	********exe.run_1780******* 
[INFO] 2021-07-12 19:08:16,992 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:16,992 [run_pretraining.py:  534]:	loss/total_loss, 7.626053333282471, 1781
[INFO] 2021-07-12 19:08:16,992 [run_pretraining.py:  535]:	loss/mlm_loss, 7.626053333282471, 1781
[INFO] 2021-07-12 19:08:16,993 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.779999911377672e-05, 1781
[INFO] 2021-07-12 19:08:16,993 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1781
[INFO] 2021-07-12 19:08:16,993 [run_pretraining.py:  558]:	worker_index: 7, step: 1781, cost: 7.626053, mlm loss: 7.626053, speed: 0.929564 steps/s, speed: 7.436515 samples/s, speed: 3807.495545 tokens/s, learning rate: 1.780e-05, loss_scalings: 6871.948730, pp_loss: 6.983821
[INFO] 2021-07-12 19:08:16,993 [run_pretraining.py:  512]:	********exe.run_1781******* 
[INFO] 2021-07-12 19:08:18,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:18,065 [run_pretraining.py:  534]:	loss/total_loss, 8.020193099975586, 1782
[INFO] 2021-07-12 19:08:18,066 [run_pretraining.py:  535]:	loss/mlm_loss, 8.020193099975586, 1782
[INFO] 2021-07-12 19:08:18,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7809999917517416e-05, 1782
[INFO] 2021-07-12 19:08:18,066 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1782
[INFO] 2021-07-12 19:08:18,066 [run_pretraining.py:  558]:	worker_index: 7, step: 1782, cost: 8.020193, mlm loss: 8.020193, speed: 0.932481 steps/s, speed: 7.459846 samples/s, speed: 3819.441144 tokens/s, learning rate: 1.781e-05, loss_scalings: 6871.948730, pp_loss: 7.361512
[INFO] 2021-07-12 19:08:18,066 [run_pretraining.py:  512]:	********exe.run_1782******* 
[INFO] 2021-07-12 19:08:19,131 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:19,131 [run_pretraining.py:  534]:	loss/total_loss, 6.876424789428711, 1783
[INFO] 2021-07-12 19:08:19,131 [run_pretraining.py:  535]:	loss/mlm_loss, 6.876424789428711, 1783
[INFO] 2021-07-12 19:08:19,132 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.782000072125811e-05, 1783
[INFO] 2021-07-12 19:08:19,132 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1783
[INFO] 2021-07-12 19:08:19,132 [run_pretraining.py:  558]:	worker_index: 7, step: 1783, cost: 6.876425, mlm loss: 6.876425, speed: 0.938732 steps/s, speed: 7.509855 samples/s, speed: 3845.045971 tokens/s, learning rate: 1.782e-05, loss_scalings: 6871.948730, pp_loss: 5.891594
[INFO] 2021-07-12 19:08:19,132 [run_pretraining.py:  512]:	********exe.run_1783******* 
[INFO] 2021-07-12 19:08:20,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:20,195 [run_pretraining.py:  534]:	loss/total_loss, 7.4431610107421875, 1784
[INFO] 2021-07-12 19:08:20,195 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4431610107421875, 1784
[INFO] 2021-07-12 19:08:20,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7829999706009403e-05, 1784
[INFO] 2021-07-12 19:08:20,195 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1784
[INFO] 2021-07-12 19:08:20,195 [run_pretraining.py:  558]:	worker_index: 7, step: 1784, cost: 7.443161, mlm loss: 7.443161, speed: 0.940811 steps/s, speed: 7.526485 samples/s, speed: 3853.560271 tokens/s, learning rate: 1.783e-05, loss_scalings: 6871.948730, pp_loss: 7.261925
[INFO] 2021-07-12 19:08:20,195 [run_pretraining.py:  512]:	********exe.run_1784******* 
[INFO] 2021-07-12 19:08:21,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:21,279 [run_pretraining.py:  534]:	loss/total_loss, 7.641569137573242, 1785
[INFO] 2021-07-12 19:08:21,279 [run_pretraining.py:  535]:	loss/mlm_loss, 7.641569137573242, 1785
[INFO] 2021-07-12 19:08:21,279 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7839998690760694e-05, 1785
[INFO] 2021-07-12 19:08:21,279 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1785
[INFO] 2021-07-12 19:08:21,279 [run_pretraining.py:  558]:	worker_index: 7, step: 1785, cost: 7.641569, mlm loss: 7.641569, speed: 0.923427 steps/s, speed: 7.387412 samples/s, speed: 3782.355109 tokens/s, learning rate: 1.784e-05, loss_scalings: 6871.948730, pp_loss: 7.421707
[INFO] 2021-07-12 19:08:21,279 [run_pretraining.py:  512]:	********exe.run_1785******* 
[INFO] 2021-07-12 19:08:22,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:22,381 [run_pretraining.py:  534]:	loss/total_loss, 7.472249984741211, 1786
[INFO] 2021-07-12 19:08:22,381 [run_pretraining.py:  535]:	loss/mlm_loss, 7.472249984741211, 1786
[INFO] 2021-07-12 19:08:22,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.784999949450139e-05, 1786
[INFO] 2021-07-12 19:08:22,381 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1786
[INFO] 2021-07-12 19:08:22,381 [run_pretraining.py:  558]:	worker_index: 7, step: 1786, cost: 7.472250, mlm loss: 7.472250, speed: 0.907602 steps/s, speed: 7.260819 samples/s, speed: 3717.539538 tokens/s, learning rate: 1.785e-05, loss_scalings: 6871.948730, pp_loss: 7.311445
[INFO] 2021-07-12 19:08:22,381 [run_pretraining.py:  512]:	********exe.run_1786******* 
[INFO] 2021-07-12 19:08:23,595 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:23,596 [run_pretraining.py:  534]:	loss/total_loss, 6.688995838165283, 1787
[INFO] 2021-07-12 19:08:23,596 [run_pretraining.py:  535]:	loss/mlm_loss, 6.688995838165283, 1787
[INFO] 2021-07-12 19:08:23,596 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.785999847925268e-05, 1787
[INFO] 2021-07-12 19:08:23,596 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1787
[INFO] 2021-07-12 19:08:23,596 [run_pretraining.py:  558]:	worker_index: 7, step: 1787, cost: 6.688996, mlm loss: 6.688996, speed: 0.823671 steps/s, speed: 6.589372 samples/s, speed: 3373.758359 tokens/s, learning rate: 1.786e-05, loss_scalings: 6871.948730, pp_loss: 6.195615
[INFO] 2021-07-12 19:08:23,596 [run_pretraining.py:  512]:	********exe.run_1787******* 
[INFO] 2021-07-12 19:08:24,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:24,550 [run_pretraining.py:  534]:	loss/total_loss, 6.9157843589782715, 1788
[INFO] 2021-07-12 19:08:24,550 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9157843589782715, 1788
[INFO] 2021-07-12 19:08:24,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7869999282993376e-05, 1788
[INFO] 2021-07-12 19:08:24,550 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1788
[INFO] 2021-07-12 19:08:24,550 [run_pretraining.py:  558]:	worker_index: 7, step: 1788, cost: 6.915784, mlm loss: 6.915784, speed: 1.048712 steps/s, speed: 8.389699 samples/s, speed: 4295.525714 tokens/s, learning rate: 1.787e-05, loss_scalings: 6871.948730, pp_loss: 7.154294
[INFO] 2021-07-12 19:08:24,550 [run_pretraining.py:  512]:	********exe.run_1788******* 
[INFO] 2021-07-12 19:08:25,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:25,516 [run_pretraining.py:  534]:	loss/total_loss, 7.362831115722656, 1789
[INFO] 2021-07-12 19:08:25,516 [run_pretraining.py:  535]:	loss/mlm_loss, 7.362831115722656, 1789
[INFO] 2021-07-12 19:08:25,516 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.788000008673407e-05, 1789
[INFO] 2021-07-12 19:08:25,516 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1789
[INFO] 2021-07-12 19:08:25,516 [run_pretraining.py:  558]:	worker_index: 7, step: 1789, cost: 7.362831, mlm loss: 7.362831, speed: 1.035777 steps/s, speed: 8.286213 samples/s, speed: 4242.541154 tokens/s, learning rate: 1.788e-05, loss_scalings: 6871.948730, pp_loss: 7.239177
[INFO] 2021-07-12 19:08:25,516 [run_pretraining.py:  512]:	********exe.run_1789******* 
[INFO] 2021-07-12 19:08:26,466 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:26,466 [run_pretraining.py:  534]:	loss/total_loss, 6.636728286743164, 1790
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  535]:	loss/mlm_loss, 6.636728286743164, 1790
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7889999071485363e-05, 1790
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1790
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  558]:	worker_index: 7, step: 1790, cost: 6.636728, mlm loss: 6.636728, speed: 1.052893 steps/s, speed: 8.423145 samples/s, speed: 4312.650240 tokens/s, learning rate: 1.789e-05, loss_scalings: 6871.948730, pp_loss: 7.014081
[INFO] 2021-07-12 19:08:26,467 [run_pretraining.py:  512]:	********exe.run_1790******* 
[INFO] 2021-07-12 19:08:27,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:27,413 [run_pretraining.py:  534]:	loss/total_loss, 8.083459854125977, 1791
[INFO] 2021-07-12 19:08:27,413 [run_pretraining.py:  535]:	loss/mlm_loss, 8.083459854125977, 1791
[INFO] 2021-07-12 19:08:27,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7899999875226058e-05, 1791
[INFO] 2021-07-12 19:08:27,413 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1791
[INFO] 2021-07-12 19:08:27,413 [run_pretraining.py:  558]:	worker_index: 7, step: 1791, cost: 8.083460, mlm loss: 8.083460, speed: 1.057254 steps/s, speed: 8.458036 samples/s, speed: 4330.514323 tokens/s, learning rate: 1.790e-05, loss_scalings: 6871.948730, pp_loss: 7.112292
[INFO] 2021-07-12 19:08:27,413 [run_pretraining.py:  512]:	********exe.run_1791******* 
[INFO] 2021-07-12 19:08:28,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:28,351 [run_pretraining.py:  534]:	loss/total_loss, 4.7488017082214355, 1792
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  535]:	loss/mlm_loss, 4.7488017082214355, 1792
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7910000678966753e-05, 1792
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1792
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  558]:	worker_index: 7, step: 1792, cost: 4.748802, mlm loss: 4.748802, speed: 1.066379 steps/s, speed: 8.531031 samples/s, speed: 4367.888096 tokens/s, learning rate: 1.791e-05, loss_scalings: 6871.948730, pp_loss: 6.693884
[INFO] 2021-07-12 19:08:28,352 [run_pretraining.py:  512]:	********exe.run_1792******* 
[INFO] 2021-07-12 19:08:29,296 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:29,296 [run_pretraining.py:  534]:	loss/total_loss, 5.369743824005127, 1793
[INFO] 2021-07-12 19:08:29,297 [run_pretraining.py:  535]:	loss/mlm_loss, 5.369743824005127, 1793
[INFO] 2021-07-12 19:08:29,297 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7919999663718045e-05, 1793
[INFO] 2021-07-12 19:08:29,297 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1793
[INFO] 2021-07-12 19:08:29,297 [run_pretraining.py:  558]:	worker_index: 7, step: 1793, cost: 5.369744, mlm loss: 5.369744, speed: 1.058889 steps/s, speed: 8.471115 samples/s, speed: 4337.210643 tokens/s, learning rate: 1.792e-05, loss_scalings: 6871.948730, pp_loss: 6.938237
[INFO] 2021-07-12 19:08:29,297 [run_pretraining.py:  512]:	********exe.run_1793******* 
[INFO] 2021-07-12 19:08:30,246 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:30,246 [run_pretraining.py:  534]:	loss/total_loss, 6.699504852294922, 1794
[INFO] 2021-07-12 19:08:30,247 [run_pretraining.py:  535]:	loss/mlm_loss, 6.699504852294922, 1794
[INFO] 2021-07-12 19:08:30,247 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7929998648469336e-05, 1794
[INFO] 2021-07-12 19:08:30,247 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1794
[INFO] 2021-07-12 19:08:30,247 [run_pretraining.py:  558]:	worker_index: 7, step: 1794, cost: 6.699505, mlm loss: 6.699505, speed: 1.053333 steps/s, speed: 8.426661 samples/s, speed: 4314.450275 tokens/s, learning rate: 1.793e-05, loss_scalings: 6871.948730, pp_loss: 7.138947
[INFO] 2021-07-12 19:08:30,247 [run_pretraining.py:  512]:	********exe.run_1794******* 
[INFO] 2021-07-12 19:08:31,210 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:31,210 [run_pretraining.py:  534]:	loss/total_loss, 7.23963737487793, 1795
[INFO] 2021-07-12 19:08:31,210 [run_pretraining.py:  535]:	loss/mlm_loss, 7.23963737487793, 1795
[INFO] 2021-07-12 19:08:31,211 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.793999945221003e-05, 1795
[INFO] 2021-07-12 19:08:31,211 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1795
[INFO] 2021-07-12 19:08:31,211 [run_pretraining.py:  558]:	worker_index: 7, step: 1795, cost: 7.239637, mlm loss: 7.239637, speed: 1.038106 steps/s, speed: 8.304847 samples/s, speed: 4252.081861 tokens/s, learning rate: 1.794e-05, loss_scalings: 6871.948730, pp_loss: 7.450716
[INFO] 2021-07-12 19:08:31,211 [run_pretraining.py:  512]:	********exe.run_1795******* 
[INFO] 2021-07-12 19:08:32,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:32,156 [run_pretraining.py:  534]:	loss/total_loss, 7.542732238769531, 1796
[INFO] 2021-07-12 19:08:32,156 [run_pretraining.py:  535]:	loss/mlm_loss, 7.542732238769531, 1796
[INFO] 2021-07-12 19:08:32,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7950000255950727e-05, 1796
[INFO] 2021-07-12 19:08:32,156 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1796
[INFO] 2021-07-12 19:08:32,156 [run_pretraining.py:  558]:	worker_index: 7, step: 1796, cost: 7.542732, mlm loss: 7.542732, speed: 1.058122 steps/s, speed: 8.464979 samples/s, speed: 4334.069269 tokens/s, learning rate: 1.795e-05, loss_scalings: 6871.948730, pp_loss: 7.492464
[INFO] 2021-07-12 19:08:32,157 [run_pretraining.py:  512]:	********exe.run_1796******* 
[INFO] 2021-07-12 19:08:33,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:33,107 [run_pretraining.py:  534]:	loss/total_loss, 7.253158092498779, 1797
[INFO] 2021-07-12 19:08:33,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.253158092498779, 1797
[INFO] 2021-07-12 19:08:33,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7959999240702018e-05, 1797
[INFO] 2021-07-12 19:08:33,107 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1797
[INFO] 2021-07-12 19:08:33,108 [run_pretraining.py:  558]:	worker_index: 7, step: 1797, cost: 7.253158, mlm loss: 7.253158, speed: 1.052134 steps/s, speed: 8.417070 samples/s, speed: 4309.540006 tokens/s, learning rate: 1.796e-05, loss_scalings: 6871.948730, pp_loss: 7.462024
[INFO] 2021-07-12 19:08:33,108 [run_pretraining.py:  512]:	********exe.run_1797******* 
[INFO] 2021-07-12 19:08:34,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:34,051 [run_pretraining.py:  534]:	loss/total_loss, 7.662161827087402, 1798
[INFO] 2021-07-12 19:08:34,051 [run_pretraining.py:  535]:	loss/mlm_loss, 7.662161827087402, 1798
[INFO] 2021-07-12 19:08:34,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7970000044442713e-05, 1798
[INFO] 2021-07-12 19:08:34,051 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1798
[INFO] 2021-07-12 19:08:34,051 [run_pretraining.py:  558]:	worker_index: 7, step: 1798, cost: 7.662162, mlm loss: 7.662162, speed: 1.060317 steps/s, speed: 8.482535 samples/s, speed: 4343.057977 tokens/s, learning rate: 1.797e-05, loss_scalings: 6871.948730, pp_loss: 7.278559
[INFO] 2021-07-12 19:08:34,051 [run_pretraining.py:  512]:	********exe.run_1798******* 
[INFO] 2021-07-12 19:08:34,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:34,989 [run_pretraining.py:  534]:	loss/total_loss, 7.70213508605957, 1799
[INFO] 2021-07-12 19:08:34,989 [run_pretraining.py:  535]:	loss/mlm_loss, 7.70213508605957, 1799
[INFO] 2021-07-12 19:08:34,989 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.7979999029194005e-05, 1799
[INFO] 2021-07-12 19:08:34,989 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1799
[INFO] 2021-07-12 19:08:34,989 [run_pretraining.py:  558]:	worker_index: 7, step: 1799, cost: 7.702135, mlm loss: 7.702135, speed: 1.067403 steps/s, speed: 8.539227 samples/s, speed: 4372.084305 tokens/s, learning rate: 1.798e-05, loss_scalings: 6871.948730, pp_loss: 7.315080
[INFO] 2021-07-12 19:08:34,989 [run_pretraining.py:  512]:	********exe.run_1799******* 
[INFO] 2021-07-12 19:08:35,924 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:35,925 [run_pretraining.py:  534]:	loss/total_loss, 7.50649356842041, 1800
[INFO] 2021-07-12 19:08:35,925 [run_pretraining.py:  535]:	loss/mlm_loss, 7.50649356842041, 1800
[INFO] 2021-07-12 19:08:35,925 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.79899998329347e-05, 1800
[INFO] 2021-07-12 19:08:35,925 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1800
[INFO] 2021-07-12 19:08:35,925 [run_pretraining.py:  558]:	worker_index: 7, step: 1800, cost: 7.506494, mlm loss: 7.506494, speed: 1.068640 steps/s, speed: 8.549118 samples/s, speed: 4377.148254 tokens/s, learning rate: 1.799e-05, loss_scalings: 6871.948730, pp_loss: 7.208830
[INFO] 2021-07-12 19:08:35,925 [run_pretraining.py:  512]:	********exe.run_1800******* 
[INFO] 2021-07-12 19:08:36,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:36,870 [run_pretraining.py:  534]:	loss/total_loss, 7.198765754699707, 1801
[INFO] 2021-07-12 19:08:36,870 [run_pretraining.py:  535]:	loss/mlm_loss, 7.198765754699707, 1801
[INFO] 2021-07-12 19:08:36,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8000000636675395e-05, 1801
[INFO] 2021-07-12 19:08:36,871 [run_pretraining.py:  539]:	lr/loss_scaling, 6871.94873046875, 1801
[INFO] 2021-07-12 19:08:36,871 [run_pretraining.py:  558]:	worker_index: 7, step: 1801, cost: 7.198766, mlm loss: 7.198766, speed: 1.058462 steps/s, speed: 8.467696 samples/s, speed: 4335.460497 tokens/s, learning rate: 1.800e-05, loss_scalings: 6871.948730, pp_loss: 7.103639
[INFO] 2021-07-12 19:08:36,871 [run_pretraining.py:  512]:	********exe.run_1801******* 
[INFO] 2021-07-12 19:08:37,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:37,812 [run_pretraining.py:  534]:	loss/total_loss, 7.647798538208008, 1802
[INFO] 2021-07-12 19:08:37,813 [run_pretraining.py:  535]:	loss/mlm_loss, 7.647798538208008, 1802
[INFO] 2021-07-12 19:08:37,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8009999621426687e-05, 1802
[INFO] 2021-07-12 19:08:37,813 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1802
[INFO] 2021-07-12 19:08:37,813 [run_pretraining.py:  558]:	worker_index: 7, step: 1802, cost: 7.647799, mlm loss: 7.647799, speed: 1.062188 steps/s, speed: 8.497508 samples/s, speed: 4350.723999 tokens/s, learning rate: 1.801e-05, loss_scalings: 5497.559082, pp_loss: 7.607906
[INFO] 2021-07-12 19:08:37,813 [run_pretraining.py:  512]:	********exe.run_1802******* 
[INFO] 2021-07-12 19:08:38,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:38,758 [run_pretraining.py:  534]:	loss/total_loss, 7.2459187507629395, 1803
[INFO] 2021-07-12 19:08:38,758 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2459187507629395, 1803
[INFO] 2021-07-12 19:08:38,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8019998606177978e-05, 1803
[INFO] 2021-07-12 19:08:38,758 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1803
[INFO] 2021-07-12 19:08:38,758 [run_pretraining.py:  558]:	worker_index: 7, step: 1803, cost: 7.245919, mlm loss: 7.245919, speed: 1.058459 steps/s, speed: 8.467671 samples/s, speed: 4335.447368 tokens/s, learning rate: 1.802e-05, loss_scalings: 5497.559082, pp_loss: 7.400656
[INFO] 2021-07-12 19:08:38,758 [run_pretraining.py:  512]:	********exe.run_1803******* 
[INFO] 2021-07-12 19:08:39,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:39,705 [run_pretraining.py:  534]:	loss/total_loss, 7.524487495422363, 1804
[INFO] 2021-07-12 19:08:39,705 [run_pretraining.py:  535]:	loss/mlm_loss, 7.524487495422363, 1804
[INFO] 2021-07-12 19:08:39,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8029999409918673e-05, 1804
[INFO] 2021-07-12 19:08:39,705 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1804
[INFO] 2021-07-12 19:08:39,705 [run_pretraining.py:  558]:	worker_index: 7, step: 1804, cost: 7.524487, mlm loss: 7.524487, speed: 1.056681 steps/s, speed: 8.453446 samples/s, speed: 4328.164316 tokens/s, learning rate: 1.803e-05, loss_scalings: 5497.559082, pp_loss: 7.212502
[INFO] 2021-07-12 19:08:39,705 [run_pretraining.py:  512]:	********exe.run_1804******* 
[INFO] 2021-07-12 19:08:40,642 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:40,643 [run_pretraining.py:  534]:	loss/total_loss, 6.73950719833374, 1805
[INFO] 2021-07-12 19:08:40,643 [run_pretraining.py:  535]:	loss/mlm_loss, 6.73950719833374, 1805
[INFO] 2021-07-12 19:08:40,643 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.804000021365937e-05, 1805
[INFO] 2021-07-12 19:08:40,643 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1805
[INFO] 2021-07-12 19:08:40,643 [run_pretraining.py:  558]:	worker_index: 7, step: 1805, cost: 6.739507, mlm loss: 6.739507, speed: 1.066953 steps/s, speed: 8.535621 samples/s, speed: 4370.238092 tokens/s, learning rate: 1.804e-05, loss_scalings: 5497.559082, pp_loss: 7.518158
[INFO] 2021-07-12 19:08:40,643 [run_pretraining.py:  512]:	********exe.run_1805******* 
[INFO] 2021-07-12 19:08:41,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:41,574 [run_pretraining.py:  534]:	loss/total_loss, 7.200807571411133, 1806
[INFO] 2021-07-12 19:08:41,574 [run_pretraining.py:  535]:	loss/mlm_loss, 7.200807571411133, 1806
[INFO] 2021-07-12 19:08:41,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.804999919841066e-05, 1806
[INFO] 2021-07-12 19:08:41,574 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1806
[INFO] 2021-07-12 19:08:41,574 [run_pretraining.py:  558]:	worker_index: 7, step: 1806, cost: 7.200808, mlm loss: 7.200808, speed: 1.074980 steps/s, speed: 8.599842 samples/s, speed: 4403.118904 tokens/s, learning rate: 1.805e-05, loss_scalings: 5497.559082, pp_loss: 7.370458
[INFO] 2021-07-12 19:08:41,574 [run_pretraining.py:  512]:	********exe.run_1806******* 
[INFO] 2021-07-12 19:08:42,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:42,515 [run_pretraining.py:  534]:	loss/total_loss, 7.273829460144043, 1807
[INFO] 2021-07-12 19:08:42,515 [run_pretraining.py:  535]:	loss/mlm_loss, 7.273829460144043, 1807
[INFO] 2021-07-12 19:08:42,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8060000002151355e-05, 1807
[INFO] 2021-07-12 19:08:42,515 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1807
[INFO] 2021-07-12 19:08:42,515 [run_pretraining.py:  558]:	worker_index: 7, step: 1807, cost: 7.273829, mlm loss: 7.273829, speed: 1.063387 steps/s, speed: 8.507097 samples/s, speed: 4355.633650 tokens/s, learning rate: 1.806e-05, loss_scalings: 5497.559082, pp_loss: 7.247530
[INFO] 2021-07-12 19:08:42,515 [run_pretraining.py:  512]:	********exe.run_1807******* 
[INFO] 2021-07-12 19:08:43,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:43,455 [run_pretraining.py:  534]:	loss/total_loss, 7.321313381195068, 1808
[INFO] 2021-07-12 19:08:43,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.321313381195068, 1808
[INFO] 2021-07-12 19:08:43,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.807000080589205e-05, 1808
[INFO] 2021-07-12 19:08:43,455 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1808
[INFO] 2021-07-12 19:08:43,455 [run_pretraining.py:  558]:	worker_index: 7, step: 1808, cost: 7.321313, mlm loss: 7.321313, speed: 1.064775 steps/s, speed: 8.518197 samples/s, speed: 4361.317103 tokens/s, learning rate: 1.807e-05, loss_scalings: 5497.559082, pp_loss: 7.381094
[INFO] 2021-07-12 19:08:43,455 [run_pretraining.py:  512]:	********exe.run_1808******* 
[INFO] 2021-07-12 19:08:44,369 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:44,370 [run_pretraining.py:  534]:	loss/total_loss, 7.063861846923828, 1809
[INFO] 2021-07-12 19:08:44,370 [run_pretraining.py:  535]:	loss/mlm_loss, 7.063861846923828, 1809
[INFO] 2021-07-12 19:08:44,370 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8079999790643342e-05, 1809
[INFO] 2021-07-12 19:08:44,370 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1809
[INFO] 2021-07-12 19:08:44,370 [run_pretraining.py:  558]:	worker_index: 7, step: 1809, cost: 7.063862, mlm loss: 7.063862, speed: 1.093182 steps/s, speed: 8.745460 samples/s, speed: 4477.675486 tokens/s, learning rate: 1.808e-05, loss_scalings: 5497.559082, pp_loss: 7.261634
[INFO] 2021-07-12 19:08:44,370 [run_pretraining.py:  512]:	********exe.run_1809******* 
[INFO] 2021-07-12 19:08:45,277 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  534]:	loss/total_loss, 7.060864448547363, 1810
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  535]:	loss/mlm_loss, 7.060864448547363, 1810
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8089998775394633e-05, 1810
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1810
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  558]:	worker_index: 7, step: 1810, cost: 7.060864, mlm loss: 7.060864, speed: 1.102375 steps/s, speed: 8.818997 samples/s, speed: 4515.326518 tokens/s, learning rate: 1.809e-05, loss_scalings: 5497.559082, pp_loss: 7.171947
[INFO] 2021-07-12 19:08:45,278 [run_pretraining.py:  512]:	********exe.run_1810******* 
[INFO] 2021-07-12 19:08:46,333 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:46,334 [run_pretraining.py:  534]:	loss/total_loss, 7.579108238220215, 1811
[INFO] 2021-07-12 19:08:46,334 [run_pretraining.py:  535]:	loss/mlm_loss, 7.579108238220215, 1811
[INFO] 2021-07-12 19:08:46,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.809999957913533e-05, 1811
[INFO] 2021-07-12 19:08:46,334 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1811
[INFO] 2021-07-12 19:08:46,334 [run_pretraining.py:  558]:	worker_index: 7, step: 1811, cost: 7.579108, mlm loss: 7.579108, speed: 0.947502 steps/s, speed: 7.580019 samples/s, speed: 3880.969704 tokens/s, learning rate: 1.810e-05, loss_scalings: 5497.559082, pp_loss: 7.474696
[INFO] 2021-07-12 19:08:46,334 [run_pretraining.py:  512]:	********exe.run_1811******* 
[INFO] 2021-07-12 19:08:47,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  534]:	loss/total_loss, 7.070317268371582, 1812
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  535]:	loss/mlm_loss, 7.070317268371582, 1812
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.810999856388662e-05, 1812
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1812
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  558]:	worker_index: 7, step: 1812, cost: 7.070317, mlm loss: 7.070317, speed: 0.872120 steps/s, speed: 6.976958 samples/s, speed: 3572.202642 tokens/s, learning rate: 1.811e-05, loss_scalings: 5497.559082, pp_loss: 7.080757
[INFO] 2021-07-12 19:08:47,481 [run_pretraining.py:  512]:	********exe.run_1812******* 
[INFO] 2021-07-12 19:08:48,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:48,726 [run_pretraining.py:  534]:	loss/total_loss, 7.031146049499512, 1813
[INFO] 2021-07-12 19:08:48,726 [run_pretraining.py:  535]:	loss/mlm_loss, 7.031146049499512, 1813
[INFO] 2021-07-12 19:08:48,726 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8119999367627315e-05, 1813
[INFO] 2021-07-12 19:08:48,726 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1813
[INFO] 2021-07-12 19:08:48,726 [run_pretraining.py:  558]:	worker_index: 7, step: 1813, cost: 7.031146, mlm loss: 7.031146, speed: 0.803769 steps/s, speed: 6.430149 samples/s, speed: 3292.236124 tokens/s, learning rate: 1.812e-05, loss_scalings: 5497.559082, pp_loss: 7.185917
[INFO] 2021-07-12 19:08:48,726 [run_pretraining.py:  512]:	********exe.run_1813******* 
[INFO] 2021-07-12 19:08:49,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:49,947 [run_pretraining.py:  534]:	loss/total_loss, 7.610126972198486, 1814
[INFO] 2021-07-12 19:08:49,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.610126972198486, 1814
[INFO] 2021-07-12 19:08:49,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.813000017136801e-05, 1814
[INFO] 2021-07-12 19:08:49,948 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1814
[INFO] 2021-07-12 19:08:49,948 [run_pretraining.py:  558]:	worker_index: 7, step: 1814, cost: 7.610127, mlm loss: 7.610127, speed: 0.819166 steps/s, speed: 6.553326 samples/s, speed: 3355.302959 tokens/s, learning rate: 1.813e-05, loss_scalings: 5497.559082, pp_loss: 6.898394
[INFO] 2021-07-12 19:08:49,948 [run_pretraining.py:  512]:	********exe.run_1814******* 
[INFO] 2021-07-12 19:08:51,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  534]:	loss/total_loss, 7.561056137084961, 1815
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  535]:	loss/mlm_loss, 7.561056137084961, 1815
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8139999156119302e-05, 1815
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1815
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  558]:	worker_index: 7, step: 1815, cost: 7.561056, mlm loss: 7.561056, speed: 0.782029 steps/s, speed: 6.256230 samples/s, speed: 3203.189712 tokens/s, learning rate: 1.814e-05, loss_scalings: 5497.559082, pp_loss: 7.265673
[INFO] 2021-07-12 19:08:51,227 [run_pretraining.py:  512]:	********exe.run_1815******* 
[INFO] 2021-07-12 19:08:52,500 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:52,501 [run_pretraining.py:  534]:	loss/total_loss, 7.572886943817139, 1816
[INFO] 2021-07-12 19:08:52,501 [run_pretraining.py:  535]:	loss/mlm_loss, 7.572886943817139, 1816
[INFO] 2021-07-12 19:08:52,501 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8149999959859997e-05, 1816
[INFO] 2021-07-12 19:08:52,501 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1816
[INFO] 2021-07-12 19:08:52,501 [run_pretraining.py:  558]:	worker_index: 7, step: 1816, cost: 7.572887, mlm loss: 7.572887, speed: 0.785405 steps/s, speed: 6.283240 samples/s, speed: 3217.019019 tokens/s, learning rate: 1.815e-05, loss_scalings: 5497.559082, pp_loss: 7.832156
[INFO] 2021-07-12 19:08:52,501 [run_pretraining.py:  512]:	********exe.run_1816******* 
[INFO] 2021-07-12 19:08:53,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:53,801 [run_pretraining.py:  534]:	loss/total_loss, 7.8436994552612305, 1817
[INFO] 2021-07-12 19:08:53,801 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8436994552612305, 1817
[INFO] 2021-07-12 19:08:53,801 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8160000763600692e-05, 1817
[INFO] 2021-07-12 19:08:53,801 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1817
[INFO] 2021-07-12 19:08:53,801 [run_pretraining.py:  558]:	worker_index: 7, step: 1817, cost: 7.843699, mlm loss: 7.843699, speed: 0.769468 steps/s, speed: 6.155742 samples/s, speed: 3151.739851 tokens/s, learning rate: 1.816e-05, loss_scalings: 5497.559082, pp_loss: 7.560184
[INFO] 2021-07-12 19:08:53,801 [run_pretraining.py:  512]:	********exe.run_1817******* 
[INFO] 2021-07-12 19:08:55,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:55,075 [run_pretraining.py:  534]:	loss/total_loss, 7.480879306793213, 1818
[INFO] 2021-07-12 19:08:55,075 [run_pretraining.py:  535]:	loss/mlm_loss, 7.480879306793213, 1818
[INFO] 2021-07-12 19:08:55,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8169999748351984e-05, 1818
[INFO] 2021-07-12 19:08:55,075 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1818
[INFO] 2021-07-12 19:08:55,075 [run_pretraining.py:  558]:	worker_index: 7, step: 1818, cost: 7.480879, mlm loss: 7.480879, speed: 0.785413 steps/s, speed: 6.283306 samples/s, speed: 3217.052754 tokens/s, learning rate: 1.817e-05, loss_scalings: 5497.559082, pp_loss: 7.501520
[INFO] 2021-07-12 19:08:55,075 [run_pretraining.py:  512]:	********exe.run_1818******* 
[INFO] 2021-07-12 19:08:56,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:56,158 [run_pretraining.py:  534]:	loss/total_loss, 7.672974586486816, 1819
[INFO] 2021-07-12 19:08:56,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.672974586486816, 1819
[INFO] 2021-07-12 19:08:56,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8179998733103275e-05, 1819
[INFO] 2021-07-12 19:08:56,158 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1819
[INFO] 2021-07-12 19:08:56,158 [run_pretraining.py:  558]:	worker_index: 7, step: 1819, cost: 7.672975, mlm loss: 7.672975, speed: 0.923834 steps/s, speed: 7.390670 samples/s, speed: 3784.022972 tokens/s, learning rate: 1.818e-05, loss_scalings: 5497.559082, pp_loss: 7.543900
[INFO] 2021-07-12 19:08:56,158 [run_pretraining.py:  512]:	********exe.run_1819******* 
[INFO] 2021-07-12 19:08:57,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:57,220 [run_pretraining.py:  534]:	loss/total_loss, 7.248075485229492, 1820
[INFO] 2021-07-12 19:08:57,220 [run_pretraining.py:  535]:	loss/mlm_loss, 7.248075485229492, 1820
[INFO] 2021-07-12 19:08:57,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.818999953684397e-05, 1820
[INFO] 2021-07-12 19:08:57,220 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1820
[INFO] 2021-07-12 19:08:57,220 [run_pretraining.py:  558]:	worker_index: 7, step: 1820, cost: 7.248075, mlm loss: 7.248075, speed: 0.942171 steps/s, speed: 7.537368 samples/s, speed: 3859.132327 tokens/s, learning rate: 1.819e-05, loss_scalings: 5497.559082, pp_loss: 7.354903
[INFO] 2021-07-12 19:08:57,220 [run_pretraining.py:  512]:	********exe.run_1820******* 
[INFO] 2021-07-12 19:08:58,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:58,279 [run_pretraining.py:  534]:	loss/total_loss, 8.30865478515625, 1821
[INFO] 2021-07-12 19:08:58,279 [run_pretraining.py:  535]:	loss/mlm_loss, 8.30865478515625, 1821
[INFO] 2021-07-12 19:08:58,279 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8199998521595262e-05, 1821
[INFO] 2021-07-12 19:08:58,279 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1821
[INFO] 2021-07-12 19:08:58,279 [run_pretraining.py:  558]:	worker_index: 7, step: 1821, cost: 8.308655, mlm loss: 8.308655, speed: 0.944524 steps/s, speed: 7.556193 samples/s, speed: 3868.770918 tokens/s, learning rate: 1.820e-05, loss_scalings: 5497.559082, pp_loss: 7.919119
[INFO] 2021-07-12 19:08:58,280 [run_pretraining.py:  512]:	********exe.run_1821******* 
[INFO] 2021-07-12 19:08:59,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:08:59,341 [run_pretraining.py:  534]:	loss/total_loss, 7.981805801391602, 1822
[INFO] 2021-07-12 19:08:59,341 [run_pretraining.py:  535]:	loss/mlm_loss, 7.981805801391602, 1822
[INFO] 2021-07-12 19:08:59,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8209999325335957e-05, 1822
[INFO] 2021-07-12 19:08:59,342 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1822
[INFO] 2021-07-12 19:08:59,342 [run_pretraining.py:  558]:	worker_index: 7, step: 1822, cost: 7.981806, mlm loss: 7.981806, speed: 0.942088 steps/s, speed: 7.536706 samples/s, speed: 3858.793407 tokens/s, learning rate: 1.821e-05, loss_scalings: 5497.559082, pp_loss: 7.894656
[INFO] 2021-07-12 19:08:59,342 [run_pretraining.py:  512]:	********exe.run_1822******* 
[INFO] 2021-07-12 19:09:00,420 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:00,421 [run_pretraining.py:  534]:	loss/total_loss, 7.65029239654541, 1823
[INFO] 2021-07-12 19:09:00,421 [run_pretraining.py:  535]:	loss/mlm_loss, 7.65029239654541, 1823
[INFO] 2021-07-12 19:09:00,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8220000129076652e-05, 1823
[INFO] 2021-07-12 19:09:00,421 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1823
[INFO] 2021-07-12 19:09:00,421 [run_pretraining.py:  558]:	worker_index: 7, step: 1823, cost: 7.650292, mlm loss: 7.650292, speed: 0.926949 steps/s, speed: 7.415588 samples/s, speed: 3796.781194 tokens/s, learning rate: 1.822e-05, loss_scalings: 5497.559082, pp_loss: 7.285320
[INFO] 2021-07-12 19:09:00,421 [run_pretraining.py:  512]:	********exe.run_1823******* 
[INFO] 2021-07-12 19:09:01,495 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:01,495 [run_pretraining.py:  534]:	loss/total_loss, 7.799520492553711, 1824
[INFO] 2021-07-12 19:09:01,495 [run_pretraining.py:  535]:	loss/mlm_loss, 7.799520492553711, 1824
[INFO] 2021-07-12 19:09:01,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8229999113827944e-05, 1824
[INFO] 2021-07-12 19:09:01,495 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1824
[INFO] 2021-07-12 19:09:01,496 [run_pretraining.py:  558]:	worker_index: 7, step: 1824, cost: 7.799520, mlm loss: 7.799520, speed: 0.931260 steps/s, speed: 7.450080 samples/s, speed: 3814.441163 tokens/s, learning rate: 1.823e-05, loss_scalings: 5497.559082, pp_loss: 7.272062
[INFO] 2021-07-12 19:09:01,496 [run_pretraining.py:  512]:	********exe.run_1824******* 
[INFO] 2021-07-12 19:09:02,572 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:02,573 [run_pretraining.py:  534]:	loss/total_loss, 7.367219924926758, 1825
[INFO] 2021-07-12 19:09:02,573 [run_pretraining.py:  535]:	loss/mlm_loss, 7.367219924926758, 1825
[INFO] 2021-07-12 19:09:02,573 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.823999991756864e-05, 1825
[INFO] 2021-07-12 19:09:02,573 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1825
[INFO] 2021-07-12 19:09:02,573 [run_pretraining.py:  558]:	worker_index: 7, step: 1825, cost: 7.367220, mlm loss: 7.367220, speed: 0.928357 steps/s, speed: 7.426859 samples/s, speed: 3802.552020 tokens/s, learning rate: 1.824e-05, loss_scalings: 5497.559082, pp_loss: 7.171986
[INFO] 2021-07-12 19:09:02,573 [run_pretraining.py:  512]:	********exe.run_1825******* 
[INFO] 2021-07-12 19:09:03,727 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:03,728 [run_pretraining.py:  534]:	loss/total_loss, 6.785656929016113, 1826
[INFO] 2021-07-12 19:09:03,728 [run_pretraining.py:  535]:	loss/mlm_loss, 6.785656929016113, 1826
[INFO] 2021-07-12 19:09:03,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8250000721309334e-05, 1826
[INFO] 2021-07-12 19:09:03,728 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1826
[INFO] 2021-07-12 19:09:03,728 [run_pretraining.py:  558]:	worker_index: 7, step: 1826, cost: 6.785657, mlm loss: 6.785657, speed: 0.866368 steps/s, speed: 6.930944 samples/s, speed: 3548.643260 tokens/s, learning rate: 1.825e-05, loss_scalings: 5497.559082, pp_loss: 7.079728
[INFO] 2021-07-12 19:09:03,728 [run_pretraining.py:  512]:	********exe.run_1826******* 
[INFO] 2021-07-12 19:09:04,834 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:04,834 [run_pretraining.py:  534]:	loss/total_loss, 7.006341934204102, 1827
[INFO] 2021-07-12 19:09:04,834 [run_pretraining.py:  535]:	loss/mlm_loss, 7.006341934204102, 1827
[INFO] 2021-07-12 19:09:04,834 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8259999706060626e-05, 1827
[INFO] 2021-07-12 19:09:04,835 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1827
[INFO] 2021-07-12 19:09:04,835 [run_pretraining.py:  558]:	worker_index: 7, step: 1827, cost: 7.006342, mlm loss: 7.006342, speed: 0.904376 steps/s, speed: 7.235009 samples/s, speed: 3704.324753 tokens/s, learning rate: 1.826e-05, loss_scalings: 5497.559082, pp_loss: 7.394106
[INFO] 2021-07-12 19:09:04,835 [run_pretraining.py:  512]:	********exe.run_1827******* 
[INFO] 2021-07-12 19:09:05,927 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:05,928 [run_pretraining.py:  534]:	loss/total_loss, 7.565807342529297, 1828
[INFO] 2021-07-12 19:09:05,928 [run_pretraining.py:  535]:	loss/mlm_loss, 7.565807342529297, 1828
[INFO] 2021-07-12 19:09:05,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8269998690811917e-05, 1828
[INFO] 2021-07-12 19:09:05,928 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1828
[INFO] 2021-07-12 19:09:05,928 [run_pretraining.py:  558]:	worker_index: 7, step: 1828, cost: 7.565807, mlm loss: 7.565807, speed: 0.915084 steps/s, speed: 7.320669 samples/s, speed: 3748.182441 tokens/s, learning rate: 1.827e-05, loss_scalings: 5497.559082, pp_loss: 7.362645
[INFO] 2021-07-12 19:09:05,928 [run_pretraining.py:  512]:	********exe.run_1828******* 
[INFO] 2021-07-12 19:09:07,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:07,029 [run_pretraining.py:  534]:	loss/total_loss, 7.096086502075195, 1829
[INFO] 2021-07-12 19:09:07,029 [run_pretraining.py:  535]:	loss/mlm_loss, 7.096086502075195, 1829
[INFO] 2021-07-12 19:09:07,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8279999494552612e-05, 1829
[INFO] 2021-07-12 19:09:07,029 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1829
[INFO] 2021-07-12 19:09:07,029 [run_pretraining.py:  558]:	worker_index: 7, step: 1829, cost: 7.096087, mlm loss: 7.096087, speed: 0.908599 steps/s, speed: 7.268796 samples/s, speed: 3721.623313 tokens/s, learning rate: 1.828e-05, loss_scalings: 5497.559082, pp_loss: 7.443331
[INFO] 2021-07-12 19:09:07,029 [run_pretraining.py:  512]:	********exe.run_1829******* 
[INFO] 2021-07-12 19:09:08,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:08,128 [run_pretraining.py:  534]:	loss/total_loss, 7.121739864349365, 1830
[INFO] 2021-07-12 19:09:08,128 [run_pretraining.py:  535]:	loss/mlm_loss, 7.121739864349365, 1830
[INFO] 2021-07-12 19:09:08,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8289998479303904e-05, 1830
[INFO] 2021-07-12 19:09:08,129 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1830
[INFO] 2021-07-12 19:09:08,129 [run_pretraining.py:  558]:	worker_index: 7, step: 1830, cost: 7.121740, mlm loss: 7.121740, speed: 0.910094 steps/s, speed: 7.280752 samples/s, speed: 3727.745199 tokens/s, learning rate: 1.829e-05, loss_scalings: 5497.559082, pp_loss: 7.392142
[INFO] 2021-07-12 19:09:08,129 [run_pretraining.py:  512]:	********exe.run_1830******* 
[INFO] 2021-07-12 19:09:09,226 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:09,226 [run_pretraining.py:  534]:	loss/total_loss, 7.312685012817383, 1831
[INFO] 2021-07-12 19:09:09,226 [run_pretraining.py:  535]:	loss/mlm_loss, 7.312685012817383, 1831
[INFO] 2021-07-12 19:09:09,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.82999992830446e-05, 1831
[INFO] 2021-07-12 19:09:09,227 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1831
[INFO] 2021-07-12 19:09:09,227 [run_pretraining.py:  558]:	worker_index: 7, step: 1831, cost: 7.312685, mlm loss: 7.312685, speed: 0.911302 steps/s, speed: 7.290416 samples/s, speed: 3732.693075 tokens/s, learning rate: 1.830e-05, loss_scalings: 5497.559082, pp_loss: 7.548988
[INFO] 2021-07-12 19:09:09,227 [run_pretraining.py:  512]:	********exe.run_1831******* 
[INFO] 2021-07-12 19:09:10,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:10,324 [run_pretraining.py:  534]:	loss/total_loss, 8.075913429260254, 1832
[INFO] 2021-07-12 19:09:10,324 [run_pretraining.py:  535]:	loss/mlm_loss, 8.075913429260254, 1832
[INFO] 2021-07-12 19:09:10,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8310000086785294e-05, 1832
[INFO] 2021-07-12 19:09:10,324 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1832
[INFO] 2021-07-12 19:09:10,324 [run_pretraining.py:  558]:	worker_index: 7, step: 1832, cost: 8.075913, mlm loss: 8.075913, speed: 0.911688 steps/s, speed: 7.293502 samples/s, speed: 3734.272774 tokens/s, learning rate: 1.831e-05, loss_scalings: 5497.559082, pp_loss: 7.327599
[INFO] 2021-07-12 19:09:10,324 [run_pretraining.py:  512]:	********exe.run_1832******* 
[INFO] 2021-07-12 19:09:11,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:11,424 [run_pretraining.py:  534]:	loss/total_loss, 6.969696998596191, 1833
[INFO] 2021-07-12 19:09:11,425 [run_pretraining.py:  535]:	loss/mlm_loss, 6.969696998596191, 1833
[INFO] 2021-07-12 19:09:11,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8319999071536586e-05, 1833
[INFO] 2021-07-12 19:09:11,425 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1833
[INFO] 2021-07-12 19:09:11,425 [run_pretraining.py:  558]:	worker_index: 7, step: 1833, cost: 6.969697, mlm loss: 6.969697, speed: 0.909181 steps/s, speed: 7.273452 samples/s, speed: 3724.007171 tokens/s, learning rate: 1.832e-05, loss_scalings: 5497.559082, pp_loss: 7.050213
[INFO] 2021-07-12 19:09:11,425 [run_pretraining.py:  512]:	********exe.run_1833******* 
[INFO] 2021-07-12 19:09:12,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:12,517 [run_pretraining.py:  534]:	loss/total_loss, 7.051392078399658, 1834
[INFO] 2021-07-12 19:09:12,517 [run_pretraining.py:  535]:	loss/mlm_loss, 7.051392078399658, 1834
[INFO] 2021-07-12 19:09:12,517 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.832999987527728e-05, 1834
[INFO] 2021-07-12 19:09:12,517 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1834
[INFO] 2021-07-12 19:09:12,517 [run_pretraining.py:  558]:	worker_index: 7, step: 1834, cost: 7.051392, mlm loss: 7.051392, speed: 0.915909 steps/s, speed: 7.327271 samples/s, speed: 3751.562803 tokens/s, learning rate: 1.833e-05, loss_scalings: 5497.559082, pp_loss: 7.440368
[INFO] 2021-07-12 19:09:12,517 [run_pretraining.py:  512]:	********exe.run_1834******* 
[INFO] 2021-07-12 19:09:13,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:13,607 [run_pretraining.py:  534]:	loss/total_loss, 6.858242511749268, 1835
[INFO] 2021-07-12 19:09:13,607 [run_pretraining.py:  535]:	loss/mlm_loss, 6.858242511749268, 1835
[INFO] 2021-07-12 19:09:13,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8340000679017976e-05, 1835
[INFO] 2021-07-12 19:09:13,607 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1835
[INFO] 2021-07-12 19:09:13,608 [run_pretraining.py:  558]:	worker_index: 7, step: 1835, cost: 6.858243, mlm loss: 6.858243, speed: 0.917721 steps/s, speed: 7.341769 samples/s, speed: 3758.985737 tokens/s, learning rate: 1.834e-05, loss_scalings: 5497.559082, pp_loss: 7.044394
[INFO] 2021-07-12 19:09:13,608 [run_pretraining.py:  512]:	********exe.run_1835******* 
[INFO] 2021-07-12 19:09:14,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:14,701 [run_pretraining.py:  534]:	loss/total_loss, 7.120743751525879, 1836
[INFO] 2021-07-12 19:09:14,701 [run_pretraining.py:  535]:	loss/mlm_loss, 7.120743751525879, 1836
[INFO] 2021-07-12 19:09:14,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8349999663769267e-05, 1836
[INFO] 2021-07-12 19:09:14,701 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1836
[INFO] 2021-07-12 19:09:14,701 [run_pretraining.py:  558]:	worker_index: 7, step: 1836, cost: 7.120744, mlm loss: 7.120744, speed: 0.914760 steps/s, speed: 7.318084 samples/s, speed: 3746.858969 tokens/s, learning rate: 1.835e-05, loss_scalings: 5497.559082, pp_loss: 7.310526
[INFO] 2021-07-12 19:09:14,701 [run_pretraining.py:  512]:	********exe.run_1836******* 
[INFO] 2021-07-12 19:09:15,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:15,791 [run_pretraining.py:  534]:	loss/total_loss, 7.432806968688965, 1837
[INFO] 2021-07-12 19:09:15,791 [run_pretraining.py:  535]:	loss/mlm_loss, 7.432806968688965, 1837
[INFO] 2021-07-12 19:09:15,791 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.835999864852056e-05, 1837
[INFO] 2021-07-12 19:09:15,791 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1837
[INFO] 2021-07-12 19:09:15,791 [run_pretraining.py:  558]:	worker_index: 7, step: 1837, cost: 7.432807, mlm loss: 7.432807, speed: 0.918274 steps/s, speed: 7.346192 samples/s, speed: 3761.250545 tokens/s, learning rate: 1.836e-05, loss_scalings: 5497.559082, pp_loss: 7.322934
[INFO] 2021-07-12 19:09:15,791 [run_pretraining.py:  512]:	********exe.run_1837******* 
[INFO] 2021-07-12 19:09:16,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:16,886 [run_pretraining.py:  534]:	loss/total_loss, 7.266416072845459, 1838
[INFO] 2021-07-12 19:09:16,887 [run_pretraining.py:  535]:	loss/mlm_loss, 7.266416072845459, 1838
[INFO] 2021-07-12 19:09:16,887 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8369999452261254e-05, 1838
[INFO] 2021-07-12 19:09:16,887 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1838
[INFO] 2021-07-12 19:09:16,887 [run_pretraining.py:  558]:	worker_index: 7, step: 1838, cost: 7.266416, mlm loss: 7.266416, speed: 0.913112 steps/s, speed: 7.304892 samples/s, speed: 3740.104960 tokens/s, learning rate: 1.837e-05, loss_scalings: 5497.559082, pp_loss: 7.238470
[INFO] 2021-07-12 19:09:16,887 [run_pretraining.py:  512]:	********exe.run_1838******* 
[INFO] 2021-07-12 19:09:17,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:17,983 [run_pretraining.py:  534]:	loss/total_loss, 7.432242393493652, 1839
[INFO] 2021-07-12 19:09:17,983 [run_pretraining.py:  535]:	loss/mlm_loss, 7.432242393493652, 1839
[INFO] 2021-07-12 19:09:17,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8379998437012546e-05, 1839
[INFO] 2021-07-12 19:09:17,983 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1839
[INFO] 2021-07-12 19:09:17,983 [run_pretraining.py:  558]:	worker_index: 7, step: 1839, cost: 7.432242, mlm loss: 7.432242, speed: 0.912867 steps/s, speed: 7.302935 samples/s, speed: 3739.102910 tokens/s, learning rate: 1.838e-05, loss_scalings: 5497.559082, pp_loss: 7.472388
[INFO] 2021-07-12 19:09:17,983 [run_pretraining.py:  512]:	********exe.run_1839******* 
[INFO] 2021-07-12 19:09:19,074 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:19,075 [run_pretraining.py:  534]:	loss/total_loss, 6.984808921813965, 1840
[INFO] 2021-07-12 19:09:19,075 [run_pretraining.py:  535]:	loss/mlm_loss, 6.984808921813965, 1840
[INFO] 2021-07-12 19:09:19,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.838999924075324e-05, 1840
[INFO] 2021-07-12 19:09:19,075 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1840
[INFO] 2021-07-12 19:09:19,075 [run_pretraining.py:  558]:	worker_index: 7, step: 1840, cost: 6.984809, mlm loss: 6.984809, speed: 0.915981 steps/s, speed: 7.327849 samples/s, speed: 3751.858567 tokens/s, learning rate: 1.839e-05, loss_scalings: 5497.559082, pp_loss: 7.500487
[INFO] 2021-07-12 19:09:19,075 [run_pretraining.py:  512]:	********exe.run_1840******* 
[INFO] 2021-07-12 19:09:20,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:20,168 [run_pretraining.py:  534]:	loss/total_loss, 7.289966106414795, 1841
[INFO] 2021-07-12 19:09:20,169 [run_pretraining.py:  535]:	loss/mlm_loss, 7.289966106414795, 1841
[INFO] 2021-07-12 19:09:20,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8400000044493936e-05, 1841
[INFO] 2021-07-12 19:09:20,169 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1841
[INFO] 2021-07-12 19:09:20,169 [run_pretraining.py:  558]:	worker_index: 7, step: 1841, cost: 7.289966, mlm loss: 7.289966, speed: 0.915019 steps/s, speed: 7.320151 samples/s, speed: 3747.917509 tokens/s, learning rate: 1.840e-05, loss_scalings: 5497.559082, pp_loss: 7.432241
[INFO] 2021-07-12 19:09:20,169 [run_pretraining.py:  512]:	********exe.run_1841******* 
[INFO] 2021-07-12 19:09:21,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:21,265 [run_pretraining.py:  534]:	loss/total_loss, 6.947501182556152, 1842
[INFO] 2021-07-12 19:09:21,265 [run_pretraining.py:  535]:	loss/mlm_loss, 6.947501182556152, 1842
[INFO] 2021-07-12 19:09:21,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8409999029245228e-05, 1842
[INFO] 2021-07-12 19:09:21,265 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1842
[INFO] 2021-07-12 19:09:21,265 [run_pretraining.py:  558]:	worker_index: 7, step: 1842, cost: 6.947501, mlm loss: 6.947501, speed: 0.912611 steps/s, speed: 7.300890 samples/s, speed: 3738.055849 tokens/s, learning rate: 1.841e-05, loss_scalings: 5497.559082, pp_loss: 6.855414
[INFO] 2021-07-12 19:09:21,265 [run_pretraining.py:  512]:	********exe.run_1842******* 
[INFO] 2021-07-12 19:09:22,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:22,409 [run_pretraining.py:  534]:	loss/total_loss, 6.991079330444336, 1843
[INFO] 2021-07-12 19:09:22,410 [run_pretraining.py:  535]:	loss/mlm_loss, 6.991079330444336, 1843
[INFO] 2021-07-12 19:09:22,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8419999832985923e-05, 1843
[INFO] 2021-07-12 19:09:22,410 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1843
[INFO] 2021-07-12 19:09:22,410 [run_pretraining.py:  558]:	worker_index: 7, step: 1843, cost: 6.991079, mlm loss: 6.991079, speed: 0.874162 steps/s, speed: 6.993298 samples/s, speed: 3580.568657 tokens/s, learning rate: 1.842e-05, loss_scalings: 5497.559082, pp_loss: 6.998433
[INFO] 2021-07-12 19:09:22,410 [run_pretraining.py:  512]:	********exe.run_1843******* 
[INFO] 2021-07-12 19:09:23,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:23,508 [run_pretraining.py:  534]:	loss/total_loss, 6.772951126098633, 1844
[INFO] 2021-07-12 19:09:23,508 [run_pretraining.py:  535]:	loss/mlm_loss, 6.772951126098633, 1844
[INFO] 2021-07-12 19:09:23,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8430000636726618e-05, 1844
[INFO] 2021-07-12 19:09:23,508 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1844
[INFO] 2021-07-12 19:09:23,508 [run_pretraining.py:  558]:	worker_index: 7, step: 1844, cost: 6.772951, mlm loss: 6.772951, speed: 0.910969 steps/s, speed: 7.287751 samples/s, speed: 3731.328649 tokens/s, learning rate: 1.843e-05, loss_scalings: 5497.559082, pp_loss: 6.950935
[INFO] 2021-07-12 19:09:23,508 [run_pretraining.py:  512]:	********exe.run_1844******* 
[INFO] 2021-07-12 19:09:24,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:24,687 [run_pretraining.py:  534]:	loss/total_loss, 7.753676414489746, 1845
[INFO] 2021-07-12 19:09:24,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.753676414489746, 1845
[INFO] 2021-07-12 19:09:24,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.843999962147791e-05, 1845
[INFO] 2021-07-12 19:09:24,687 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1845
[INFO] 2021-07-12 19:09:24,687 [run_pretraining.py:  558]:	worker_index: 7, step: 1845, cost: 7.753676, mlm loss: 7.753676, speed: 0.848627 steps/s, speed: 6.789013 samples/s, speed: 3475.974658 tokens/s, learning rate: 1.844e-05, loss_scalings: 5497.559082, pp_loss: 7.393679
[INFO] 2021-07-12 19:09:24,687 [run_pretraining.py:  512]:	********exe.run_1845******* 
[INFO] 2021-07-12 19:09:25,755 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:25,755 [run_pretraining.py:  534]:	loss/total_loss, 7.474859237670898, 1846
[INFO] 2021-07-12 19:09:25,755 [run_pretraining.py:  535]:	loss/mlm_loss, 7.474859237670898, 1846
[INFO] 2021-07-12 19:09:25,756 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.84499986062292e-05, 1846
[INFO] 2021-07-12 19:09:25,756 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1846
[INFO] 2021-07-12 19:09:25,756 [run_pretraining.py:  558]:	worker_index: 7, step: 1846, cost: 7.474859, mlm loss: 7.474859, speed: 0.936498 steps/s, speed: 7.491981 samples/s, speed: 3835.894192 tokens/s, learning rate: 1.845e-05, loss_scalings: 5497.559082, pp_loss: 7.339823
[INFO] 2021-07-12 19:09:25,756 [run_pretraining.py:  512]:	********exe.run_1846******* 
[INFO] 2021-07-12 19:09:26,815 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:26,815 [run_pretraining.py:  534]:	loss/total_loss, 7.11254358291626, 1847
[INFO] 2021-07-12 19:09:26,816 [run_pretraining.py:  535]:	loss/mlm_loss, 7.11254358291626, 1847
[INFO] 2021-07-12 19:09:26,816 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8459999409969896e-05, 1847
[INFO] 2021-07-12 19:09:26,816 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1847
[INFO] 2021-07-12 19:09:26,816 [run_pretraining.py:  558]:	worker_index: 7, step: 1847, cost: 7.112544, mlm loss: 7.112544, speed: 0.943851 steps/s, speed: 7.550805 samples/s, speed: 3866.012001 tokens/s, learning rate: 1.846e-05, loss_scalings: 5497.559082, pp_loss: 6.645653
[INFO] 2021-07-12 19:09:26,816 [run_pretraining.py:  512]:	********exe.run_1847******* 
[INFO] 2021-07-12 19:09:27,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:27,880 [run_pretraining.py:  534]:	loss/total_loss, 7.291443824768066, 1848
[INFO] 2021-07-12 19:09:27,880 [run_pretraining.py:  535]:	loss/mlm_loss, 7.291443824768066, 1848
[INFO] 2021-07-12 19:09:27,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8469998394721188e-05, 1848
[INFO] 2021-07-12 19:09:27,880 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1848
[INFO] 2021-07-12 19:09:27,881 [run_pretraining.py:  558]:	worker_index: 7, step: 1848, cost: 7.291444, mlm loss: 7.291444, speed: 0.939796 steps/s, speed: 7.518366 samples/s, speed: 3849.403637 tokens/s, learning rate: 1.847e-05, loss_scalings: 5497.559082, pp_loss: 7.281898
[INFO] 2021-07-12 19:09:27,881 [run_pretraining.py:  512]:	********exe.run_1848******* 
[INFO] 2021-07-12 19:09:28,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:28,942 [run_pretraining.py:  534]:	loss/total_loss, 6.565516948699951, 1849
[INFO] 2021-07-12 19:09:28,942 [run_pretraining.py:  535]:	loss/mlm_loss, 6.565516948699951, 1849
[INFO] 2021-07-12 19:09:28,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8479999198461883e-05, 1849
[INFO] 2021-07-12 19:09:28,942 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1849
[INFO] 2021-07-12 19:09:28,942 [run_pretraining.py:  558]:	worker_index: 7, step: 1849, cost: 6.565517, mlm loss: 6.565517, speed: 0.942378 steps/s, speed: 7.539021 samples/s, speed: 3859.978589 tokens/s, learning rate: 1.848e-05, loss_scalings: 5497.559082, pp_loss: 7.105462
[INFO] 2021-07-12 19:09:28,942 [run_pretraining.py:  512]:	********exe.run_1849******* 
[INFO] 2021-07-12 19:09:29,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  534]:	loss/total_loss, 7.454682350158691, 1850
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  535]:	loss/mlm_loss, 7.454682350158691, 1850
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8490000002202578e-05, 1850
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1850
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  558]:	worker_index: 7, step: 1850, cost: 7.454682, mlm loss: 7.454682, speed: 0.946830 steps/s, speed: 7.574637 samples/s, speed: 3878.214379 tokens/s, learning rate: 1.849e-05, loss_scalings: 5497.559082, pp_loss: 7.530948
[INFO] 2021-07-12 19:09:29,999 [run_pretraining.py:  512]:	********exe.run_1850******* 
[INFO] 2021-07-12 19:09:31,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:31,183 [run_pretraining.py:  534]:	loss/total_loss, 7.617866516113281, 1851
[INFO] 2021-07-12 19:09:31,184 [run_pretraining.py:  535]:	loss/mlm_loss, 7.617866516113281, 1851
[INFO] 2021-07-12 19:09:31,184 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.849999898695387e-05, 1851
[INFO] 2021-07-12 19:09:31,184 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1851
[INFO] 2021-07-12 19:09:31,184 [run_pretraining.py:  558]:	worker_index: 7, step: 1851, cost: 7.617867, mlm loss: 7.617867, speed: 0.844601 steps/s, speed: 6.756806 samples/s, speed: 3459.484493 tokens/s, learning rate: 1.850e-05, loss_scalings: 5497.559082, pp_loss: 7.566622
[INFO] 2021-07-12 19:09:31,184 [run_pretraining.py:  512]:	********exe.run_1851******* 
[INFO] 2021-07-12 19:09:32,341 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:32,341 [run_pretraining.py:  534]:	loss/total_loss, 7.569559097290039, 1852
[INFO] 2021-07-12 19:09:32,341 [run_pretraining.py:  535]:	loss/mlm_loss, 7.569559097290039, 1852
[INFO] 2021-07-12 19:09:32,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8509999790694565e-05, 1852
[INFO] 2021-07-12 19:09:32,341 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1852
[INFO] 2021-07-12 19:09:32,342 [run_pretraining.py:  558]:	worker_index: 7, step: 1852, cost: 7.569559, mlm loss: 7.569559, speed: 0.864246 steps/s, speed: 6.913969 samples/s, speed: 3539.952143 tokens/s, learning rate: 1.851e-05, loss_scalings: 5497.559082, pp_loss: 7.120108
[INFO] 2021-07-12 19:09:32,342 [run_pretraining.py:  512]:	********exe.run_1852******* 
[INFO] 2021-07-12 19:09:33,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:33,515 [run_pretraining.py:  534]:	loss/total_loss, 7.667635440826416, 1853
[INFO] 2021-07-12 19:09:33,515 [run_pretraining.py:  535]:	loss/mlm_loss, 7.667635440826416, 1853
[INFO] 2021-07-12 19:09:33,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.852000059443526e-05, 1853
[INFO] 2021-07-12 19:09:33,515 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1853
[INFO] 2021-07-12 19:09:33,516 [run_pretraining.py:  558]:	worker_index: 7, step: 1853, cost: 7.667635, mlm loss: 7.667635, speed: 0.852299 steps/s, speed: 6.818395 samples/s, speed: 3491.018116 tokens/s, learning rate: 1.852e-05, loss_scalings: 5497.559082, pp_loss: 7.591100
[INFO] 2021-07-12 19:09:33,516 [run_pretraining.py:  512]:	********exe.run_1853******* 
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  534]:	loss/total_loss, 7.37497091293335, 1854
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37497091293335, 1854
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.852999957918655e-05, 1854
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1854
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  558]:	worker_index: 7, step: 1854, cost: 7.374971, mlm loss: 7.374971, speed: 0.835239 steps/s, speed: 6.681911 samples/s, speed: 3421.138412 tokens/s, learning rate: 1.853e-05, loss_scalings: 5497.559082, pp_loss: 7.463192
[INFO] 2021-07-12 19:09:34,713 [run_pretraining.py:  512]:	********exe.run_1854******* 
[INFO] 2021-07-12 19:09:35,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:35,982 [run_pretraining.py:  534]:	loss/total_loss, 6.934076309204102, 1855
[INFO] 2021-07-12 19:09:35,982 [run_pretraining.py:  535]:	loss/mlm_loss, 6.934076309204102, 1855
[INFO] 2021-07-12 19:09:35,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8539998563937843e-05, 1855
[INFO] 2021-07-12 19:09:35,982 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1855
[INFO] 2021-07-12 19:09:35,982 [run_pretraining.py:  558]:	worker_index: 7, step: 1855, cost: 6.934076, mlm loss: 6.934076, speed: 0.788486 steps/s, speed: 6.307887 samples/s, speed: 3229.638074 tokens/s, learning rate: 1.854e-05, loss_scalings: 5497.559082, pp_loss: 7.309454
[INFO] 2021-07-12 19:09:35,982 [run_pretraining.py:  512]:	********exe.run_1855******* 
[INFO] 2021-07-12 19:09:37,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:37,167 [run_pretraining.py:  534]:	loss/total_loss, 7.249689102172852, 1856
[INFO] 2021-07-12 19:09:37,167 [run_pretraining.py:  535]:	loss/mlm_loss, 7.249689102172852, 1856
[INFO] 2021-07-12 19:09:37,167 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8549999367678538e-05, 1856
[INFO] 2021-07-12 19:09:37,168 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1856
[INFO] 2021-07-12 19:09:37,168 [run_pretraining.py:  558]:	worker_index: 7, step: 1856, cost: 7.249689, mlm loss: 7.249689, speed: 0.844178 steps/s, speed: 6.753425 samples/s, speed: 3457.753535 tokens/s, learning rate: 1.855e-05, loss_scalings: 5497.559082, pp_loss: 7.050560
[INFO] 2021-07-12 19:09:37,168 [run_pretraining.py:  512]:	********exe.run_1856******* 
[INFO] 2021-07-12 19:09:38,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:38,306 [run_pretraining.py:  534]:	loss/total_loss, 6.743613243103027, 1857
[INFO] 2021-07-12 19:09:38,306 [run_pretraining.py:  535]:	loss/mlm_loss, 6.743613243103027, 1857
[INFO] 2021-07-12 19:09:38,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8560000171419233e-05, 1857
[INFO] 2021-07-12 19:09:38,306 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1857
[INFO] 2021-07-12 19:09:38,306 [run_pretraining.py:  558]:	worker_index: 7, step: 1857, cost: 6.743613, mlm loss: 6.743613, speed: 0.878703 steps/s, speed: 7.029624 samples/s, speed: 3599.167280 tokens/s, learning rate: 1.856e-05, loss_scalings: 5497.559082, pp_loss: 7.250663
[INFO] 2021-07-12 19:09:38,306 [run_pretraining.py:  512]:	********exe.run_1857******* 
[INFO] 2021-07-12 19:09:39,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:39,457 [run_pretraining.py:  534]:	loss/total_loss, 7.235875606536865, 1858
[INFO] 2021-07-12 19:09:39,457 [run_pretraining.py:  535]:	loss/mlm_loss, 7.235875606536865, 1858
[INFO] 2021-07-12 19:09:39,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8569999156170525e-05, 1858
[INFO] 2021-07-12 19:09:39,457 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1858
[INFO] 2021-07-12 19:09:39,458 [run_pretraining.py:  558]:	worker_index: 7, step: 1858, cost: 7.235876, mlm loss: 7.235876, speed: 0.869107 steps/s, speed: 6.952854 samples/s, speed: 3559.861281 tokens/s, learning rate: 1.857e-05, loss_scalings: 5497.559082, pp_loss: 7.459101
[INFO] 2021-07-12 19:09:39,458 [run_pretraining.py:  512]:	********exe.run_1858******* 
[INFO] 2021-07-12 19:09:40,581 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  534]:	loss/total_loss, 8.091444969177246, 1859
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  535]:	loss/mlm_loss, 8.091444969177246, 1859
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.857999995991122e-05, 1859
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1859
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  558]:	worker_index: 7, step: 1859, cost: 8.091445, mlm loss: 8.091445, speed: 0.889870 steps/s, speed: 7.118959 samples/s, speed: 3644.907208 tokens/s, learning rate: 1.858e-05, loss_scalings: 5497.559082, pp_loss: 7.474137
[INFO] 2021-07-12 19:09:40,582 [run_pretraining.py:  512]:	********exe.run_1859******* 
[INFO] 2021-07-12 19:09:41,641 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:41,642 [run_pretraining.py:  534]:	loss/total_loss, 7.212396144866943, 1860
[INFO] 2021-07-12 19:09:41,642 [run_pretraining.py:  535]:	loss/mlm_loss, 7.212396144866943, 1860
[INFO] 2021-07-12 19:09:41,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.858999894466251e-05, 1860
[INFO] 2021-07-12 19:09:41,642 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1860
[INFO] 2021-07-12 19:09:41,642 [run_pretraining.py:  558]:	worker_index: 7, step: 1860, cost: 7.212396, mlm loss: 7.212396, speed: 0.943866 steps/s, speed: 7.550929 samples/s, speed: 3866.075511 tokens/s, learning rate: 1.859e-05, loss_scalings: 5497.559082, pp_loss: 7.410851
[INFO] 2021-07-12 19:09:41,642 [run_pretraining.py:  512]:	********exe.run_1860******* 
[INFO] 2021-07-12 19:09:42,555 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:42,555 [run_pretraining.py:  534]:	loss/total_loss, 7.165160655975342, 1861
[INFO] 2021-07-12 19:09:42,555 [run_pretraining.py:  535]:	loss/mlm_loss, 7.165160655975342, 1861
[INFO] 2021-07-12 19:09:42,555 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8599999748403206e-05, 1861
[INFO] 2021-07-12 19:09:42,555 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1861
[INFO] 2021-07-12 19:09:42,556 [run_pretraining.py:  558]:	worker_index: 7, step: 1861, cost: 7.165161, mlm loss: 7.165161, speed: 1.095533 steps/s, speed: 8.764262 samples/s, speed: 4487.302036 tokens/s, learning rate: 1.860e-05, loss_scalings: 5497.559082, pp_loss: 7.186840
[INFO] 2021-07-12 19:09:42,556 [run_pretraining.py:  512]:	********exe.run_1861******* 
[INFO] 2021-07-12 19:09:43,473 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:43,474 [run_pretraining.py:  534]:	loss/total_loss, 6.746607780456543, 1862
[INFO] 2021-07-12 19:09:43,474 [run_pretraining.py:  535]:	loss/mlm_loss, 6.746607780456543, 1862
[INFO] 2021-07-12 19:09:43,474 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.86100005521439e-05, 1862
[INFO] 2021-07-12 19:09:43,474 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1862
[INFO] 2021-07-12 19:09:43,474 [run_pretraining.py:  558]:	worker_index: 7, step: 1862, cost: 6.746608, mlm loss: 6.746608, speed: 1.089559 steps/s, speed: 8.716469 samples/s, speed: 4462.832269 tokens/s, learning rate: 1.861e-05, loss_scalings: 5497.559082, pp_loss: 7.264351
[INFO] 2021-07-12 19:09:43,474 [run_pretraining.py:  512]:	********exe.run_1862******* 
[INFO] 2021-07-12 19:09:44,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:44,384 [run_pretraining.py:  534]:	loss/total_loss, 7.7362871170043945, 1863
[INFO] 2021-07-12 19:09:44,384 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7362871170043945, 1863
[INFO] 2021-07-12 19:09:44,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8619999536895193e-05, 1863
[INFO] 2021-07-12 19:09:44,385 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1863
[INFO] 2021-07-12 19:09:44,385 [run_pretraining.py:  558]:	worker_index: 7, step: 1863, cost: 7.736287, mlm loss: 7.736287, speed: 1.098812 steps/s, speed: 8.790496 samples/s, speed: 4500.734108 tokens/s, learning rate: 1.862e-05, loss_scalings: 5497.559082, pp_loss: 7.680343
[INFO] 2021-07-12 19:09:44,385 [run_pretraining.py:  512]:	********exe.run_1863******* 
[INFO] 2021-07-12 19:09:45,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:45,303 [run_pretraining.py:  534]:	loss/total_loss, 7.339764595031738, 1864
[INFO] 2021-07-12 19:09:45,303 [run_pretraining.py:  535]:	loss/mlm_loss, 7.339764595031738, 1864
[INFO] 2021-07-12 19:09:45,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8629998521646485e-05, 1864
[INFO] 2021-07-12 19:09:45,303 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1864
[INFO] 2021-07-12 19:09:45,303 [run_pretraining.py:  558]:	worker_index: 7, step: 1864, cost: 7.339765, mlm loss: 7.339765, speed: 1.089767 steps/s, speed: 8.718136 samples/s, speed: 4463.685688 tokens/s, learning rate: 1.863e-05, loss_scalings: 5497.559082, pp_loss: 7.558595
[INFO] 2021-07-12 19:09:45,303 [run_pretraining.py:  512]:	********exe.run_1864******* 
[INFO] 2021-07-12 19:09:46,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:46,236 [run_pretraining.py:  534]:	loss/total_loss, 7.493468761444092, 1865
[INFO] 2021-07-12 19:09:46,236 [run_pretraining.py:  535]:	loss/mlm_loss, 7.493468761444092, 1865
[INFO] 2021-07-12 19:09:46,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.863999932538718e-05, 1865
[INFO] 2021-07-12 19:09:46,236 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1865
[INFO] 2021-07-12 19:09:46,236 [run_pretraining.py:  558]:	worker_index: 7, step: 1865, cost: 7.493469, mlm loss: 7.493469, speed: 1.072603 steps/s, speed: 8.580827 samples/s, speed: 4393.383479 tokens/s, learning rate: 1.864e-05, loss_scalings: 5497.559082, pp_loss: 7.386824
[INFO] 2021-07-12 19:09:46,236 [run_pretraining.py:  512]:	********exe.run_1865******* 
[INFO] 2021-07-12 19:09:47,146 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:47,147 [run_pretraining.py:  534]:	loss/total_loss, 7.266221046447754, 1866
[INFO] 2021-07-12 19:09:47,147 [run_pretraining.py:  535]:	loss/mlm_loss, 7.266221046447754, 1866
[INFO] 2021-07-12 19:09:47,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8650000129127875e-05, 1866
[INFO] 2021-07-12 19:09:47,147 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1866
[INFO] 2021-07-12 19:09:47,147 [run_pretraining.py:  558]:	worker_index: 7, step: 1866, cost: 7.266221, mlm loss: 7.266221, speed: 1.098480 steps/s, speed: 8.787840 samples/s, speed: 4499.373850 tokens/s, learning rate: 1.865e-05, loss_scalings: 5497.559082, pp_loss: 7.217695
[INFO] 2021-07-12 19:09:47,147 [run_pretraining.py:  512]:	********exe.run_1866******* 
[INFO] 2021-07-12 19:09:48,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:48,051 [run_pretraining.py:  534]:	loss/total_loss, 6.993197917938232, 1867
[INFO] 2021-07-12 19:09:48,051 [run_pretraining.py:  535]:	loss/mlm_loss, 6.993197917938232, 1867
[INFO] 2021-07-12 19:09:48,051 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8659999113879167e-05, 1867
[INFO] 2021-07-12 19:09:48,051 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1867
[INFO] 2021-07-12 19:09:48,051 [run_pretraining.py:  558]:	worker_index: 7, step: 1867, cost: 6.993198, mlm loss: 6.993198, speed: 1.107076 steps/s, speed: 8.856609 samples/s, speed: 4534.583772 tokens/s, learning rate: 1.866e-05, loss_scalings: 5497.559082, pp_loss: 7.202832
[INFO] 2021-07-12 19:09:48,051 [run_pretraining.py:  512]:	********exe.run_1867******* 
[INFO] 2021-07-12 19:09:48,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:48,965 [run_pretraining.py:  534]:	loss/total_loss, 7.643108367919922, 1868
[INFO] 2021-07-12 19:09:48,965 [run_pretraining.py:  535]:	loss/mlm_loss, 7.643108367919922, 1868
[INFO] 2021-07-12 19:09:48,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.866999991761986e-05, 1868
[INFO] 2021-07-12 19:09:48,965 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1868
[INFO] 2021-07-12 19:09:48,965 [run_pretraining.py:  558]:	worker_index: 7, step: 1868, cost: 7.643108, mlm loss: 7.643108, speed: 1.094835 steps/s, speed: 8.758680 samples/s, speed: 4484.444025 tokens/s, learning rate: 1.867e-05, loss_scalings: 5497.559082, pp_loss: 7.531082
[INFO] 2021-07-12 19:09:48,965 [run_pretraining.py:  512]:	********exe.run_1868******* 
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  534]:	loss/total_loss, 7.049856662750244, 1869
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  535]:	loss/mlm_loss, 7.049856662750244, 1869
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8680000721360557e-05, 1869
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1869
[INFO] 2021-07-12 19:09:49,871 [run_pretraining.py:  558]:	worker_index: 7, step: 1869, cost: 7.049857, mlm loss: 7.049857, speed: 1.103854 steps/s, speed: 8.830832 samples/s, speed: 4521.385866 tokens/s, learning rate: 1.868e-05, loss_scalings: 5497.559082, pp_loss: 6.888971
[INFO] 2021-07-12 19:09:49,872 [run_pretraining.py:  512]:	********exe.run_1869******* 
[INFO] 2021-07-12 19:09:50,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:50,783 [run_pretraining.py:  534]:	loss/total_loss, 7.512243270874023, 1870
[INFO] 2021-07-12 19:09:50,783 [run_pretraining.py:  535]:	loss/mlm_loss, 7.512243270874023, 1870
[INFO] 2021-07-12 19:09:50,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.868999970611185e-05, 1870
[INFO] 2021-07-12 19:09:50,783 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1870
[INFO] 2021-07-12 19:09:50,783 [run_pretraining.py:  558]:	worker_index: 7, step: 1870, cost: 7.512243, mlm loss: 7.512243, speed: 1.097320 steps/s, speed: 8.778558 samples/s, speed: 4494.621766 tokens/s, learning rate: 1.869e-05, loss_scalings: 5497.559082, pp_loss: 7.213901
[INFO] 2021-07-12 19:09:50,784 [run_pretraining.py:  512]:	********exe.run_1870******* 
[INFO] 2021-07-12 19:09:51,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:51,693 [run_pretraining.py:  534]:	loss/total_loss, 7.664776802062988, 1871
[INFO] 2021-07-12 19:09:51,693 [run_pretraining.py:  535]:	loss/mlm_loss, 7.664776802062988, 1871
[INFO] 2021-07-12 19:09:51,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8700000509852543e-05, 1871
[INFO] 2021-07-12 19:09:51,693 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1871
[INFO] 2021-07-12 19:09:51,694 [run_pretraining.py:  558]:	worker_index: 7, step: 1871, cost: 7.664777, mlm loss: 7.664777, speed: 1.099574 steps/s, speed: 8.796589 samples/s, speed: 4503.853783 tokens/s, learning rate: 1.870e-05, loss_scalings: 5497.559082, pp_loss: 6.882480
[INFO] 2021-07-12 19:09:51,694 [run_pretraining.py:  512]:	********exe.run_1871******* 
[INFO] 2021-07-12 19:09:52,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:52,597 [run_pretraining.py:  534]:	loss/total_loss, 7.594325542449951, 1872
[INFO] 2021-07-12 19:09:52,597 [run_pretraining.py:  535]:	loss/mlm_loss, 7.594325542449951, 1872
[INFO] 2021-07-12 19:09:52,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8709999494603835e-05, 1872
[INFO] 2021-07-12 19:09:52,598 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1872
[INFO] 2021-07-12 19:09:52,598 [run_pretraining.py:  558]:	worker_index: 7, step: 1872, cost: 7.594326, mlm loss: 7.594326, speed: 1.106894 steps/s, speed: 8.855155 samples/s, speed: 4533.839427 tokens/s, learning rate: 1.871e-05, loss_scalings: 5497.559082, pp_loss: 7.332407
[INFO] 2021-07-12 19:09:52,598 [run_pretraining.py:  512]:	********exe.run_1872******* 
[INFO] 2021-07-12 19:09:53,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:53,503 [run_pretraining.py:  534]:	loss/total_loss, 7.386081218719482, 1873
[INFO] 2021-07-12 19:09:53,503 [run_pretraining.py:  535]:	loss/mlm_loss, 7.386081218719482, 1873
[INFO] 2021-07-12 19:09:53,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8719998479355127e-05, 1873
[INFO] 2021-07-12 19:09:53,503 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1873
[INFO] 2021-07-12 19:09:53,503 [run_pretraining.py:  558]:	worker_index: 7, step: 1873, cost: 7.386081, mlm loss: 7.386081, speed: 1.105398 steps/s, speed: 8.843181 samples/s, speed: 4527.708491 tokens/s, learning rate: 1.872e-05, loss_scalings: 5497.559082, pp_loss: 7.373690
[INFO] 2021-07-12 19:09:53,503 [run_pretraining.py:  512]:	********exe.run_1873******* 
[INFO] 2021-07-12 19:09:54,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:54,407 [run_pretraining.py:  534]:	loss/total_loss, 7.657515525817871, 1874
[INFO] 2021-07-12 19:09:54,407 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657515525817871, 1874
[INFO] 2021-07-12 19:09:54,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8729999283095822e-05, 1874
[INFO] 2021-07-12 19:09:54,407 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1874
[INFO] 2021-07-12 19:09:54,407 [run_pretraining.py:  558]:	worker_index: 7, step: 1874, cost: 7.657516, mlm loss: 7.657516, speed: 1.107005 steps/s, speed: 8.856036 samples/s, speed: 4534.290552 tokens/s, learning rate: 1.873e-05, loss_scalings: 5497.559082, pp_loss: 7.551279
[INFO] 2021-07-12 19:09:54,407 [run_pretraining.py:  512]:	********exe.run_1874******* 
[INFO] 2021-07-12 19:09:55,310 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:55,310 [run_pretraining.py:  534]:	loss/total_loss, 7.506951808929443, 1875
[INFO] 2021-07-12 19:09:55,311 [run_pretraining.py:  535]:	loss/mlm_loss, 7.506951808929443, 1875
[INFO] 2021-07-12 19:09:55,311 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8740000086836517e-05, 1875
[INFO] 2021-07-12 19:09:55,311 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1875
[INFO] 2021-07-12 19:09:55,311 [run_pretraining.py:  558]:	worker_index: 7, step: 1875, cost: 7.506952, mlm loss: 7.506952, speed: 1.107072 steps/s, speed: 8.856574 samples/s, speed: 4534.565818 tokens/s, learning rate: 1.874e-05, loss_scalings: 5497.559082, pp_loss: 7.513338
[INFO] 2021-07-12 19:09:55,311 [run_pretraining.py:  512]:	********exe.run_1875******* 
[INFO] 2021-07-12 19:09:56,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:56,220 [run_pretraining.py:  534]:	loss/total_loss, 6.946828365325928, 1876
[INFO] 2021-07-12 19:09:56,220 [run_pretraining.py:  535]:	loss/mlm_loss, 6.946828365325928, 1876
[INFO] 2021-07-12 19:09:56,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.874999907158781e-05, 1876
[INFO] 2021-07-12 19:09:56,220 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1876
[INFO] 2021-07-12 19:09:56,220 [run_pretraining.py:  558]:	worker_index: 7, step: 1876, cost: 6.946828, mlm loss: 6.946828, speed: 1.100396 steps/s, speed: 8.803164 samples/s, speed: 4507.220182 tokens/s, learning rate: 1.875e-05, loss_scalings: 5497.559082, pp_loss: 7.435191
[INFO] 2021-07-12 19:09:56,220 [run_pretraining.py:  512]:	********exe.run_1876******* 
[INFO] 2021-07-12 19:09:57,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:57,158 [run_pretraining.py:  534]:	loss/total_loss, 7.691093444824219, 1877
[INFO] 2021-07-12 19:09:57,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.691093444824219, 1877
[INFO] 2021-07-12 19:09:57,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8759999875328504e-05, 1877
[INFO] 2021-07-12 19:09:57,158 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1877
[INFO] 2021-07-12 19:09:57,159 [run_pretraining.py:  558]:	worker_index: 7, step: 1877, cost: 7.691093, mlm loss: 7.691093, speed: 1.066518 steps/s, speed: 8.532142 samples/s, speed: 4368.456752 tokens/s, learning rate: 1.876e-05, loss_scalings: 5497.559082, pp_loss: 7.424446
[INFO] 2021-07-12 19:09:57,159 [run_pretraining.py:  512]:	********exe.run_1877******* 
[INFO] 2021-07-12 19:09:58,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:58,068 [run_pretraining.py:  534]:	loss/total_loss, 8.293916702270508, 1878
[INFO] 2021-07-12 19:09:58,068 [run_pretraining.py:  535]:	loss/mlm_loss, 8.293916702270508, 1878
[INFO] 2021-07-12 19:09:58,068 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.87700006790692e-05, 1878
[INFO] 2021-07-12 19:09:58,068 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1878
[INFO] 2021-07-12 19:09:58,069 [run_pretraining.py:  558]:	worker_index: 7, step: 1878, cost: 8.293917, mlm loss: 8.293917, speed: 1.099674 steps/s, speed: 8.797394 samples/s, speed: 4504.265893 tokens/s, learning rate: 1.877e-05, loss_scalings: 5497.559082, pp_loss: 7.391646
[INFO] 2021-07-12 19:09:58,069 [run_pretraining.py:  512]:	********exe.run_1878******* 
[INFO] 2021-07-12 19:09:58,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:58,973 [run_pretraining.py:  534]:	loss/total_loss, 7.808610439300537, 1879
[INFO] 2021-07-12 19:09:58,974 [run_pretraining.py:  535]:	loss/mlm_loss, 7.808610439300537, 1879
[INFO] 2021-07-12 19:09:58,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.877999966382049e-05, 1879
[INFO] 2021-07-12 19:09:58,974 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1879
[INFO] 2021-07-12 19:09:58,974 [run_pretraining.py:  558]:	worker_index: 7, step: 1879, cost: 7.808610, mlm loss: 7.808610, speed: 1.105461 steps/s, speed: 8.843684 samples/s, speed: 4527.966251 tokens/s, learning rate: 1.878e-05, loss_scalings: 5497.559082, pp_loss: 7.468684
[INFO] 2021-07-12 19:09:58,974 [run_pretraining.py:  512]:	********exe.run_1879******* 
[INFO] 2021-07-12 19:09:59,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:09:59,930 [run_pretraining.py:  534]:	loss/total_loss, 7.261992454528809, 1880
[INFO] 2021-07-12 19:09:59,930 [run_pretraining.py:  535]:	loss/mlm_loss, 7.261992454528809, 1880
[INFO] 2021-07-12 19:09:59,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8790000467561185e-05, 1880
[INFO] 2021-07-12 19:09:59,930 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1880
[INFO] 2021-07-12 19:09:59,930 [run_pretraining.py:  558]:	worker_index: 7, step: 1880, cost: 7.261992, mlm loss: 7.261992, speed: 1.046016 steps/s, speed: 8.368127 samples/s, speed: 4284.481029 tokens/s, learning rate: 1.879e-05, loss_scalings: 5497.559082, pp_loss: 7.776225
[INFO] 2021-07-12 19:09:59,930 [run_pretraining.py:  512]:	********exe.run_1880******* 
[INFO] 2021-07-12 19:10:00,986 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:00,986 [run_pretraining.py:  534]:	loss/total_loss, 7.284523010253906, 1881
[INFO] 2021-07-12 19:10:00,986 [run_pretraining.py:  535]:	loss/mlm_loss, 7.284523010253906, 1881
[INFO] 2021-07-12 19:10:00,987 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8799999452312477e-05, 1881
[INFO] 2021-07-12 19:10:00,987 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1881
[INFO] 2021-07-12 19:10:00,987 [run_pretraining.py:  558]:	worker_index: 7, step: 1881, cost: 7.284523, mlm loss: 7.284523, speed: 0.947301 steps/s, speed: 7.578410 samples/s, speed: 3880.145763 tokens/s, learning rate: 1.880e-05, loss_scalings: 5497.559082, pp_loss: 7.245872
[INFO] 2021-07-12 19:10:00,987 [run_pretraining.py:  512]:	********exe.run_1881******* 
[INFO] 2021-07-12 19:10:02,065 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:02,065 [run_pretraining.py:  534]:	loss/total_loss, 7.623147487640381, 1882
[INFO] 2021-07-12 19:10:02,066 [run_pretraining.py:  535]:	loss/mlm_loss, 7.623147487640381, 1882
[INFO] 2021-07-12 19:10:02,066 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.880999843706377e-05, 1882
[INFO] 2021-07-12 19:10:02,066 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1882
[INFO] 2021-07-12 19:10:02,066 [run_pretraining.py:  558]:	worker_index: 7, step: 1882, cost: 7.623147, mlm loss: 7.623147, speed: 0.927219 steps/s, speed: 7.417754 samples/s, speed: 3797.889963 tokens/s, learning rate: 1.881e-05, loss_scalings: 5497.559082, pp_loss: 7.508466
[INFO] 2021-07-12 19:10:02,066 [run_pretraining.py:  512]:	********exe.run_1882******* 
[INFO] 2021-07-12 19:10:03,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:03,117 [run_pretraining.py:  534]:	loss/total_loss, 7.251491069793701, 1883
[INFO] 2021-07-12 19:10:03,117 [run_pretraining.py:  535]:	loss/mlm_loss, 7.251491069793701, 1883
[INFO] 2021-07-12 19:10:03,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8819999240804464e-05, 1883
[INFO] 2021-07-12 19:10:03,117 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1883
[INFO] 2021-07-12 19:10:03,117 [run_pretraining.py:  558]:	worker_index: 7, step: 1883, cost: 7.251491, mlm loss: 7.251491, speed: 0.951785 steps/s, speed: 7.614280 samples/s, speed: 3898.511130 tokens/s, learning rate: 1.882e-05, loss_scalings: 5497.559082, pp_loss: 7.685816
[INFO] 2021-07-12 19:10:03,117 [run_pretraining.py:  512]:	********exe.run_1883******* 
[INFO] 2021-07-12 19:10:04,180 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:04,180 [run_pretraining.py:  534]:	loss/total_loss, 7.1422247886657715, 1884
[INFO] 2021-07-12 19:10:04,180 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1422247886657715, 1884
[INFO] 2021-07-12 19:10:04,180 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.883000004454516e-05, 1884
[INFO] 2021-07-12 19:10:04,180 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1884
[INFO] 2021-07-12 19:10:04,180 [run_pretraining.py:  558]:	worker_index: 7, step: 1884, cost: 7.142225, mlm loss: 7.142225, speed: 0.941067 steps/s, speed: 7.528533 samples/s, speed: 3854.609049 tokens/s, learning rate: 1.883e-05, loss_scalings: 5497.559082, pp_loss: 7.427185
[INFO] 2021-07-12 19:10:04,180 [run_pretraining.py:  512]:	********exe.run_1884******* 
[INFO] 2021-07-12 19:10:05,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:05,239 [run_pretraining.py:  534]:	loss/total_loss, 7.247125625610352, 1885
[INFO] 2021-07-12 19:10:05,239 [run_pretraining.py:  535]:	loss/mlm_loss, 7.247125625610352, 1885
[INFO] 2021-07-12 19:10:05,239 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.883999902929645e-05, 1885
[INFO] 2021-07-12 19:10:05,239 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1885
[INFO] 2021-07-12 19:10:05,239 [run_pretraining.py:  558]:	worker_index: 7, step: 1885, cost: 7.247126, mlm loss: 7.247126, speed: 0.944817 steps/s, speed: 7.558534 samples/s, speed: 3869.969212 tokens/s, learning rate: 1.884e-05, loss_scalings: 5497.559082, pp_loss: 7.368264
[INFO] 2021-07-12 19:10:05,240 [run_pretraining.py:  512]:	********exe.run_1885******* 
[INFO] 2021-07-12 19:10:06,443 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:06,444 [run_pretraining.py:  534]:	loss/total_loss, 6.764424800872803, 1886
[INFO] 2021-07-12 19:10:06,444 [run_pretraining.py:  535]:	loss/mlm_loss, 6.764424800872803, 1886
[INFO] 2021-07-12 19:10:06,444 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8849999833037145e-05, 1886
[INFO] 2021-07-12 19:10:06,444 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1886
[INFO] 2021-07-12 19:10:06,444 [run_pretraining.py:  558]:	worker_index: 7, step: 1886, cost: 6.764425, mlm loss: 6.764425, speed: 0.830557 steps/s, speed: 6.644453 samples/s, speed: 3401.959683 tokens/s, learning rate: 1.885e-05, loss_scalings: 5497.559082, pp_loss: 7.073466
[INFO] 2021-07-12 19:10:06,444 [run_pretraining.py:  512]:	********exe.run_1886******* 
[INFO] 2021-07-12 19:10:07,673 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:07,674 [run_pretraining.py:  534]:	loss/total_loss, 7.158144950866699, 1887
[INFO] 2021-07-12 19:10:07,674 [run_pretraining.py:  535]:	loss/mlm_loss, 7.158144950866699, 1887
[INFO] 2021-07-12 19:10:07,674 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.886000063677784e-05, 1887
[INFO] 2021-07-12 19:10:07,674 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1887
[INFO] 2021-07-12 19:10:07,674 [run_pretraining.py:  558]:	worker_index: 7, step: 1887, cost: 7.158145, mlm loss: 7.158145, speed: 0.813413 steps/s, speed: 6.507308 samples/s, speed: 3331.741633 tokens/s, learning rate: 1.886e-05, loss_scalings: 5497.559082, pp_loss: 7.216225
[INFO] 2021-07-12 19:10:07,674 [run_pretraining.py:  512]:	********exe.run_1887******* 
[INFO] 2021-07-12 19:10:08,946 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:08,947 [run_pretraining.py:  534]:	loss/total_loss, 7.014413356781006, 1888
[INFO] 2021-07-12 19:10:08,947 [run_pretraining.py:  535]:	loss/mlm_loss, 7.014413356781006, 1888
[INFO] 2021-07-12 19:10:08,947 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8869999621529132e-05, 1888
[INFO] 2021-07-12 19:10:08,947 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1888
[INFO] 2021-07-12 19:10:08,947 [run_pretraining.py:  558]:	worker_index: 7, step: 1888, cost: 7.014413, mlm loss: 7.014413, speed: 0.786077 steps/s, speed: 6.288618 samples/s, speed: 3219.772550 tokens/s, learning rate: 1.887e-05, loss_scalings: 5497.559082, pp_loss: 7.533233
[INFO] 2021-07-12 19:10:08,947 [run_pretraining.py:  512]:	********exe.run_1888******* 
[INFO] 2021-07-12 19:10:09,906 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:09,907 [run_pretraining.py:  534]:	loss/total_loss, 7.482888221740723, 1889
[INFO] 2021-07-12 19:10:09,907 [run_pretraining.py:  535]:	loss/mlm_loss, 7.482888221740723, 1889
[INFO] 2021-07-12 19:10:09,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8880000425269827e-05, 1889
[INFO] 2021-07-12 19:10:09,907 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1889
[INFO] 2021-07-12 19:10:09,907 [run_pretraining.py:  558]:	worker_index: 7, step: 1889, cost: 7.482888, mlm loss: 7.482888, speed: 1.041997 steps/s, speed: 8.335977 samples/s, speed: 4268.020084 tokens/s, learning rate: 1.888e-05, loss_scalings: 5497.559082, pp_loss: 7.357685
[INFO] 2021-07-12 19:10:09,907 [run_pretraining.py:  512]:	********exe.run_1889******* 
[INFO] 2021-07-12 19:10:10,812 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:10,812 [run_pretraining.py:  534]:	loss/total_loss, 4.492311000823975, 1890
[INFO] 2021-07-12 19:10:10,812 [run_pretraining.py:  535]:	loss/mlm_loss, 4.492311000823975, 1890
[INFO] 2021-07-12 19:10:10,812 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.888999941002112e-05, 1890
[INFO] 2021-07-12 19:10:10,812 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1890
[INFO] 2021-07-12 19:10:10,813 [run_pretraining.py:  558]:	worker_index: 7, step: 1890, cost: 4.492311, mlm loss: 4.492311, speed: 1.105583 steps/s, speed: 8.844665 samples/s, speed: 4528.468729 tokens/s, learning rate: 1.889e-05, loss_scalings: 5497.559082, pp_loss: 6.434999
[INFO] 2021-07-12 19:10:10,813 [run_pretraining.py:  512]:	********exe.run_1890******* 
[INFO] 2021-07-12 19:10:11,731 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:11,732 [run_pretraining.py:  534]:	loss/total_loss, 7.37971305847168, 1891
[INFO] 2021-07-12 19:10:11,732 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37971305847168, 1891
[INFO] 2021-07-12 19:10:11,732 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.889999839477241e-05, 1891
[INFO] 2021-07-12 19:10:11,732 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1891
[INFO] 2021-07-12 19:10:11,732 [run_pretraining.py:  558]:	worker_index: 7, step: 1891, cost: 7.379713, mlm loss: 7.379713, speed: 1.087916 steps/s, speed: 8.703325 samples/s, speed: 4456.102179 tokens/s, learning rate: 1.890e-05, loss_scalings: 5497.559082, pp_loss: 7.296451
[INFO] 2021-07-12 19:10:11,732 [run_pretraining.py:  512]:	********exe.run_1891******* 
[INFO] 2021-07-12 19:10:12,650 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:12,650 [run_pretraining.py:  534]:	loss/total_loss, 8.5453462600708, 1892
[INFO] 2021-07-12 19:10:12,650 [run_pretraining.py:  535]:	loss/mlm_loss, 8.5453462600708, 1892
[INFO] 2021-07-12 19:10:12,650 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8909999198513106e-05, 1892
[INFO] 2021-07-12 19:10:12,650 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1892
[INFO] 2021-07-12 19:10:12,651 [run_pretraining.py:  558]:	worker_index: 7, step: 1892, cost: 8.545346, mlm loss: 8.545346, speed: 1.089815 steps/s, speed: 8.718519 samples/s, speed: 4463.881695 tokens/s, learning rate: 1.891e-05, loss_scalings: 5497.559082, pp_loss: 7.679385
[INFO] 2021-07-12 19:10:12,651 [run_pretraining.py:  512]:	********exe.run_1892******* 
[INFO] 2021-07-12 19:10:13,564 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:13,564 [run_pretraining.py:  534]:	loss/total_loss, 7.559893608093262, 1893
[INFO] 2021-07-12 19:10:13,564 [run_pretraining.py:  535]:	loss/mlm_loss, 7.559893608093262, 1893
[INFO] 2021-07-12 19:10:13,564 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.89200000022538e-05, 1893
[INFO] 2021-07-12 19:10:13,564 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1893
[INFO] 2021-07-12 19:10:13,564 [run_pretraining.py:  558]:	worker_index: 7, step: 1893, cost: 7.559894, mlm loss: 7.559894, speed: 1.095087 steps/s, speed: 8.760697 samples/s, speed: 4485.476705 tokens/s, learning rate: 1.892e-05, loss_scalings: 5497.559082, pp_loss: 7.346336
[INFO] 2021-07-12 19:10:13,564 [run_pretraining.py:  512]:	********exe.run_1893******* 
[INFO] 2021-07-12 19:10:14,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:14,476 [run_pretraining.py:  534]:	loss/total_loss, 7.138810634613037, 1894
[INFO] 2021-07-12 19:10:14,477 [run_pretraining.py:  535]:	loss/mlm_loss, 7.138810634613037, 1894
[INFO] 2021-07-12 19:10:14,477 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8929998987005092e-05, 1894
[INFO] 2021-07-12 19:10:14,477 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1894
[INFO] 2021-07-12 19:10:14,477 [run_pretraining.py:  558]:	worker_index: 7, step: 1894, cost: 7.138811, mlm loss: 7.138811, speed: 1.096776 steps/s, speed: 8.774210 samples/s, speed: 4492.395734 tokens/s, learning rate: 1.893e-05, loss_scalings: 5497.559082, pp_loss: 7.183412
[INFO] 2021-07-12 19:10:14,477 [run_pretraining.py:  512]:	********exe.run_1894******* 
[INFO] 2021-07-12 19:10:15,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:15,388 [run_pretraining.py:  534]:	loss/total_loss, 7.341622352600098, 1895
[INFO] 2021-07-12 19:10:15,388 [run_pretraining.py:  535]:	loss/mlm_loss, 7.341622352600098, 1895
[INFO] 2021-07-12 19:10:15,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8939999790745787e-05, 1895
[INFO] 2021-07-12 19:10:15,389 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1895
[INFO] 2021-07-12 19:10:15,389 [run_pretraining.py:  558]:	worker_index: 7, step: 1895, cost: 7.341622, mlm loss: 7.341622, speed: 1.097412 steps/s, speed: 8.779293 samples/s, speed: 4494.998082 tokens/s, learning rate: 1.894e-05, loss_scalings: 5497.559082, pp_loss: 7.518361
[INFO] 2021-07-12 19:10:15,389 [run_pretraining.py:  512]:	********exe.run_1895******* 
[INFO] 2021-07-12 19:10:16,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:16,301 [run_pretraining.py:  534]:	loss/total_loss, 6.884134769439697, 1896
[INFO] 2021-07-12 19:10:16,301 [run_pretraining.py:  535]:	loss/mlm_loss, 6.884134769439697, 1896
[INFO] 2021-07-12 19:10:16,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8950000594486482e-05, 1896
[INFO] 2021-07-12 19:10:16,302 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1896
[INFO] 2021-07-12 19:10:16,302 [run_pretraining.py:  558]:	worker_index: 7, step: 1896, cost: 6.884135, mlm loss: 6.884135, speed: 1.096090 steps/s, speed: 8.768717 samples/s, speed: 4489.582856 tokens/s, learning rate: 1.895e-05, loss_scalings: 5497.559082, pp_loss: 7.392666
[INFO] 2021-07-12 19:10:16,302 [run_pretraining.py:  512]:	********exe.run_1896******* 
[INFO] 2021-07-12 19:10:17,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:17,209 [run_pretraining.py:  534]:	loss/total_loss, 7.204000949859619, 1897
[INFO] 2021-07-12 19:10:17,209 [run_pretraining.py:  535]:	loss/mlm_loss, 7.204000949859619, 1897
[INFO] 2021-07-12 19:10:17,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8959999579237774e-05, 1897
[INFO] 2021-07-12 19:10:17,209 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1897
[INFO] 2021-07-12 19:10:17,209 [run_pretraining.py:  558]:	worker_index: 7, step: 1897, cost: 7.204001, mlm loss: 7.204001, speed: 1.102611 steps/s, speed: 8.820889 samples/s, speed: 4516.295112 tokens/s, learning rate: 1.896e-05, loss_scalings: 5497.559082, pp_loss: 7.032028
[INFO] 2021-07-12 19:10:17,209 [run_pretraining.py:  512]:	********exe.run_1897******* 
[INFO] 2021-07-12 19:10:18,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:18,117 [run_pretraining.py:  534]:	loss/total_loss, 7.06890344619751, 1898
[INFO] 2021-07-12 19:10:18,117 [run_pretraining.py:  535]:	loss/mlm_loss, 7.06890344619751, 1898
[INFO] 2021-07-12 19:10:18,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.897000038297847e-05, 1898
[INFO] 2021-07-12 19:10:18,118 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1898
[INFO] 2021-07-12 19:10:18,118 [run_pretraining.py:  558]:	worker_index: 7, step: 1898, cost: 7.068903, mlm loss: 7.068903, speed: 1.101593 steps/s, speed: 8.812743 samples/s, speed: 4512.124571 tokens/s, learning rate: 1.897e-05, loss_scalings: 5497.559082, pp_loss: 7.065858
[INFO] 2021-07-12 19:10:18,118 [run_pretraining.py:  512]:	********exe.run_1898******* 
[INFO] 2021-07-12 19:10:19,044 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:19,044 [run_pretraining.py:  534]:	loss/total_loss, 7.117465019226074, 1899
[INFO] 2021-07-12 19:10:19,044 [run_pretraining.py:  535]:	loss/mlm_loss, 7.117465019226074, 1899
[INFO] 2021-07-12 19:10:19,045 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.897999936772976e-05, 1899
[INFO] 2021-07-12 19:10:19,045 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1899
[INFO] 2021-07-12 19:10:19,045 [run_pretraining.py:  558]:	worker_index: 7, step: 1899, cost: 7.117465, mlm loss: 7.117465, speed: 1.079519 steps/s, speed: 8.636148 samples/s, speed: 4421.707812 tokens/s, learning rate: 1.898e-05, loss_scalings: 5497.559082, pp_loss: 6.860848
[INFO] 2021-07-12 19:10:19,045 [run_pretraining.py:  512]:	********exe.run_1899******* 
[INFO] 2021-07-12 19:10:19,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:19,964 [run_pretraining.py:  534]:	loss/total_loss, 7.033097267150879, 1900
[INFO] 2021-07-12 19:10:19,964 [run_pretraining.py:  535]:	loss/mlm_loss, 7.033097267150879, 1900
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8989998352481052e-05, 1900
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1900
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  558]:	worker_index: 7, step: 1900, cost: 7.033097, mlm loss: 7.033097, speed: 1.087764 steps/s, speed: 8.702112 samples/s, speed: 4455.481590 tokens/s, learning rate: 1.899e-05, loss_scalings: 5497.559082, pp_loss: 7.136194
[INFO] 2021-07-12 19:10:19,965 [run_pretraining.py:  512]:	********exe.run_1900******* 
[INFO] 2021-07-12 19:10:20,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:20,887 [run_pretraining.py:  534]:	loss/total_loss, 6.844451427459717, 1901
[INFO] 2021-07-12 19:10:20,888 [run_pretraining.py:  535]:	loss/mlm_loss, 6.844451427459717, 1901
[INFO] 2021-07-12 19:10:20,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.8999999156221747e-05, 1901
[INFO] 2021-07-12 19:10:20,888 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1901
[INFO] 2021-07-12 19:10:20,888 [run_pretraining.py:  558]:	worker_index: 7, step: 1901, cost: 6.844451, mlm loss: 6.844451, speed: 1.084019 steps/s, speed: 8.672153 samples/s, speed: 4440.142185 tokens/s, learning rate: 1.900e-05, loss_scalings: 5497.559082, pp_loss: 6.246487
[INFO] 2021-07-12 19:10:20,888 [run_pretraining.py:  512]:	********exe.run_1901******* 
[INFO] 2021-07-12 19:10:21,813 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:21,813 [run_pretraining.py:  534]:	loss/total_loss, 7.729597091674805, 1902
[INFO] 2021-07-12 19:10:21,813 [run_pretraining.py:  535]:	loss/mlm_loss, 7.729597091674805, 1902
[INFO] 2021-07-12 19:10:21,813 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9009999959962443e-05, 1902
[INFO] 2021-07-12 19:10:21,813 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1902
[INFO] 2021-07-12 19:10:21,814 [run_pretraining.py:  558]:	worker_index: 7, step: 1902, cost: 7.729597, mlm loss: 7.729597, speed: 1.081019 steps/s, speed: 8.648154 samples/s, speed: 4427.854972 tokens/s, learning rate: 1.901e-05, loss_scalings: 5497.559082, pp_loss: 7.469319
[INFO] 2021-07-12 19:10:21,814 [run_pretraining.py:  512]:	********exe.run_1902******* 
[INFO] 2021-07-12 19:10:22,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:22,737 [run_pretraining.py:  534]:	loss/total_loss, 6.438838481903076, 1903
[INFO] 2021-07-12 19:10:22,737 [run_pretraining.py:  535]:	loss/mlm_loss, 6.438838481903076, 1903
[INFO] 2021-07-12 19:10:22,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9019998944713734e-05, 1903
[INFO] 2021-07-12 19:10:22,738 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1903
[INFO] 2021-07-12 19:10:22,738 [run_pretraining.py:  558]:	worker_index: 7, step: 1903, cost: 6.438838, mlm loss: 6.438838, speed: 1.082777 steps/s, speed: 8.662219 samples/s, speed: 4435.056311 tokens/s, learning rate: 1.902e-05, loss_scalings: 5497.559082, pp_loss: 7.127393
[INFO] 2021-07-12 19:10:22,738 [run_pretraining.py:  512]:	********exe.run_1903******* 
[INFO] 2021-07-12 19:10:23,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  534]:	loss/total_loss, 7.530582427978516, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  535]:	loss/mlm_loss, 7.530582427978516, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.902999974845443e-05, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1904
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  558]:	worker_index: 7, step: 1904, cost: 7.530582, mlm loss: 7.530582, speed: 1.073487 steps/s, speed: 8.587894 samples/s, speed: 4397.001924 tokens/s, learning rate: 1.903e-05, loss_scalings: 5497.559082, pp_loss: 7.144394
[INFO] 2021-07-12 19:10:23,670 [run_pretraining.py:  512]:	********exe.run_1904******* 
[INFO] 2021-07-12 19:10:24,592 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:24,592 [run_pretraining.py:  534]:	loss/total_loss, 6.061951160430908, 1905
[INFO] 2021-07-12 19:10:24,592 [run_pretraining.py:  535]:	loss/mlm_loss, 6.061951160430908, 1905
[INFO] 2021-07-12 19:10:24,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9040000552195124e-05, 1905
[INFO] 2021-07-12 19:10:24,592 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1905
[INFO] 2021-07-12 19:10:24,593 [run_pretraining.py:  558]:	worker_index: 7, step: 1905, cost: 6.061951, mlm loss: 6.061951, speed: 1.084639 steps/s, speed: 8.677109 samples/s, speed: 4442.679733 tokens/s, learning rate: 1.904e-05, loss_scalings: 5497.559082, pp_loss: 7.228209
[INFO] 2021-07-12 19:10:24,593 [run_pretraining.py:  512]:	********exe.run_1905******* 
[INFO] 2021-07-12 19:10:25,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:25,519 [run_pretraining.py:  534]:	loss/total_loss, 7.40477991104126, 1906
[INFO] 2021-07-12 19:10:25,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.40477991104126, 1906
[INFO] 2021-07-12 19:10:25,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9049999536946416e-05, 1906
[INFO] 2021-07-12 19:10:25,520 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1906
[INFO] 2021-07-12 19:10:25,520 [run_pretraining.py:  558]:	worker_index: 7, step: 1906, cost: 7.404780, mlm loss: 7.404780, speed: 1.079415 steps/s, speed: 8.635319 samples/s, speed: 4421.283362 tokens/s, learning rate: 1.905e-05, loss_scalings: 5497.559082, pp_loss: 7.419402
[INFO] 2021-07-12 19:10:25,520 [run_pretraining.py:  512]:	********exe.run_1906******* 
[INFO] 2021-07-12 19:10:26,438 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:26,439 [run_pretraining.py:  534]:	loss/total_loss, 6.795332431793213, 1907
[INFO] 2021-07-12 19:10:26,439 [run_pretraining.py:  535]:	loss/mlm_loss, 6.795332431793213, 1907
[INFO] 2021-07-12 19:10:26,439 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9059998521697707e-05, 1907
[INFO] 2021-07-12 19:10:26,439 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1907
[INFO] 2021-07-12 19:10:26,439 [run_pretraining.py:  558]:	worker_index: 7, step: 1907, cost: 6.795332, mlm loss: 6.795332, speed: 1.088669 steps/s, speed: 8.709352 samples/s, speed: 4459.188044 tokens/s, learning rate: 1.906e-05, loss_scalings: 5497.559082, pp_loss: 7.209422
[INFO] 2021-07-12 19:10:26,439 [run_pretraining.py:  512]:	********exe.run_1907******* 
[INFO] 2021-07-12 19:10:27,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:27,397 [run_pretraining.py:  534]:	loss/total_loss, 7.549104690551758, 1908
[INFO] 2021-07-12 19:10:27,397 [run_pretraining.py:  535]:	loss/mlm_loss, 7.549104690551758, 1908
[INFO] 2021-07-12 19:10:27,397 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9069999325438403e-05, 1908
[INFO] 2021-07-12 19:10:27,398 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1908
[INFO] 2021-07-12 19:10:27,398 [run_pretraining.py:  558]:	worker_index: 7, step: 1908, cost: 7.549105, mlm loss: 7.549105, speed: 1.043699 steps/s, speed: 8.349588 samples/s, speed: 4274.989203 tokens/s, learning rate: 1.907e-05, loss_scalings: 5497.559082, pp_loss: 7.404220
[INFO] 2021-07-12 19:10:27,398 [run_pretraining.py:  512]:	********exe.run_1908******* 
[INFO] 2021-07-12 19:10:28,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:28,313 [run_pretraining.py:  534]:	loss/total_loss, 6.761755466461182, 1909
[INFO] 2021-07-12 19:10:28,313 [run_pretraining.py:  535]:	loss/mlm_loss, 6.761755466461182, 1909
[INFO] 2021-07-12 19:10:28,313 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9079998310189694e-05, 1909
[INFO] 2021-07-12 19:10:28,313 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1909
[INFO] 2021-07-12 19:10:28,314 [run_pretraining.py:  558]:	worker_index: 7, step: 1909, cost: 6.761755, mlm loss: 6.761755, speed: 1.092582 steps/s, speed: 8.740653 samples/s, speed: 4475.214387 tokens/s, learning rate: 1.908e-05, loss_scalings: 5497.559082, pp_loss: 7.049932
[INFO] 2021-07-12 19:10:28,314 [run_pretraining.py:  512]:	********exe.run_1909******* 
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  534]:	loss/total_loss, 6.798855781555176, 1910
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  535]:	loss/mlm_loss, 6.798855781555176, 1910
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.908999911393039e-05, 1910
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1910
[INFO] 2021-07-12 19:10:29,242 [run_pretraining.py:  558]:	worker_index: 7, step: 1910, cost: 6.798856, mlm loss: 6.798856, speed: 1.077236 steps/s, speed: 8.617887 samples/s, speed: 4412.358083 tokens/s, learning rate: 1.909e-05, loss_scalings: 5497.559082, pp_loss: 7.422055
[INFO] 2021-07-12 19:10:29,243 [run_pretraining.py:  512]:	********exe.run_1910******* 
[INFO] 2021-07-12 19:10:30,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:30,175 [run_pretraining.py:  534]:	loss/total_loss, 7.2681097984313965, 1911
[INFO] 2021-07-12 19:10:30,175 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2681097984313965, 1911
[INFO] 2021-07-12 19:10:30,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9099999917671084e-05, 1911
[INFO] 2021-07-12 19:10:30,175 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1911
[INFO] 2021-07-12 19:10:30,175 [run_pretraining.py:  558]:	worker_index: 7, step: 1911, cost: 7.268110, mlm loss: 7.268110, speed: 1.072819 steps/s, speed: 8.582554 samples/s, speed: 4394.267863 tokens/s, learning rate: 1.910e-05, loss_scalings: 5497.559082, pp_loss: 7.372350
[INFO] 2021-07-12 19:10:30,175 [run_pretraining.py:  512]:	********exe.run_1911******* 
[INFO] 2021-07-12 19:10:31,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:31,097 [run_pretraining.py:  534]:	loss/total_loss, 7.307933807373047, 1912
[INFO] 2021-07-12 19:10:31,097 [run_pretraining.py:  535]:	loss/mlm_loss, 7.307933807373047, 1912
[INFO] 2021-07-12 19:10:31,097 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9109998902422376e-05, 1912
[INFO] 2021-07-12 19:10:31,097 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1912
[INFO] 2021-07-12 19:10:31,097 [run_pretraining.py:  558]:	worker_index: 7, step: 1912, cost: 7.307934, mlm loss: 7.307934, speed: 1.085121 steps/s, speed: 8.680968 samples/s, speed: 4444.655516 tokens/s, learning rate: 1.911e-05, loss_scalings: 5497.559082, pp_loss: 7.380804
[INFO] 2021-07-12 19:10:31,098 [run_pretraining.py:  512]:	********exe.run_1912******* 
[INFO] 2021-07-12 19:10:32,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:32,013 [run_pretraining.py:  534]:	loss/total_loss, 7.169289588928223, 1913
[INFO] 2021-07-12 19:10:32,013 [run_pretraining.py:  535]:	loss/mlm_loss, 7.169289588928223, 1913
[INFO] 2021-07-12 19:10:32,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.911999970616307e-05, 1913
[INFO] 2021-07-12 19:10:32,014 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1913
[INFO] 2021-07-12 19:10:32,014 [run_pretraining.py:  558]:	worker_index: 7, step: 1913, cost: 7.169290, mlm loss: 7.169290, speed: 1.092342 steps/s, speed: 8.738734 samples/s, speed: 4474.231870 tokens/s, learning rate: 1.912e-05, loss_scalings: 5497.559082, pp_loss: 7.259830
[INFO] 2021-07-12 19:10:32,014 [run_pretraining.py:  512]:	********exe.run_1913******* 
[INFO] 2021-07-12 19:10:32,960 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:32,961 [run_pretraining.py:  534]:	loss/total_loss, 8.594161987304688, 1914
[INFO] 2021-07-12 19:10:32,961 [run_pretraining.py:  535]:	loss/mlm_loss, 8.594161987304688, 1914
[INFO] 2021-07-12 19:10:32,961 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9130000509903766e-05, 1914
[INFO] 2021-07-12 19:10:32,961 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1914
[INFO] 2021-07-12 19:10:32,961 [run_pretraining.py:  558]:	worker_index: 7, step: 1914, cost: 8.594162, mlm loss: 8.594162, speed: 1.056377 steps/s, speed: 8.451015 samples/s, speed: 4326.919433 tokens/s, learning rate: 1.913e-05, loss_scalings: 5497.559082, pp_loss: 7.830769
[INFO] 2021-07-12 19:10:32,961 [run_pretraining.py:  512]:	********exe.run_1914******* 
[INFO] 2021-07-12 19:10:33,902 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:33,903 [run_pretraining.py:  534]:	loss/total_loss, 6.0005621910095215, 1915
[INFO] 2021-07-12 19:10:33,903 [run_pretraining.py:  535]:	loss/mlm_loss, 6.0005621910095215, 1915
[INFO] 2021-07-12 19:10:33,903 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9139999494655058e-05, 1915
[INFO] 2021-07-12 19:10:33,903 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1915
[INFO] 2021-07-12 19:10:33,903 [run_pretraining.py:  558]:	worker_index: 7, step: 1915, cost: 6.000562, mlm loss: 6.000562, speed: 1.062271 steps/s, speed: 8.498169 samples/s, speed: 4351.062279 tokens/s, learning rate: 1.914e-05, loss_scalings: 5497.559082, pp_loss: 6.766045
[INFO] 2021-07-12 19:10:33,903 [run_pretraining.py:  512]:	********exe.run_1915******* 
[INFO] 2021-07-12 19:10:34,833 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:34,833 [run_pretraining.py:  534]:	loss/total_loss, 8.315345764160156, 1916
[INFO] 2021-07-12 19:10:34,833 [run_pretraining.py:  535]:	loss/mlm_loss, 8.315345764160156, 1916
[INFO] 2021-07-12 19:10:34,833 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.914999847940635e-05, 1916
[INFO] 2021-07-12 19:10:34,834 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1916
[INFO] 2021-07-12 19:10:34,834 [run_pretraining.py:  558]:	worker_index: 7, step: 1916, cost: 8.315346, mlm loss: 8.315346, speed: 1.075131 steps/s, speed: 8.601052 samples/s, speed: 4403.738537 tokens/s, learning rate: 1.915e-05, loss_scalings: 5497.559082, pp_loss: 7.393671
[INFO] 2021-07-12 19:10:34,834 [run_pretraining.py:  512]:	********exe.run_1916******* 
[INFO] 2021-07-12 19:10:35,776 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:35,776 [run_pretraining.py:  534]:	loss/total_loss, 7.777053356170654, 1917
[INFO] 2021-07-12 19:10:35,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.777053356170654, 1917
[INFO] 2021-07-12 19:10:35,777 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9159999283147044e-05, 1917
[INFO] 2021-07-12 19:10:35,777 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1917
[INFO] 2021-07-12 19:10:35,777 [run_pretraining.py:  558]:	worker_index: 7, step: 1917, cost: 7.777053, mlm loss: 7.777053, speed: 1.061151 steps/s, speed: 8.489209 samples/s, speed: 4346.475200 tokens/s, learning rate: 1.916e-05, loss_scalings: 5497.559082, pp_loss: 7.188967
[INFO] 2021-07-12 19:10:35,777 [run_pretraining.py:  512]:	********exe.run_1917******* 
[INFO] 2021-07-12 19:10:36,706 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:36,706 [run_pretraining.py:  534]:	loss/total_loss, 7.567584037780762, 1918
[INFO] 2021-07-12 19:10:36,706 [run_pretraining.py:  535]:	loss/mlm_loss, 7.567584037780762, 1918
[INFO] 2021-07-12 19:10:36,706 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9169998267898336e-05, 1918
[INFO] 2021-07-12 19:10:36,707 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1918
[INFO] 2021-07-12 19:10:36,707 [run_pretraining.py:  558]:	worker_index: 7, step: 1918, cost: 7.567584, mlm loss: 7.567584, speed: 1.076121 steps/s, speed: 8.608970 samples/s, speed: 4407.792458 tokens/s, learning rate: 1.917e-05, loss_scalings: 5497.559082, pp_loss: 7.461619
[INFO] 2021-07-12 19:10:36,707 [run_pretraining.py:  512]:	********exe.run_1918******* 
[INFO] 2021-07-12 19:10:37,645 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:37,646 [run_pretraining.py:  534]:	loss/total_loss, 7.437951564788818, 1919
[INFO] 2021-07-12 19:10:37,646 [run_pretraining.py:  535]:	loss/mlm_loss, 7.437951564788818, 1919
[INFO] 2021-07-12 19:10:37,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.917999907163903e-05, 1919
[INFO] 2021-07-12 19:10:37,646 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1919
[INFO] 2021-07-12 19:10:37,646 [run_pretraining.py:  558]:	worker_index: 7, step: 1919, cost: 7.437952, mlm loss: 7.437952, speed: 1.065148 steps/s, speed: 8.521181 samples/s, speed: 4362.844430 tokens/s, learning rate: 1.918e-05, loss_scalings: 5497.559082, pp_loss: 7.189894
[INFO] 2021-07-12 19:10:37,646 [run_pretraining.py:  512]:	********exe.run_1919******* 
[INFO] 2021-07-12 19:10:38,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:38,591 [run_pretraining.py:  534]:	loss/total_loss, 7.169527053833008, 1920
[INFO] 2021-07-12 19:10:38,591 [run_pretraining.py:  535]:	loss/mlm_loss, 7.169527053833008, 1920
[INFO] 2021-07-12 19:10:38,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9189999875379726e-05, 1920
[INFO] 2021-07-12 19:10:38,591 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1920
[INFO] 2021-07-12 19:10:38,591 [run_pretraining.py:  558]:	worker_index: 7, step: 1920, cost: 7.169527, mlm loss: 7.169527, speed: 1.058504 steps/s, speed: 8.468032 samples/s, speed: 4335.632275 tokens/s, learning rate: 1.919e-05, loss_scalings: 5497.559082, pp_loss: 7.782500
[INFO] 2021-07-12 19:10:38,592 [run_pretraining.py:  512]:	********exe.run_1920******* 
[INFO] 2021-07-12 19:10:39,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:39,498 [run_pretraining.py:  534]:	loss/total_loss, 7.794500827789307, 1921
[INFO] 2021-07-12 19:10:39,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.794500827789307, 1921
[INFO] 2021-07-12 19:10:39,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9199998860131018e-05, 1921
[INFO] 2021-07-12 19:10:39,498 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1921
[INFO] 2021-07-12 19:10:39,498 [run_pretraining.py:  558]:	worker_index: 7, step: 1921, cost: 7.794501, mlm loss: 7.794501, speed: 1.103621 steps/s, speed: 8.828966 samples/s, speed: 4520.430550 tokens/s, learning rate: 1.920e-05, loss_scalings: 5497.559082, pp_loss: 7.550697
[INFO] 2021-07-12 19:10:39,498 [run_pretraining.py:  512]:	********exe.run_1921******* 
[INFO] 2021-07-12 19:10:40,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:40,408 [run_pretraining.py:  534]:	loss/total_loss, 5.533970355987549, 1922
[INFO] 2021-07-12 19:10:40,408 [run_pretraining.py:  535]:	loss/mlm_loss, 5.533970355987549, 1922
[INFO] 2021-07-12 19:10:40,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9209999663871713e-05, 1922
[INFO] 2021-07-12 19:10:40,408 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1922
[INFO] 2021-07-12 19:10:40,409 [run_pretraining.py:  558]:	worker_index: 7, step: 1922, cost: 5.533970, mlm loss: 5.533970, speed: 1.099351 steps/s, speed: 8.794805 samples/s, speed: 4502.940087 tokens/s, learning rate: 1.921e-05, loss_scalings: 5497.559082, pp_loss: 6.740337
[INFO] 2021-07-12 19:10:40,409 [run_pretraining.py:  512]:	********exe.run_1922******* 
[INFO] 2021-07-12 19:10:41,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:41,330 [run_pretraining.py:  534]:	loss/total_loss, 7.944729328155518, 1923
[INFO] 2021-07-12 19:10:41,330 [run_pretraining.py:  535]:	loss/mlm_loss, 7.944729328155518, 1923
[INFO] 2021-07-12 19:10:41,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9220000467612408e-05, 1923
[INFO] 2021-07-12 19:10:41,330 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1923
[INFO] 2021-07-12 19:10:41,330 [run_pretraining.py:  558]:	worker_index: 7, step: 1923, cost: 7.944729, mlm loss: 7.944729, speed: 1.085932 steps/s, speed: 8.687457 samples/s, speed: 4447.977730 tokens/s, learning rate: 1.922e-05, loss_scalings: 5497.559082, pp_loss: 7.596656
[INFO] 2021-07-12 19:10:41,330 [run_pretraining.py:  512]:	********exe.run_1923******* 
[INFO] 2021-07-12 19:10:42,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:42,239 [run_pretraining.py:  534]:	loss/total_loss, 6.870328903198242, 1924
[INFO] 2021-07-12 19:10:42,240 [run_pretraining.py:  535]:	loss/mlm_loss, 6.870328903198242, 1924
[INFO] 2021-07-12 19:10:42,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.92299994523637e-05, 1924
[INFO] 2021-07-12 19:10:42,240 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1924
[INFO] 2021-07-12 19:10:42,240 [run_pretraining.py:  558]:	worker_index: 7, step: 1924, cost: 6.870329, mlm loss: 6.870329, speed: 1.100054 steps/s, speed: 8.800431 samples/s, speed: 4505.820548 tokens/s, learning rate: 1.923e-05, loss_scalings: 5497.559082, pp_loss: 7.244149
[INFO] 2021-07-12 19:10:42,240 [run_pretraining.py:  512]:	********exe.run_1924******* 
[INFO] 2021-07-12 19:10:43,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:43,178 [run_pretraining.py:  534]:	loss/total_loss, 7.343820571899414, 1925
[INFO] 2021-07-12 19:10:43,178 [run_pretraining.py:  535]:	loss/mlm_loss, 7.343820571899414, 1925
[INFO] 2021-07-12 19:10:43,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.923999843711499e-05, 1925
[INFO] 2021-07-12 19:10:43,178 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1925
[INFO] 2021-07-12 19:10:43,178 [run_pretraining.py:  558]:	worker_index: 7, step: 1925, cost: 7.343821, mlm loss: 7.343821, speed: 1.066258 steps/s, speed: 8.530066 samples/s, speed: 4367.393974 tokens/s, learning rate: 1.924e-05, loss_scalings: 5497.559082, pp_loss: 7.621576
[INFO] 2021-07-12 19:10:43,178 [run_pretraining.py:  512]:	********exe.run_1925******* 
[INFO] 2021-07-12 19:10:44,117 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:44,117 [run_pretraining.py:  534]:	loss/total_loss, 7.288789749145508, 1926
[INFO] 2021-07-12 19:10:44,117 [run_pretraining.py:  535]:	loss/mlm_loss, 7.288789749145508, 1926
[INFO] 2021-07-12 19:10:44,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9249999240855686e-05, 1926
[INFO] 2021-07-12 19:10:44,117 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1926
[INFO] 2021-07-12 19:10:44,118 [run_pretraining.py:  558]:	worker_index: 7, step: 1926, cost: 7.288790, mlm loss: 7.288790, speed: 1.065358 steps/s, speed: 8.522864 samples/s, speed: 4363.706584 tokens/s, learning rate: 1.925e-05, loss_scalings: 5497.559082, pp_loss: 7.349831
[INFO] 2021-07-12 19:10:44,118 [run_pretraining.py:  512]:	********exe.run_1926******* 
[INFO] 2021-07-12 19:10:45,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:45,081 [run_pretraining.py:  534]:	loss/total_loss, 7.732624053955078, 1927
[INFO] 2021-07-12 19:10:45,081 [run_pretraining.py:  535]:	loss/mlm_loss, 7.732624053955078, 1927
[INFO] 2021-07-12 19:10:45,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.926000004459638e-05, 1927
[INFO] 2021-07-12 19:10:45,081 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1927
[INFO] 2021-07-12 19:10:45,081 [run_pretraining.py:  558]:	worker_index: 7, step: 1927, cost: 7.732624, mlm loss: 7.732624, speed: 1.038323 steps/s, speed: 8.306583 samples/s, speed: 4252.970278 tokens/s, learning rate: 1.926e-05, loss_scalings: 5497.559082, pp_loss: 7.189451
[INFO] 2021-07-12 19:10:45,081 [run_pretraining.py:  512]:	********exe.run_1927******* 
[INFO] 2021-07-12 19:10:46,066 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:46,066 [run_pretraining.py:  534]:	loss/total_loss, 7.017560958862305, 1928
[INFO] 2021-07-12 19:10:46,067 [run_pretraining.py:  535]:	loss/mlm_loss, 7.017560958862305, 1928
[INFO] 2021-07-12 19:10:46,067 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9269999029347673e-05, 1928
[INFO] 2021-07-12 19:10:46,067 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1928
[INFO] 2021-07-12 19:10:46,067 [run_pretraining.py:  558]:	worker_index: 7, step: 1928, cost: 7.017561, mlm loss: 7.017561, speed: 1.015426 steps/s, speed: 8.123405 samples/s, speed: 4159.183473 tokens/s, learning rate: 1.927e-05, loss_scalings: 5497.559082, pp_loss: 7.266143
[INFO] 2021-07-12 19:10:46,067 [run_pretraining.py:  512]:	********exe.run_1928******* 
[INFO] 2021-07-12 19:10:47,023 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:47,023 [run_pretraining.py:  534]:	loss/total_loss, 7.314522743225098, 1929
[INFO] 2021-07-12 19:10:47,024 [run_pretraining.py:  535]:	loss/mlm_loss, 7.314522743225098, 1929
[INFO] 2021-07-12 19:10:47,024 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9279999833088368e-05, 1929
[INFO] 2021-07-12 19:10:47,024 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1929
[INFO] 2021-07-12 19:10:47,024 [run_pretraining.py:  558]:	worker_index: 7, step: 1929, cost: 7.314523, mlm loss: 7.314523, speed: 1.045684 steps/s, speed: 8.365471 samples/s, speed: 4283.121253 tokens/s, learning rate: 1.928e-05, loss_scalings: 5497.559082, pp_loss: 6.779562
[INFO] 2021-07-12 19:10:47,024 [run_pretraining.py:  512]:	********exe.run_1929******* 
[INFO] 2021-07-12 19:10:47,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:47,991 [run_pretraining.py:  534]:	loss/total_loss, 6.671957492828369, 1930
[INFO] 2021-07-12 19:10:47,991 [run_pretraining.py:  535]:	loss/mlm_loss, 6.671957492828369, 1930
[INFO] 2021-07-12 19:10:47,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.928999881783966e-05, 1930
[INFO] 2021-07-12 19:10:47,992 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1930
[INFO] 2021-07-12 19:10:47,992 [run_pretraining.py:  558]:	worker_index: 7, step: 1930, cost: 6.671957, mlm loss: 6.671957, speed: 1.033953 steps/s, speed: 8.271627 samples/s, speed: 4235.072779 tokens/s, learning rate: 1.929e-05, loss_scalings: 5497.559082, pp_loss: 6.947404
[INFO] 2021-07-12 19:10:47,992 [run_pretraining.py:  512]:	********exe.run_1930******* 
[INFO] 2021-07-12 19:10:48,959 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:48,959 [run_pretraining.py:  534]:	loss/total_loss, 7.345922470092773, 1931
[INFO] 2021-07-12 19:10:48,960 [run_pretraining.py:  535]:	loss/mlm_loss, 7.345922470092773, 1931
[INFO] 2021-07-12 19:10:48,960 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9299999621580355e-05, 1931
[INFO] 2021-07-12 19:10:48,960 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1931
[INFO] 2021-07-12 19:10:48,960 [run_pretraining.py:  558]:	worker_index: 7, step: 1931, cost: 7.345922, mlm loss: 7.345922, speed: 1.033583 steps/s, speed: 8.268663 samples/s, speed: 4233.555342 tokens/s, learning rate: 1.930e-05, loss_scalings: 5497.559082, pp_loss: 7.304407
[INFO] 2021-07-12 19:10:48,960 [run_pretraining.py:  512]:	********exe.run_1931******* 
[INFO] 2021-07-12 19:10:49,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:49,926 [run_pretraining.py:  534]:	loss/total_loss, 8.11943531036377, 1932
[INFO] 2021-07-12 19:10:49,926 [run_pretraining.py:  535]:	loss/mlm_loss, 8.11943531036377, 1932
[INFO] 2021-07-12 19:10:49,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.931000042532105e-05, 1932
[INFO] 2021-07-12 19:10:49,927 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1932
[INFO] 2021-07-12 19:10:49,927 [run_pretraining.py:  558]:	worker_index: 7, step: 1932, cost: 8.119435, mlm loss: 8.119435, speed: 1.034873 steps/s, speed: 8.278988 samples/s, speed: 4238.841851 tokens/s, learning rate: 1.931e-05, loss_scalings: 5497.559082, pp_loss: 7.469395
[INFO] 2021-07-12 19:10:49,927 [run_pretraining.py:  512]:	********exe.run_1932******* 
[INFO] 2021-07-12 19:10:50,875 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:50,876 [run_pretraining.py:  534]:	loss/total_loss, 7.243893146514893, 1933
[INFO] 2021-07-12 19:10:50,876 [run_pretraining.py:  535]:	loss/mlm_loss, 7.243893146514893, 1933
[INFO] 2021-07-12 19:10:50,876 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.931999941007234e-05, 1933
[INFO] 2021-07-12 19:10:50,876 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1933
[INFO] 2021-07-12 19:10:50,876 [run_pretraining.py:  558]:	worker_index: 7, step: 1933, cost: 7.243893, mlm loss: 7.243893, speed: 1.054171 steps/s, speed: 8.433366 samples/s, speed: 4317.883383 tokens/s, learning rate: 1.932e-05, loss_scalings: 5497.559082, pp_loss: 7.382625
[INFO] 2021-07-12 19:10:50,876 [run_pretraining.py:  512]:	********exe.run_1933******* 
[INFO] 2021-07-12 19:10:51,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:51,824 [run_pretraining.py:  534]:	loss/total_loss, 7.854320049285889, 1934
[INFO] 2021-07-12 19:10:51,824 [run_pretraining.py:  535]:	loss/mlm_loss, 7.854320049285889, 1934
[INFO] 2021-07-12 19:10:51,824 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9329998394823633e-05, 1934
[INFO] 2021-07-12 19:10:51,824 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1934
[INFO] 2021-07-12 19:10:51,824 [run_pretraining.py:  558]:	worker_index: 7, step: 1934, cost: 7.854320, mlm loss: 7.854320, speed: 1.055011 steps/s, speed: 8.440090 samples/s, speed: 4321.326306 tokens/s, learning rate: 1.933e-05, loss_scalings: 5497.559082, pp_loss: 7.202526
[INFO] 2021-07-12 19:10:51,825 [run_pretraining.py:  512]:	********exe.run_1934******* 
[INFO] 2021-07-12 19:10:52,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:52,772 [run_pretraining.py:  534]:	loss/total_loss, 7.303508758544922, 1935
[INFO] 2021-07-12 19:10:52,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.303508758544922, 1935
[INFO] 2021-07-12 19:10:52,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9339999198564328e-05, 1935
[INFO] 2021-07-12 19:10:52,772 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1935
[INFO] 2021-07-12 19:10:52,772 [run_pretraining.py:  558]:	worker_index: 7, step: 1935, cost: 7.303509, mlm loss: 7.303509, speed: 1.055777 steps/s, speed: 8.446213 samples/s, speed: 4324.461203 tokens/s, learning rate: 1.934e-05, loss_scalings: 5497.559082, pp_loss: 7.296990
[INFO] 2021-07-12 19:10:52,772 [run_pretraining.py:  512]:	********exe.run_1935******* 
[INFO] 2021-07-12 19:10:53,713 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:53,713 [run_pretraining.py:  534]:	loss/total_loss, 7.420044898986816, 1936
[INFO] 2021-07-12 19:10:53,713 [run_pretraining.py:  535]:	loss/mlm_loss, 7.420044898986816, 1936
[INFO] 2021-07-12 19:10:53,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9350000002305023e-05, 1936
[INFO] 2021-07-12 19:10:53,714 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1936
[INFO] 2021-07-12 19:10:53,714 [run_pretraining.py:  558]:	worker_index: 7, step: 1936, cost: 7.420045, mlm loss: 7.420045, speed: 1.063076 steps/s, speed: 8.504604 samples/s, speed: 4354.357466 tokens/s, learning rate: 1.935e-05, loss_scalings: 5497.559082, pp_loss: 7.370313
[INFO] 2021-07-12 19:10:53,714 [run_pretraining.py:  512]:	********exe.run_1936******* 
[INFO] 2021-07-12 19:10:54,637 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:54,638 [run_pretraining.py:  534]:	loss/total_loss, 7.015831470489502, 1937
[INFO] 2021-07-12 19:10:54,638 [run_pretraining.py:  535]:	loss/mlm_loss, 7.015831470489502, 1937
[INFO] 2021-07-12 19:10:54,638 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9359998987056315e-05, 1937
[INFO] 2021-07-12 19:10:54,638 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1937
[INFO] 2021-07-12 19:10:54,638 [run_pretraining.py:  558]:	worker_index: 7, step: 1937, cost: 7.015831, mlm loss: 7.015831, speed: 1.082134 steps/s, speed: 8.657072 samples/s, speed: 4432.421107 tokens/s, learning rate: 1.936e-05, loss_scalings: 5497.559082, pp_loss: 7.309673
[INFO] 2021-07-12 19:10:54,638 [run_pretraining.py:  512]:	********exe.run_1937******* 
[INFO] 2021-07-12 19:10:55,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:55,563 [run_pretraining.py:  534]:	loss/total_loss, 6.930712699890137, 1938
[INFO] 2021-07-12 19:10:55,563 [run_pretraining.py:  535]:	loss/mlm_loss, 6.930712699890137, 1938
[INFO] 2021-07-12 19:10:55,563 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.936999979079701e-05, 1938
[INFO] 2021-07-12 19:10:55,563 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1938
[INFO] 2021-07-12 19:10:55,563 [run_pretraining.py:  558]:	worker_index: 7, step: 1938, cost: 6.930713, mlm loss: 6.930713, speed: 1.082398 steps/s, speed: 8.659184 samples/s, speed: 4433.502043 tokens/s, learning rate: 1.937e-05, loss_scalings: 5497.559082, pp_loss: 7.367667
[INFO] 2021-07-12 19:10:55,563 [run_pretraining.py:  512]:	********exe.run_1938******* 
[INFO] 2021-07-12 19:10:56,490 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:56,491 [run_pretraining.py:  534]:	loss/total_loss, 7.216973304748535, 1939
[INFO] 2021-07-12 19:10:56,491 [run_pretraining.py:  535]:	loss/mlm_loss, 7.216973304748535, 1939
[INFO] 2021-07-12 19:10:56,491 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9380000594537705e-05, 1939
[INFO] 2021-07-12 19:10:56,491 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1939
[INFO] 2021-07-12 19:10:56,491 [run_pretraining.py:  558]:	worker_index: 7, step: 1939, cost: 7.216973, mlm loss: 7.216973, speed: 1.078264 steps/s, speed: 8.626111 samples/s, speed: 4416.568682 tokens/s, learning rate: 1.938e-05, loss_scalings: 5497.559082, pp_loss: 7.116553
[INFO] 2021-07-12 19:10:56,491 [run_pretraining.py:  512]:	********exe.run_1939******* 
[INFO] 2021-07-12 19:10:57,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:57,431 [run_pretraining.py:  534]:	loss/total_loss, 7.49256706237793, 1940
[INFO] 2021-07-12 19:10:57,431 [run_pretraining.py:  535]:	loss/mlm_loss, 7.49256706237793, 1940
[INFO] 2021-07-12 19:10:57,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9389999579288997e-05, 1940
[INFO] 2021-07-12 19:10:57,431 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1940
[INFO] 2021-07-12 19:10:57,431 [run_pretraining.py:  558]:	worker_index: 7, step: 1940, cost: 7.492567, mlm loss: 7.492567, speed: 1.064216 steps/s, speed: 8.513728 samples/s, speed: 4359.028671 tokens/s, learning rate: 1.939e-05, loss_scalings: 5497.559082, pp_loss: 7.374046
[INFO] 2021-07-12 19:10:57,431 [run_pretraining.py:  512]:	********exe.run_1940******* 
[INFO] 2021-07-12 19:10:58,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:58,349 [run_pretraining.py:  534]:	loss/total_loss, 6.740387916564941, 1941
[INFO] 2021-07-12 19:10:58,349 [run_pretraining.py:  535]:	loss/mlm_loss, 6.740387916564941, 1941
[INFO] 2021-07-12 19:10:58,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9400000383029692e-05, 1941
[INFO] 2021-07-12 19:10:58,349 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1941
[INFO] 2021-07-12 19:10:58,349 [run_pretraining.py:  558]:	worker_index: 7, step: 1941, cost: 6.740388, mlm loss: 6.740388, speed: 1.089843 steps/s, speed: 8.718745 samples/s, speed: 4463.997684 tokens/s, learning rate: 1.940e-05, loss_scalings: 5497.559082, pp_loss: 7.508533
[INFO] 2021-07-12 19:10:58,350 [run_pretraining.py:  512]:	********exe.run_1941******* 
[INFO] 2021-07-12 19:10:59,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  534]:	loss/total_loss, 7.251397132873535, 1942
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  535]:	loss/mlm_loss, 7.251397132873535, 1942
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9409999367780983e-05, 1942
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1942
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  558]:	worker_index: 7, step: 1942, cost: 7.251397, mlm loss: 7.251397, speed: 1.071679 steps/s, speed: 8.573434 samples/s, speed: 4389.598255 tokens/s, learning rate: 1.941e-05, loss_scalings: 5497.559082, pp_loss: 7.573733
[INFO] 2021-07-12 19:10:59,283 [run_pretraining.py:  512]:	********exe.run_1942******* 
[INFO] 2021-07-12 19:11:00,205 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:00,206 [run_pretraining.py:  534]:	loss/total_loss, 7.2159423828125, 1943
[INFO] 2021-07-12 19:11:00,206 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2159423828125, 1943
[INFO] 2021-07-12 19:11:00,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9419998352532275e-05, 1943
[INFO] 2021-07-12 19:11:00,206 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1943
[INFO] 2021-07-12 19:11:00,206 [run_pretraining.py:  558]:	worker_index: 7, step: 1943, cost: 7.215942, mlm loss: 7.215942, speed: 1.084468 steps/s, speed: 8.675747 samples/s, speed: 4441.982480 tokens/s, learning rate: 1.942e-05, loss_scalings: 5497.559082, pp_loss: 7.091017
[INFO] 2021-07-12 19:11:00,206 [run_pretraining.py:  512]:	********exe.run_1943******* 
[INFO] 2021-07-12 19:11:01,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:01,130 [run_pretraining.py:  534]:	loss/total_loss, 6.908369064331055, 1944
[INFO] 2021-07-12 19:11:01,130 [run_pretraining.py:  535]:	loss/mlm_loss, 6.908369064331055, 1944
[INFO] 2021-07-12 19:11:01,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.942999915627297e-05, 1944
[INFO] 2021-07-12 19:11:01,130 [run_pretraining.py:  539]:	lr/loss_scaling, 5497.55908203125, 1944
[INFO] 2021-07-12 19:11:01,130 [run_pretraining.py:  558]:	worker_index: 7, step: 1944, cost: 6.908369, mlm loss: 6.908369, speed: 1.082525 steps/s, speed: 8.660196 samples/s, speed: 4434.020393 tokens/s, learning rate: 1.943e-05, loss_scalings: 5497.559082, pp_loss: 6.597159
[INFO] 2021-07-12 19:11:01,130 [run_pretraining.py:  512]:	********exe.run_1944******* 
[INFO] 2021-07-12 19:11:02,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:02,059 [run_pretraining.py:  534]:	loss/total_loss, 8.034008979797363, 1945
[INFO] 2021-07-12 19:11:02,059 [run_pretraining.py:  535]:	loss/mlm_loss, 8.034008979797363, 1945
[INFO] 2021-07-12 19:11:02,059 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9439999960013665e-05, 1945
[INFO] 2021-07-12 19:11:02,059 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1945
[INFO] 2021-07-12 19:11:02,059 [run_pretraining.py:  558]:	worker_index: 7, step: 1945, cost: 8.034009, mlm loss: 8.034009, speed: 1.077777 steps/s, speed: 8.622216 samples/s, speed: 4414.574679 tokens/s, learning rate: 1.944e-05, loss_scalings: 4398.047363, pp_loss: 7.273319
[INFO] 2021-07-12 19:11:02,059 [run_pretraining.py:  512]:	********exe.run_1945******* 
[INFO] 2021-07-12 19:11:02,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  534]:	loss/total_loss, 7.664048194885254, 1946
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  535]:	loss/mlm_loss, 7.664048194885254, 1946
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9449998944764957e-05, 1946
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1946
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  558]:	worker_index: 7, step: 1946, cost: 7.664048, mlm loss: 7.664048, speed: 1.071968 steps/s, speed: 8.575741 samples/s, speed: 4390.779595 tokens/s, learning rate: 1.945e-05, loss_scalings: 4398.047363, pp_loss: 7.498644
[INFO] 2021-07-12 19:11:02,992 [run_pretraining.py:  512]:	********exe.run_1946******* 
[INFO] 2021-07-12 19:11:29,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:29,612 [run_pretraining.py:  534]:	loss/total_loss, 7.4624786376953125, 1947
[INFO] 2021-07-12 19:11:29,612 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4624786376953125, 1947
[INFO] 2021-07-12 19:11:29,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9459999748505652e-05, 1947
[INFO] 2021-07-12 19:11:29,612 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1947
[INFO] 2021-07-12 19:11:29,612 [run_pretraining.py:  558]:	worker_index: 7, step: 1947, cost: 7.462479, mlm loss: 7.462479, speed: 0.037567 steps/s, speed: 0.300539 samples/s, speed: 153.876033 tokens/s, learning rate: 1.946e-05, loss_scalings: 4398.047363, pp_loss: 6.841046
[INFO] 2021-07-12 19:11:29,612 [run_pretraining.py:  512]:	********exe.run_1947******* 
[INFO] 2021-07-12 19:11:30,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:30,534 [run_pretraining.py:  534]:	loss/total_loss, 7.422443389892578, 1948
[INFO] 2021-07-12 19:11:30,534 [run_pretraining.py:  535]:	loss/mlm_loss, 7.422443389892578, 1948
[INFO] 2021-07-12 19:11:30,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9470000552246347e-05, 1948
[INFO] 2021-07-12 19:11:30,534 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1948
[INFO] 2021-07-12 19:11:30,534 [run_pretraining.py:  558]:	worker_index: 7, step: 1948, cost: 7.422443, mlm loss: 7.422443, speed: 1.085002 steps/s, speed: 8.680018 samples/s, speed: 4444.169165 tokens/s, learning rate: 1.947e-05, loss_scalings: 4398.047363, pp_loss: 7.580761
[INFO] 2021-07-12 19:11:30,534 [run_pretraining.py:  512]:	********exe.run_1948******* 
[INFO] 2021-07-12 19:11:31,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:31,458 [run_pretraining.py:  534]:	loss/total_loss, 7.707569122314453, 1949
[INFO] 2021-07-12 19:11:31,458 [run_pretraining.py:  535]:	loss/mlm_loss, 7.707569122314453, 1949
[INFO] 2021-07-12 19:11:31,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.947999953699764e-05, 1949
[INFO] 2021-07-12 19:11:31,458 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1949
[INFO] 2021-07-12 19:11:31,458 [run_pretraining.py:  558]:	worker_index: 7, step: 1949, cost: 7.707569, mlm loss: 7.707569, speed: 1.082744 steps/s, speed: 8.661949 samples/s, speed: 4434.917779 tokens/s, learning rate: 1.948e-05, loss_scalings: 4398.047363, pp_loss: 7.520680
[INFO] 2021-07-12 19:11:31,458 [run_pretraining.py:  512]:	********exe.run_1949******* 
[INFO] 2021-07-12 19:11:32,376 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:32,377 [run_pretraining.py:  534]:	loss/total_loss, 7.135775566101074, 1950
[INFO] 2021-07-12 19:11:32,377 [run_pretraining.py:  535]:	loss/mlm_loss, 7.135775566101074, 1950
[INFO] 2021-07-12 19:11:32,377 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9490000340738334e-05, 1950
[INFO] 2021-07-12 19:11:32,377 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1950
[INFO] 2021-07-12 19:11:32,377 [run_pretraining.py:  558]:	worker_index: 7, step: 1950, cost: 7.135776, mlm loss: 7.135776, speed: 1.089453 steps/s, speed: 8.715623 samples/s, speed: 4462.398727 tokens/s, learning rate: 1.949e-05, loss_scalings: 4398.047363, pp_loss: 7.232948
[INFO] 2021-07-12 19:11:32,377 [run_pretraining.py:  512]:	********exe.run_1950******* 
[INFO] 2021-07-12 19:11:33,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:33,301 [run_pretraining.py:  534]:	loss/total_loss, 7.815428256988525, 1951
[INFO] 2021-07-12 19:11:33,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.815428256988525, 1951
[INFO] 2021-07-12 19:11:33,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9499999325489625e-05, 1951
[INFO] 2021-07-12 19:11:33,301 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1951
[INFO] 2021-07-12 19:11:33,301 [run_pretraining.py:  558]:	worker_index: 7, step: 1951, cost: 7.815428, mlm loss: 7.815428, speed: 1.083127 steps/s, speed: 8.665013 samples/s, speed: 4436.486788 tokens/s, learning rate: 1.950e-05, loss_scalings: 4398.047363, pp_loss: 7.721753
[INFO] 2021-07-12 19:11:33,301 [run_pretraining.py:  512]:	********exe.run_1951******* 
[INFO] 2021-07-12 19:11:34,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:34,227 [run_pretraining.py:  534]:	loss/total_loss, 7.583553791046143, 1952
[INFO] 2021-07-12 19:11:34,227 [run_pretraining.py:  535]:	loss/mlm_loss, 7.583553791046143, 1952
[INFO] 2021-07-12 19:11:34,227 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9509998310240917e-05, 1952
[INFO] 2021-07-12 19:11:34,227 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1952
[INFO] 2021-07-12 19:11:34,227 [run_pretraining.py:  558]:	worker_index: 7, step: 1952, cost: 7.583554, mlm loss: 7.583554, speed: 1.080126 steps/s, speed: 8.641005 samples/s, speed: 4424.194705 tokens/s, learning rate: 1.951e-05, loss_scalings: 4398.047363, pp_loss: 7.298118
[INFO] 2021-07-12 19:11:34,227 [run_pretraining.py:  512]:	********exe.run_1952******* 
[INFO] 2021-07-12 19:11:35,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:35,157 [run_pretraining.py:  534]:	loss/total_loss, 6.88313102722168, 1953
[INFO] 2021-07-12 19:11:35,157 [run_pretraining.py:  535]:	loss/mlm_loss, 6.88313102722168, 1953
[INFO] 2021-07-12 19:11:35,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9519999113981612e-05, 1953
[INFO] 2021-07-12 19:11:35,157 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1953
[INFO] 2021-07-12 19:11:35,157 [run_pretraining.py:  558]:	worker_index: 7, step: 1953, cost: 6.883131, mlm loss: 6.883131, speed: 1.076619 steps/s, speed: 8.612949 samples/s, speed: 4409.830142 tokens/s, learning rate: 1.952e-05, loss_scalings: 4398.047363, pp_loss: 7.486017
[INFO] 2021-07-12 19:11:35,157 [run_pretraining.py:  512]:	********exe.run_1953******* 
[INFO] 2021-07-12 19:11:36,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:36,080 [run_pretraining.py:  534]:	loss/total_loss, 6.780246257781982, 1954
[INFO] 2021-07-12 19:11:36,080 [run_pretraining.py:  535]:	loss/mlm_loss, 6.780246257781982, 1954
[INFO] 2021-07-12 19:11:36,080 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9529999917722307e-05, 1954
[INFO] 2021-07-12 19:11:36,081 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1954
[INFO] 2021-07-12 19:11:36,081 [run_pretraining.py:  558]:	worker_index: 7, step: 1954, cost: 6.780246, mlm loss: 6.780246, speed: 1.083353 steps/s, speed: 8.666824 samples/s, speed: 4437.413827 tokens/s, learning rate: 1.953e-05, loss_scalings: 4398.047363, pp_loss: 7.009226
[INFO] 2021-07-12 19:11:36,081 [run_pretraining.py:  512]:	********exe.run_1954******* 
[INFO] 2021-07-12 19:11:37,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:37,028 [run_pretraining.py:  534]:	loss/total_loss, 7.08923864364624, 1955
[INFO] 2021-07-12 19:11:37,028 [run_pretraining.py:  535]:	loss/mlm_loss, 7.08923864364624, 1955
[INFO] 2021-07-12 19:11:37,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.95399989024736e-05, 1955
[INFO] 2021-07-12 19:11:37,028 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1955
[INFO] 2021-07-12 19:11:37,028 [run_pretraining.py:  558]:	worker_index: 7, step: 1955, cost: 7.089239, mlm loss: 7.089239, speed: 1.056310 steps/s, speed: 8.450478 samples/s, speed: 4326.644826 tokens/s, learning rate: 1.954e-05, loss_scalings: 4398.047363, pp_loss: 7.037962
[INFO] 2021-07-12 19:11:37,028 [run_pretraining.py:  512]:	********exe.run_1955******* 
[INFO] 2021-07-12 19:11:37,969 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:37,970 [run_pretraining.py:  534]:	loss/total_loss, 7.08449125289917, 1956
[INFO] 2021-07-12 19:11:37,970 [run_pretraining.py:  535]:	loss/mlm_loss, 7.08449125289917, 1956
[INFO] 2021-07-12 19:11:37,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9549999706214294e-05, 1956
[INFO] 2021-07-12 19:11:37,970 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1956
[INFO] 2021-07-12 19:11:37,970 [run_pretraining.py:  558]:	worker_index: 7, step: 1956, cost: 7.084491, mlm loss: 7.084491, speed: 1.061952 steps/s, speed: 8.495619 samples/s, speed: 4349.756833 tokens/s, learning rate: 1.955e-05, loss_scalings: 4398.047363, pp_loss: 6.601390
[INFO] 2021-07-12 19:11:37,970 [run_pretraining.py:  512]:	********exe.run_1956******* 
[INFO] 2021-07-12 19:11:38,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:38,900 [run_pretraining.py:  534]:	loss/total_loss, 7.134677410125732, 1957
[INFO] 2021-07-12 19:11:38,900 [run_pretraining.py:  535]:	loss/mlm_loss, 7.134677410125732, 1957
[INFO] 2021-07-12 19:11:38,900 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.956000050995499e-05, 1957
[INFO] 2021-07-12 19:11:38,900 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1957
[INFO] 2021-07-12 19:11:38,900 [run_pretraining.py:  558]:	worker_index: 7, step: 1957, cost: 7.134677, mlm loss: 7.134677, speed: 1.076297 steps/s, speed: 8.610379 samples/s, speed: 4408.514087 tokens/s, learning rate: 1.956e-05, loss_scalings: 4398.047363, pp_loss: 7.478977
[INFO] 2021-07-12 19:11:38,900 [run_pretraining.py:  512]:	********exe.run_1957******* 
[INFO] 2021-07-12 19:11:39,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:39,822 [run_pretraining.py:  534]:	loss/total_loss, 6.800258636474609, 1958
[INFO] 2021-07-12 19:11:39,822 [run_pretraining.py:  535]:	loss/mlm_loss, 6.800258636474609, 1958
[INFO] 2021-07-12 19:11:39,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.956999949470628e-05, 1958
[INFO] 2021-07-12 19:11:39,823 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1958
[INFO] 2021-07-12 19:11:39,823 [run_pretraining.py:  558]:	worker_index: 7, step: 1958, cost: 6.800259, mlm loss: 6.800259, speed: 1.084657 steps/s, speed: 8.677257 samples/s, speed: 4442.755560 tokens/s, learning rate: 1.957e-05, loss_scalings: 4398.047363, pp_loss: 6.520407
[INFO] 2021-07-12 19:11:39,823 [run_pretraining.py:  512]:	********exe.run_1958******* 
[INFO] 2021-07-12 19:11:40,743 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:40,744 [run_pretraining.py:  534]:	loss/total_loss, 7.278128147125244, 1959
[INFO] 2021-07-12 19:11:40,744 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278128147125244, 1959
[INFO] 2021-07-12 19:11:40,744 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9580000298446976e-05, 1959
[INFO] 2021-07-12 19:11:40,744 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1959
[INFO] 2021-07-12 19:11:40,744 [run_pretraining.py:  558]:	worker_index: 7, step: 1959, cost: 7.278128, mlm loss: 7.278128, speed: 1.085756 steps/s, speed: 8.686044 samples/s, speed: 4447.254637 tokens/s, learning rate: 1.958e-05, loss_scalings: 4398.047363, pp_loss: 7.318058
[INFO] 2021-07-12 19:11:40,744 [run_pretraining.py:  512]:	********exe.run_1959******* 
[INFO] 2021-07-12 19:11:41,672 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:41,672 [run_pretraining.py:  534]:	loss/total_loss, 6.89181661605835, 1960
[INFO] 2021-07-12 19:11:41,672 [run_pretraining.py:  535]:	loss/mlm_loss, 6.89181661605835, 1960
[INFO] 2021-07-12 19:11:41,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9589999283198267e-05, 1960
[INFO] 2021-07-12 19:11:41,672 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1960
[INFO] 2021-07-12 19:11:41,673 [run_pretraining.py:  558]:	worker_index: 7, step: 1960, cost: 6.891817, mlm loss: 6.891817, speed: 1.078008 steps/s, speed: 8.624064 samples/s, speed: 4415.520953 tokens/s, learning rate: 1.959e-05, loss_scalings: 4398.047363, pp_loss: 7.211155
[INFO] 2021-07-12 19:11:41,673 [run_pretraining.py:  512]:	********exe.run_1960******* 
[INFO] 2021-07-12 19:11:42,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  534]:	loss/total_loss, 6.7780632972717285, 1961
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7780632972717285, 1961
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.959999826794956e-05, 1961
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1961
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  558]:	worker_index: 7, step: 1961, cost: 6.778063, mlm loss: 6.778063, speed: 1.094365 steps/s, speed: 8.754920 samples/s, speed: 4482.519264 tokens/s, learning rate: 1.960e-05, loss_scalings: 4398.047363, pp_loss: 7.233325
[INFO] 2021-07-12 19:11:42,587 [run_pretraining.py:  512]:	********exe.run_1961******* 
[INFO] 2021-07-12 19:11:43,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:43,518 [run_pretraining.py:  534]:	loss/total_loss, 6.942038536071777, 1962
[INFO] 2021-07-12 19:11:43,518 [run_pretraining.py:  535]:	loss/mlm_loss, 6.942038536071777, 1962
[INFO] 2021-07-12 19:11:43,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9609999071690254e-05, 1962
[INFO] 2021-07-12 19:11:43,518 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1962
[INFO] 2021-07-12 19:11:43,518 [run_pretraining.py:  558]:	worker_index: 7, step: 1962, cost: 6.942039, mlm loss: 6.942039, speed: 1.074704 steps/s, speed: 8.597629 samples/s, speed: 4401.986183 tokens/s, learning rate: 1.961e-05, loss_scalings: 4398.047363, pp_loss: 7.139084
[INFO] 2021-07-12 19:11:43,518 [run_pretraining.py:  512]:	********exe.run_1962******* 
[INFO] 2021-07-12 19:11:44,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  534]:	loss/total_loss, 7.768086910247803, 1963
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  535]:	loss/mlm_loss, 7.768086910247803, 1963
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.961999987543095e-05, 1963
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1963
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  558]:	worker_index: 7, step: 1963, cost: 7.768087, mlm loss: 7.768087, speed: 1.079306 steps/s, speed: 8.634450 samples/s, speed: 4420.838515 tokens/s, learning rate: 1.962e-05, loss_scalings: 4398.047363, pp_loss: 7.418247
[INFO] 2021-07-12 19:11:44,445 [run_pretraining.py:  512]:	********exe.run_1963******* 
[INFO] 2021-07-12 19:11:45,366 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:45,367 [run_pretraining.py:  534]:	loss/total_loss, 7.414677143096924, 1964
[INFO] 2021-07-12 19:11:45,367 [run_pretraining.py:  535]:	loss/mlm_loss, 7.414677143096924, 1964
[INFO] 2021-07-12 19:11:45,367 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.962999886018224e-05, 1964
[INFO] 2021-07-12 19:11:45,367 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1964
[INFO] 2021-07-12 19:11:45,367 [run_pretraining.py:  558]:	worker_index: 7, step: 1964, cost: 7.414677, mlm loss: 7.414677, speed: 1.085881 steps/s, speed: 8.687052 samples/s, speed: 4447.770450 tokens/s, learning rate: 1.963e-05, loss_scalings: 4398.047363, pp_loss: 7.378730
[INFO] 2021-07-12 19:11:45,367 [run_pretraining.py:  512]:	********exe.run_1964******* 
[INFO] 2021-07-12 19:11:46,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:46,294 [run_pretraining.py:  534]:	loss/total_loss, 7.043027877807617, 1965
[INFO] 2021-07-12 19:11:46,294 [run_pretraining.py:  535]:	loss/mlm_loss, 7.043027877807617, 1965
[INFO] 2021-07-12 19:11:46,294 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9639999663922936e-05, 1965
[INFO] 2021-07-12 19:11:46,294 [run_pretraining.py:  539]:	lr/loss_scaling, 4398.04736328125, 1965
[INFO] 2021-07-12 19:11:46,294 [run_pretraining.py:  558]:	worker_index: 7, step: 1965, cost: 7.043028, mlm loss: 7.043028, speed: 1.078806 steps/s, speed: 8.630450 samples/s, speed: 4418.790648 tokens/s, learning rate: 1.964e-05, loss_scalings: 4398.047363, pp_loss: 7.294481
[INFO] 2021-07-12 19:11:46,295 [run_pretraining.py:  512]:	********exe.run_1965******* 
[INFO] 2021-07-12 19:11:47,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:47,236 [run_pretraining.py:  534]:	loss/total_loss, 6.985589981079102, 1966
[INFO] 2021-07-12 19:11:47,236 [run_pretraining.py:  535]:	loss/mlm_loss, 6.985589981079102, 1966
[INFO] 2021-07-12 19:11:47,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.965000046766363e-05, 1966
[INFO] 2021-07-12 19:11:47,236 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1966
[INFO] 2021-07-12 19:11:47,236 [run_pretraining.py:  558]:	worker_index: 7, step: 1966, cost: 6.985590, mlm loss: 6.985590, speed: 1.062484 steps/s, speed: 8.499869 samples/s, speed: 4351.933011 tokens/s, learning rate: 1.965e-05, loss_scalings: 3518.437988, pp_loss: 7.296134
[INFO] 2021-07-12 19:11:47,236 [run_pretraining.py:  512]:	********exe.run_1966******* 
[INFO] 2021-07-12 19:11:48,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:48,151 [run_pretraining.py:  534]:	loss/total_loss, 6.808062553405762, 1967
[INFO] 2021-07-12 19:11:48,151 [run_pretraining.py:  535]:	loss/mlm_loss, 6.808062553405762, 1967
[INFO] 2021-07-12 19:11:48,151 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9659999452414922e-05, 1967
[INFO] 2021-07-12 19:11:48,151 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1967
[INFO] 2021-07-12 19:11:48,151 [run_pretraining.py:  558]:	worker_index: 7, step: 1967, cost: 6.808063, mlm loss: 6.808063, speed: 1.093796 steps/s, speed: 8.750366 samples/s, speed: 4480.187195 tokens/s, learning rate: 1.966e-05, loss_scalings: 3518.437988, pp_loss: 7.024822
[INFO] 2021-07-12 19:11:48,151 [run_pretraining.py:  512]:	********exe.run_1967******* 
[INFO] 2021-07-12 19:11:49,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:49,081 [run_pretraining.py:  534]:	loss/total_loss, 6.969822883605957, 1968
[INFO] 2021-07-12 19:11:49,081 [run_pretraining.py:  535]:	loss/mlm_loss, 6.969822883605957, 1968
[INFO] 2021-07-12 19:11:49,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9670000256155618e-05, 1968
[INFO] 2021-07-12 19:11:49,081 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1968
[INFO] 2021-07-12 19:11:49,082 [run_pretraining.py:  558]:	worker_index: 7, step: 1968, cost: 6.969823, mlm loss: 6.969823, speed: 1.075647 steps/s, speed: 8.605172 samples/s, speed: 4405.848176 tokens/s, learning rate: 1.967e-05, loss_scalings: 3518.437988, pp_loss: 7.433457
[INFO] 2021-07-12 19:11:49,082 [run_pretraining.py:  512]:	********exe.run_1968******* 
[INFO] 2021-07-12 19:11:50,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:50,001 [run_pretraining.py:  534]:	loss/total_loss, 7.092489242553711, 1969
[INFO] 2021-07-12 19:11:50,001 [run_pretraining.py:  535]:	loss/mlm_loss, 7.092489242553711, 1969
[INFO] 2021-07-12 19:11:50,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.967999924090691e-05, 1969
[INFO] 2021-07-12 19:11:50,001 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1969
[INFO] 2021-07-12 19:11:50,001 [run_pretraining.py:  558]:	worker_index: 7, step: 1969, cost: 7.092489, mlm loss: 7.092489, speed: 1.088167 steps/s, speed: 8.705334 samples/s, speed: 4457.131097 tokens/s, learning rate: 1.968e-05, loss_scalings: 3518.437988, pp_loss: 7.255008
[INFO] 2021-07-12 19:11:50,001 [run_pretraining.py:  512]:	********exe.run_1969******* 
[INFO] 2021-07-12 19:11:50,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:50,926 [run_pretraining.py:  534]:	loss/total_loss, 7.3703508377075195, 1970
[INFO] 2021-07-12 19:11:50,926 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3703508377075195, 1970
[INFO] 2021-07-12 19:11:50,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.96899982256582e-05, 1970
[INFO] 2021-07-12 19:11:50,927 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1970
[INFO] 2021-07-12 19:11:50,927 [run_pretraining.py:  558]:	worker_index: 7, step: 1970, cost: 7.370351, mlm loss: 7.370351, speed: 1.081273 steps/s, speed: 8.650185 samples/s, speed: 4428.894862 tokens/s, learning rate: 1.969e-05, loss_scalings: 3518.437988, pp_loss: 7.135267
[INFO] 2021-07-12 19:11:50,927 [run_pretraining.py:  512]:	********exe.run_1970******* 
[INFO] 2021-07-12 19:11:51,855 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:51,856 [run_pretraining.py:  534]:	loss/total_loss, 7.892153739929199, 1971
[INFO] 2021-07-12 19:11:51,856 [run_pretraining.py:  535]:	loss/mlm_loss, 7.892153739929199, 1971
[INFO] 2021-07-12 19:11:51,856 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9699999029398896e-05, 1971
[INFO] 2021-07-12 19:11:51,856 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1971
[INFO] 2021-07-12 19:11:51,856 [run_pretraining.py:  558]:	worker_index: 7, step: 1971, cost: 7.892154, mlm loss: 7.892154, speed: 1.076479 steps/s, speed: 8.611835 samples/s, speed: 4409.259717 tokens/s, learning rate: 1.970e-05, loss_scalings: 3518.437988, pp_loss: 7.325112
[INFO] 2021-07-12 19:11:51,856 [run_pretraining.py:  512]:	********exe.run_1971******* 
[INFO] 2021-07-12 19:11:52,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:52,775 [run_pretraining.py:  534]:	loss/total_loss, 6.7052435874938965, 1972
[INFO] 2021-07-12 19:11:52,775 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7052435874938965, 1972
[INFO] 2021-07-12 19:11:52,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.970999983313959e-05, 1972
[INFO] 2021-07-12 19:11:52,775 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1972
[INFO] 2021-07-12 19:11:52,775 [run_pretraining.py:  558]:	worker_index: 7, step: 1972, cost: 6.705244, mlm loss: 6.705244, speed: 1.088856 steps/s, speed: 8.710848 samples/s, speed: 4459.954389 tokens/s, learning rate: 1.971e-05, loss_scalings: 3518.437988, pp_loss: 7.260139
[INFO] 2021-07-12 19:11:52,775 [run_pretraining.py:  512]:	********exe.run_1972******* 
[INFO] 2021-07-12 19:11:53,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:53,695 [run_pretraining.py:  534]:	loss/total_loss, 7.436274528503418, 1973
[INFO] 2021-07-12 19:11:53,695 [run_pretraining.py:  535]:	loss/mlm_loss, 7.436274528503418, 1973
[INFO] 2021-07-12 19:11:53,695 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9719998817890882e-05, 1973
[INFO] 2021-07-12 19:11:53,695 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1973
[INFO] 2021-07-12 19:11:53,695 [run_pretraining.py:  558]:	worker_index: 7, step: 1973, cost: 7.436275, mlm loss: 7.436275, speed: 1.087927 steps/s, speed: 8.703413 samples/s, speed: 4456.147256 tokens/s, learning rate: 1.972e-05, loss_scalings: 3518.437988, pp_loss: 6.354288
[INFO] 2021-07-12 19:11:53,695 [run_pretraining.py:  512]:	********exe.run_1973******* 
[INFO] 2021-07-12 19:11:54,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:54,618 [run_pretraining.py:  534]:	loss/total_loss, 7.848937034606934, 1974
[INFO] 2021-07-12 19:11:54,618 [run_pretraining.py:  535]:	loss/mlm_loss, 7.848937034606934, 1974
[INFO] 2021-07-12 19:11:54,618 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9729999621631578e-05, 1974
[INFO] 2021-07-12 19:11:54,618 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1974
[INFO] 2021-07-12 19:11:54,618 [run_pretraining.py:  558]:	worker_index: 7, step: 1974, cost: 7.848937, mlm loss: 7.848937, speed: 1.083944 steps/s, speed: 8.671552 samples/s, speed: 4439.834661 tokens/s, learning rate: 1.973e-05, loss_scalings: 3518.437988, pp_loss: 7.549207
[INFO] 2021-07-12 19:11:54,618 [run_pretraining.py:  512]:	********exe.run_1974******* 
[INFO] 2021-07-12 19:11:55,573 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:55,574 [run_pretraining.py:  534]:	loss/total_loss, 7.275724411010742, 1975
[INFO] 2021-07-12 19:11:55,574 [run_pretraining.py:  535]:	loss/mlm_loss, 7.275724411010742, 1975
[INFO] 2021-07-12 19:11:55,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9740000425372273e-05, 1975
[INFO] 2021-07-12 19:11:55,574 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1975
[INFO] 2021-07-12 19:11:55,574 [run_pretraining.py:  558]:	worker_index: 7, step: 1975, cost: 7.275724, mlm loss: 7.275724, speed: 1.047028 steps/s, speed: 8.376224 samples/s, speed: 4288.626562 tokens/s, learning rate: 1.974e-05, loss_scalings: 3518.437988, pp_loss: 7.325719
[INFO] 2021-07-12 19:11:55,574 [run_pretraining.py:  512]:	********exe.run_1975******* 
[INFO] 2021-07-12 19:11:56,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:56,504 [run_pretraining.py:  534]:	loss/total_loss, 9.416450500488281, 1976
[INFO] 2021-07-12 19:11:56,504 [run_pretraining.py:  535]:	loss/mlm_loss, 9.416450500488281, 1976
[INFO] 2021-07-12 19:11:56,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9749999410123564e-05, 1976
[INFO] 2021-07-12 19:11:56,505 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1976
[INFO] 2021-07-12 19:11:56,505 [run_pretraining.py:  558]:	worker_index: 7, step: 1976, cost: 9.416451, mlm loss: 9.416451, speed: 1.075295 steps/s, speed: 8.602362 samples/s, speed: 4404.409156 tokens/s, learning rate: 1.975e-05, loss_scalings: 3518.437988, pp_loss: 7.926525
[INFO] 2021-07-12 19:11:56,505 [run_pretraining.py:  512]:	********exe.run_1976******* 
[INFO] 2021-07-12 19:11:57,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:57,430 [run_pretraining.py:  534]:	loss/total_loss, 7.267327785491943, 1977
[INFO] 2021-07-12 19:11:57,430 [run_pretraining.py:  535]:	loss/mlm_loss, 7.267327785491943, 1977
[INFO] 2021-07-12 19:11:57,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.976000021386426e-05, 1977
[INFO] 2021-07-12 19:11:57,430 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1977
[INFO] 2021-07-12 19:11:57,430 [run_pretraining.py:  558]:	worker_index: 7, step: 1977, cost: 7.267328, mlm loss: 7.267328, speed: 1.081429 steps/s, speed: 8.651434 samples/s, speed: 4429.534334 tokens/s, learning rate: 1.976e-05, loss_scalings: 3518.437988, pp_loss: 6.978250
[INFO] 2021-07-12 19:11:57,430 [run_pretraining.py:  512]:	********exe.run_1977******* 
[INFO] 2021-07-12 19:11:58,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:58,351 [run_pretraining.py:  534]:	loss/total_loss, 4.038852214813232, 1978
[INFO] 2021-07-12 19:11:58,351 [run_pretraining.py:  535]:	loss/mlm_loss, 4.038852214813232, 1978
[INFO] 2021-07-12 19:11:58,351 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.976999919861555e-05, 1978
[INFO] 2021-07-12 19:11:58,351 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1978
[INFO] 2021-07-12 19:11:58,352 [run_pretraining.py:  558]:	worker_index: 7, step: 1978, cost: 4.038852, mlm loss: 4.038852, speed: 1.085987 steps/s, speed: 8.687895 samples/s, speed: 4448.202305 tokens/s, learning rate: 1.977e-05, loss_scalings: 3518.437988, pp_loss: 6.453506
[INFO] 2021-07-12 19:11:58,352 [run_pretraining.py:  512]:	********exe.run_1978******* 
[INFO] 2021-07-12 19:11:59,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:11:59,269 [run_pretraining.py:  534]:	loss/total_loss, 6.397833347320557, 1979
[INFO] 2021-07-12 19:11:59,269 [run_pretraining.py:  535]:	loss/mlm_loss, 6.397833347320557, 1979
[INFO] 2021-07-12 19:11:59,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9779998183366843e-05, 1979
[INFO] 2021-07-12 19:11:59,269 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1979
[INFO] 2021-07-12 19:11:59,269 [run_pretraining.py:  558]:	worker_index: 7, step: 1979, cost: 6.397833, mlm loss: 6.397833, speed: 1.090433 steps/s, speed: 8.723465 samples/s, speed: 4466.413945 tokens/s, learning rate: 1.978e-05, loss_scalings: 3518.437988, pp_loss: 7.446084
[INFO] 2021-07-12 19:11:59,269 [run_pretraining.py:  512]:	********exe.run_1979******* 
[INFO] 2021-07-12 19:12:00,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:00,189 [run_pretraining.py:  534]:	loss/total_loss, 7.455014705657959, 1980
[INFO] 2021-07-12 19:12:00,190 [run_pretraining.py:  535]:	loss/mlm_loss, 7.455014705657959, 1980
[INFO] 2021-07-12 19:12:00,190 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9789998987107538e-05, 1980
[INFO] 2021-07-12 19:12:00,190 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1980
[INFO] 2021-07-12 19:12:00,190 [run_pretraining.py:  558]:	worker_index: 7, step: 1980, cost: 7.455015, mlm loss: 7.455015, speed: 1.087027 steps/s, speed: 8.696215 samples/s, speed: 4452.462008 tokens/s, learning rate: 1.979e-05, loss_scalings: 3518.437988, pp_loss: 7.088871
[INFO] 2021-07-12 19:12:00,190 [run_pretraining.py:  512]:	********exe.run_1980******* 
[INFO] 2021-07-12 19:12:01,122 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:01,123 [run_pretraining.py:  534]:	loss/total_loss, 6.991921901702881, 1981
[INFO] 2021-07-12 19:12:01,123 [run_pretraining.py:  535]:	loss/mlm_loss, 6.991921901702881, 1981
[INFO] 2021-07-12 19:12:01,123 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9799999790848233e-05, 1981
[INFO] 2021-07-12 19:12:01,123 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1981
[INFO] 2021-07-12 19:12:01,123 [run_pretraining.py:  558]:	worker_index: 7, step: 1981, cost: 6.991922, mlm loss: 6.991922, speed: 1.072298 steps/s, speed: 8.578385 samples/s, speed: 4392.133364 tokens/s, learning rate: 1.980e-05, loss_scalings: 3518.437988, pp_loss: 7.138960
[INFO] 2021-07-12 19:12:01,123 [run_pretraining.py:  512]:	********exe.run_1981******* 
[INFO] 2021-07-12 19:12:02,047 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:02,047 [run_pretraining.py:  534]:	loss/total_loss, 7.124796390533447, 1982
[INFO] 2021-07-12 19:12:02,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.124796390533447, 1982
[INFO] 2021-07-12 19:12:02,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9809998775599524e-05, 1982
[INFO] 2021-07-12 19:12:02,047 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1982
[INFO] 2021-07-12 19:12:02,048 [run_pretraining.py:  558]:	worker_index: 7, step: 1982, cost: 7.124796, mlm loss: 7.124796, speed: 1.082369 steps/s, speed: 8.658949 samples/s, speed: 4433.381913 tokens/s, learning rate: 1.981e-05, loss_scalings: 3518.437988, pp_loss: 6.604614
[INFO] 2021-07-12 19:12:02,048 [run_pretraining.py:  512]:	********exe.run_1982******* 
[INFO] 2021-07-12 19:12:02,971 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:02,972 [run_pretraining.py:  534]:	loss/total_loss, 6.9507222175598145, 1983
[INFO] 2021-07-12 19:12:02,972 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9507222175598145, 1983
[INFO] 2021-07-12 19:12:02,972 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.981999957934022e-05, 1983
[INFO] 2021-07-12 19:12:02,972 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1983
[INFO] 2021-07-12 19:12:02,972 [run_pretraining.py:  558]:	worker_index: 7, step: 1983, cost: 6.950722, mlm loss: 6.950722, speed: 1.082415 steps/s, speed: 8.659322 samples/s, speed: 4433.572980 tokens/s, learning rate: 1.982e-05, loss_scalings: 3518.437988, pp_loss: 7.202239
[INFO] 2021-07-12 19:12:02,972 [run_pretraining.py:  512]:	********exe.run_1983******* 
[INFO] 2021-07-12 19:12:03,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:03,905 [run_pretraining.py:  534]:	loss/total_loss, 6.726998329162598, 1984
[INFO] 2021-07-12 19:12:03,906 [run_pretraining.py:  535]:	loss/mlm_loss, 6.726998329162598, 1984
[INFO] 2021-07-12 19:12:03,906 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9830000383080915e-05, 1984
[INFO] 2021-07-12 19:12:03,906 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1984
[INFO] 2021-07-12 19:12:03,906 [run_pretraining.py:  558]:	worker_index: 7, step: 1984, cost: 6.726998, mlm loss: 6.726998, speed: 1.071663 steps/s, speed: 8.573307 samples/s, speed: 4389.533205 tokens/s, learning rate: 1.983e-05, loss_scalings: 3518.437988, pp_loss: 6.936990
[INFO] 2021-07-12 19:12:03,906 [run_pretraining.py:  512]:	********exe.run_1984******* 
[INFO] 2021-07-12 19:12:04,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:04,832 [run_pretraining.py:  534]:	loss/total_loss, 6.868391036987305, 1985
[INFO] 2021-07-12 19:12:04,832 [run_pretraining.py:  535]:	loss/mlm_loss, 6.868391036987305, 1985
[INFO] 2021-07-12 19:12:04,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9839999367832206e-05, 1985
[INFO] 2021-07-12 19:12:04,832 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1985
[INFO] 2021-07-12 19:12:04,832 [run_pretraining.py:  558]:	worker_index: 7, step: 1985, cost: 6.868391, mlm loss: 6.868391, speed: 1.080254 steps/s, speed: 8.642036 samples/s, speed: 4424.722277 tokens/s, learning rate: 1.984e-05, loss_scalings: 3518.437988, pp_loss: 7.103933
[INFO] 2021-07-12 19:12:04,832 [run_pretraining.py:  512]:	********exe.run_1985******* 
[INFO] 2021-07-12 19:12:05,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:05,758 [run_pretraining.py:  534]:	loss/total_loss, 7.34718132019043, 1986
[INFO] 2021-07-12 19:12:05,758 [run_pretraining.py:  535]:	loss/mlm_loss, 7.34718132019043, 1986
[INFO] 2021-07-12 19:12:05,759 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.98500001715729e-05, 1986
[INFO] 2021-07-12 19:12:05,759 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1986
[INFO] 2021-07-12 19:12:05,759 [run_pretraining.py:  558]:	worker_index: 7, step: 1986, cost: 7.347181, mlm loss: 7.347181, speed: 1.080154 steps/s, speed: 8.641232 samples/s, speed: 4424.310920 tokens/s, learning rate: 1.985e-05, loss_scalings: 3518.437988, pp_loss: 7.170907
[INFO] 2021-07-12 19:12:05,759 [run_pretraining.py:  512]:	********exe.run_1986******* 
[INFO] 2021-07-12 19:12:06,698 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:06,699 [run_pretraining.py:  534]:	loss/total_loss, 6.805492877960205, 1987
[INFO] 2021-07-12 19:12:06,699 [run_pretraining.py:  535]:	loss/mlm_loss, 6.805492877960205, 1987
[INFO] 2021-07-12 19:12:06,699 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9859999156324193e-05, 1987
[INFO] 2021-07-12 19:12:06,699 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1987
[INFO] 2021-07-12 19:12:06,699 [run_pretraining.py:  558]:	worker_index: 7, step: 1987, cost: 6.805493, mlm loss: 6.805493, speed: 1.064150 steps/s, speed: 8.513201 samples/s, speed: 4358.758821 tokens/s, learning rate: 1.986e-05, loss_scalings: 3518.437988, pp_loss: 7.297637
[INFO] 2021-07-12 19:12:06,699 [run_pretraining.py:  512]:	********exe.run_1987******* 
[INFO] 2021-07-12 19:12:07,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:07,634 [run_pretraining.py:  534]:	loss/total_loss, 7.115113258361816, 1988
[INFO] 2021-07-12 19:12:07,634 [run_pretraining.py:  535]:	loss/mlm_loss, 7.115113258361816, 1988
[INFO] 2021-07-12 19:12:07,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9869999960064888e-05, 1988
[INFO] 2021-07-12 19:12:07,634 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1988
[INFO] 2021-07-12 19:12:07,634 [run_pretraining.py:  558]:	worker_index: 7, step: 1988, cost: 7.115113, mlm loss: 7.115113, speed: 1.069980 steps/s, speed: 8.559837 samples/s, speed: 4382.636460 tokens/s, learning rate: 1.987e-05, loss_scalings: 3518.437988, pp_loss: 7.183443
[INFO] 2021-07-12 19:12:07,634 [run_pretraining.py:  512]:	********exe.run_1988******* 
[INFO] 2021-07-12 19:12:08,560 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:08,560 [run_pretraining.py:  534]:	loss/total_loss, 7.704147815704346, 1989
[INFO] 2021-07-12 19:12:08,560 [run_pretraining.py:  535]:	loss/mlm_loss, 7.704147815704346, 1989
[INFO] 2021-07-12 19:12:08,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.987999894481618e-05, 1989
[INFO] 2021-07-12 19:12:08,560 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1989
[INFO] 2021-07-12 19:12:08,560 [run_pretraining.py:  558]:	worker_index: 7, step: 1989, cost: 7.704148, mlm loss: 7.704148, speed: 1.080399 steps/s, speed: 8.643191 samples/s, speed: 4425.313808 tokens/s, learning rate: 1.988e-05, loss_scalings: 3518.437988, pp_loss: 7.239436
[INFO] 2021-07-12 19:12:08,561 [run_pretraining.py:  512]:	********exe.run_1989******* 
[INFO] 2021-07-12 19:12:09,503 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:09,503 [run_pretraining.py:  534]:	loss/total_loss, 8.474781036376953, 1990
[INFO] 2021-07-12 19:12:09,503 [run_pretraining.py:  535]:	loss/mlm_loss, 8.474781036376953, 1990
[INFO] 2021-07-12 19:12:09,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9889999748556875e-05, 1990
[INFO] 2021-07-12 19:12:09,503 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1990
[INFO] 2021-07-12 19:12:09,503 [run_pretraining.py:  558]:	worker_index: 7, step: 1990, cost: 8.474781, mlm loss: 8.474781, speed: 1.061210 steps/s, speed: 8.489680 samples/s, speed: 4346.716037 tokens/s, learning rate: 1.989e-05, loss_scalings: 3518.437988, pp_loss: 7.581389
[INFO] 2021-07-12 19:12:09,504 [run_pretraining.py:  512]:	********exe.run_1990******* 
[INFO] 2021-07-12 19:12:10,450 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:10,451 [run_pretraining.py:  534]:	loss/total_loss, 7.780493259429932, 1991
[INFO] 2021-07-12 19:12:10,451 [run_pretraining.py:  535]:	loss/mlm_loss, 7.780493259429932, 1991
[INFO] 2021-07-12 19:12:10,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9899998733308166e-05, 1991
[INFO] 2021-07-12 19:12:10,451 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1991
[INFO] 2021-07-12 19:12:10,451 [run_pretraining.py:  558]:	worker_index: 7, step: 1991, cost: 7.780493, mlm loss: 7.780493, speed: 1.056278 steps/s, speed: 8.450225 samples/s, speed: 4326.515163 tokens/s, learning rate: 1.990e-05, loss_scalings: 3518.437988, pp_loss: 7.018821
[INFO] 2021-07-12 19:12:10,451 [run_pretraining.py:  512]:	********exe.run_1991******* 
[INFO] 2021-07-12 19:12:11,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:11,388 [run_pretraining.py:  534]:	loss/total_loss, 7.113138675689697, 1992
[INFO] 2021-07-12 19:12:11,388 [run_pretraining.py:  535]:	loss/mlm_loss, 7.113138675689697, 1992
[INFO] 2021-07-12 19:12:11,388 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.990999953704886e-05, 1992
[INFO] 2021-07-12 19:12:11,388 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1992
[INFO] 2021-07-12 19:12:11,388 [run_pretraining.py:  558]:	worker_index: 7, step: 1992, cost: 7.113139, mlm loss: 7.113139, speed: 1.067390 steps/s, speed: 8.539123 samples/s, speed: 4372.030899 tokens/s, learning rate: 1.991e-05, loss_scalings: 3518.437988, pp_loss: 7.292257
[INFO] 2021-07-12 19:12:11,388 [run_pretraining.py:  512]:	********exe.run_1992******* 
[INFO] 2021-07-12 19:12:12,324 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:12,325 [run_pretraining.py:  534]:	loss/total_loss, 7.41914701461792, 1993
[INFO] 2021-07-12 19:12:12,325 [run_pretraining.py:  535]:	loss/mlm_loss, 7.41914701461792, 1993
[INFO] 2021-07-12 19:12:12,325 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9920000340789557e-05, 1993
[INFO] 2021-07-12 19:12:12,325 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1993
[INFO] 2021-07-12 19:12:12,325 [run_pretraining.py:  558]:	worker_index: 7, step: 1993, cost: 7.419147, mlm loss: 7.419147, speed: 1.068082 steps/s, speed: 8.544653 samples/s, speed: 4374.862122 tokens/s, learning rate: 1.992e-05, loss_scalings: 3518.437988, pp_loss: 7.374719
[INFO] 2021-07-12 19:12:12,325 [run_pretraining.py:  512]:	********exe.run_1993******* 
[INFO] 2021-07-12 19:12:13,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:13,263 [run_pretraining.py:  534]:	loss/total_loss, 7.022768020629883, 1994
[INFO] 2021-07-12 19:12:13,263 [run_pretraining.py:  535]:	loss/mlm_loss, 7.022768020629883, 1994
[INFO] 2021-07-12 19:12:13,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9929999325540848e-05, 1994
[INFO] 2021-07-12 19:12:13,263 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1994
[INFO] 2021-07-12 19:12:13,263 [run_pretraining.py:  558]:	worker_index: 7, step: 1994, cost: 7.022768, mlm loss: 7.022768, speed: 1.066637 steps/s, speed: 8.533097 samples/s, speed: 4368.945559 tokens/s, learning rate: 1.993e-05, loss_scalings: 3518.437988, pp_loss: 7.171303
[INFO] 2021-07-12 19:12:13,264 [run_pretraining.py:  512]:	********exe.run_1994******* 
[INFO] 2021-07-12 19:12:14,212 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:14,213 [run_pretraining.py:  534]:	loss/total_loss, 7.20789909362793, 1995
[INFO] 2021-07-12 19:12:14,213 [run_pretraining.py:  535]:	loss/mlm_loss, 7.20789909362793, 1995
[INFO] 2021-07-12 19:12:14,213 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.993999831029214e-05, 1995
[INFO] 2021-07-12 19:12:14,213 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1995
[INFO] 2021-07-12 19:12:14,213 [run_pretraining.py:  558]:	worker_index: 7, step: 1995, cost: 7.207899, mlm loss: 7.207899, speed: 1.053768 steps/s, speed: 8.430145 samples/s, speed: 4316.234462 tokens/s, learning rate: 1.994e-05, loss_scalings: 3518.437988, pp_loss: 7.361151
[INFO] 2021-07-12 19:12:14,213 [run_pretraining.py:  512]:	********exe.run_1995******* 
[INFO] 2021-07-12 19:12:15,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:15,138 [run_pretraining.py:  534]:	loss/total_loss, 7.340542316436768, 1996
[INFO] 2021-07-12 19:12:15,138 [run_pretraining.py:  535]:	loss/mlm_loss, 7.340542316436768, 1996
[INFO] 2021-07-12 19:12:15,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9949999114032835e-05, 1996
[INFO] 2021-07-12 19:12:15,138 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1996
[INFO] 2021-07-12 19:12:15,138 [run_pretraining.py:  558]:	worker_index: 7, step: 1996, cost: 7.340542, mlm loss: 7.340542, speed: 1.082139 steps/s, speed: 8.657113 samples/s, speed: 4432.441691 tokens/s, learning rate: 1.995e-05, loss_scalings: 3518.437988, pp_loss: 7.422785
[INFO] 2021-07-12 19:12:15,138 [run_pretraining.py:  512]:	********exe.run_1996******* 
[INFO] 2021-07-12 19:12:16,046 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:16,047 [run_pretraining.py:  534]:	loss/total_loss, 7.396811485290527, 1997
[INFO] 2021-07-12 19:12:16,047 [run_pretraining.py:  535]:	loss/mlm_loss, 7.396811485290527, 1997
[INFO] 2021-07-12 19:12:16,047 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.995999991777353e-05, 1997
[INFO] 2021-07-12 19:12:16,047 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1997
[INFO] 2021-07-12 19:12:16,047 [run_pretraining.py:  558]:	worker_index: 7, step: 1997, cost: 7.396811, mlm loss: 7.396811, speed: 1.100496 steps/s, speed: 8.803966 samples/s, speed: 4507.630544 tokens/s, learning rate: 1.996e-05, loss_scalings: 3518.437988, pp_loss: 7.147123
[INFO] 2021-07-12 19:12:16,047 [run_pretraining.py:  512]:	********exe.run_1997******* 
[INFO] 2021-07-12 19:12:17,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:17,000 [run_pretraining.py:  534]:	loss/total_loss, 7.459466457366943, 1998
[INFO] 2021-07-12 19:12:17,000 [run_pretraining.py:  535]:	loss/mlm_loss, 7.459466457366943, 1998
[INFO] 2021-07-12 19:12:17,001 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.996999890252482e-05, 1998
[INFO] 2021-07-12 19:12:17,001 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1998
[INFO] 2021-07-12 19:12:17,001 [run_pretraining.py:  558]:	worker_index: 7, step: 1998, cost: 7.459466, mlm loss: 7.459466, speed: 1.049433 steps/s, speed: 8.395467 samples/s, speed: 4298.479153 tokens/s, learning rate: 1.997e-05, loss_scalings: 3518.437988, pp_loss: 7.257077
[INFO] 2021-07-12 19:12:17,001 [run_pretraining.py:  512]:	********exe.run_1998******* 
[INFO] 2021-07-12 19:12:17,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:17,915 [run_pretraining.py:  534]:	loss/total_loss, 6.847769260406494, 1999
[INFO] 2021-07-12 19:12:17,915 [run_pretraining.py:  535]:	loss/mlm_loss, 6.847769260406494, 1999
[INFO] 2021-07-12 19:12:17,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9979999706265517e-05, 1999
[INFO] 2021-07-12 19:12:17,916 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 1999
[INFO] 2021-07-12 19:12:17,916 [run_pretraining.py:  558]:	worker_index: 7, step: 1999, cost: 6.847769, mlm loss: 6.847769, speed: 1.093816 steps/s, speed: 8.750530 samples/s, speed: 4480.271318 tokens/s, learning rate: 1.998e-05, loss_scalings: 3518.437988, pp_loss: 7.172026
[INFO] 2021-07-12 19:12:17,916 [run_pretraining.py:  512]:	********exe.run_1999******* 
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  534]:	loss/total_loss, 7.604189395904541, 2000
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  535]:	loss/mlm_loss, 7.604189395904541, 2000
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9990000510006212e-05, 2000
[INFO] 2021-07-12 19:12:18,828 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2000
[INFO] 2021-07-12 19:12:18,829 [run_pretraining.py:  558]:	worker_index: 7, step: 2000, cost: 7.604189, mlm loss: 7.604189, speed: 1.096179 steps/s, speed: 8.769432 samples/s, speed: 4489.948941 tokens/s, learning rate: 1.999e-05, loss_scalings: 3518.437988, pp_loss: 7.657829
[INFO] 2021-07-12 19:12:18,829 [run_pretraining.py:  512]:	********exe.run_2000******* 
[INFO] 2021-07-12 19:12:19,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:19,737 [run_pretraining.py:  534]:	loss/total_loss, 8.111611366271973, 2001
[INFO] 2021-07-12 19:12:19,737 [run_pretraining.py:  535]:	loss/mlm_loss, 8.111611366271973, 2001
[INFO] 2021-07-12 19:12:19,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 1.9999999494757503e-05, 2001
[INFO] 2021-07-12 19:12:19,737 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2001
[INFO] 2021-07-12 19:12:19,737 [run_pretraining.py:  558]:	worker_index: 7, step: 2001, cost: 8.111611, mlm loss: 8.111611, speed: 1.101074 steps/s, speed: 8.808591 samples/s, speed: 4509.998381 tokens/s, learning rate: 2.000e-05, loss_scalings: 3518.437988, pp_loss: 7.647389
[INFO] 2021-07-12 19:12:19,737 [run_pretraining.py:  512]:	********exe.run_2001******* 
[INFO] 2021-07-12 19:12:20,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:20,653 [run_pretraining.py:  534]:	loss/total_loss, 7.318183898925781, 2002
[INFO] 2021-07-12 19:12:20,653 [run_pretraining.py:  535]:	loss/mlm_loss, 7.318183898925781, 2002
[INFO] 2021-07-12 19:12:20,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.00100002984982e-05, 2002
[INFO] 2021-07-12 19:12:20,653 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2002
[INFO] 2021-07-12 19:12:20,653 [run_pretraining.py:  558]:	worker_index: 7, step: 2002, cost: 7.318184, mlm loss: 7.318184, speed: 1.092758 steps/s, speed: 8.742063 samples/s, speed: 4475.936107 tokens/s, learning rate: 2.001e-05, loss_scalings: 3518.437988, pp_loss: 7.435937
[INFO] 2021-07-12 19:12:20,653 [run_pretraining.py:  512]:	********exe.run_2002******* 
[INFO] 2021-07-12 19:12:21,569 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:21,569 [run_pretraining.py:  534]:	loss/total_loss, 7.484864234924316, 2003
[INFO] 2021-07-12 19:12:21,569 [run_pretraining.py:  535]:	loss/mlm_loss, 7.484864234924316, 2003
[INFO] 2021-07-12 19:12:21,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.001999928324949e-05, 2003
[INFO] 2021-07-12 19:12:21,569 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2003
[INFO] 2021-07-12 19:12:21,569 [run_pretraining.py:  558]:	worker_index: 7, step: 2003, cost: 7.484864, mlm loss: 7.484864, speed: 1.092162 steps/s, speed: 8.737296 samples/s, speed: 4473.495557 tokens/s, learning rate: 2.002e-05, loss_scalings: 3518.437988, pp_loss: 6.908188
[INFO] 2021-07-12 19:12:21,569 [run_pretraining.py:  512]:	********exe.run_2003******* 
[INFO] 2021-07-12 19:12:22,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:22,485 [run_pretraining.py:  534]:	loss/total_loss, 6.597710132598877, 2004
[INFO] 2021-07-12 19:12:22,485 [run_pretraining.py:  535]:	loss/mlm_loss, 6.597710132598877, 2004
[INFO] 2021-07-12 19:12:22,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.002999826800078e-05, 2004
[INFO] 2021-07-12 19:12:22,485 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2004
[INFO] 2021-07-12 19:12:22,485 [run_pretraining.py:  558]:	worker_index: 7, step: 2004, cost: 6.597710, mlm loss: 6.597710, speed: 1.093158 steps/s, speed: 8.745266 samples/s, speed: 4477.576290 tokens/s, learning rate: 2.003e-05, loss_scalings: 3518.437988, pp_loss: 7.149257
[INFO] 2021-07-12 19:12:22,485 [run_pretraining.py:  512]:	********exe.run_2004******* 
[INFO] 2021-07-12 19:12:23,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:23,403 [run_pretraining.py:  534]:	loss/total_loss, 4.464284420013428, 2005
[INFO] 2021-07-12 19:12:23,403 [run_pretraining.py:  535]:	loss/mlm_loss, 4.464284420013428, 2005
[INFO] 2021-07-12 19:12:23,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0039999071741477e-05, 2005
[INFO] 2021-07-12 19:12:23,403 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2005
[INFO] 2021-07-12 19:12:23,403 [run_pretraining.py:  558]:	worker_index: 7, step: 2005, cost: 4.464284, mlm loss: 4.464284, speed: 1.089644 steps/s, speed: 8.717153 samples/s, speed: 4463.182409 tokens/s, learning rate: 2.004e-05, loss_scalings: 3518.437988, pp_loss: 6.433753
[INFO] 2021-07-12 19:12:23,403 [run_pretraining.py:  512]:	********exe.run_2005******* 
[INFO] 2021-07-12 19:12:24,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:24,321 [run_pretraining.py:  534]:	loss/total_loss, 7.755512237548828, 2006
[INFO] 2021-07-12 19:12:24,321 [run_pretraining.py:  535]:	loss/mlm_loss, 7.755512237548828, 2006
[INFO] 2021-07-12 19:12:24,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0049999875482172e-05, 2006
[INFO] 2021-07-12 19:12:24,321 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2006
[INFO] 2021-07-12 19:12:24,321 [run_pretraining.py:  558]:	worker_index: 7, step: 2006, cost: 7.755512, mlm loss: 7.755512, speed: 1.090234 steps/s, speed: 8.721875 samples/s, speed: 4465.600109 tokens/s, learning rate: 2.005e-05, loss_scalings: 3518.437988, pp_loss: 7.393687
[INFO] 2021-07-12 19:12:24,321 [run_pretraining.py:  512]:	********exe.run_2006******* 
[INFO] 2021-07-12 19:12:25,235 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:25,236 [run_pretraining.py:  534]:	loss/total_loss, 7.133015155792236, 2007
[INFO] 2021-07-12 19:12:25,236 [run_pretraining.py:  535]:	loss/mlm_loss, 7.133015155792236, 2007
[INFO] 2021-07-12 19:12:25,236 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0059998860233463e-05, 2007
[INFO] 2021-07-12 19:12:25,236 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2007
[INFO] 2021-07-12 19:12:25,236 [run_pretraining.py:  558]:	worker_index: 7, step: 2007, cost: 7.133015, mlm loss: 7.133015, speed: 1.094000 steps/s, speed: 8.752000 samples/s, speed: 4481.023889 tokens/s, learning rate: 2.006e-05, loss_scalings: 3518.437988, pp_loss: 7.120309
[INFO] 2021-07-12 19:12:25,236 [run_pretraining.py:  512]:	********exe.run_2007******* 
[INFO] 2021-07-12 19:12:26,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:26,162 [run_pretraining.py:  534]:	loss/total_loss, 6.881400108337402, 2008
[INFO] 2021-07-12 19:12:26,163 [run_pretraining.py:  535]:	loss/mlm_loss, 6.881400108337402, 2008
[INFO] 2021-07-12 19:12:26,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.006999966397416e-05, 2008
[INFO] 2021-07-12 19:12:26,163 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2008
[INFO] 2021-07-12 19:12:26,163 [run_pretraining.py:  558]:	worker_index: 7, step: 2008, cost: 6.881400, mlm loss: 6.881400, speed: 1.079550 steps/s, speed: 8.636401 samples/s, speed: 4421.837554 tokens/s, learning rate: 2.007e-05, loss_scalings: 3518.437988, pp_loss: 7.357797
[INFO] 2021-07-12 19:12:26,163 [run_pretraining.py:  512]:	********exe.run_2008******* 
[INFO] 2021-07-12 19:12:27,098 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:27,098 [run_pretraining.py:  534]:	loss/total_loss, 7.363335132598877, 2009
[INFO] 2021-07-12 19:12:27,098 [run_pretraining.py:  535]:	loss/mlm_loss, 7.363335132598877, 2009
[INFO] 2021-07-12 19:12:27,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0080000467714854e-05, 2009
[INFO] 2021-07-12 19:12:27,099 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2009
[INFO] 2021-07-12 19:12:27,099 [run_pretraining.py:  558]:	worker_index: 7, step: 2009, cost: 7.363335, mlm loss: 7.363335, speed: 1.069309 steps/s, speed: 8.554475 samples/s, speed: 4379.891196 tokens/s, learning rate: 2.008e-05, loss_scalings: 3518.437988, pp_loss: 7.364791
[INFO] 2021-07-12 19:12:27,099 [run_pretraining.py:  512]:	********exe.run_2009******* 
[INFO] 2021-07-12 19:12:28,037 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:28,038 [run_pretraining.py:  534]:	loss/total_loss, 7.1149678230285645, 2010
[INFO] 2021-07-12 19:12:28,038 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1149678230285645, 2010
[INFO] 2021-07-12 19:12:28,038 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0089999452466145e-05, 2010
[INFO] 2021-07-12 19:12:28,038 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2010
[INFO] 2021-07-12 19:12:28,038 [run_pretraining.py:  558]:	worker_index: 7, step: 2010, cost: 7.114968, mlm loss: 7.114968, speed: 1.065108 steps/s, speed: 8.520865 samples/s, speed: 4362.682675 tokens/s, learning rate: 2.009e-05, loss_scalings: 3518.437988, pp_loss: 7.146976
[INFO] 2021-07-12 19:12:28,038 [run_pretraining.py:  512]:	********exe.run_2010******* 
[INFO] 2021-07-12 19:12:29,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:29,025 [run_pretraining.py:  534]:	loss/total_loss, 8.090169906616211, 2011
[INFO] 2021-07-12 19:12:29,026 [run_pretraining.py:  535]:	loss/mlm_loss, 8.090169906616211, 2011
[INFO] 2021-07-12 19:12:29,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.010000025620684e-05, 2011
[INFO] 2021-07-12 19:12:29,026 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2011
[INFO] 2021-07-12 19:12:29,026 [run_pretraining.py:  558]:	worker_index: 7, step: 2011, cost: 8.090170, mlm loss: 8.090170, speed: 1.013233 steps/s, speed: 8.105867 samples/s, speed: 4150.204029 tokens/s, learning rate: 2.010e-05, loss_scalings: 3518.437988, pp_loss: 7.355475
[INFO] 2021-07-12 19:12:29,026 [run_pretraining.py:  512]:	********exe.run_2011******* 
[INFO] 2021-07-12 19:12:29,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:29,973 [run_pretraining.py:  534]:	loss/total_loss, 7.015811443328857, 2012
[INFO] 2021-07-12 19:12:29,973 [run_pretraining.py:  535]:	loss/mlm_loss, 7.015811443328857, 2012
[INFO] 2021-07-12 19:12:29,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0110001059947535e-05, 2012
[INFO] 2021-07-12 19:12:29,973 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2012
[INFO] 2021-07-12 19:12:29,973 [run_pretraining.py:  558]:	worker_index: 7, step: 2012, cost: 7.015811, mlm loss: 7.015811, speed: 1.056468 steps/s, speed: 8.451740 samples/s, speed: 4327.291079 tokens/s, learning rate: 2.011e-05, loss_scalings: 3518.437988, pp_loss: 7.060585
[INFO] 2021-07-12 19:12:29,973 [run_pretraining.py:  512]:	********exe.run_2012******* 
[INFO] 2021-07-12 19:12:30,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:30,913 [run_pretraining.py:  534]:	loss/total_loss, 6.834325790405273, 2013
[INFO] 2021-07-12 19:12:30,913 [run_pretraining.py:  535]:	loss/mlm_loss, 6.834325790405273, 2013
[INFO] 2021-07-12 19:12:30,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0119998225709423e-05, 2013
[INFO] 2021-07-12 19:12:30,913 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2013
[INFO] 2021-07-12 19:12:30,913 [run_pretraining.py:  558]:	worker_index: 7, step: 2013, cost: 6.834326, mlm loss: 6.834326, speed: 1.064638 steps/s, speed: 8.517101 samples/s, speed: 4360.755839 tokens/s, learning rate: 2.012e-05, loss_scalings: 3518.437988, pp_loss: 7.127140
[INFO] 2021-07-12 19:12:30,913 [run_pretraining.py:  512]:	********exe.run_2013******* 
[INFO] 2021-07-12 19:12:31,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:31,852 [run_pretraining.py:  534]:	loss/total_loss, 7.380242347717285, 2014
[INFO] 2021-07-12 19:12:31,852 [run_pretraining.py:  535]:	loss/mlm_loss, 7.380242347717285, 2014
[INFO] 2021-07-12 19:12:31,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.012999902945012e-05, 2014
[INFO] 2021-07-12 19:12:31,852 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2014
[INFO] 2021-07-12 19:12:31,852 [run_pretraining.py:  558]:	worker_index: 7, step: 2014, cost: 7.380242, mlm loss: 7.380242, speed: 1.065204 steps/s, speed: 8.521635 samples/s, speed: 4363.077111 tokens/s, learning rate: 2.013e-05, loss_scalings: 3518.437988, pp_loss: 7.244946
[INFO] 2021-07-12 19:12:31,852 [run_pretraining.py:  512]:	********exe.run_2014******* 
[INFO] 2021-07-12 19:12:32,784 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:32,785 [run_pretraining.py:  534]:	loss/total_loss, 6.961703300476074, 2015
[INFO] 2021-07-12 19:12:32,785 [run_pretraining.py:  535]:	loss/mlm_loss, 6.961703300476074, 2015
[INFO] 2021-07-12 19:12:32,785 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0139999833190814e-05, 2015
[INFO] 2021-07-12 19:12:32,785 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2015
[INFO] 2021-07-12 19:12:32,785 [run_pretraining.py:  558]:	worker_index: 7, step: 2015, cost: 6.961703, mlm loss: 6.961703, speed: 1.072997 steps/s, speed: 8.583973 samples/s, speed: 4394.994065 tokens/s, learning rate: 2.014e-05, loss_scalings: 3518.437988, pp_loss: 6.984357
[INFO] 2021-07-12 19:12:32,785 [run_pretraining.py:  512]:	********exe.run_2015******* 
[INFO] 2021-07-12 19:12:33,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:33,725 [run_pretraining.py:  534]:	loss/total_loss, 6.949704170227051, 2016
[INFO] 2021-07-12 19:12:33,725 [run_pretraining.py:  535]:	loss/mlm_loss, 6.949704170227051, 2016
[INFO] 2021-07-12 19:12:33,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0149998817942105e-05, 2016
[INFO] 2021-07-12 19:12:33,725 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2016
[INFO] 2021-07-12 19:12:33,725 [run_pretraining.py:  558]:	worker_index: 7, step: 2016, cost: 6.949704, mlm loss: 6.949704, speed: 1.064555 steps/s, speed: 8.516442 samples/s, speed: 4360.418264 tokens/s, learning rate: 2.015e-05, loss_scalings: 3518.437988, pp_loss: 7.050395
[INFO] 2021-07-12 19:12:33,725 [run_pretraining.py:  512]:	********exe.run_2016******* 
[INFO] 2021-07-12 19:12:34,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:34,659 [run_pretraining.py:  534]:	loss/total_loss, 7.593583106994629, 2017
[INFO] 2021-07-12 19:12:34,659 [run_pretraining.py:  535]:	loss/mlm_loss, 7.593583106994629, 2017
[INFO] 2021-07-12 19:12:34,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.01599996216828e-05, 2017
[INFO] 2021-07-12 19:12:34,659 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2017
[INFO] 2021-07-12 19:12:34,659 [run_pretraining.py:  558]:	worker_index: 7, step: 2017, cost: 7.593583, mlm loss: 7.593583, speed: 1.071575 steps/s, speed: 8.572597 samples/s, speed: 4389.169854 tokens/s, learning rate: 2.016e-05, loss_scalings: 3518.437988, pp_loss: 7.389414
[INFO] 2021-07-12 19:12:34,659 [run_pretraining.py:  512]:	********exe.run_2017******* 
[INFO] 2021-07-12 19:12:35,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:35,618 [run_pretraining.py:  534]:	loss/total_loss, 7.730036735534668, 2018
[INFO] 2021-07-12 19:12:35,619 [run_pretraining.py:  535]:	loss/mlm_loss, 7.730036735534668, 2018
[INFO] 2021-07-12 19:12:35,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0170000425423495e-05, 2018
[INFO] 2021-07-12 19:12:35,619 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2018
[INFO] 2021-07-12 19:12:35,619 [run_pretraining.py:  558]:	worker_index: 7, step: 2018, cost: 7.730037, mlm loss: 7.730037, speed: 1.042502 steps/s, speed: 8.340019 samples/s, speed: 4270.089753 tokens/s, learning rate: 2.017e-05, loss_scalings: 3518.437988, pp_loss: 7.236457
[INFO] 2021-07-12 19:12:35,619 [run_pretraining.py:  512]:	********exe.run_2018******* 
[INFO] 2021-07-12 19:12:36,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:36,580 [run_pretraining.py:  534]:	loss/total_loss, 7.383052349090576, 2019
[INFO] 2021-07-12 19:12:36,580 [run_pretraining.py:  535]:	loss/mlm_loss, 7.383052349090576, 2019
[INFO] 2021-07-12 19:12:36,580 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0179999410174787e-05, 2019
[INFO] 2021-07-12 19:12:36,580 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2019
[INFO] 2021-07-12 19:12:36,580 [run_pretraining.py:  558]:	worker_index: 7, step: 2019, cost: 7.383052, mlm loss: 7.383052, speed: 1.041241 steps/s, speed: 8.329932 samples/s, speed: 4264.925163 tokens/s, learning rate: 2.018e-05, loss_scalings: 3518.437988, pp_loss: 6.395962
[INFO] 2021-07-12 19:12:36,580 [run_pretraining.py:  512]:	********exe.run_2019******* 
[INFO] 2021-07-12 19:12:37,544 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:37,545 [run_pretraining.py:  534]:	loss/total_loss, 6.846832752227783, 2020
[INFO] 2021-07-12 19:12:37,545 [run_pretraining.py:  535]:	loss/mlm_loss, 6.846832752227783, 2020
[INFO] 2021-07-12 19:12:37,545 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0190000213915482e-05, 2020
[INFO] 2021-07-12 19:12:37,545 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2020
[INFO] 2021-07-12 19:12:37,545 [run_pretraining.py:  558]:	worker_index: 7, step: 2020, cost: 6.846833, mlm loss: 6.846833, speed: 1.036402 steps/s, speed: 8.291213 samples/s, speed: 4245.101154 tokens/s, learning rate: 2.019e-05, loss_scalings: 3518.437988, pp_loss: 7.161720
[INFO] 2021-07-12 19:12:37,545 [run_pretraining.py:  512]:	********exe.run_2020******* 
[INFO] 2021-07-12 19:12:38,499 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:38,499 [run_pretraining.py:  534]:	loss/total_loss, 6.638534069061279, 2021
[INFO] 2021-07-12 19:12:38,499 [run_pretraining.py:  535]:	loss/mlm_loss, 6.638534069061279, 2021
[INFO] 2021-07-12 19:12:38,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0200001017656177e-05, 2021
[INFO] 2021-07-12 19:12:38,500 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2021
[INFO] 2021-07-12 19:12:38,500 [run_pretraining.py:  558]:	worker_index: 7, step: 2021, cost: 6.638534, mlm loss: 6.638534, speed: 1.048652 steps/s, speed: 8.389212 samples/s, speed: 4295.276556 tokens/s, learning rate: 2.020e-05, loss_scalings: 3518.437988, pp_loss: 6.890022
[INFO] 2021-07-12 19:12:38,500 [run_pretraining.py:  512]:	********exe.run_2021******* 
[INFO] 2021-07-12 19:12:39,457 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:39,457 [run_pretraining.py:  534]:	loss/total_loss, 7.269331932067871, 2022
[INFO] 2021-07-12 19:12:39,457 [run_pretraining.py:  535]:	loss/mlm_loss, 7.269331932067871, 2022
[INFO] 2021-07-12 19:12:39,457 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0209998183418065e-05, 2022
[INFO] 2021-07-12 19:12:39,458 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2022
[INFO] 2021-07-12 19:12:39,458 [run_pretraining.py:  558]:	worker_index: 7, step: 2022, cost: 7.269332, mlm loss: 7.269332, speed: 1.044546 steps/s, speed: 8.356365 samples/s, speed: 4278.458862 tokens/s, learning rate: 2.021e-05, loss_scalings: 3518.437988, pp_loss: 7.021507
[INFO] 2021-07-12 19:12:39,458 [run_pretraining.py:  512]:	********exe.run_2022******* 
[INFO] 2021-07-12 19:12:40,393 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:40,394 [run_pretraining.py:  534]:	loss/total_loss, 7.194146633148193, 2023
[INFO] 2021-07-12 19:12:40,394 [run_pretraining.py:  535]:	loss/mlm_loss, 7.194146633148193, 2023
[INFO] 2021-07-12 19:12:40,394 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.021999898715876e-05, 2023
[INFO] 2021-07-12 19:12:40,394 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2023
[INFO] 2021-07-12 19:12:40,394 [run_pretraining.py:  558]:	worker_index: 7, step: 2023, cost: 7.194147, mlm loss: 7.194147, speed: 1.068441 steps/s, speed: 8.547530 samples/s, speed: 4376.335406 tokens/s, learning rate: 2.022e-05, loss_scalings: 3518.437988, pp_loss: 7.513286
[INFO] 2021-07-12 19:12:40,394 [run_pretraining.py:  512]:	********exe.run_2023******* 
[INFO] 2021-07-12 19:12:41,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:41,334 [run_pretraining.py:  534]:	loss/total_loss, 6.833075523376465, 2024
[INFO] 2021-07-12 19:12:41,335 [run_pretraining.py:  535]:	loss/mlm_loss, 6.833075523376465, 2024
[INFO] 2021-07-12 19:12:41,335 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0229999790899456e-05, 2024
[INFO] 2021-07-12 19:12:41,335 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2024
[INFO] 2021-07-12 19:12:41,335 [run_pretraining.py:  558]:	worker_index: 7, step: 2024, cost: 6.833076, mlm loss: 6.833076, speed: 1.063917 steps/s, speed: 8.511337 samples/s, speed: 4357.804660 tokens/s, learning rate: 2.023e-05, loss_scalings: 3518.437988, pp_loss: 7.265227
[INFO] 2021-07-12 19:12:41,335 [run_pretraining.py:  512]:	********exe.run_2024******* 
[INFO] 2021-07-12 19:12:42,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:42,273 [run_pretraining.py:  534]:	loss/total_loss, 8.12871265411377, 2025
[INFO] 2021-07-12 19:12:42,273 [run_pretraining.py:  535]:	loss/mlm_loss, 8.12871265411377, 2025
[INFO] 2021-07-12 19:12:42,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0239998775650747e-05, 2025
[INFO] 2021-07-12 19:12:42,273 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2025
[INFO] 2021-07-12 19:12:42,273 [run_pretraining.py:  558]:	worker_index: 7, step: 2025, cost: 8.128713, mlm loss: 8.128713, speed: 1.066250 steps/s, speed: 8.530003 samples/s, speed: 4367.361777 tokens/s, learning rate: 2.024e-05, loss_scalings: 3518.437988, pp_loss: 7.504379
[INFO] 2021-07-12 19:12:42,273 [run_pretraining.py:  512]:	********exe.run_2025******* 
[INFO] 2021-07-12 19:12:43,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:43,207 [run_pretraining.py:  534]:	loss/total_loss, 7.115418434143066, 2026
[INFO] 2021-07-12 19:12:43,207 [run_pretraining.py:  535]:	loss/mlm_loss, 7.115418434143066, 2026
[INFO] 2021-07-12 19:12:43,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0249999579391442e-05, 2026
[INFO] 2021-07-12 19:12:43,208 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2026
[INFO] 2021-07-12 19:12:43,208 [run_pretraining.py:  558]:	worker_index: 7, step: 2026, cost: 7.115418, mlm loss: 7.115418, speed: 1.071006 steps/s, speed: 8.568049 samples/s, speed: 4386.840905 tokens/s, learning rate: 2.025e-05, loss_scalings: 3518.437988, pp_loss: 7.066117
[INFO] 2021-07-12 19:12:43,208 [run_pretraining.py:  512]:	********exe.run_2026******* 
[INFO] 2021-07-12 19:12:44,155 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:44,156 [run_pretraining.py:  534]:	loss/total_loss, 6.785425662994385, 2027
[INFO] 2021-07-12 19:12:44,156 [run_pretraining.py:  535]:	loss/mlm_loss, 6.785425662994385, 2027
[INFO] 2021-07-12 19:12:44,156 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0260000383132137e-05, 2027
[INFO] 2021-07-12 19:12:44,156 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2027
[INFO] 2021-07-12 19:12:44,156 [run_pretraining.py:  558]:	worker_index: 7, step: 2027, cost: 6.785426, mlm loss: 6.785426, speed: 1.054836 steps/s, speed: 8.438687 samples/s, speed: 4320.607944 tokens/s, learning rate: 2.026e-05, loss_scalings: 3518.437988, pp_loss: 7.250219
[INFO] 2021-07-12 19:12:44,156 [run_pretraining.py:  512]:	********exe.run_2027******* 
[INFO] 2021-07-12 19:12:45,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:45,100 [run_pretraining.py:  534]:	loss/total_loss, 7.859292507171631, 2028
[INFO] 2021-07-12 19:12:45,100 [run_pretraining.py:  535]:	loss/mlm_loss, 7.859292507171631, 2028
[INFO] 2021-07-12 19:12:45,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.026999936788343e-05, 2028
[INFO] 2021-07-12 19:12:45,100 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2028
[INFO] 2021-07-12 19:12:45,100 [run_pretraining.py:  558]:	worker_index: 7, step: 2028, cost: 7.859293, mlm loss: 7.859293, speed: 1.060588 steps/s, speed: 8.484708 samples/s, speed: 4344.170457 tokens/s, learning rate: 2.027e-05, loss_scalings: 3518.437988, pp_loss: 7.711711
[INFO] 2021-07-12 19:12:45,100 [run_pretraining.py:  512]:	********exe.run_2028******* 
[INFO] 2021-07-12 19:12:46,059 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:46,060 [run_pretraining.py:  534]:	loss/total_loss, 7.932238578796387, 2029
[INFO] 2021-07-12 19:12:46,060 [run_pretraining.py:  535]:	loss/mlm_loss, 7.932238578796387, 2029
[INFO] 2021-07-12 19:12:46,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0280000171624124e-05, 2029
[INFO] 2021-07-12 19:12:46,060 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2029
[INFO] 2021-07-12 19:12:46,060 [run_pretraining.py:  558]:	worker_index: 7, step: 2029, cost: 7.932239, mlm loss: 7.932239, speed: 1.042209 steps/s, speed: 8.337675 samples/s, speed: 4268.889716 tokens/s, learning rate: 2.028e-05, loss_scalings: 3518.437988, pp_loss: 7.519183
[INFO] 2021-07-12 19:12:46,060 [run_pretraining.py:  512]:	********exe.run_2029******* 
[INFO] 2021-07-12 19:12:47,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:47,007 [run_pretraining.py:  534]:	loss/total_loss, 7.554722785949707, 2030
[INFO] 2021-07-12 19:12:47,008 [run_pretraining.py:  535]:	loss/mlm_loss, 7.554722785949707, 2030
[INFO] 2021-07-12 19:12:47,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.029000097536482e-05, 2030
[INFO] 2021-07-12 19:12:47,008 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2030
[INFO] 2021-07-12 19:12:47,008 [run_pretraining.py:  558]:	worker_index: 7, step: 2030, cost: 7.554723, mlm loss: 7.554723, speed: 1.055918 steps/s, speed: 8.447342 samples/s, speed: 4325.039294 tokens/s, learning rate: 2.029e-05, loss_scalings: 3518.437988, pp_loss: 7.118532
[INFO] 2021-07-12 19:12:47,008 [run_pretraining.py:  512]:	********exe.run_2030******* 
[INFO] 2021-07-12 19:12:47,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:47,952 [run_pretraining.py:  534]:	loss/total_loss, 7.748499870300293, 2031
[INFO] 2021-07-12 19:12:47,952 [run_pretraining.py:  535]:	loss/mlm_loss, 7.748499870300293, 2031
[INFO] 2021-07-12 19:12:47,952 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0299998141126707e-05, 2031
[INFO] 2021-07-12 19:12:47,952 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2031
[INFO] 2021-07-12 19:12:47,952 [run_pretraining.py:  558]:	worker_index: 7, step: 2031, cost: 7.748500, mlm loss: 7.748500, speed: 1.059207 steps/s, speed: 8.473654 samples/s, speed: 4338.510759 tokens/s, learning rate: 2.030e-05, loss_scalings: 3518.437988, pp_loss: 7.483688
[INFO] 2021-07-12 19:12:47,953 [run_pretraining.py:  512]:	********exe.run_2031******* 
[INFO] 2021-07-12 19:12:48,915 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:12:48,916 [run_pretraining.py:  534]:	loss/total_loss, 6.563583850860596, 2032
[INFO] 2021-07-12 19:12:48,916 [run_pretraining.py:  535]:	loss/mlm_loss, 6.563583850860596, 2032
[INFO] 2021-07-12 19:12:48,916 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0309998944867402e-05, 2032
[INFO] 2021-07-12 19:12:48,916 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2032
[INFO] 2021-07-12 19:12:48,916 [run_pretraining.py:  558]:	worker_index: 7, step: 2032, cost: 6.563584, mlm loss: 6.563584, speed: 1.038749 steps/s, speed: 8.309989 samples/s, speed: 4254.714506 tokens/s, learning rate: 2.031e-05, loss_scalings: 3518.437988, pp_loss: 6.866090
[INFO] 2021-07-12 19:12:48,916 [run_pretraining.py:  512]:	********exe.run_2032******* 
[INFO] 2021-07-12 19:13:15,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:15,584 [run_pretraining.py:  534]:	loss/total_loss, 7.211906433105469, 2033
[INFO] 2021-07-12 19:13:15,584 [run_pretraining.py:  535]:	loss/mlm_loss, 7.211906433105469, 2033
[INFO] 2021-07-12 19:13:15,584 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0319999748608097e-05, 2033
[INFO] 2021-07-12 19:13:15,585 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2033
[INFO] 2021-07-12 19:13:15,585 [run_pretraining.py:  558]:	worker_index: 7, step: 2033, cost: 7.211906, mlm loss: 7.211906, speed: 0.037498 steps/s, speed: 0.299984 samples/s, speed: 153.591818 tokens/s, learning rate: 2.032e-05, loss_scalings: 3518.437988, pp_loss: 7.172966
[INFO] 2021-07-12 19:13:15,585 [run_pretraining.py:  512]:	********exe.run_2033******* 
[INFO] 2021-07-12 19:13:41,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:41,713 [run_pretraining.py:  534]:	loss/total_loss, 7.183472633361816, 2034
[INFO] 2021-07-12 19:13:41,713 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183472633361816, 2034
[INFO] 2021-07-12 19:13:41,713 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.032999873335939e-05, 2034
[INFO] 2021-07-12 19:13:41,713 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2034
[INFO] 2021-07-12 19:13:41,713 [run_pretraining.py:  558]:	worker_index: 7, step: 2034, cost: 7.183473, mlm loss: 7.183473, speed: 0.038273 steps/s, speed: 0.306184 samples/s, speed: 156.766374 tokens/s, learning rate: 2.033e-05, loss_scalings: 3518.437988, pp_loss: 7.219996
[INFO] 2021-07-12 19:13:41,713 [run_pretraining.py:  512]:	********exe.run_2034******* 
[INFO] 2021-07-12 19:13:42,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:42,633 [run_pretraining.py:  534]:	loss/total_loss, 6.887922286987305, 2035
[INFO] 2021-07-12 19:13:42,634 [run_pretraining.py:  535]:	loss/mlm_loss, 6.887922286987305, 2035
[INFO] 2021-07-12 19:13:42,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0339999537100084e-05, 2035
[INFO] 2021-07-12 19:13:42,634 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2035
[INFO] 2021-07-12 19:13:42,634 [run_pretraining.py:  558]:	worker_index: 7, step: 2035, cost: 6.887922, mlm loss: 6.887922, speed: 1.087170 steps/s, speed: 8.697358 samples/s, speed: 4453.047129 tokens/s, learning rate: 2.034e-05, loss_scalings: 3518.437988, pp_loss: 7.259369
[INFO] 2021-07-12 19:13:42,634 [run_pretraining.py:  512]:	********exe.run_2035******* 
[INFO] 2021-07-12 19:13:43,576 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:43,576 [run_pretraining.py:  534]:	loss/total_loss, 7.23776912689209, 2036
[INFO] 2021-07-12 19:13:43,577 [run_pretraining.py:  535]:	loss/mlm_loss, 7.23776912689209, 2036
[INFO] 2021-07-12 19:13:43,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.035000034084078e-05, 2036
[INFO] 2021-07-12 19:13:43,577 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2036
[INFO] 2021-07-12 19:13:43,577 [run_pretraining.py:  558]:	worker_index: 7, step: 2036, cost: 7.237769, mlm loss: 7.237769, speed: 1.061157 steps/s, speed: 8.489252 samples/s, speed: 4346.497193 tokens/s, learning rate: 2.035e-05, loss_scalings: 3518.437988, pp_loss: 7.231869
[INFO] 2021-07-12 19:13:43,577 [run_pretraining.py:  512]:	********exe.run_2036******* 
[INFO] 2021-07-12 19:13:44,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:44,507 [run_pretraining.py:  534]:	loss/total_loss, 3.5313332080841064, 2037
[INFO] 2021-07-12 19:13:44,507 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5313332080841064, 2037
[INFO] 2021-07-12 19:13:44,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.035999932559207e-05, 2037
[INFO] 2021-07-12 19:13:44,507 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2037
[INFO] 2021-07-12 19:13:44,507 [run_pretraining.py:  558]:	worker_index: 7, step: 2037, cost: 3.531333, mlm loss: 3.531333, speed: 1.075391 steps/s, speed: 8.603127 samples/s, speed: 4404.801009 tokens/s, learning rate: 2.036e-05, loss_scalings: 3518.437988, pp_loss: 6.434065
[INFO] 2021-07-12 19:13:44,507 [run_pretraining.py:  512]:	********exe.run_2037******* 
[INFO] 2021-07-12 19:13:45,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:45,442 [run_pretraining.py:  534]:	loss/total_loss, 7.361438274383545, 2038
[INFO] 2021-07-12 19:13:45,442 [run_pretraining.py:  535]:	loss/mlm_loss, 7.361438274383545, 2038
[INFO] 2021-07-12 19:13:45,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0370000129332766e-05, 2038
[INFO] 2021-07-12 19:13:45,442 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2038
[INFO] 2021-07-12 19:13:45,443 [run_pretraining.py:  558]:	worker_index: 7, step: 2038, cost: 7.361438, mlm loss: 7.361438, speed: 1.070052 steps/s, speed: 8.560418 samples/s, speed: 4382.933875 tokens/s, learning rate: 2.037e-05, loss_scalings: 3518.437988, pp_loss: 7.203323
[INFO] 2021-07-12 19:13:45,443 [run_pretraining.py:  512]:	********exe.run_2038******* 
[INFO] 2021-07-12 19:13:46,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:46,381 [run_pretraining.py:  534]:	loss/total_loss, 7.732810020446777, 2039
[INFO] 2021-07-12 19:13:46,381 [run_pretraining.py:  535]:	loss/mlm_loss, 7.732810020446777, 2039
[INFO] 2021-07-12 19:13:46,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0379999114084058e-05, 2039
[INFO] 2021-07-12 19:13:46,381 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2039
[INFO] 2021-07-12 19:13:46,381 [run_pretraining.py:  558]:	worker_index: 7, step: 2039, cost: 7.732810, mlm loss: 7.732810, speed: 1.066020 steps/s, speed: 8.528161 samples/s, speed: 4366.418273 tokens/s, learning rate: 2.038e-05, loss_scalings: 3518.437988, pp_loss: 7.189121
[INFO] 2021-07-12 19:13:46,381 [run_pretraining.py:  512]:	********exe.run_2039******* 
[INFO] 2021-07-12 19:13:47,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:47,308 [run_pretraining.py:  534]:	loss/total_loss, 7.320974349975586, 2040
[INFO] 2021-07-12 19:13:47,308 [run_pretraining.py:  535]:	loss/mlm_loss, 7.320974349975586, 2040
[INFO] 2021-07-12 19:13:47,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.038999809883535e-05, 2040
[INFO] 2021-07-12 19:13:47,308 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2040
[INFO] 2021-07-12 19:13:47,308 [run_pretraining.py:  558]:	worker_index: 7, step: 2040, cost: 7.320974, mlm loss: 7.320974, speed: 1.079788 steps/s, speed: 8.638302 samples/s, speed: 4422.810855 tokens/s, learning rate: 2.039e-05, loss_scalings: 3518.437988, pp_loss: 7.420622
[INFO] 2021-07-12 19:13:47,308 [run_pretraining.py:  512]:	********exe.run_2040******* 
[INFO] 2021-07-12 19:13:48,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:48,225 [run_pretraining.py:  534]:	loss/total_loss, 7.197659969329834, 2041
[INFO] 2021-07-12 19:13:48,226 [run_pretraining.py:  535]:	loss/mlm_loss, 7.197659969329834, 2041
[INFO] 2021-07-12 19:13:48,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0399998902576044e-05, 2041
[INFO] 2021-07-12 19:13:48,226 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2041
[INFO] 2021-07-12 19:13:48,226 [run_pretraining.py:  558]:	worker_index: 7, step: 2041, cost: 7.197660, mlm loss: 7.197660, speed: 1.090272 steps/s, speed: 8.722174 samples/s, speed: 4465.753334 tokens/s, learning rate: 2.040e-05, loss_scalings: 3518.437988, pp_loss: 7.400818
[INFO] 2021-07-12 19:13:48,226 [run_pretraining.py:  512]:	********exe.run_2041******* 
[INFO] 2021-07-12 19:13:49,140 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:49,141 [run_pretraining.py:  534]:	loss/total_loss, 6.877650260925293, 2042
[INFO] 2021-07-12 19:13:49,141 [run_pretraining.py:  535]:	loss/mlm_loss, 6.877650260925293, 2042
[INFO] 2021-07-12 19:13:49,141 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.040999970631674e-05, 2042
[INFO] 2021-07-12 19:13:49,141 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2042
[INFO] 2021-07-12 19:13:49,141 [run_pretraining.py:  558]:	worker_index: 7, step: 2042, cost: 6.877650, mlm loss: 6.877650, speed: 1.093329 steps/s, speed: 8.746634 samples/s, speed: 4478.276592 tokens/s, learning rate: 2.041e-05, loss_scalings: 3518.437988, pp_loss: 7.159883
[INFO] 2021-07-12 19:13:49,141 [run_pretraining.py:  512]:	********exe.run_2042******* 
[INFO] 2021-07-12 19:13:50,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:50,063 [run_pretraining.py:  534]:	loss/total_loss, 6.7791643142700195, 2043
[INFO] 2021-07-12 19:13:50,063 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7791643142700195, 2043
[INFO] 2021-07-12 19:13:50,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.041999869106803e-05, 2043
[INFO] 2021-07-12 19:13:50,063 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2043
[INFO] 2021-07-12 19:13:50,063 [run_pretraining.py:  558]:	worker_index: 7, step: 2043, cost: 6.779164, mlm loss: 6.779164, speed: 1.084995 steps/s, speed: 8.679960 samples/s, speed: 4444.139275 tokens/s, learning rate: 2.042e-05, loss_scalings: 3518.437988, pp_loss: 7.385890
[INFO] 2021-07-12 19:13:50,064 [run_pretraining.py:  512]:	********exe.run_2043******* 
[INFO] 2021-07-12 19:13:50,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:50,983 [run_pretraining.py:  534]:	loss/total_loss, 5.102118968963623, 2044
[INFO] 2021-07-12 19:13:50,983 [run_pretraining.py:  535]:	loss/mlm_loss, 5.102118968963623, 2044
[INFO] 2021-07-12 19:13:50,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0429999494808726e-05, 2044
[INFO] 2021-07-12 19:13:50,983 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2044
[INFO] 2021-07-12 19:13:50,984 [run_pretraining.py:  558]:	worker_index: 7, step: 2044, cost: 5.102119, mlm loss: 5.102119, speed: 1.087688 steps/s, speed: 8.701503 samples/s, speed: 4455.169627 tokens/s, learning rate: 2.043e-05, loss_scalings: 3518.437988, pp_loss: 6.922459
[INFO] 2021-07-12 19:13:50,984 [run_pretraining.py:  512]:	********exe.run_2044******* 
[INFO] 2021-07-12 19:13:51,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:51,910 [run_pretraining.py:  534]:	loss/total_loss, 7.214966773986816, 2045
[INFO] 2021-07-12 19:13:51,910 [run_pretraining.py:  535]:	loss/mlm_loss, 7.214966773986816, 2045
[INFO] 2021-07-12 19:13:51,911 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.044000029854942e-05, 2045
[INFO] 2021-07-12 19:13:51,911 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2045
[INFO] 2021-07-12 19:13:51,911 [run_pretraining.py:  558]:	worker_index: 7, step: 2045, cost: 7.214967, mlm loss: 7.214967, speed: 1.079306 steps/s, speed: 8.634450 samples/s, speed: 4420.838515 tokens/s, learning rate: 2.044e-05, loss_scalings: 3518.437988, pp_loss: 7.371068
[INFO] 2021-07-12 19:13:51,911 [run_pretraining.py:  512]:	********exe.run_2045******* 
[INFO] 2021-07-12 19:13:52,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:52,835 [run_pretraining.py:  534]:	loss/total_loss, 7.385616302490234, 2046
[INFO] 2021-07-12 19:13:52,835 [run_pretraining.py:  535]:	loss/mlm_loss, 7.385616302490234, 2046
[INFO] 2021-07-12 19:13:52,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0449999283300713e-05, 2046
[INFO] 2021-07-12 19:13:52,836 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2046
[INFO] 2021-07-12 19:13:52,836 [run_pretraining.py:  558]:	worker_index: 7, step: 2046, cost: 7.385616, mlm loss: 7.385616, speed: 1.081849 steps/s, speed: 8.654790 samples/s, speed: 4431.252688 tokens/s, learning rate: 2.045e-05, loss_scalings: 3518.437988, pp_loss: 7.410125
[INFO] 2021-07-12 19:13:52,836 [run_pretraining.py:  512]:	********exe.run_2046******* 
[INFO] 2021-07-12 19:13:53,791 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:53,791 [run_pretraining.py:  534]:	loss/total_loss, 7.406737804412842, 2047
[INFO] 2021-07-12 19:13:53,792 [run_pretraining.py:  535]:	loss/mlm_loss, 7.406737804412842, 2047
[INFO] 2021-07-12 19:13:53,792 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0460000087041408e-05, 2047
[INFO] 2021-07-12 19:13:53,792 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2047
[INFO] 2021-07-12 19:13:53,792 [run_pretraining.py:  558]:	worker_index: 7, step: 2047, cost: 7.406738, mlm loss: 7.406738, speed: 1.046683 steps/s, speed: 8.373465 samples/s, speed: 4287.213870 tokens/s, learning rate: 2.046e-05, loss_scalings: 3518.437988, pp_loss: 7.261489
[INFO] 2021-07-12 19:13:53,792 [run_pretraining.py:  512]:	********exe.run_2047******* 
[INFO] 2021-07-12 19:13:54,717 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:54,717 [run_pretraining.py:  534]:	loss/total_loss, 7.256300926208496, 2048
[INFO] 2021-07-12 19:13:54,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.256300926208496, 2048
[INFO] 2021-07-12 19:13:54,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.04699990717927e-05, 2048
[INFO] 2021-07-12 19:13:54,717 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2048
[INFO] 2021-07-12 19:13:54,717 [run_pretraining.py:  558]:	worker_index: 7, step: 2048, cost: 7.256301, mlm loss: 7.256301, speed: 1.081093 steps/s, speed: 8.648747 samples/s, speed: 4428.158556 tokens/s, learning rate: 2.047e-05, loss_scalings: 3518.437988, pp_loss: 7.271836
[INFO] 2021-07-12 19:13:54,718 [run_pretraining.py:  512]:	********exe.run_2048******* 
[INFO] 2021-07-12 19:13:55,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:55,653 [run_pretraining.py:  534]:	loss/total_loss, 7.702271461486816, 2049
[INFO] 2021-07-12 19:13:55,653 [run_pretraining.py:  535]:	loss/mlm_loss, 7.702271461486816, 2049
[INFO] 2021-07-12 19:13:55,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.047999805654399e-05, 2049
[INFO] 2021-07-12 19:13:55,654 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2049
[INFO] 2021-07-12 19:13:55,654 [run_pretraining.py:  558]:	worker_index: 7, step: 2049, cost: 7.702271, mlm loss: 7.702271, speed: 1.068976 steps/s, speed: 8.551804 samples/s, speed: 4378.523760 tokens/s, learning rate: 2.048e-05, loss_scalings: 3518.437988, pp_loss: 7.404726
[INFO] 2021-07-12 19:13:55,654 [run_pretraining.py:  512]:	********exe.run_2049******* 
[INFO] 2021-07-12 19:13:56,596 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:56,597 [run_pretraining.py:  534]:	loss/total_loss, 6.992871284484863, 2050
[INFO] 2021-07-12 19:13:56,597 [run_pretraining.py:  535]:	loss/mlm_loss, 6.992871284484863, 2050
[INFO] 2021-07-12 19:13:56,597 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0489998860284686e-05, 2050
[INFO] 2021-07-12 19:13:56,597 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2050
[INFO] 2021-07-12 19:13:56,597 [run_pretraining.py:  558]:	worker_index: 7, step: 2050, cost: 6.992871, mlm loss: 6.992871, speed: 1.060822 steps/s, speed: 8.486575 samples/s, speed: 4345.126348 tokens/s, learning rate: 2.049e-05, loss_scalings: 3518.437988, pp_loss: 7.594183
[INFO] 2021-07-12 19:13:56,597 [run_pretraining.py:  512]:	********exe.run_2050******* 
[INFO] 2021-07-12 19:13:57,547 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:57,548 [run_pretraining.py:  534]:	loss/total_loss, 6.959587097167969, 2051
[INFO] 2021-07-12 19:13:57,548 [run_pretraining.py:  535]:	loss/mlm_loss, 6.959587097167969, 2051
[INFO] 2021-07-12 19:13:57,548 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.049999966402538e-05, 2051
[INFO] 2021-07-12 19:13:57,548 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2051
[INFO] 2021-07-12 19:13:57,548 [run_pretraining.py:  558]:	worker_index: 7, step: 2051, cost: 6.959587, mlm loss: 6.959587, speed: 1.052126 steps/s, speed: 8.417009 samples/s, speed: 4309.508656 tokens/s, learning rate: 2.050e-05, loss_scalings: 3518.437988, pp_loss: 7.122379
[INFO] 2021-07-12 19:13:57,548 [run_pretraining.py:  512]:	********exe.run_2051******* 
[INFO] 2021-07-12 19:13:58,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:58,507 [run_pretraining.py:  534]:	loss/total_loss, 7.0572896003723145, 2052
[INFO] 2021-07-12 19:13:58,507 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0572896003723145, 2052
[INFO] 2021-07-12 19:13:58,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0509998648776673e-05, 2052
[INFO] 2021-07-12 19:13:58,507 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2052
[INFO] 2021-07-12 19:13:58,507 [run_pretraining.py:  558]:	worker_index: 7, step: 2052, cost: 7.057290, mlm loss: 7.057290, speed: 1.043449 steps/s, speed: 8.347594 samples/s, speed: 4273.968222 tokens/s, learning rate: 2.051e-05, loss_scalings: 3518.437988, pp_loss: 7.071067
[INFO] 2021-07-12 19:13:58,507 [run_pretraining.py:  512]:	********exe.run_2052******* 
[INFO] 2021-07-12 19:13:59,444 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:13:59,445 [run_pretraining.py:  534]:	loss/total_loss, 6.896437644958496, 2053
[INFO] 2021-07-12 19:13:59,445 [run_pretraining.py:  535]:	loss/mlm_loss, 6.896437644958496, 2053
[INFO] 2021-07-12 19:13:59,445 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0519999452517368e-05, 2053
[INFO] 2021-07-12 19:13:59,445 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2053
[INFO] 2021-07-12 19:13:59,445 [run_pretraining.py:  558]:	worker_index: 7, step: 2053, cost: 6.896438, mlm loss: 6.896438, speed: 1.066772 steps/s, speed: 8.534173 samples/s, speed: 4369.496709 tokens/s, learning rate: 2.052e-05, loss_scalings: 3518.437988, pp_loss: 7.216658
[INFO] 2021-07-12 19:13:59,445 [run_pretraining.py:  512]:	********exe.run_2053******* 
[INFO] 2021-07-12 19:14:00,397 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:00,398 [run_pretraining.py:  534]:	loss/total_loss, 7.774901390075684, 2054
[INFO] 2021-07-12 19:14:00,398 [run_pretraining.py:  535]:	loss/mlm_loss, 7.774901390075684, 2054
[INFO] 2021-07-12 19:14:00,398 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0530000256258063e-05, 2054
[INFO] 2021-07-12 19:14:00,398 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2054
[INFO] 2021-07-12 19:14:00,398 [run_pretraining.py:  558]:	worker_index: 7, step: 2054, cost: 7.774901, mlm loss: 7.774901, speed: 1.049983 steps/s, speed: 8.399866 samples/s, speed: 4300.731351 tokens/s, learning rate: 2.053e-05, loss_scalings: 3518.437988, pp_loss: 7.392667
[INFO] 2021-07-12 19:14:00,398 [run_pretraining.py:  512]:	********exe.run_2054******* 
[INFO] 2021-07-12 19:14:01,342 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:01,343 [run_pretraining.py:  534]:	loss/total_loss, 6.878653049468994, 2055
[INFO] 2021-07-12 19:14:01,343 [run_pretraining.py:  535]:	loss/mlm_loss, 6.878653049468994, 2055
[INFO] 2021-07-12 19:14:01,343 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0539999241009355e-05, 2055
[INFO] 2021-07-12 19:14:01,343 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2055
[INFO] 2021-07-12 19:14:01,343 [run_pretraining.py:  558]:	worker_index: 7, step: 2055, cost: 6.878653, mlm loss: 6.878653, speed: 1.059015 steps/s, speed: 8.472122 samples/s, speed: 4337.726434 tokens/s, learning rate: 2.054e-05, loss_scalings: 3518.437988, pp_loss: 7.142930
[INFO] 2021-07-12 19:14:01,343 [run_pretraining.py:  512]:	********exe.run_2055******* 
[INFO] 2021-07-12 19:14:02,290 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:02,290 [run_pretraining.py:  534]:	loss/total_loss, 6.735698223114014, 2056
[INFO] 2021-07-12 19:14:02,290 [run_pretraining.py:  535]:	loss/mlm_loss, 6.735698223114014, 2056
[INFO] 2021-07-12 19:14:02,290 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.055000004475005e-05, 2056
[INFO] 2021-07-12 19:14:02,290 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2056
[INFO] 2021-07-12 19:14:02,291 [run_pretraining.py:  558]:	worker_index: 7, step: 2056, cost: 6.735698, mlm loss: 6.735698, speed: 1.056149 steps/s, speed: 8.449191 samples/s, speed: 4325.985695 tokens/s, learning rate: 2.055e-05, loss_scalings: 3518.437988, pp_loss: 7.435650
[INFO] 2021-07-12 19:14:02,291 [run_pretraining.py:  512]:	********exe.run_2056******* 
[INFO] 2021-07-12 19:14:03,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  534]:	loss/total_loss, 6.560399532318115, 2057
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  535]:	loss/mlm_loss, 6.560399532318115, 2057
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.055999902950134e-05, 2057
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2057
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  558]:	worker_index: 7, step: 2057, cost: 6.560400, mlm loss: 6.560400, speed: 1.062607 steps/s, speed: 8.500855 samples/s, speed: 4352.437975 tokens/s, learning rate: 2.056e-05, loss_scalings: 3518.437988, pp_loss: 6.563396
[INFO] 2021-07-12 19:14:03,232 [run_pretraining.py:  512]:	********exe.run_2057******* 
[INFO] 2021-07-12 19:14:04,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:04,173 [run_pretraining.py:  534]:	loss/total_loss, 7.7008748054504395, 2058
[INFO] 2021-07-12 19:14:04,173 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7008748054504395, 2058
[INFO] 2021-07-12 19:14:04,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0569999833242036e-05, 2058
[INFO] 2021-07-12 19:14:04,173 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2058
[INFO] 2021-07-12 19:14:04,173 [run_pretraining.py:  558]:	worker_index: 7, step: 2058, cost: 7.700875, mlm loss: 7.700875, speed: 1.063538 steps/s, speed: 8.508305 samples/s, speed: 4356.252140 tokens/s, learning rate: 2.057e-05, loss_scalings: 3518.437988, pp_loss: 7.386383
[INFO] 2021-07-12 19:14:04,173 [run_pretraining.py:  512]:	********exe.run_2058******* 
[INFO] 2021-07-12 19:14:05,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:05,119 [run_pretraining.py:  534]:	loss/total_loss, 5.806107044219971, 2059
[INFO] 2021-07-12 19:14:05,119 [run_pretraining.py:  535]:	loss/mlm_loss, 5.806107044219971, 2059
[INFO] 2021-07-12 19:14:05,119 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0579998817993328e-05, 2059
[INFO] 2021-07-12 19:14:05,119 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2059
[INFO] 2021-07-12 19:14:05,119 [run_pretraining.py:  558]:	worker_index: 7, step: 2059, cost: 5.806107, mlm loss: 5.806107, speed: 1.057842 steps/s, speed: 8.462733 samples/s, speed: 4332.919336 tokens/s, learning rate: 2.058e-05, loss_scalings: 3518.437988, pp_loss: 6.141337
[INFO] 2021-07-12 19:14:05,119 [run_pretraining.py:  512]:	********exe.run_2059******* 
[INFO] 2021-07-12 19:14:06,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:06,058 [run_pretraining.py:  534]:	loss/total_loss, 6.947876930236816, 2060
[INFO] 2021-07-12 19:14:06,058 [run_pretraining.py:  535]:	loss/mlm_loss, 6.947876930236816, 2060
[INFO] 2021-07-12 19:14:06,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0589999621734023e-05, 2060
[INFO] 2021-07-12 19:14:06,058 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2060
[INFO] 2021-07-12 19:14:06,058 [run_pretraining.py:  558]:	worker_index: 7, step: 2060, cost: 6.947877, mlm loss: 6.947877, speed: 1.065501 steps/s, speed: 8.524005 samples/s, speed: 4364.290782 tokens/s, learning rate: 2.059e-05, loss_scalings: 3518.437988, pp_loss: 7.466272
[INFO] 2021-07-12 19:14:06,058 [run_pretraining.py:  512]:	********exe.run_2060******* 
[INFO] 2021-07-12 19:14:06,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:07,000 [run_pretraining.py:  534]:	loss/total_loss, 7.452435493469238, 2061
[INFO] 2021-07-12 19:14:07,000 [run_pretraining.py:  535]:	loss/mlm_loss, 7.452435493469238, 2061
[INFO] 2021-07-12 19:14:07,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0599998606485315e-05, 2061
[INFO] 2021-07-12 19:14:07,000 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2061
[INFO] 2021-07-12 19:14:07,000 [run_pretraining.py:  558]:	worker_index: 7, step: 2061, cost: 7.452435, mlm loss: 7.452435, speed: 1.062796 steps/s, speed: 8.502365 samples/s, speed: 4353.211084 tokens/s, learning rate: 2.060e-05, loss_scalings: 3518.437988, pp_loss: 7.266963
[INFO] 2021-07-12 19:14:07,000 [run_pretraining.py:  512]:	********exe.run_2061******* 
[INFO] 2021-07-12 19:14:07,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:07,943 [run_pretraining.py:  534]:	loss/total_loss, 7.838135719299316, 2062
[INFO] 2021-07-12 19:14:07,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.838135719299316, 2062
[INFO] 2021-07-12 19:14:07,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.060999941022601e-05, 2062
[INFO] 2021-07-12 19:14:07,943 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2062
[INFO] 2021-07-12 19:14:07,943 [run_pretraining.py:  558]:	worker_index: 7, step: 2062, cost: 7.838136, mlm loss: 7.838136, speed: 1.060829 steps/s, speed: 8.486631 samples/s, speed: 4345.154922 tokens/s, learning rate: 2.061e-05, loss_scalings: 3518.437988, pp_loss: 7.157647
[INFO] 2021-07-12 19:14:07,943 [run_pretraining.py:  512]:	********exe.run_2062******* 
[INFO] 2021-07-12 19:14:08,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:08,885 [run_pretraining.py:  534]:	loss/total_loss, 7.095178604125977, 2063
[INFO] 2021-07-12 19:14:08,885 [run_pretraining.py:  535]:	loss/mlm_loss, 7.095178604125977, 2063
[INFO] 2021-07-12 19:14:08,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0620000213966705e-05, 2063
[INFO] 2021-07-12 19:14:08,885 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2063
[INFO] 2021-07-12 19:14:08,885 [run_pretraining.py:  558]:	worker_index: 7, step: 2063, cost: 7.095179, mlm loss: 7.095179, speed: 1.062370 steps/s, speed: 8.498956 samples/s, speed: 4351.465638 tokens/s, learning rate: 2.062e-05, loss_scalings: 3518.437988, pp_loss: 6.773054
[INFO] 2021-07-12 19:14:08,885 [run_pretraining.py:  512]:	********exe.run_2063******* 
[INFO] 2021-07-12 19:14:09,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:09,831 [run_pretraining.py:  534]:	loss/total_loss, 7.5863728523254395, 2064
[INFO] 2021-07-12 19:14:09,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5863728523254395, 2064
[INFO] 2021-07-12 19:14:09,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0629999198717996e-05, 2064
[INFO] 2021-07-12 19:14:09,832 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2064
[INFO] 2021-07-12 19:14:09,832 [run_pretraining.py:  558]:	worker_index: 7, step: 2064, cost: 7.586373, mlm loss: 7.586373, speed: 1.057270 steps/s, speed: 8.458164 samples/s, speed: 4330.579819 tokens/s, learning rate: 2.063e-05, loss_scalings: 3518.437988, pp_loss: 7.424286
[INFO] 2021-07-12 19:14:09,832 [run_pretraining.py:  512]:	********exe.run_2064******* 
[INFO] 2021-07-12 19:14:10,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:10,772 [run_pretraining.py:  534]:	loss/total_loss, 7.134309768676758, 2065
[INFO] 2021-07-12 19:14:10,773 [run_pretraining.py:  535]:	loss/mlm_loss, 7.134309768676758, 2065
[INFO] 2021-07-12 19:14:10,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.064000000245869e-05, 2065
[INFO] 2021-07-12 19:14:10,773 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2065
[INFO] 2021-07-12 19:14:10,773 [run_pretraining.py:  558]:	worker_index: 7, step: 2065, cost: 7.134310, mlm loss: 7.134310, speed: 1.063331 steps/s, speed: 8.506646 samples/s, speed: 4355.402866 tokens/s, learning rate: 2.064e-05, loss_scalings: 3518.437988, pp_loss: 7.246124
[INFO] 2021-07-12 19:14:10,773 [run_pretraining.py:  512]:	********exe.run_2065******* 
[INFO] 2021-07-12 19:14:11,712 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:11,712 [run_pretraining.py:  534]:	loss/total_loss, 6.7637553215026855, 2066
[INFO] 2021-07-12 19:14:11,712 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7637553215026855, 2066
[INFO] 2021-07-12 19:14:11,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0649998987209983e-05, 2066
[INFO] 2021-07-12 19:14:11,712 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2066
[INFO] 2021-07-12 19:14:11,713 [run_pretraining.py:  558]:	worker_index: 7, step: 2066, cost: 6.763755, mlm loss: 6.763755, speed: 1.064944 steps/s, speed: 8.519549 samples/s, speed: 4362.009196 tokens/s, learning rate: 2.065e-05, loss_scalings: 3518.437988, pp_loss: 6.983729
[INFO] 2021-07-12 19:14:11,713 [run_pretraining.py:  512]:	********exe.run_2066******* 
[INFO] 2021-07-12 19:14:12,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:12,647 [run_pretraining.py:  534]:	loss/total_loss, 7.651803970336914, 2067
[INFO] 2021-07-12 19:14:12,647 [run_pretraining.py:  535]:	loss/mlm_loss, 7.651803970336914, 2067
[INFO] 2021-07-12 19:14:12,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0659999790950678e-05, 2067
[INFO] 2021-07-12 19:14:12,647 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2067
[INFO] 2021-07-12 19:14:12,647 [run_pretraining.py:  558]:	worker_index: 7, step: 2067, cost: 7.651804, mlm loss: 7.651804, speed: 1.070402 steps/s, speed: 8.563214 samples/s, speed: 4384.365607 tokens/s, learning rate: 2.066e-05, loss_scalings: 3518.437988, pp_loss: 7.514857
[INFO] 2021-07-12 19:14:12,647 [run_pretraining.py:  512]:	********exe.run_2067******* 
[INFO] 2021-07-12 19:14:13,578 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:13,578 [run_pretraining.py:  534]:	loss/total_loss, 8.116125106811523, 2068
[INFO] 2021-07-12 19:14:13,578 [run_pretraining.py:  535]:	loss/mlm_loss, 8.116125106811523, 2068
[INFO] 2021-07-12 19:14:13,578 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.066999877570197e-05, 2068
[INFO] 2021-07-12 19:14:13,578 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2068
[INFO] 2021-07-12 19:14:13,578 [run_pretraining.py:  558]:	worker_index: 7, step: 2068, cost: 8.116125, mlm loss: 8.116125, speed: 1.074795 steps/s, speed: 8.598356 samples/s, speed: 4402.358427 tokens/s, learning rate: 2.067e-05, loss_scalings: 3518.437988, pp_loss: 7.762709
[INFO] 2021-07-12 19:14:13,579 [run_pretraining.py:  512]:	********exe.run_2068******* 
[INFO] 2021-07-12 19:14:14,508 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:14,509 [run_pretraining.py:  534]:	loss/total_loss, 6.538780212402344, 2069
[INFO] 2021-07-12 19:14:14,509 [run_pretraining.py:  535]:	loss/mlm_loss, 6.538780212402344, 2069
[INFO] 2021-07-12 19:14:14,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0679999579442665e-05, 2069
[INFO] 2021-07-12 19:14:14,509 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2069
[INFO] 2021-07-12 19:14:14,509 [run_pretraining.py:  558]:	worker_index: 7, step: 2069, cost: 6.538780, mlm loss: 6.538780, speed: 1.075315 steps/s, speed: 8.602516 samples/s, speed: 4404.488198 tokens/s, learning rate: 2.068e-05, loss_scalings: 3518.437988, pp_loss: 7.228742
[INFO] 2021-07-12 19:14:14,509 [run_pretraining.py:  512]:	********exe.run_2069******* 
[INFO] 2021-07-12 19:14:15,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  534]:	loss/total_loss, 7.118688106536865, 2070
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  535]:	loss/mlm_loss, 7.118688106536865, 2070
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069000038318336e-05, 2070
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2070
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  558]:	worker_index: 7, step: 2070, cost: 7.118688, mlm loss: 7.118688, speed: 1.061084 steps/s, speed: 8.488672 samples/s, speed: 4346.200305 tokens/s, learning rate: 2.069e-05, loss_scalings: 3518.437988, pp_loss: 7.008658
[INFO] 2021-07-12 19:14:15,452 [run_pretraining.py:  512]:	********exe.run_2070******* 
[INFO] 2021-07-12 19:14:16,381 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:16,381 [run_pretraining.py:  534]:	loss/total_loss, 6.559928894042969, 2071
[INFO] 2021-07-12 19:14:16,381 [run_pretraining.py:  535]:	loss/mlm_loss, 6.559928894042969, 2071
[INFO] 2021-07-12 19:14:16,382 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.069999936793465e-05, 2071
[INFO] 2021-07-12 19:14:16,382 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2071
[INFO] 2021-07-12 19:14:16,382 [run_pretraining.py:  558]:	worker_index: 7, step: 2071, cost: 6.559929, mlm loss: 6.559929, speed: 1.076571 steps/s, speed: 8.612571 samples/s, speed: 4409.636588 tokens/s, learning rate: 2.070e-05, loss_scalings: 3518.437988, pp_loss: 6.941230
[INFO] 2021-07-12 19:14:16,382 [run_pretraining.py:  512]:	********exe.run_2071******* 
[INFO] 2021-07-12 19:14:17,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:17,315 [run_pretraining.py:  534]:	loss/total_loss, 7.832772254943848, 2072
[INFO] 2021-07-12 19:14:17,315 [run_pretraining.py:  535]:	loss/mlm_loss, 7.832772254943848, 2072
[INFO] 2021-07-12 19:14:17,315 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0710000171675347e-05, 2072
[INFO] 2021-07-12 19:14:17,315 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2072
[INFO] 2021-07-12 19:14:17,315 [run_pretraining.py:  558]:	worker_index: 7, step: 2072, cost: 7.832772, mlm loss: 7.832772, speed: 1.072323 steps/s, speed: 8.578581 samples/s, speed: 4392.233302 tokens/s, learning rate: 2.071e-05, loss_scalings: 3518.437988, pp_loss: 7.537101
[INFO] 2021-07-12 19:14:17,315 [run_pretraining.py:  512]:	********exe.run_2072******* 
[INFO] 2021-07-12 19:14:18,242 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:18,242 [run_pretraining.py:  534]:	loss/total_loss, 7.576052665710449, 2073
[INFO] 2021-07-12 19:14:18,242 [run_pretraining.py:  535]:	loss/mlm_loss, 7.576052665710449, 2073
[INFO] 2021-07-12 19:14:18,242 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.071999915642664e-05, 2073
[INFO] 2021-07-12 19:14:18,242 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2073
[INFO] 2021-07-12 19:14:18,242 [run_pretraining.py:  558]:	worker_index: 7, step: 2073, cost: 7.576053, mlm loss: 7.576053, speed: 1.078880 steps/s, speed: 8.631043 samples/s, speed: 4419.094126 tokens/s, learning rate: 2.072e-05, loss_scalings: 3518.437988, pp_loss: 7.288344
[INFO] 2021-07-12 19:14:18,243 [run_pretraining.py:  512]:	********exe.run_2073******* 
[INFO] 2021-07-12 19:14:19,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:19,171 [run_pretraining.py:  534]:	loss/total_loss, 7.249366283416748, 2074
[INFO] 2021-07-12 19:14:19,172 [run_pretraining.py:  535]:	loss/mlm_loss, 7.249366283416748, 2074
[INFO] 2021-07-12 19:14:19,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0729999960167333e-05, 2074
[INFO] 2021-07-12 19:14:19,172 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2074
[INFO] 2021-07-12 19:14:19,172 [run_pretraining.py:  558]:	worker_index: 7, step: 2074, cost: 7.249366, mlm loss: 7.249366, speed: 1.076824 steps/s, speed: 8.614595 samples/s, speed: 4410.672467 tokens/s, learning rate: 2.073e-05, loss_scalings: 3518.437988, pp_loss: 7.010094
[INFO] 2021-07-12 19:14:19,172 [run_pretraining.py:  512]:	********exe.run_2074******* 
[INFO] 2021-07-12 19:14:20,099 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:20,099 [run_pretraining.py:  534]:	loss/total_loss, 6.828782558441162, 2075
[INFO] 2021-07-12 19:14:20,099 [run_pretraining.py:  535]:	loss/mlm_loss, 6.828782558441162, 2075
[INFO] 2021-07-12 19:14:20,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0739998944918625e-05, 2075
[INFO] 2021-07-12 19:14:20,099 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2075
[INFO] 2021-07-12 19:14:20,100 [run_pretraining.py:  558]:	worker_index: 7, step: 2075, cost: 6.828783, mlm loss: 6.828783, speed: 1.078685 steps/s, speed: 8.629481 samples/s, speed: 4418.294033 tokens/s, learning rate: 2.074e-05, loss_scalings: 3518.437988, pp_loss: 7.323230
[INFO] 2021-07-12 19:14:20,100 [run_pretraining.py:  512]:	********exe.run_2075******* 
[INFO] 2021-07-12 19:14:21,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:21,036 [run_pretraining.py:  534]:	loss/total_loss, 7.269662857055664, 2076
[INFO] 2021-07-12 19:14:21,036 [run_pretraining.py:  535]:	loss/mlm_loss, 7.269662857055664, 2076
[INFO] 2021-07-12 19:14:21,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.074999974865932e-05, 2076
[INFO] 2021-07-12 19:14:21,036 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2076
[INFO] 2021-07-12 19:14:21,036 [run_pretraining.py:  558]:	worker_index: 7, step: 2076, cost: 7.269663, mlm loss: 7.269663, speed: 1.068658 steps/s, speed: 8.549264 samples/s, speed: 4377.222976 tokens/s, learning rate: 2.075e-05, loss_scalings: 3518.437988, pp_loss: 7.363482
[INFO] 2021-07-12 19:14:21,036 [run_pretraining.py:  512]:	********exe.run_2076******* 
[INFO] 2021-07-12 19:14:21,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:21,992 [run_pretraining.py:  534]:	loss/total_loss, 8.275348663330078, 2077
[INFO] 2021-07-12 19:14:21,992 [run_pretraining.py:  535]:	loss/mlm_loss, 8.275348663330078, 2077
[INFO] 2021-07-12 19:14:21,992 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0759998733410612e-05, 2077
[INFO] 2021-07-12 19:14:21,992 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2077
[INFO] 2021-07-12 19:14:21,992 [run_pretraining.py:  558]:	worker_index: 7, step: 2077, cost: 8.275349, mlm loss: 8.275349, speed: 1.046801 steps/s, speed: 8.374407 samples/s, speed: 4287.696435 tokens/s, learning rate: 2.076e-05, loss_scalings: 3518.437988, pp_loss: 7.664951
[INFO] 2021-07-12 19:14:21,992 [run_pretraining.py:  512]:	********exe.run_2077******* 
[INFO] 2021-07-12 19:14:22,939 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:22,940 [run_pretraining.py:  534]:	loss/total_loss, 6.661833763122559, 2078
[INFO] 2021-07-12 19:14:22,940 [run_pretraining.py:  535]:	loss/mlm_loss, 6.661833763122559, 2078
[INFO] 2021-07-12 19:14:22,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0769999537151307e-05, 2078
[INFO] 2021-07-12 19:14:22,940 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2078
[INFO] 2021-07-12 19:14:22,940 [run_pretraining.py:  558]:	worker_index: 7, step: 2078, cost: 6.661834, mlm loss: 6.661834, speed: 1.055645 steps/s, speed: 8.445163 samples/s, speed: 4323.923531 tokens/s, learning rate: 2.077e-05, loss_scalings: 3518.437988, pp_loss: 6.623760
[INFO] 2021-07-12 19:14:22,940 [run_pretraining.py:  512]:	********exe.run_2078******* 
[INFO] 2021-07-12 19:14:23,891 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:23,891 [run_pretraining.py:  534]:	loss/total_loss, 7.3008036613464355, 2079
[INFO] 2021-07-12 19:14:23,892 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3008036613464355, 2079
[INFO] 2021-07-12 19:14:23,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0780000340892002e-05, 2079
[INFO] 2021-07-12 19:14:23,892 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2079
[INFO] 2021-07-12 19:14:23,892 [run_pretraining.py:  558]:	worker_index: 7, step: 2079, cost: 7.300804, mlm loss: 7.300804, speed: 1.051241 steps/s, speed: 8.409927 samples/s, speed: 4305.882709 tokens/s, learning rate: 2.078e-05, loss_scalings: 3518.437988, pp_loss: 7.236308
[INFO] 2021-07-12 19:14:23,892 [run_pretraining.py:  512]:	********exe.run_2079******* 
[INFO] 2021-07-12 19:14:24,831 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:24,831 [run_pretraining.py:  534]:	loss/total_loss, 7.764186859130859, 2080
[INFO] 2021-07-12 19:14:24,831 [run_pretraining.py:  535]:	loss/mlm_loss, 7.764186859130859, 2080
[INFO] 2021-07-12 19:14:24,832 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0789999325643294e-05, 2080
[INFO] 2021-07-12 19:14:24,832 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2080
[INFO] 2021-07-12 19:14:24,832 [run_pretraining.py:  558]:	worker_index: 7, step: 2080, cost: 7.764187, mlm loss: 7.764187, speed: 1.064683 steps/s, speed: 8.517464 samples/s, speed: 4360.941804 tokens/s, learning rate: 2.079e-05, loss_scalings: 3518.437988, pp_loss: 7.540672
[INFO] 2021-07-12 19:14:24,832 [run_pretraining.py:  512]:	********exe.run_2080******* 
[INFO] 2021-07-12 19:14:25,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:25,788 [run_pretraining.py:  534]:	loss/total_loss, 7.274330139160156, 2081
[INFO] 2021-07-12 19:14:25,793 [run_pretraining.py:  535]:	loss/mlm_loss, 7.274330139160156, 2081
[INFO] 2021-07-12 19:14:25,799 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.080000012938399e-05, 2081
[INFO] 2021-07-12 19:14:25,804 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2081
[INFO] 2021-07-12 19:14:25,807 [run_pretraining.py:  558]:	worker_index: 7, step: 2081, cost: 7.274330, mlm loss: 7.274330, speed: 1.045735 steps/s, speed: 8.365878 samples/s, speed: 4283.329490 tokens/s, learning rate: 2.080e-05, loss_scalings: 3518.437988, pp_loss: 7.282938
[INFO] 2021-07-12 19:14:25,816 [run_pretraining.py:  512]:	********exe.run_2081******* 
[INFO] 2021-07-12 19:14:26,721 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:26,721 [run_pretraining.py:  534]:	loss/total_loss, 7.187557697296143, 2082
[INFO] 2021-07-12 19:14:26,721 [run_pretraining.py:  535]:	loss/mlm_loss, 7.187557697296143, 2082
[INFO] 2021-07-12 19:14:26,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0810000933124684e-05, 2082
[INFO] 2021-07-12 19:14:26,721 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2082
[INFO] 2021-07-12 19:14:26,721 [run_pretraining.py:  558]:	worker_index: 7, step: 2082, cost: 7.187558, mlm loss: 7.187558, speed: 1.105090 steps/s, speed: 8.840718 samples/s, speed: 4526.447561 tokens/s, learning rate: 2.081e-05, loss_scalings: 3518.437988, pp_loss: 7.476568
[INFO] 2021-07-12 19:14:26,722 [run_pretraining.py:  512]:	********exe.run_2082******* 
[INFO] 2021-07-12 19:14:27,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  534]:	loss/total_loss, 7.234824180603027, 2083
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.234824180603027, 2083
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0819998098886572e-05, 2083
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2083
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  558]:	worker_index: 7, step: 2083, cost: 7.234824, mlm loss: 7.234824, speed: 1.069766 steps/s, speed: 8.558127 samples/s, speed: 4381.761222 tokens/s, learning rate: 2.082e-05, loss_scalings: 3518.437988, pp_loss: 7.411066
[INFO] 2021-07-12 19:14:27,657 [run_pretraining.py:  512]:	********exe.run_2083******* 
[INFO] 2021-07-12 19:14:28,589 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:28,590 [run_pretraining.py:  534]:	loss/total_loss, 7.354034423828125, 2084
[INFO] 2021-07-12 19:14:28,590 [run_pretraining.py:  535]:	loss/mlm_loss, 7.354034423828125, 2084
[INFO] 2021-07-12 19:14:28,590 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0829998902627267e-05, 2084
[INFO] 2021-07-12 19:14:28,590 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2084
[INFO] 2021-07-12 19:14:28,590 [run_pretraining.py:  558]:	worker_index: 7, step: 2084, cost: 7.354034, mlm loss: 7.354034, speed: 1.072153 steps/s, speed: 8.577225 samples/s, speed: 4391.539444 tokens/s, learning rate: 2.083e-05, loss_scalings: 3518.437988, pp_loss: 7.375511
[INFO] 2021-07-12 19:14:28,590 [run_pretraining.py:  512]:	********exe.run_2084******* 
[INFO] 2021-07-12 19:14:29,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:29,498 [run_pretraining.py:  534]:	loss/total_loss, 6.7474775314331055, 2085
[INFO] 2021-07-12 19:14:29,498 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7474775314331055, 2085
[INFO] 2021-07-12 19:14:29,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0839999706367962e-05, 2085
[INFO] 2021-07-12 19:14:29,498 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2085
[INFO] 2021-07-12 19:14:29,498 [run_pretraining.py:  558]:	worker_index: 7, step: 2085, cost: 6.747478, mlm loss: 6.747478, speed: 1.102201 steps/s, speed: 8.817611 samples/s, speed: 4514.616955 tokens/s, learning rate: 2.084e-05, loss_scalings: 3518.437988, pp_loss: 7.084364
[INFO] 2021-07-12 19:14:29,498 [run_pretraining.py:  512]:	********exe.run_2085******* 
[INFO] 2021-07-12 19:14:30,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:30,414 [run_pretraining.py:  534]:	loss/total_loss, 7.803586006164551, 2086
[INFO] 2021-07-12 19:14:30,414 [run_pretraining.py:  535]:	loss/mlm_loss, 7.803586006164551, 2086
[INFO] 2021-07-12 19:14:30,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0849998691119254e-05, 2086
[INFO] 2021-07-12 19:14:30,415 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2086
[INFO] 2021-07-12 19:14:30,415 [run_pretraining.py:  558]:	worker_index: 7, step: 2086, cost: 7.803586, mlm loss: 7.803586, speed: 1.091973 steps/s, speed: 8.735788 samples/s, speed: 4472.723387 tokens/s, learning rate: 2.085e-05, loss_scalings: 3518.437988, pp_loss: 7.108169
[INFO] 2021-07-12 19:14:30,415 [run_pretraining.py:  512]:	********exe.run_2086******* 
[INFO] 2021-07-12 19:14:31,340 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:31,340 [run_pretraining.py:  534]:	loss/total_loss, 6.609748363494873, 2087
[INFO] 2021-07-12 19:14:31,340 [run_pretraining.py:  535]:	loss/mlm_loss, 6.609748363494873, 2087
[INFO] 2021-07-12 19:14:31,340 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.085999949485995e-05, 2087
[INFO] 2021-07-12 19:14:31,340 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2087
[INFO] 2021-07-12 19:14:31,340 [run_pretraining.py:  558]:	worker_index: 7, step: 2087, cost: 6.609748, mlm loss: 6.609748, speed: 1.080889 steps/s, speed: 8.647109 samples/s, speed: 4427.319808 tokens/s, learning rate: 2.086e-05, loss_scalings: 3518.437988, pp_loss: 7.068649
[INFO] 2021-07-12 19:14:31,340 [run_pretraining.py:  512]:	********exe.run_2087******* 
[INFO] 2021-07-12 19:14:32,263 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:32,264 [run_pretraining.py:  534]:	loss/total_loss, 7.52415657043457, 2088
[INFO] 2021-07-12 19:14:32,264 [run_pretraining.py:  535]:	loss/mlm_loss, 7.52415657043457, 2088
[INFO] 2021-07-12 19:14:32,264 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0870000298600644e-05, 2088
[INFO] 2021-07-12 19:14:32,264 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2088
[INFO] 2021-07-12 19:14:32,264 [run_pretraining.py:  558]:	worker_index: 7, step: 2088, cost: 7.524157, mlm loss: 7.524157, speed: 1.083651 steps/s, speed: 8.669209 samples/s, speed: 4438.634808 tokens/s, learning rate: 2.087e-05, loss_scalings: 3518.437988, pp_loss: 7.351165
[INFO] 2021-07-12 19:14:32,264 [run_pretraining.py:  512]:	********exe.run_2088******* 
[INFO] 2021-07-12 19:14:33,186 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:33,187 [run_pretraining.py:  534]:	loss/total_loss, 6.669919967651367, 2089
[INFO] 2021-07-12 19:14:33,187 [run_pretraining.py:  535]:	loss/mlm_loss, 6.669919967651367, 2089
[INFO] 2021-07-12 19:14:33,187 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0879999283351935e-05, 2089
[INFO] 2021-07-12 19:14:33,187 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2089
[INFO] 2021-07-12 19:14:33,187 [run_pretraining.py:  558]:	worker_index: 7, step: 2089, cost: 6.669920, mlm loss: 6.669920, speed: 1.083656 steps/s, speed: 8.669249 samples/s, speed: 4438.655450 tokens/s, learning rate: 2.088e-05, loss_scalings: 3518.437988, pp_loss: 5.955080
[INFO] 2021-07-12 19:14:33,187 [run_pretraining.py:  512]:	********exe.run_2089******* 
[INFO] 2021-07-12 19:14:34,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:34,101 [run_pretraining.py:  534]:	loss/total_loss, 8.846739768981934, 2090
[INFO] 2021-07-12 19:14:34,102 [run_pretraining.py:  535]:	loss/mlm_loss, 8.846739768981934, 2090
[INFO] 2021-07-12 19:14:34,102 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.089000008709263e-05, 2090
[INFO] 2021-07-12 19:14:34,102 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2090
[INFO] 2021-07-12 19:14:34,102 [run_pretraining.py:  558]:	worker_index: 7, step: 2090, cost: 8.846740, mlm loss: 8.846740, speed: 1.094282 steps/s, speed: 8.754256 samples/s, speed: 4482.178946 tokens/s, learning rate: 2.089e-05, loss_scalings: 3518.437988, pp_loss: 7.594189
[INFO] 2021-07-12 19:14:34,102 [run_pretraining.py:  512]:	********exe.run_2090******* 
[INFO] 2021-07-12 19:14:35,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:35,022 [run_pretraining.py:  534]:	loss/total_loss, 7.661551475524902, 2091
[INFO] 2021-07-12 19:14:35,022 [run_pretraining.py:  535]:	loss/mlm_loss, 7.661551475524902, 2091
[INFO] 2021-07-12 19:14:35,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0900000890833326e-05, 2091
[INFO] 2021-07-12 19:14:35,022 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2091
[INFO] 2021-07-12 19:14:35,022 [run_pretraining.py:  558]:	worker_index: 7, step: 2091, cost: 7.661551, mlm loss: 7.661551, speed: 1.087697 steps/s, speed: 8.701573 samples/s, speed: 4455.205443 tokens/s, learning rate: 2.090e-05, loss_scalings: 3518.437988, pp_loss: 7.407324
[INFO] 2021-07-12 19:14:35,022 [run_pretraining.py:  512]:	********exe.run_2091******* 
[INFO] 2021-07-12 19:14:35,943 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  534]:	loss/total_loss, 7.535009384155273, 2092
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  535]:	loss/mlm_loss, 7.535009384155273, 2092
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0909998056595214e-05, 2092
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2092
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  558]:	worker_index: 7, step: 2092, cost: 7.535009, mlm loss: 7.535009, speed: 1.085193 steps/s, speed: 8.681547 samples/s, speed: 4444.952207 tokens/s, learning rate: 2.091e-05, loss_scalings: 3518.437988, pp_loss: 7.343637
[INFO] 2021-07-12 19:14:35,944 [run_pretraining.py:  512]:	********exe.run_2092******* 
[INFO] 2021-07-12 19:14:36,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:36,867 [run_pretraining.py:  534]:	loss/total_loss, 8.160024642944336, 2093
[INFO] 2021-07-12 19:14:36,868 [run_pretraining.py:  535]:	loss/mlm_loss, 8.160024642944336, 2093
[INFO] 2021-07-12 19:14:36,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.091999886033591e-05, 2093
[INFO] 2021-07-12 19:14:36,868 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2093
[INFO] 2021-07-12 19:14:36,868 [run_pretraining.py:  558]:	worker_index: 7, step: 2093, cost: 8.160025, mlm loss: 8.160025, speed: 1.083297 steps/s, speed: 8.666376 samples/s, speed: 4437.184609 tokens/s, learning rate: 2.092e-05, loss_scalings: 3518.437988, pp_loss: 7.465374
[INFO] 2021-07-12 19:14:36,868 [run_pretraining.py:  512]:	********exe.run_2093******* 
[INFO] 2021-07-12 19:14:37,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:37,790 [run_pretraining.py:  534]:	loss/total_loss, 6.530209064483643, 2094
[INFO] 2021-07-12 19:14:37,790 [run_pretraining.py:  535]:	loss/mlm_loss, 6.530209064483643, 2094
[INFO] 2021-07-12 19:14:37,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0929999664076604e-05, 2094
[INFO] 2021-07-12 19:14:37,790 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2094
[INFO] 2021-07-12 19:14:37,790 [run_pretraining.py:  558]:	worker_index: 7, step: 2094, cost: 6.530209, mlm loss: 6.530209, speed: 1.084625 steps/s, speed: 8.677001 samples/s, speed: 4442.624588 tokens/s, learning rate: 2.093e-05, loss_scalings: 3518.437988, pp_loss: 6.720993
[INFO] 2021-07-12 19:14:37,790 [run_pretraining.py:  512]:	********exe.run_2094******* 
[INFO] 2021-07-12 19:14:38,726 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:38,727 [run_pretraining.py:  534]:	loss/total_loss, 7.5907883644104, 2095
[INFO] 2021-07-12 19:14:38,727 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5907883644104, 2095
[INFO] 2021-07-12 19:14:38,727 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0939998648827896e-05, 2095
[INFO] 2021-07-12 19:14:38,727 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2095
[INFO] 2021-07-12 19:14:38,727 [run_pretraining.py:  558]:	worker_index: 7, step: 2095, cost: 7.590788, mlm loss: 7.590788, speed: 1.068563 steps/s, speed: 8.548501 samples/s, speed: 4376.832668 tokens/s, learning rate: 2.094e-05, loss_scalings: 3518.437988, pp_loss: 6.904135
[INFO] 2021-07-12 19:14:38,727 [run_pretraining.py:  512]:	********exe.run_2095******* 
[INFO] 2021-07-12 19:14:39,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:39,639 [run_pretraining.py:  534]:	loss/total_loss, 7.288866996765137, 2096
[INFO] 2021-07-12 19:14:39,639 [run_pretraining.py:  535]:	loss/mlm_loss, 7.288866996765137, 2096
[INFO] 2021-07-12 19:14:39,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.094999945256859e-05, 2096
[INFO] 2021-07-12 19:14:39,639 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2096
[INFO] 2021-07-12 19:14:39,640 [run_pretraining.py:  558]:	worker_index: 7, step: 2096, cost: 7.288867, mlm loss: 7.288867, speed: 1.096554 steps/s, speed: 8.772430 samples/s, speed: 4491.484333 tokens/s, learning rate: 2.095e-05, loss_scalings: 3518.437988, pp_loss: 7.143927
[INFO] 2021-07-12 19:14:39,640 [run_pretraining.py:  512]:	********exe.run_2096******* 
[INFO] 2021-07-12 19:14:40,567 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:40,567 [run_pretraining.py:  534]:	loss/total_loss, 7.111985683441162, 2097
[INFO] 2021-07-12 19:14:40,567 [run_pretraining.py:  535]:	loss/mlm_loss, 7.111985683441162, 2097
[INFO] 2021-07-12 19:14:40,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0960000256309286e-05, 2097
[INFO] 2021-07-12 19:14:40,568 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2097
[INFO] 2021-07-12 19:14:40,568 [run_pretraining.py:  558]:	worker_index: 7, step: 2097, cost: 7.111986, mlm loss: 7.111986, speed: 1.078254 steps/s, speed: 8.626031 samples/s, speed: 4416.527807 tokens/s, learning rate: 2.096e-05, loss_scalings: 3518.437988, pp_loss: 7.725891
[INFO] 2021-07-12 19:14:40,568 [run_pretraining.py:  512]:	********exe.run_2097******* 
[INFO] 2021-07-12 19:14:41,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:41,484 [run_pretraining.py:  534]:	loss/total_loss, 7.2119646072387695, 2098
[INFO] 2021-07-12 19:14:41,484 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2119646072387695, 2098
[INFO] 2021-07-12 19:14:41,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0969999241060577e-05, 2098
[INFO] 2021-07-12 19:14:41,484 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2098
[INFO] 2021-07-12 19:14:41,484 [run_pretraining.py:  558]:	worker_index: 7, step: 2098, cost: 7.211965, mlm loss: 7.211965, speed: 1.091502 steps/s, speed: 8.732019 samples/s, speed: 4470.793547 tokens/s, learning rate: 2.097e-05, loss_scalings: 3518.437988, pp_loss: 7.182621
[INFO] 2021-07-12 19:14:41,485 [run_pretraining.py:  512]:	********exe.run_2098******* 
[INFO] 2021-07-12 19:14:42,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:42,402 [run_pretraining.py:  534]:	loss/total_loss, 7.125916004180908, 2099
[INFO] 2021-07-12 19:14:42,403 [run_pretraining.py:  535]:	loss/mlm_loss, 7.125916004180908, 2099
[INFO] 2021-07-12 19:14:42,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0980000044801272e-05, 2099
[INFO] 2021-07-12 19:14:42,403 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2099
[INFO] 2021-07-12 19:14:42,403 [run_pretraining.py:  558]:	worker_index: 7, step: 2099, cost: 7.125916, mlm loss: 7.125916, speed: 1.089723 steps/s, speed: 8.717787 samples/s, speed: 4463.507092 tokens/s, learning rate: 2.098e-05, loss_scalings: 3518.437988, pp_loss: 7.804540
[INFO] 2021-07-12 19:14:42,403 [run_pretraining.py:  512]:	********exe.run_2099******* 
[INFO] 2021-07-12 19:14:43,314 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:43,314 [run_pretraining.py:  534]:	loss/total_loss, 7.336758613586426, 2100
[INFO] 2021-07-12 19:14:43,314 [run_pretraining.py:  535]:	loss/mlm_loss, 7.336758613586426, 2100
[INFO] 2021-07-12 19:14:43,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0990000848541968e-05, 2100
[INFO] 2021-07-12 19:14:43,315 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2100
[INFO] 2021-07-12 19:14:43,315 [run_pretraining.py:  558]:	worker_index: 7, step: 2100, cost: 7.336759, mlm loss: 7.336759, speed: 1.097458 steps/s, speed: 8.779663 samples/s, speed: 4495.187440 tokens/s, learning rate: 2.099e-05, loss_scalings: 3518.437988, pp_loss: 7.239601
[INFO] 2021-07-12 19:14:43,315 [run_pretraining.py:  512]:	********exe.run_2100******* 
[INFO] 2021-07-12 19:14:44,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:44,231 [run_pretraining.py:  534]:	loss/total_loss, 8.153414726257324, 2101
[INFO] 2021-07-12 19:14:44,231 [run_pretraining.py:  535]:	loss/mlm_loss, 8.153414726257324, 2101
[INFO] 2021-07-12 19:14:44,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.0999998014303856e-05, 2101
[INFO] 2021-07-12 19:14:44,232 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2101
[INFO] 2021-07-12 19:14:44,232 [run_pretraining.py:  558]:	worker_index: 7, step: 2101, cost: 8.153415, mlm loss: 8.153415, speed: 1.091308 steps/s, speed: 8.730465 samples/s, speed: 4469.997886 tokens/s, learning rate: 2.100e-05, loss_scalings: 3518.437988, pp_loss: 7.494842
[INFO] 2021-07-12 19:14:44,232 [run_pretraining.py:  512]:	********exe.run_2101******* 
[INFO] 2021-07-12 19:14:45,157 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:45,158 [run_pretraining.py:  534]:	loss/total_loss, 7.123020172119141, 2102
[INFO] 2021-07-12 19:14:45,158 [run_pretraining.py:  535]:	loss/mlm_loss, 7.123020172119141, 2102
[INFO] 2021-07-12 19:14:45,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.100999881804455e-05, 2102
[INFO] 2021-07-12 19:14:45,158 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2102
[INFO] 2021-07-12 19:14:45,158 [run_pretraining.py:  558]:	worker_index: 7, step: 2102, cost: 7.123020, mlm loss: 7.123020, speed: 1.080269 steps/s, speed: 8.642151 samples/s, speed: 4424.781537 tokens/s, learning rate: 2.101e-05, loss_scalings: 3518.437988, pp_loss: 7.145493
[INFO] 2021-07-12 19:14:45,158 [run_pretraining.py:  512]:	********exe.run_2102******* 
[INFO] 2021-07-12 19:14:46,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:46,081 [run_pretraining.py:  534]:	loss/total_loss, 7.942364692687988, 2103
[INFO] 2021-07-12 19:14:46,081 [run_pretraining.py:  535]:	loss/mlm_loss, 7.942364692687988, 2103
[INFO] 2021-07-12 19:14:46,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1019999621785246e-05, 2103
[INFO] 2021-07-12 19:14:46,081 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2103
[INFO] 2021-07-12 19:14:46,081 [run_pretraining.py:  558]:	worker_index: 7, step: 2103, cost: 7.942365, mlm loss: 7.942365, speed: 1.084008 steps/s, speed: 8.672063 samples/s, speed: 4440.096283 tokens/s, learning rate: 2.102e-05, loss_scalings: 3518.437988, pp_loss: 7.384193
[INFO] 2021-07-12 19:14:46,081 [run_pretraining.py:  512]:	********exe.run_2103******* 
[INFO] 2021-07-12 19:14:46,995 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:46,996 [run_pretraining.py:  534]:	loss/total_loss, 6.969693183898926, 2104
[INFO] 2021-07-12 19:14:46,996 [run_pretraining.py:  535]:	loss/mlm_loss, 6.969693183898926, 2104
[INFO] 2021-07-12 19:14:46,996 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1029998606536537e-05, 2104
[INFO] 2021-07-12 19:14:46,996 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2104
[INFO] 2021-07-12 19:14:46,996 [run_pretraining.py:  558]:	worker_index: 7, step: 2104, cost: 6.969693, mlm loss: 6.969693, speed: 1.093457 steps/s, speed: 8.747656 samples/s, speed: 4478.799627 tokens/s, learning rate: 2.103e-05, loss_scalings: 3518.437988, pp_loss: 7.019224
[INFO] 2021-07-12 19:14:46,996 [run_pretraining.py:  512]:	********exe.run_2104******* 
[INFO] 2021-07-12 19:14:47,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:47,912 [run_pretraining.py:  534]:	loss/total_loss, 6.805521011352539, 2105
[INFO] 2021-07-12 19:14:47,912 [run_pretraining.py:  535]:	loss/mlm_loss, 6.805521011352539, 2105
[INFO] 2021-07-12 19:14:47,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1039999410277233e-05, 2105
[INFO] 2021-07-12 19:14:47,912 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2105
[INFO] 2021-07-12 19:14:47,912 [run_pretraining.py:  558]:	worker_index: 7, step: 2105, cost: 6.805521, mlm loss: 6.805521, speed: 1.092426 steps/s, speed: 8.739406 samples/s, speed: 4474.575644 tokens/s, learning rate: 2.104e-05, loss_scalings: 3518.437988, pp_loss: 7.254557
[INFO] 2021-07-12 19:14:47,912 [run_pretraining.py:  512]:	********exe.run_2105******* 
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  534]:	loss/total_loss, 7.505929470062256, 2106
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  535]:	loss/mlm_loss, 7.505929470062256, 2106
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1050000214017928e-05, 2106
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2106
[INFO] 2021-07-12 19:14:48,830 [run_pretraining.py:  558]:	worker_index: 7, step: 2106, cost: 7.505929, mlm loss: 7.505929, speed: 1.089936 steps/s, speed: 8.719489 samples/s, speed: 4464.378171 tokens/s, learning rate: 2.105e-05, loss_scalings: 3518.437988, pp_loss: 7.328206
[INFO] 2021-07-12 19:14:48,831 [run_pretraining.py:  512]:	********exe.run_2106******* 
[INFO] 2021-07-12 19:14:49,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:49,789 [run_pretraining.py:  534]:	loss/total_loss, 6.524193286895752, 2107
[INFO] 2021-07-12 19:14:49,789 [run_pretraining.py:  535]:	loss/mlm_loss, 6.524193286895752, 2107
[INFO] 2021-07-12 19:14:49,789 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.105999919876922e-05, 2107
[INFO] 2021-07-12 19:14:49,790 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2107
[INFO] 2021-07-12 19:14:49,790 [run_pretraining.py:  558]:	worker_index: 7, step: 2107, cost: 6.524193, mlm loss: 6.524193, speed: 1.043357 steps/s, speed: 8.346855 samples/s, speed: 4273.589732 tokens/s, learning rate: 2.106e-05, loss_scalings: 3518.437988, pp_loss: 6.902287
[INFO] 2021-07-12 19:14:49,790 [run_pretraining.py:  512]:	********exe.run_2107******* 
[INFO] 2021-07-12 19:14:50,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:50,847 [run_pretraining.py:  534]:	loss/total_loss, 7.544485092163086, 2108
[INFO] 2021-07-12 19:14:50,847 [run_pretraining.py:  535]:	loss/mlm_loss, 7.544485092163086, 2108
[INFO] 2021-07-12 19:14:50,847 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1070000002509914e-05, 2108
[INFO] 2021-07-12 19:14:50,848 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2108
[INFO] 2021-07-12 19:14:50,848 [run_pretraining.py:  558]:	worker_index: 7, step: 2108, cost: 7.544485, mlm loss: 7.544485, speed: 0.945777 steps/s, speed: 7.566219 samples/s, speed: 3873.903958 tokens/s, learning rate: 2.107e-05, loss_scalings: 3518.437988, pp_loss: 7.317289
[INFO] 2021-07-12 19:14:50,848 [run_pretraining.py:  512]:	********exe.run_2108******* 
[INFO] 2021-07-12 19:14:51,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:51,905 [run_pretraining.py:  534]:	loss/total_loss, 6.665624618530273, 2109
[INFO] 2021-07-12 19:14:51,905 [run_pretraining.py:  535]:	loss/mlm_loss, 6.665624618530273, 2109
[INFO] 2021-07-12 19:14:51,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.108000080625061e-05, 2109
[INFO] 2021-07-12 19:14:51,906 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2109
[INFO] 2021-07-12 19:14:51,906 [run_pretraining.py:  558]:	worker_index: 7, step: 2109, cost: 6.665625, mlm loss: 6.665625, speed: 0.945737 steps/s, speed: 7.565893 samples/s, speed: 3873.737121 tokens/s, learning rate: 2.108e-05, loss_scalings: 3518.437988, pp_loss: 6.790874
[INFO] 2021-07-12 19:14:51,906 [run_pretraining.py:  512]:	********exe.run_2109******* 
[INFO] 2021-07-12 19:14:52,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:52,965 [run_pretraining.py:  534]:	loss/total_loss, 7.933984756469727, 2110
[INFO] 2021-07-12 19:14:52,965 [run_pretraining.py:  535]:	loss/mlm_loss, 7.933984756469727, 2110
[INFO] 2021-07-12 19:14:52,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1089997972012497e-05, 2110
[INFO] 2021-07-12 19:14:52,965 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2110
[INFO] 2021-07-12 19:14:52,965 [run_pretraining.py:  558]:	worker_index: 7, step: 2110, cost: 7.933985, mlm loss: 7.933985, speed: 0.944162 steps/s, speed: 7.553295 samples/s, speed: 3867.286934 tokens/s, learning rate: 2.109e-05, loss_scalings: 3518.437988, pp_loss: 7.468814
[INFO] 2021-07-12 19:14:52,966 [run_pretraining.py:  512]:	********exe.run_2110******* 
[INFO] 2021-07-12 19:14:54,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:54,026 [run_pretraining.py:  534]:	loss/total_loss, 8.014750480651855, 2111
[INFO] 2021-07-12 19:14:54,026 [run_pretraining.py:  535]:	loss/mlm_loss, 8.014750480651855, 2111
[INFO] 2021-07-12 19:14:54,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1099998775753193e-05, 2111
[INFO] 2021-07-12 19:14:54,026 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2111
[INFO] 2021-07-12 19:14:54,026 [run_pretraining.py:  558]:	worker_index: 7, step: 2111, cost: 8.014750, mlm loss: 8.014750, speed: 0.943593 steps/s, speed: 7.548746 samples/s, speed: 3864.957880 tokens/s, learning rate: 2.110e-05, loss_scalings: 3518.437988, pp_loss: 7.592911
[INFO] 2021-07-12 19:14:54,026 [run_pretraining.py:  512]:	********exe.run_2111******* 
[INFO] 2021-07-12 19:14:55,080 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:55,081 [run_pretraining.py:  534]:	loss/total_loss, 6.968952178955078, 2112
[INFO] 2021-07-12 19:14:55,081 [run_pretraining.py:  535]:	loss/mlm_loss, 6.968952178955078, 2112
[INFO] 2021-07-12 19:14:55,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1109999579493888e-05, 2112
[INFO] 2021-07-12 19:14:55,081 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2112
[INFO] 2021-07-12 19:14:55,081 [run_pretraining.py:  558]:	worker_index: 7, step: 2112, cost: 6.968952, mlm loss: 6.968952, speed: 0.948063 steps/s, speed: 7.584506 samples/s, speed: 3883.267192 tokens/s, learning rate: 2.111e-05, loss_scalings: 3518.437988, pp_loss: 7.376630
[INFO] 2021-07-12 19:14:55,081 [run_pretraining.py:  512]:	********exe.run_2112******* 
[INFO] 2021-07-12 19:14:56,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:56,134 [run_pretraining.py:  534]:	loss/total_loss, 7.351060390472412, 2113
[INFO] 2021-07-12 19:14:56,134 [run_pretraining.py:  535]:	loss/mlm_loss, 7.351060390472412, 2113
[INFO] 2021-07-12 19:14:56,134 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.111999856424518e-05, 2113
[INFO] 2021-07-12 19:14:56,134 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2113
[INFO] 2021-07-12 19:14:56,134 [run_pretraining.py:  558]:	worker_index: 7, step: 2113, cost: 7.351060, mlm loss: 7.351060, speed: 0.950180 steps/s, speed: 7.601443 samples/s, speed: 3891.938570 tokens/s, learning rate: 2.112e-05, loss_scalings: 3518.437988, pp_loss: 7.369017
[INFO] 2021-07-12 19:14:56,134 [run_pretraining.py:  512]:	********exe.run_2113******* 
[INFO] 2021-07-12 19:14:57,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  534]:	loss/total_loss, 7.1143646240234375, 2114
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1143646240234375, 2114
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1129999367985874e-05, 2114
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2114
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  558]:	worker_index: 7, step: 2114, cost: 7.114365, mlm loss: 7.114365, speed: 0.943518 steps/s, speed: 7.548143 samples/s, speed: 3864.649232 tokens/s, learning rate: 2.113e-05, loss_scalings: 3518.437988, pp_loss: 7.429442
[INFO] 2021-07-12 19:14:57,195 [run_pretraining.py:  512]:	********exe.run_2114******* 
[INFO] 2021-07-12 19:14:58,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:58,257 [run_pretraining.py:  534]:	loss/total_loss, 7.094508171081543, 2115
[INFO] 2021-07-12 19:14:58,258 [run_pretraining.py:  535]:	loss/mlm_loss, 7.094508171081543, 2115
[INFO] 2021-07-12 19:14:58,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.114000017172657e-05, 2115
[INFO] 2021-07-12 19:14:58,258 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2115
[INFO] 2021-07-12 19:14:58,258 [run_pretraining.py:  558]:	worker_index: 7, step: 2115, cost: 7.094508, mlm loss: 7.094508, speed: 0.941382 steps/s, speed: 7.531058 samples/s, speed: 3855.901568 tokens/s, learning rate: 2.114e-05, loss_scalings: 3518.437988, pp_loss: 7.236320
[INFO] 2021-07-12 19:14:58,258 [run_pretraining.py:  512]:	********exe.run_2115******* 
[INFO] 2021-07-12 19:14:59,318 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:14:59,319 [run_pretraining.py:  534]:	loss/total_loss, 7.039890289306641, 2116
[INFO] 2021-07-12 19:14:59,319 [run_pretraining.py:  535]:	loss/mlm_loss, 7.039890289306641, 2116
[INFO] 2021-07-12 19:14:59,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.114999915647786e-05, 2116
[INFO] 2021-07-12 19:14:59,319 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2116
[INFO] 2021-07-12 19:14:59,319 [run_pretraining.py:  558]:	worker_index: 7, step: 2116, cost: 7.039890, mlm loss: 7.039890, speed: 0.943045 steps/s, speed: 7.544364 samples/s, speed: 3862.714134 tokens/s, learning rate: 2.115e-05, loss_scalings: 3518.437988, pp_loss: 7.293590
[INFO] 2021-07-12 19:14:59,319 [run_pretraining.py:  512]:	********exe.run_2116******* 
[INFO] 2021-07-12 19:15:00,388 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:00,389 [run_pretraining.py:  534]:	loss/total_loss, 7.153765678405762, 2117
[INFO] 2021-07-12 19:15:00,389 [run_pretraining.py:  535]:	loss/mlm_loss, 7.153765678405762, 2117
[INFO] 2021-07-12 19:15:00,389 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1159999960218556e-05, 2117
[INFO] 2021-07-12 19:15:00,389 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2117
[INFO] 2021-07-12 19:15:00,389 [run_pretraining.py:  558]:	worker_index: 7, step: 2117, cost: 7.153766, mlm loss: 7.153766, speed: 0.935111 steps/s, speed: 7.480888 samples/s, speed: 3830.214780 tokens/s, learning rate: 2.116e-05, loss_scalings: 3518.437988, pp_loss: 6.256867
[INFO] 2021-07-12 19:15:00,389 [run_pretraining.py:  512]:	********exe.run_2117******* 
[INFO] 2021-07-12 19:15:01,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:01,447 [run_pretraining.py:  534]:	loss/total_loss, 6.253064155578613, 2118
[INFO] 2021-07-12 19:15:01,448 [run_pretraining.py:  535]:	loss/mlm_loss, 6.253064155578613, 2118
[INFO] 2021-07-12 19:15:01,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.117000076395925e-05, 2118
[INFO] 2021-07-12 19:15:01,448 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2118
[INFO] 2021-07-12 19:15:01,448 [run_pretraining.py:  558]:	worker_index: 7, step: 2118, cost: 6.253064, mlm loss: 6.253064, speed: 0.944973 steps/s, speed: 7.559787 samples/s, speed: 3870.610931 tokens/s, learning rate: 2.117e-05, loss_scalings: 3518.437988, pp_loss: 6.933099
[INFO] 2021-07-12 19:15:01,448 [run_pretraining.py:  512]:	********exe.run_2118******* 
[INFO] 2021-07-12 19:15:02,506 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:02,506 [run_pretraining.py:  534]:	loss/total_loss, 7.566537857055664, 2119
[INFO] 2021-07-12 19:15:02,506 [run_pretraining.py:  535]:	loss/mlm_loss, 7.566537857055664, 2119
[INFO] 2021-07-12 19:15:02,507 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1179999748710543e-05, 2119
[INFO] 2021-07-12 19:15:02,507 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2119
[INFO] 2021-07-12 19:15:02,507 [run_pretraining.py:  558]:	worker_index: 7, step: 2119, cost: 7.566538, mlm loss: 7.566538, speed: 0.944951 steps/s, speed: 7.559605 samples/s, speed: 3870.517625 tokens/s, learning rate: 2.118e-05, loss_scalings: 3518.437988, pp_loss: 7.534460
[INFO] 2021-07-12 19:15:02,507 [run_pretraining.py:  512]:	********exe.run_2119******* 
[INFO] 2021-07-12 19:15:03,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  534]:	loss/total_loss, 6.860088348388672, 2120
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  535]:	loss/mlm_loss, 6.860088348388672, 2120
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1189998733461834e-05, 2120
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2120
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  558]:	worker_index: 7, step: 2120, cost: 6.860088, mlm loss: 6.860088, speed: 0.941739 steps/s, speed: 7.533914 samples/s, speed: 3857.363834 tokens/s, learning rate: 2.119e-05, loss_scalings: 3518.437988, pp_loss: 7.416093
[INFO] 2021-07-12 19:15:03,569 [run_pretraining.py:  512]:	********exe.run_2120******* 
[INFO] 2021-07-12 19:15:04,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:04,630 [run_pretraining.py:  534]:	loss/total_loss, 7.027947425842285, 2121
[INFO] 2021-07-12 19:15:04,631 [run_pretraining.py:  535]:	loss/mlm_loss, 7.027947425842285, 2121
[INFO] 2021-07-12 19:15:04,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.119999953720253e-05, 2121
[INFO] 2021-07-12 19:15:04,631 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2121
[INFO] 2021-07-12 19:15:04,631 [run_pretraining.py:  558]:	worker_index: 7, step: 2121, cost: 7.027947, mlm loss: 7.027947, speed: 0.942599 steps/s, speed: 7.540795 samples/s, speed: 3860.886825 tokens/s, learning rate: 2.120e-05, loss_scalings: 3518.437988, pp_loss: 7.019801
[INFO] 2021-07-12 19:15:04,631 [run_pretraining.py:  512]:	********exe.run_2121******* 
[INFO] 2021-07-12 19:15:05,692 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:05,693 [run_pretraining.py:  534]:	loss/total_loss, 7.79340934753418, 2122
[INFO] 2021-07-12 19:15:05,693 [run_pretraining.py:  535]:	loss/mlm_loss, 7.79340934753418, 2122
[INFO] 2021-07-12 19:15:05,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.120999852195382e-05, 2122
[INFO] 2021-07-12 19:15:05,693 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2122
[INFO] 2021-07-12 19:15:05,693 [run_pretraining.py:  558]:	worker_index: 7, step: 2122, cost: 7.793409, mlm loss: 7.793409, speed: 0.941717 steps/s, speed: 7.533740 samples/s, speed: 3857.274629 tokens/s, learning rate: 2.121e-05, loss_scalings: 3518.437988, pp_loss: 7.574898
[INFO] 2021-07-12 19:15:05,693 [run_pretraining.py:  512]:	********exe.run_2122******* 
[INFO] 2021-07-12 19:15:06,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:06,758 [run_pretraining.py:  534]:	loss/total_loss, 7.265261650085449, 2123
[INFO] 2021-07-12 19:15:06,758 [run_pretraining.py:  535]:	loss/mlm_loss, 7.265261650085449, 2123
[INFO] 2021-07-12 19:15:06,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1219999325694516e-05, 2123
[INFO] 2021-07-12 19:15:06,758 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2123
[INFO] 2021-07-12 19:15:06,758 [run_pretraining.py:  558]:	worker_index: 7, step: 2123, cost: 7.265262, mlm loss: 7.265262, speed: 0.939645 steps/s, speed: 7.517164 samples/s, speed: 3848.787899 tokens/s, learning rate: 2.122e-05, loss_scalings: 3518.437988, pp_loss: 7.265218
[INFO] 2021-07-12 19:15:06,758 [run_pretraining.py:  512]:	********exe.run_2123******* 
[INFO] 2021-07-12 19:15:07,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:07,818 [run_pretraining.py:  534]:	loss/total_loss, 7.340094089508057, 2124
[INFO] 2021-07-12 19:15:07,819 [run_pretraining.py:  535]:	loss/mlm_loss, 7.340094089508057, 2124
[INFO] 2021-07-12 19:15:07,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.123000012943521e-05, 2124
[INFO] 2021-07-12 19:15:07,819 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2124
[INFO] 2021-07-12 19:15:07,819 [run_pretraining.py:  558]:	worker_index: 7, step: 2124, cost: 7.340094, mlm loss: 7.340094, speed: 0.943511 steps/s, speed: 7.548090 samples/s, speed: 3864.622282 tokens/s, learning rate: 2.123e-05, loss_scalings: 3518.437988, pp_loss: 7.457610
[INFO] 2021-07-12 19:15:07,819 [run_pretraining.py:  512]:	********exe.run_2124******* 
[INFO] 2021-07-12 19:15:08,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:08,880 [run_pretraining.py:  534]:	loss/total_loss, 7.343416690826416, 2125
[INFO] 2021-07-12 19:15:08,880 [run_pretraining.py:  535]:	loss/mlm_loss, 7.343416690826416, 2125
[INFO] 2021-07-12 19:15:08,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1239999114186503e-05, 2125
[INFO] 2021-07-12 19:15:08,880 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2125
[INFO] 2021-07-12 19:15:08,880 [run_pretraining.py:  558]:	worker_index: 7, step: 2125, cost: 7.343417, mlm loss: 7.343417, speed: 0.942492 steps/s, speed: 7.539939 samples/s, speed: 3860.448702 tokens/s, learning rate: 2.124e-05, loss_scalings: 3518.437988, pp_loss: 7.012093
[INFO] 2021-07-12 19:15:08,880 [run_pretraining.py:  512]:	********exe.run_2125******* 
[INFO] 2021-07-12 19:15:09,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:09,964 [run_pretraining.py:  534]:	loss/total_loss, 6.719188690185547, 2126
[INFO] 2021-07-12 19:15:09,964 [run_pretraining.py:  535]:	loss/mlm_loss, 6.719188690185547, 2126
[INFO] 2021-07-12 19:15:09,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1249999917927198e-05, 2126
[INFO] 2021-07-12 19:15:09,964 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2126
[INFO] 2021-07-12 19:15:09,964 [run_pretraining.py:  558]:	worker_index: 7, step: 2126, cost: 6.719189, mlm loss: 6.719189, speed: 0.923529 steps/s, speed: 7.388229 samples/s, speed: 3782.773187 tokens/s, learning rate: 2.125e-05, loss_scalings: 3518.437988, pp_loss: 6.805906
[INFO] 2021-07-12 19:15:09,964 [run_pretraining.py:  512]:	********exe.run_2126******* 
[INFO] 2021-07-12 19:15:11,042 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:11,042 [run_pretraining.py:  534]:	loss/total_loss, 6.990296363830566, 2127
[INFO] 2021-07-12 19:15:11,042 [run_pretraining.py:  535]:	loss/mlm_loss, 6.990296363830566, 2127
[INFO] 2021-07-12 19:15:11,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.125999890267849e-05, 2127
[INFO] 2021-07-12 19:15:11,042 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2127
[INFO] 2021-07-12 19:15:11,042 [run_pretraining.py:  558]:	worker_index: 7, step: 2127, cost: 6.990296, mlm loss: 6.990296, speed: 0.927739 steps/s, speed: 7.421910 samples/s, speed: 3800.017824 tokens/s, learning rate: 2.126e-05, loss_scalings: 3518.437988, pp_loss: 6.804967
[INFO] 2021-07-12 19:15:11,042 [run_pretraining.py:  512]:	********exe.run_2127******* 
[INFO] 2021-07-12 19:15:12,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:12,102 [run_pretraining.py:  534]:	loss/total_loss, 7.10292387008667, 2128
[INFO] 2021-07-12 19:15:12,102 [run_pretraining.py:  535]:	loss/mlm_loss, 7.10292387008667, 2128
[INFO] 2021-07-12 19:15:12,102 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1269999706419185e-05, 2128
[INFO] 2021-07-12 19:15:12,102 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2128
[INFO] 2021-07-12 19:15:12,103 [run_pretraining.py:  558]:	worker_index: 7, step: 2128, cost: 7.102924, mlm loss: 7.102924, speed: 0.943779 steps/s, speed: 7.550234 samples/s, speed: 3865.719712 tokens/s, learning rate: 2.127e-05, loss_scalings: 3518.437988, pp_loss: 7.181825
[INFO] 2021-07-12 19:15:12,103 [run_pretraining.py:  512]:	********exe.run_2128******* 
[INFO] 2021-07-12 19:15:13,162 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:13,162 [run_pretraining.py:  534]:	loss/total_loss, 8.704331398010254, 2129
[INFO] 2021-07-12 19:15:13,162 [run_pretraining.py:  535]:	loss/mlm_loss, 8.704331398010254, 2129
[INFO] 2021-07-12 19:15:13,163 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1279998691170476e-05, 2129
[INFO] 2021-07-12 19:15:13,163 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2129
[INFO] 2021-07-12 19:15:13,163 [run_pretraining.py:  558]:	worker_index: 7, step: 2129, cost: 8.704331, mlm loss: 8.704331, speed: 0.943870 steps/s, speed: 7.550958 samples/s, speed: 3866.090301 tokens/s, learning rate: 2.128e-05, loss_scalings: 3518.437988, pp_loss: 7.398172
[INFO] 2021-07-12 19:15:13,163 [run_pretraining.py:  512]:	********exe.run_2129******* 
[INFO] 2021-07-12 19:15:14,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  534]:	loss/total_loss, 6.985564708709717, 2130
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  535]:	loss/mlm_loss, 6.985564708709717, 2130
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.128999949491117e-05, 2130
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2130
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  558]:	worker_index: 7, step: 2130, cost: 6.985565, mlm loss: 6.985565, speed: 0.947014 steps/s, speed: 7.576110 samples/s, speed: 3878.968309 tokens/s, learning rate: 2.129e-05, loss_scalings: 3518.437988, pp_loss: 7.410922
[INFO] 2021-07-12 19:15:14,219 [run_pretraining.py:  512]:	********exe.run_2130******* 
[INFO] 2021-07-12 19:15:15,284 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:15,285 [run_pretraining.py:  534]:	loss/total_loss, 7.104278087615967, 2131
[INFO] 2021-07-12 19:15:15,285 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104278087615967, 2131
[INFO] 2021-07-12 19:15:15,285 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1300000298651867e-05, 2131
[INFO] 2021-07-12 19:15:15,285 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2131
[INFO] 2021-07-12 19:15:15,285 [run_pretraining.py:  558]:	worker_index: 7, step: 2131, cost: 7.104278, mlm loss: 7.104278, speed: 0.938722 steps/s, speed: 7.509775 samples/s, speed: 3845.004664 tokens/s, learning rate: 2.130e-05, loss_scalings: 3518.437988, pp_loss: 7.395192
[INFO] 2021-07-12 19:15:15,285 [run_pretraining.py:  512]:	********exe.run_2131******* 
[INFO] 2021-07-12 19:15:16,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:16,347 [run_pretraining.py:  534]:	loss/total_loss, 7.822452545166016, 2132
[INFO] 2021-07-12 19:15:16,348 [run_pretraining.py:  535]:	loss/mlm_loss, 7.822452545166016, 2132
[INFO] 2021-07-12 19:15:16,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1309999283403158e-05, 2132
[INFO] 2021-07-12 19:15:16,348 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2132
[INFO] 2021-07-12 19:15:16,348 [run_pretraining.py:  558]:	worker_index: 7, step: 2132, cost: 7.822453, mlm loss: 7.822453, speed: 0.941699 steps/s, speed: 7.533594 samples/s, speed: 3857.200151 tokens/s, learning rate: 2.131e-05, loss_scalings: 3518.437988, pp_loss: 7.433028
[INFO] 2021-07-12 19:15:16,348 [run_pretraining.py:  512]:	********exe.run_2132******* 
[INFO] 2021-07-12 19:15:17,416 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  534]:	loss/total_loss, 7.0085906982421875, 2133
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0085906982421875, 2133
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1320000087143853e-05, 2133
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2133
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  558]:	worker_index: 7, step: 2133, cost: 7.008591, mlm loss: 7.008591, speed: 0.935598 steps/s, speed: 7.484786 samples/s, speed: 3832.210619 tokens/s, learning rate: 2.132e-05, loss_scalings: 3518.437988, pp_loss: 7.033408
[INFO] 2021-07-12 19:15:17,417 [run_pretraining.py:  512]:	********exe.run_2133******* 
[INFO] 2021-07-12 19:15:18,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  534]:	loss/total_loss, 5.9026031494140625, 2134
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  535]:	loss/mlm_loss, 5.9026031494140625, 2134
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1329999071895145e-05, 2134
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2134
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  558]:	worker_index: 7, step: 2134, cost: 5.902603, mlm loss: 5.902603, speed: 0.928545 steps/s, speed: 7.428357 samples/s, speed: 3803.318916 tokens/s, learning rate: 2.133e-05, loss_scalings: 3518.437988, pp_loss: 6.807265
[INFO] 2021-07-12 19:15:18,495 [run_pretraining.py:  512]:	********exe.run_2134******* 
[INFO] 2021-07-12 19:15:19,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:19,447 [run_pretraining.py:  534]:	loss/total_loss, 7.359046936035156, 2135
[INFO] 2021-07-12 19:15:19,447 [run_pretraining.py:  535]:	loss/mlm_loss, 7.359046936035156, 2135
[INFO] 2021-07-12 19:15:19,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.133999987563584e-05, 2135
[INFO] 2021-07-12 19:15:19,447 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2135
[INFO] 2021-07-12 19:15:19,447 [run_pretraining.py:  558]:	worker_index: 7, step: 2135, cost: 7.359047, mlm loss: 7.359047, speed: 1.051154 steps/s, speed: 8.409232 samples/s, speed: 4305.526600 tokens/s, learning rate: 2.134e-05, loss_scalings: 3518.437988, pp_loss: 7.255700
[INFO] 2021-07-12 19:15:19,447 [run_pretraining.py:  512]:	********exe.run_2135******* 
[INFO] 2021-07-12 19:15:20,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:20,358 [run_pretraining.py:  534]:	loss/total_loss, 7.420376777648926, 2136
[INFO] 2021-07-12 19:15:20,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.420376777648926, 2136
[INFO] 2021-07-12 19:15:20,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.134999886038713e-05, 2136
[INFO] 2021-07-12 19:15:20,359 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2136
[INFO] 2021-07-12 19:15:20,359 [run_pretraining.py:  558]:	worker_index: 7, step: 2136, cost: 7.420377, mlm loss: 7.420377, speed: 1.097632 steps/s, speed: 8.781055 samples/s, speed: 4495.900321 tokens/s, learning rate: 2.135e-05, loss_scalings: 3518.437988, pp_loss: 7.055427
[INFO] 2021-07-12 19:15:20,359 [run_pretraining.py:  512]:	********exe.run_2136******* 
[INFO] 2021-07-12 19:15:21,267 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:21,268 [run_pretraining.py:  534]:	loss/total_loss, 7.861723899841309, 2137
[INFO] 2021-07-12 19:15:21,268 [run_pretraining.py:  535]:	loss/mlm_loss, 7.861723899841309, 2137
[INFO] 2021-07-12 19:15:21,268 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1359999664127827e-05, 2137
[INFO] 2021-07-12 19:15:21,268 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2137
[INFO] 2021-07-12 19:15:21,268 [run_pretraining.py:  558]:	worker_index: 7, step: 2137, cost: 7.861724, mlm loss: 7.861724, speed: 1.100552 steps/s, speed: 8.804419 samples/s, speed: 4507.862366 tokens/s, learning rate: 2.136e-05, loss_scalings: 3518.437988, pp_loss: 7.342091
[INFO] 2021-07-12 19:15:21,268 [run_pretraining.py:  512]:	********exe.run_2137******* 
[INFO] 2021-07-12 19:15:22,179 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:22,179 [run_pretraining.py:  534]:	loss/total_loss, 7.380022048950195, 2138
[INFO] 2021-07-12 19:15:22,179 [run_pretraining.py:  535]:	loss/mlm_loss, 7.380022048950195, 2138
[INFO] 2021-07-12 19:15:22,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1369998648879118e-05, 2138
[INFO] 2021-07-12 19:15:22,180 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2138
[INFO] 2021-07-12 19:15:22,180 [run_pretraining.py:  558]:	worker_index: 7, step: 2138, cost: 7.380022, mlm loss: 7.380022, speed: 1.097668 steps/s, speed: 8.781343 samples/s, speed: 4496.047396 tokens/s, learning rate: 2.137e-05, loss_scalings: 3518.437988, pp_loss: 7.060036
[INFO] 2021-07-12 19:15:22,180 [run_pretraining.py:  512]:	********exe.run_2138******* 
[INFO] 2021-07-12 19:15:23,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:23,090 [run_pretraining.py:  534]:	loss/total_loss, 6.800697326660156, 2139
[INFO] 2021-07-12 19:15:23,090 [run_pretraining.py:  535]:	loss/mlm_loss, 6.800697326660156, 2139
[INFO] 2021-07-12 19:15:23,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1379999452619813e-05, 2139
[INFO] 2021-07-12 19:15:23,091 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2139
[INFO] 2021-07-12 19:15:23,091 [run_pretraining.py:  558]:	worker_index: 7, step: 2139, cost: 6.800697, mlm loss: 6.800697, speed: 1.098447 steps/s, speed: 8.787575 samples/s, speed: 4499.238341 tokens/s, learning rate: 2.138e-05, loss_scalings: 3518.437988, pp_loss: 6.762630
[INFO] 2021-07-12 19:15:23,091 [run_pretraining.py:  512]:	********exe.run_2139******* 
[INFO] 2021-07-12 19:15:23,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:23,997 [run_pretraining.py:  534]:	loss/total_loss, 5.726614475250244, 2140
[INFO] 2021-07-12 19:15:23,997 [run_pretraining.py:  535]:	loss/mlm_loss, 5.726614475250244, 2140
[INFO] 2021-07-12 19:15:23,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.139000025636051e-05, 2140
[INFO] 2021-07-12 19:15:23,997 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2140
[INFO] 2021-07-12 19:15:23,997 [run_pretraining.py:  558]:	worker_index: 7, step: 2140, cost: 5.726614, mlm loss: 5.726614, speed: 1.104036 steps/s, speed: 8.832289 samples/s, speed: 4522.132079 tokens/s, learning rate: 2.139e-05, loss_scalings: 3518.437988, pp_loss: 6.892110
[INFO] 2021-07-12 19:15:23,997 [run_pretraining.py:  512]:	********exe.run_2140******* 
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  534]:	loss/total_loss, 6.867308616638184, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  535]:	loss/mlm_loss, 6.867308616638184, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.13999992411118e-05, 2141
[INFO] 2021-07-12 19:15:24,899 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2141
[INFO] 2021-07-12 19:15:24,900 [run_pretraining.py:  558]:	worker_index: 7, step: 2141, cost: 6.867309, mlm loss: 6.867309, speed: 1.108928 steps/s, speed: 8.871422 samples/s, speed: 4542.167975 tokens/s, learning rate: 2.140e-05, loss_scalings: 3518.437988, pp_loss: 7.238088
[INFO] 2021-07-12 19:15:24,900 [run_pretraining.py:  512]:	********exe.run_2141******* 
[INFO] 2021-07-12 19:15:25,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:25,804 [run_pretraining.py:  534]:	loss/total_loss, 6.893749713897705, 2142
[INFO] 2021-07-12 19:15:25,804 [run_pretraining.py:  535]:	loss/mlm_loss, 6.893749713897705, 2142
[INFO] 2021-07-12 19:15:25,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1410000044852495e-05, 2142
[INFO] 2021-07-12 19:15:25,804 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2142
[INFO] 2021-07-12 19:15:25,804 [run_pretraining.py:  558]:	worker_index: 7, step: 2142, cost: 6.893750, mlm loss: 6.893750, speed: 1.106341 steps/s, speed: 8.850729 samples/s, speed: 4531.573194 tokens/s, learning rate: 2.141e-05, loss_scalings: 3518.437988, pp_loss: 7.165278
[INFO] 2021-07-12 19:15:25,804 [run_pretraining.py:  512]:	********exe.run_2142******* 
[INFO] 2021-07-12 19:15:26,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:26,711 [run_pretraining.py:  534]:	loss/total_loss, 7.537703990936279, 2143
[INFO] 2021-07-12 19:15:26,711 [run_pretraining.py:  535]:	loss/mlm_loss, 7.537703990936279, 2143
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.142000084859319e-05, 2143
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2143
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  558]:	worker_index: 7, step: 2143, cost: 7.537704, mlm loss: 7.537704, speed: 1.102662 steps/s, speed: 8.821297 samples/s, speed: 4516.504079 tokens/s, learning rate: 2.142e-05, loss_scalings: 3518.437988, pp_loss: 7.323936
[INFO] 2021-07-12 19:15:26,712 [run_pretraining.py:  512]:	********exe.run_2143******* 
[INFO] 2021-07-12 19:15:27,633 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  534]:	loss/total_loss, 7.696662425994873, 2144
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  535]:	loss/mlm_loss, 7.696662425994873, 2144
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1429999833344482e-05, 2144
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2144
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  558]:	worker_index: 7, step: 2144, cost: 7.696662, mlm loss: 7.696662, speed: 1.085056 steps/s, speed: 8.680447 samples/s, speed: 4444.388757 tokens/s, learning rate: 2.143e-05, loss_scalings: 3518.437988, pp_loss: 7.727364
[INFO] 2021-07-12 19:15:27,634 [run_pretraining.py:  512]:	********exe.run_2144******* 
[INFO] 2021-07-12 19:15:28,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:28,540 [run_pretraining.py:  534]:	loss/total_loss, 7.333486557006836, 2145
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  535]:	loss/mlm_loss, 7.333486557006836, 2145
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1439998818095773e-05, 2145
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2145
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  558]:	worker_index: 7, step: 2145, cost: 7.333487, mlm loss: 7.333487, speed: 1.103451 steps/s, speed: 8.827612 samples/s, speed: 4519.737218 tokens/s, learning rate: 2.144e-05, loss_scalings: 3518.437988, pp_loss: 7.288225
[INFO] 2021-07-12 19:15:28,541 [run_pretraining.py:  512]:	********exe.run_2145******* 
[INFO] 2021-07-12 19:15:29,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:29,481 [run_pretraining.py:  534]:	loss/total_loss, 7.418625354766846, 2146
[INFO] 2021-07-12 19:15:29,481 [run_pretraining.py:  535]:	loss/mlm_loss, 7.418625354766846, 2146
[INFO] 2021-07-12 19:15:29,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.144999962183647e-05, 2146
[INFO] 2021-07-12 19:15:29,481 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2146
[INFO] 2021-07-12 19:15:29,481 [run_pretraining.py:  558]:	worker_index: 7, step: 2146, cost: 7.418625, mlm loss: 7.418625, speed: 1.064286 steps/s, speed: 8.514290 samples/s, speed: 4359.316253 tokens/s, learning rate: 2.145e-05, loss_scalings: 3518.437988, pp_loss: 7.392145
[INFO] 2021-07-12 19:15:29,481 [run_pretraining.py:  512]:	********exe.run_2146******* 
[INFO] 2021-07-12 19:15:30,408 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:30,408 [run_pretraining.py:  534]:	loss/total_loss, 6.975215911865234, 2147
[INFO] 2021-07-12 19:15:30,408 [run_pretraining.py:  535]:	loss/mlm_loss, 6.975215911865234, 2147
[INFO] 2021-07-12 19:15:30,408 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.145999860658776e-05, 2147
[INFO] 2021-07-12 19:15:30,408 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2147
[INFO] 2021-07-12 19:15:30,408 [run_pretraining.py:  558]:	worker_index: 7, step: 2147, cost: 6.975216, mlm loss: 6.975216, speed: 1.079089 steps/s, speed: 8.632711 samples/s, speed: 4419.947954 tokens/s, learning rate: 2.146e-05, loss_scalings: 3518.437988, pp_loss: 6.780196
[INFO] 2021-07-12 19:15:30,408 [run_pretraining.py:  512]:	********exe.run_2147******* 
[INFO] 2021-07-12 19:15:31,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  534]:	loss/total_loss, 7.112273693084717, 2148
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  535]:	loss/mlm_loss, 7.112273693084717, 2148
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1469999410328455e-05, 2148
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2148
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  558]:	worker_index: 7, step: 2148, cost: 7.112274, mlm loss: 7.112274, speed: 1.115746 steps/s, speed: 8.925969 samples/s, speed: 4570.096229 tokens/s, learning rate: 2.147e-05, loss_scalings: 3518.437988, pp_loss: 7.392766
[INFO] 2021-07-12 19:15:31,305 [run_pretraining.py:  512]:	********exe.run_2148******* 
[INFO] 2021-07-12 19:15:32,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:32,209 [run_pretraining.py:  534]:	loss/total_loss, 7.103339672088623, 2149
[INFO] 2021-07-12 19:15:32,209 [run_pretraining.py:  535]:	loss/mlm_loss, 7.103339672088623, 2149
[INFO] 2021-07-12 19:15:32,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.148000021406915e-05, 2149
[INFO] 2021-07-12 19:15:32,209 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2149
[INFO] 2021-07-12 19:15:32,209 [run_pretraining.py:  558]:	worker_index: 7, step: 2149, cost: 7.103340, mlm loss: 7.103340, speed: 1.107384 steps/s, speed: 8.859076 samples/s, speed: 4535.846845 tokens/s, learning rate: 2.148e-05, loss_scalings: 3518.437988, pp_loss: 7.274363
[INFO] 2021-07-12 19:15:32,209 [run_pretraining.py:  512]:	********exe.run_2149******* 
[INFO] 2021-07-12 19:15:33,107 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:33,107 [run_pretraining.py:  534]:	loss/total_loss, 7.265427589416504, 2150
[INFO] 2021-07-12 19:15:33,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.265427589416504, 2150
[INFO] 2021-07-12 19:15:33,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1489999198820442e-05, 2150
[INFO] 2021-07-12 19:15:33,108 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2150
[INFO] 2021-07-12 19:15:33,108 [run_pretraining.py:  558]:	worker_index: 7, step: 2150, cost: 7.265428, mlm loss: 7.265428, speed: 1.113657 steps/s, speed: 8.909256 samples/s, speed: 4561.539078 tokens/s, learning rate: 2.149e-05, loss_scalings: 3518.437988, pp_loss: 7.797298
[INFO] 2021-07-12 19:15:33,108 [run_pretraining.py:  512]:	********exe.run_2150******* 
[INFO] 2021-07-12 19:15:34,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  534]:	loss/total_loss, 6.591794013977051, 2151
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  535]:	loss/mlm_loss, 6.591794013977051, 2151
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1500000002561137e-05, 2151
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2151
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  558]:	worker_index: 7, step: 2151, cost: 6.591794, mlm loss: 6.591794, speed: 1.105140 steps/s, speed: 8.841116 samples/s, speed: 4526.651505 tokens/s, learning rate: 2.150e-05, loss_scalings: 3518.437988, pp_loss: 7.665018
[INFO] 2021-07-12 19:15:34,013 [run_pretraining.py:  512]:	********exe.run_2151******* 
[INFO] 2021-07-12 19:15:34,912 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  534]:	loss/total_loss, 6.014470100402832, 2152
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  535]:	loss/mlm_loss, 6.014470100402832, 2152
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1510000806301832e-05, 2152
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2152
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  558]:	worker_index: 7, step: 2152, cost: 6.014470, mlm loss: 6.014470, speed: 1.112155 steps/s, speed: 8.897239 samples/s, speed: 4555.386198 tokens/s, learning rate: 2.151e-05, loss_scalings: 3518.437988, pp_loss: 6.588607
[INFO] 2021-07-12 19:15:34,913 [run_pretraining.py:  512]:	********exe.run_2152******* 
[INFO] 2021-07-12 19:15:35,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:35,822 [run_pretraining.py:  534]:	loss/total_loss, 7.148775577545166, 2153
[INFO] 2021-07-12 19:15:35,823 [run_pretraining.py:  535]:	loss/mlm_loss, 7.148775577545166, 2153
[INFO] 2021-07-12 19:15:35,823 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1519999791053124e-05, 2153
[INFO] 2021-07-12 19:15:35,823 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2153
[INFO] 2021-07-12 19:15:35,823 [run_pretraining.py:  558]:	worker_index: 7, step: 2153, cost: 7.148776, mlm loss: 7.148776, speed: 1.099780 steps/s, speed: 8.798239 samples/s, speed: 4504.698159 tokens/s, learning rate: 2.152e-05, loss_scalings: 3518.437988, pp_loss: 7.102037
[INFO] 2021-07-12 19:15:35,823 [run_pretraining.py:  512]:	********exe.run_2153******* 
[INFO] 2021-07-12 19:15:36,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  534]:	loss/total_loss, 7.146787643432617, 2154
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  535]:	loss/mlm_loss, 7.146787643432617, 2154
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1529998775804415e-05, 2154
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2154
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  558]:	worker_index: 7, step: 2154, cost: 7.146788, mlm loss: 7.146788, speed: 1.113855 steps/s, speed: 8.910844 samples/s, speed: 4562.351914 tokens/s, learning rate: 2.153e-05, loss_scalings: 3518.437988, pp_loss: 7.211331
[INFO] 2021-07-12 19:15:36,721 [run_pretraining.py:  512]:	********exe.run_2154******* 
[INFO] 2021-07-12 19:15:37,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:37,632 [run_pretraining.py:  534]:	loss/total_loss, 7.151449680328369, 2155
[INFO] 2021-07-12 19:15:37,632 [run_pretraining.py:  535]:	loss/mlm_loss, 7.151449680328369, 2155
[INFO] 2021-07-12 19:15:37,632 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.153999957954511e-05, 2155
[INFO] 2021-07-12 19:15:37,632 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2155
[INFO] 2021-07-12 19:15:37,632 [run_pretraining.py:  558]:	worker_index: 7, step: 2155, cost: 7.151450, mlm loss: 7.151450, speed: 1.098174 steps/s, speed: 8.785391 samples/s, speed: 4498.120406 tokens/s, learning rate: 2.154e-05, loss_scalings: 3518.437988, pp_loss: 7.259297
[INFO] 2021-07-12 19:15:37,633 [run_pretraining.py:  512]:	********exe.run_2155******* 
[INFO] 2021-07-12 19:15:38,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:38,542 [run_pretraining.py:  534]:	loss/total_loss, 6.827609062194824, 2156
[INFO] 2021-07-12 19:15:38,542 [run_pretraining.py:  535]:	loss/mlm_loss, 6.827609062194824, 2156
[INFO] 2021-07-12 19:15:38,542 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1549998564296402e-05, 2156
[INFO] 2021-07-12 19:15:38,542 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2156
[INFO] 2021-07-12 19:15:38,542 [run_pretraining.py:  558]:	worker_index: 7, step: 2156, cost: 6.827609, mlm loss: 6.827609, speed: 1.100050 steps/s, speed: 8.800403 samples/s, speed: 4505.806367 tokens/s, learning rate: 2.155e-05, loss_scalings: 3518.437988, pp_loss: 6.937870
[INFO] 2021-07-12 19:15:38,542 [run_pretraining.py:  512]:	********exe.run_2156******* 
[INFO] 2021-07-12 19:15:39,453 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:39,453 [run_pretraining.py:  534]:	loss/total_loss, 7.861025810241699, 2157
[INFO] 2021-07-12 19:15:39,454 [run_pretraining.py:  535]:	loss/mlm_loss, 7.861025810241699, 2157
[INFO] 2021-07-12 19:15:39,454 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1559999368037097e-05, 2157
[INFO] 2021-07-12 19:15:39,454 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2157
[INFO] 2021-07-12 19:15:39,454 [run_pretraining.py:  558]:	worker_index: 7, step: 2157, cost: 7.861026, mlm loss: 7.861026, speed: 1.097744 steps/s, speed: 8.781952 samples/s, speed: 4496.359226 tokens/s, learning rate: 2.156e-05, loss_scalings: 3518.437988, pp_loss: 8.000209
[INFO] 2021-07-12 19:15:39,454 [run_pretraining.py:  512]:	********exe.run_2157******* 
[INFO] 2021-07-12 19:15:40,363 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:40,363 [run_pretraining.py:  534]:	loss/total_loss, 6.942830562591553, 2158
[INFO] 2021-07-12 19:15:40,364 [run_pretraining.py:  535]:	loss/mlm_loss, 6.942830562591553, 2158
[INFO] 2021-07-12 19:15:40,364 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1570000171777792e-05, 2158
[INFO] 2021-07-12 19:15:40,364 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2158
[INFO] 2021-07-12 19:15:40,364 [run_pretraining.py:  558]:	worker_index: 7, step: 2158, cost: 6.942831, mlm loss: 6.942831, speed: 1.099774 steps/s, speed: 8.798195 samples/s, speed: 4504.675717 tokens/s, learning rate: 2.157e-05, loss_scalings: 3518.437988, pp_loss: 7.168540
[INFO] 2021-07-12 19:15:40,364 [run_pretraining.py:  512]:	********exe.run_2158******* 
[INFO] 2021-07-12 19:15:41,286 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  534]:	loss/total_loss, 4.712339878082275, 2159
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  535]:	loss/mlm_loss, 4.712339878082275, 2159
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1579999156529084e-05, 2159
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2159
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  558]:	worker_index: 7, step: 2159, cost: 4.712340, mlm loss: 4.712340, speed: 1.083819 steps/s, speed: 8.670553 samples/s, speed: 4439.322981 tokens/s, learning rate: 2.158e-05, loss_scalings: 3518.437988, pp_loss: 5.472188
[INFO] 2021-07-12 19:15:41,287 [run_pretraining.py:  512]:	********exe.run_2159******* 
[INFO] 2021-07-12 19:15:42,211 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  534]:	loss/total_loss, 7.167917251586914, 2160
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  535]:	loss/mlm_loss, 7.167917251586914, 2160
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.158999996026978e-05, 2160
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2160
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  558]:	worker_index: 7, step: 2160, cost: 7.167917, mlm loss: 7.167917, speed: 1.081891 steps/s, speed: 8.655130 samples/s, speed: 4431.426426 tokens/s, learning rate: 2.159e-05, loss_scalings: 3518.437988, pp_loss: 7.284422
[INFO] 2021-07-12 19:15:42,212 [run_pretraining.py:  512]:	********exe.run_2160******* 
[INFO] 2021-07-12 19:15:43,126 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:43,127 [run_pretraining.py:  534]:	loss/total_loss, 7.240959167480469, 2161
[INFO] 2021-07-12 19:15:43,127 [run_pretraining.py:  535]:	loss/mlm_loss, 7.240959167480469, 2161
[INFO] 2021-07-12 19:15:43,127 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1600000764010474e-05, 2161
[INFO] 2021-07-12 19:15:43,127 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2161
[INFO] 2021-07-12 19:15:43,127 [run_pretraining.py:  558]:	worker_index: 7, step: 2161, cost: 7.240959, mlm loss: 7.240959, speed: 1.093334 steps/s, speed: 8.746673 samples/s, speed: 4478.296437 tokens/s, learning rate: 2.160e-05, loss_scalings: 3518.437988, pp_loss: 7.336873
[INFO] 2021-07-12 19:15:43,127 [run_pretraining.py:  512]:	********exe.run_2161******* 
[INFO] 2021-07-12 19:15:44,033 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  534]:	loss/total_loss, 6.614457607269287, 2162
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  535]:	loss/mlm_loss, 6.614457607269287, 2162
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1609999748761766e-05, 2162
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2162
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  558]:	worker_index: 7, step: 2162, cost: 6.614458, mlm loss: 6.614458, speed: 1.103501 steps/s, speed: 8.828004 samples/s, speed: 4519.938179 tokens/s, learning rate: 2.161e-05, loss_scalings: 3518.437988, pp_loss: 7.092227
[INFO] 2021-07-12 19:15:44,034 [run_pretraining.py:  512]:	********exe.run_2162******* 
[INFO] 2021-07-12 19:15:44,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:44,973 [run_pretraining.py:  534]:	loss/total_loss, 7.289658546447754, 2163
[INFO] 2021-07-12 19:15:44,973 [run_pretraining.py:  535]:	loss/mlm_loss, 7.289658546447754, 2163
[INFO] 2021-07-12 19:15:44,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1619998733513057e-05, 2163
[INFO] 2021-07-12 19:15:44,973 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2163
[INFO] 2021-07-12 19:15:44,973 [run_pretraining.py:  558]:	worker_index: 7, step: 2163, cost: 7.289659, mlm loss: 7.289659, speed: 1.066121 steps/s, speed: 8.528969 samples/s, speed: 4366.832254 tokens/s, learning rate: 2.162e-05, loss_scalings: 3518.437988, pp_loss: 7.254418
[INFO] 2021-07-12 19:15:44,973 [run_pretraining.py:  512]:	********exe.run_2163******* 
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  534]:	loss/total_loss, 7.727971076965332, 2164
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.727971076965332, 2164
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1629999537253752e-05, 2164
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2164
[INFO] 2021-07-12 19:15:45,945 [run_pretraining.py:  558]:	worker_index: 7, step: 2164, cost: 7.727971, mlm loss: 7.727971, speed: 1.028853 steps/s, speed: 8.230825 samples/s, speed: 4214.182472 tokens/s, learning rate: 2.163e-05, loss_scalings: 3518.437988, pp_loss: 7.556299
[INFO] 2021-07-12 19:15:45,946 [run_pretraining.py:  512]:	********exe.run_2164******* 
[INFO] 2021-07-12 19:15:46,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:46,862 [run_pretraining.py:  534]:	loss/total_loss, 7.776822090148926, 2165
[INFO] 2021-07-12 19:15:46,862 [run_pretraining.py:  535]:	loss/mlm_loss, 7.776822090148926, 2165
[INFO] 2021-07-12 19:15:46,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1639998522005044e-05, 2165
[INFO] 2021-07-12 19:15:46,862 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2165
[INFO] 2021-07-12 19:15:46,862 [run_pretraining.py:  558]:	worker_index: 7, step: 2165, cost: 7.776822, mlm loss: 7.776822, speed: 1.091586 steps/s, speed: 8.732687 samples/s, speed: 4471.135629 tokens/s, learning rate: 2.164e-05, loss_scalings: 3518.437988, pp_loss: 7.075818
[INFO] 2021-07-12 19:15:46,862 [run_pretraining.py:  512]:	********exe.run_2165******* 
[INFO] 2021-07-12 19:15:47,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  534]:	loss/total_loss, 6.641807556152344, 2166
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  535]:	loss/mlm_loss, 6.641807556152344, 2166
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.164999932574574e-05, 2166
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2166
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  558]:	worker_index: 7, step: 2166, cost: 6.641808, mlm loss: 6.641808, speed: 1.099477 steps/s, speed: 8.795812 samples/s, speed: 4503.455913 tokens/s, learning rate: 2.165e-05, loss_scalings: 3518.437988, pp_loss: 7.119784
[INFO] 2021-07-12 19:15:47,772 [run_pretraining.py:  512]:	********exe.run_2166******* 
[INFO] 2021-07-12 19:15:48,682 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:48,683 [run_pretraining.py:  534]:	loss/total_loss, 4.314740180969238, 2167
[INFO] 2021-07-12 19:15:48,683 [run_pretraining.py:  535]:	loss/mlm_loss, 4.314740180969238, 2167
[INFO] 2021-07-12 19:15:48,683 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1660000129486434e-05, 2167
[INFO] 2021-07-12 19:15:48,683 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2167
[INFO] 2021-07-12 19:15:48,683 [run_pretraining.py:  558]:	worker_index: 7, step: 2167, cost: 4.314740, mlm loss: 4.314740, speed: 1.098824 steps/s, speed: 8.790591 samples/s, speed: 4500.782452 tokens/s, learning rate: 2.166e-05, loss_scalings: 3518.437988, pp_loss: 7.194970
[INFO] 2021-07-12 19:15:48,683 [run_pretraining.py:  512]:	********exe.run_2167******* 
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  534]:	loss/total_loss, 7.00666618347168, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  535]:	loss/mlm_loss, 7.00666618347168, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1669999114237726e-05, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2168
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  558]:	worker_index: 7, step: 2168, cost: 7.006666, mlm loss: 7.006666, speed: 1.101755 steps/s, speed: 8.814042 samples/s, speed: 4512.789491 tokens/s, learning rate: 2.167e-05, loss_scalings: 3518.437988, pp_loss: 7.443678
[INFO] 2021-07-12 19:15:49,591 [run_pretraining.py:  512]:	********exe.run_2168******* 
[INFO] 2021-07-12 19:15:50,496 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:50,497 [run_pretraining.py:  534]:	loss/total_loss, 7.70250129699707, 2169
[INFO] 2021-07-12 19:15:50,497 [run_pretraining.py:  535]:	loss/mlm_loss, 7.70250129699707, 2169
[INFO] 2021-07-12 19:15:50,497 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.167999991797842e-05, 2169
[INFO] 2021-07-12 19:15:50,497 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2169
[INFO] 2021-07-12 19:15:50,497 [run_pretraining.py:  558]:	worker_index: 7, step: 2169, cost: 7.702501, mlm loss: 7.702501, speed: 1.104876 steps/s, speed: 8.839009 samples/s, speed: 4525.572361 tokens/s, learning rate: 2.168e-05, loss_scalings: 3518.437988, pp_loss: 7.258473
[INFO] 2021-07-12 19:15:50,497 [run_pretraining.py:  512]:	********exe.run_2169******* 
[INFO] 2021-07-12 19:15:51,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:51,407 [run_pretraining.py:  534]:	loss/total_loss, 7.334893703460693, 2170
[INFO] 2021-07-12 19:15:51,407 [run_pretraining.py:  535]:	loss/mlm_loss, 7.334893703460693, 2170
[INFO] 2021-07-12 19:15:51,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1690000721719116e-05, 2170
[INFO] 2021-07-12 19:15:51,407 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2170
[INFO] 2021-07-12 19:15:51,407 [run_pretraining.py:  558]:	worker_index: 7, step: 2170, cost: 7.334894, mlm loss: 7.334894, speed: 1.099894 steps/s, speed: 8.799152 samples/s, speed: 4505.165950 tokens/s, learning rate: 2.169e-05, loss_scalings: 3518.437988, pp_loss: 7.453434
[INFO] 2021-07-12 19:15:51,407 [run_pretraining.py:  512]:	********exe.run_2170******* 
[INFO] 2021-07-12 19:15:52,313 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:52,314 [run_pretraining.py:  534]:	loss/total_loss, 6.529811859130859, 2171
[INFO] 2021-07-12 19:15:52,314 [run_pretraining.py:  535]:	loss/mlm_loss, 6.529811859130859, 2171
[INFO] 2021-07-12 19:15:52,314 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1699997887481004e-05, 2171
[INFO] 2021-07-12 19:15:52,314 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2171
[INFO] 2021-07-12 19:15:52,314 [run_pretraining.py:  558]:	worker_index: 7, step: 2171, cost: 6.529812, mlm loss: 6.529812, speed: 1.103265 steps/s, speed: 8.826123 samples/s, speed: 4518.975154 tokens/s, learning rate: 2.170e-05, loss_scalings: 3518.437988, pp_loss: 7.018162
[INFO] 2021-07-12 19:15:52,314 [run_pretraining.py:  512]:	********exe.run_2171******* 
[INFO] 2021-07-12 19:15:53,252 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:53,253 [run_pretraining.py:  534]:	loss/total_loss, 7.232428550720215, 2172
[INFO] 2021-07-12 19:15:53,253 [run_pretraining.py:  535]:	loss/mlm_loss, 7.232428550720215, 2172
[INFO] 2021-07-12 19:15:53,253 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.17099986912217e-05, 2172
[INFO] 2021-07-12 19:15:53,253 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2172
[INFO] 2021-07-12 19:15:53,253 [run_pretraining.py:  558]:	worker_index: 7, step: 2172, cost: 7.232429, mlm loss: 7.232429, speed: 1.065595 steps/s, speed: 8.524757 samples/s, speed: 4364.675529 tokens/s, learning rate: 2.171e-05, loss_scalings: 3518.437988, pp_loss: 6.637494
[INFO] 2021-07-12 19:15:53,253 [run_pretraining.py:  512]:	********exe.run_2172******* 
[INFO] 2021-07-12 19:15:54,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:54,165 [run_pretraining.py:  534]:	loss/total_loss, 7.5247392654418945, 2173
[INFO] 2021-07-12 19:15:54,165 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5247392654418945, 2173
[INFO] 2021-07-12 19:15:54,165 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1719999494962394e-05, 2173
[INFO] 2021-07-12 19:15:54,165 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2173
[INFO] 2021-07-12 19:15:54,165 [run_pretraining.py:  558]:	worker_index: 7, step: 2173, cost: 7.524739, mlm loss: 7.524739, speed: 1.096992 steps/s, speed: 8.775936 samples/s, speed: 4493.279301 tokens/s, learning rate: 2.172e-05, loss_scalings: 3518.437988, pp_loss: 7.105062
[INFO] 2021-07-12 19:15:54,165 [run_pretraining.py:  512]:	********exe.run_2173******* 
[INFO] 2021-07-12 19:15:55,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:55,077 [run_pretraining.py:  534]:	loss/total_loss, 6.954196453094482, 2174
[INFO] 2021-07-12 19:15:55,077 [run_pretraining.py:  535]:	loss/mlm_loss, 6.954196453094482, 2174
[INFO] 2021-07-12 19:15:55,077 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1729998479713686e-05, 2174
[INFO] 2021-07-12 19:15:55,077 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2174
[INFO] 2021-07-12 19:15:55,077 [run_pretraining.py:  558]:	worker_index: 7, step: 2174, cost: 6.954196, mlm loss: 6.954196, speed: 1.097334 steps/s, speed: 8.778668 samples/s, speed: 4494.678209 tokens/s, learning rate: 2.173e-05, loss_scalings: 3518.437988, pp_loss: 7.079518
[INFO] 2021-07-12 19:15:55,077 [run_pretraining.py:  512]:	********exe.run_2174******* 
[INFO] 2021-07-12 19:15:55,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  534]:	loss/total_loss, 7.72584342956543, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  535]:	loss/mlm_loss, 7.72584342956543, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.173999928345438e-05, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2175
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  558]:	worker_index: 7, step: 2175, cost: 7.725843, mlm loss: 7.725843, speed: 1.102135 steps/s, speed: 8.817078 samples/s, speed: 4514.344105 tokens/s, learning rate: 2.174e-05, loss_scalings: 3518.437988, pp_loss: 7.304005
[INFO] 2021-07-12 19:15:55,985 [run_pretraining.py:  512]:	********exe.run_2175******* 
[INFO] 2021-07-12 19:15:56,892 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:56,892 [run_pretraining.py:  534]:	loss/total_loss, 6.542209625244141, 2176
[INFO] 2021-07-12 19:15:56,892 [run_pretraining.py:  535]:	loss/mlm_loss, 6.542209625244141, 2176
[INFO] 2021-07-12 19:15:56,892 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1750000087195076e-05, 2176
[INFO] 2021-07-12 19:15:56,892 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2176
[INFO] 2021-07-12 19:15:56,893 [run_pretraining.py:  558]:	worker_index: 7, step: 2176, cost: 6.542210, mlm loss: 6.542210, speed: 1.102927 steps/s, speed: 8.823417 samples/s, speed: 4517.589594 tokens/s, learning rate: 2.175e-05, loss_scalings: 3518.437988, pp_loss: 6.953425
[INFO] 2021-07-12 19:15:56,893 [run_pretraining.py:  512]:	********exe.run_2176******* 
[INFO] 2021-07-12 19:15:57,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:57,797 [run_pretraining.py:  534]:	loss/total_loss, 7.779428005218506, 2177
[INFO] 2021-07-12 19:15:57,797 [run_pretraining.py:  535]:	loss/mlm_loss, 7.779428005218506, 2177
[INFO] 2021-07-12 19:15:57,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1759999071946368e-05, 2177
[INFO] 2021-07-12 19:15:57,797 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2177
[INFO] 2021-07-12 19:15:57,797 [run_pretraining.py:  558]:	worker_index: 7, step: 2177, cost: 7.779428, mlm loss: 7.779428, speed: 1.105971 steps/s, speed: 8.847765 samples/s, speed: 4530.055667 tokens/s, learning rate: 2.176e-05, loss_scalings: 3518.437988, pp_loss: 7.639652
[INFO] 2021-07-12 19:15:57,797 [run_pretraining.py:  512]:	********exe.run_2177******* 
[INFO] 2021-07-12 19:15:58,705 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:58,705 [run_pretraining.py:  534]:	loss/total_loss, 6.843108654022217, 2178
[INFO] 2021-07-12 19:15:58,705 [run_pretraining.py:  535]:	loss/mlm_loss, 6.843108654022217, 2178
[INFO] 2021-07-12 19:15:58,705 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1769999875687063e-05, 2178
[INFO] 2021-07-12 19:15:58,705 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2178
[INFO] 2021-07-12 19:15:58,705 [run_pretraining.py:  558]:	worker_index: 7, step: 2178, cost: 6.843109, mlm loss: 6.843109, speed: 1.102017 steps/s, speed: 8.816135 samples/s, speed: 4513.861360 tokens/s, learning rate: 2.177e-05, loss_scalings: 3518.437988, pp_loss: 6.399918
[INFO] 2021-07-12 19:15:58,706 [run_pretraining.py:  512]:	********exe.run_2178******* 
[INFO] 2021-07-12 19:15:59,617 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:15:59,617 [run_pretraining.py:  534]:	loss/total_loss, 6.937424182891846, 2179
[INFO] 2021-07-12 19:15:59,617 [run_pretraining.py:  535]:	loss/mlm_loss, 6.937424182891846, 2179
[INFO] 2021-07-12 19:15:59,617 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1780000679427758e-05, 2179
[INFO] 2021-07-12 19:15:59,618 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2179
[INFO] 2021-07-12 19:15:59,618 [run_pretraining.py:  558]:	worker_index: 7, step: 2179, cost: 6.937424, mlm loss: 6.937424, speed: 1.097161 steps/s, speed: 8.777291 samples/s, speed: 4493.972769 tokens/s, learning rate: 2.178e-05, loss_scalings: 3518.437988, pp_loss: 7.160774
[INFO] 2021-07-12 19:15:59,618 [run_pretraining.py:  512]:	********exe.run_2179******* 
[INFO] 2021-07-12 19:16:00,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:00,531 [run_pretraining.py:  534]:	loss/total_loss, 7.506897926330566, 2180
[INFO] 2021-07-12 19:16:00,531 [run_pretraining.py:  535]:	loss/mlm_loss, 7.506897926330566, 2180
[INFO] 2021-07-12 19:16:00,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.178999966417905e-05, 2180
[INFO] 2021-07-12 19:16:00,531 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2180
[INFO] 2021-07-12 19:16:00,531 [run_pretraining.py:  558]:	worker_index: 7, step: 2180, cost: 7.506898, mlm loss: 7.506898, speed: 1.095706 steps/s, speed: 8.765645 samples/s, speed: 4488.010073 tokens/s, learning rate: 2.179e-05, loss_scalings: 3518.437988, pp_loss: 7.118941
[INFO] 2021-07-12 19:16:00,531 [run_pretraining.py:  512]:	********exe.run_2180******* 
[INFO] 2021-07-12 19:16:01,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:01,441 [run_pretraining.py:  534]:	loss/total_loss, 7.299663066864014, 2181
[INFO] 2021-07-12 19:16:01,441 [run_pretraining.py:  535]:	loss/mlm_loss, 7.299663066864014, 2181
[INFO] 2021-07-12 19:16:01,441 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.179999864893034e-05, 2181
[INFO] 2021-07-12 19:16:01,441 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2181
[INFO] 2021-07-12 19:16:01,441 [run_pretraining.py:  558]:	worker_index: 7, step: 2181, cost: 7.299663, mlm loss: 7.299663, speed: 1.098966 steps/s, speed: 8.791729 samples/s, speed: 4501.365010 tokens/s, learning rate: 2.180e-05, loss_scalings: 3518.437988, pp_loss: 7.309374
[INFO] 2021-07-12 19:16:01,442 [run_pretraining.py:  512]:	********exe.run_2181******* 
[INFO] 2021-07-12 19:16:02,347 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  534]:	loss/total_loss, 7.92860221862793, 2182
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  535]:	loss/mlm_loss, 7.92860221862793, 2182
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1809999452671036e-05, 2182
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2182
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  558]:	worker_index: 7, step: 2182, cost: 7.928602, mlm loss: 7.928602, speed: 1.103700 steps/s, speed: 8.829602 samples/s, speed: 4520.756478 tokens/s, learning rate: 2.181e-05, loss_scalings: 3518.437988, pp_loss: 7.635699
[INFO] 2021-07-12 19:16:02,348 [run_pretraining.py:  512]:	********exe.run_2182******* 
[INFO] 2021-07-12 19:16:03,257 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:03,258 [run_pretraining.py:  534]:	loss/total_loss, 6.842076778411865, 2183
[INFO] 2021-07-12 19:16:03,258 [run_pretraining.py:  535]:	loss/mlm_loss, 6.842076778411865, 2183
[INFO] 2021-07-12 19:16:03,258 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1819998437422328e-05, 2183
[INFO] 2021-07-12 19:16:03,258 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2183
[INFO] 2021-07-12 19:16:03,258 [run_pretraining.py:  558]:	worker_index: 7, step: 2183, cost: 6.842077, mlm loss: 6.842077, speed: 1.099573 steps/s, speed: 8.796583 samples/s, speed: 4503.850240 tokens/s, learning rate: 2.182e-05, loss_scalings: 3518.437988, pp_loss: 7.114481
[INFO] 2021-07-12 19:16:03,258 [run_pretraining.py:  512]:	********exe.run_2183******* 
[INFO] 2021-07-12 19:16:04,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:04,169 [run_pretraining.py:  534]:	loss/total_loss, 7.9036149978637695, 2184
[INFO] 2021-07-12 19:16:04,169 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9036149978637695, 2184
[INFO] 2021-07-12 19:16:04,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1829999241163023e-05, 2184
[INFO] 2021-07-12 19:16:04,169 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2184
[INFO] 2021-07-12 19:16:04,170 [run_pretraining.py:  558]:	worker_index: 7, step: 2184, cost: 7.903615, mlm loss: 7.903615, speed: 1.098154 steps/s, speed: 8.785233 samples/s, speed: 4498.039145 tokens/s, learning rate: 2.183e-05, loss_scalings: 3518.437988, pp_loss: 7.719144
[INFO] 2021-07-12 19:16:04,170 [run_pretraining.py:  512]:	********exe.run_2184******* 
[INFO] 2021-07-12 19:16:05,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:05,082 [run_pretraining.py:  534]:	loss/total_loss, 6.955502510070801, 2185
[INFO] 2021-07-12 19:16:05,082 [run_pretraining.py:  535]:	loss/mlm_loss, 6.955502510070801, 2185
[INFO] 2021-07-12 19:16:05,082 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1840000044903718e-05, 2185
[INFO] 2021-07-12 19:16:05,082 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2185
[INFO] 2021-07-12 19:16:05,082 [run_pretraining.py:  558]:	worker_index: 7, step: 2185, cost: 6.955503, mlm loss: 6.955503, speed: 1.096785 steps/s, speed: 8.774277 samples/s, speed: 4492.429802 tokens/s, learning rate: 2.184e-05, loss_scalings: 3518.437988, pp_loss: 6.942724
[INFO] 2021-07-12 19:16:05,082 [run_pretraining.py:  512]:	********exe.run_2185******* 
[INFO] 2021-07-12 19:16:06,023 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:06,023 [run_pretraining.py:  534]:	loss/total_loss, 7.079056262969971, 2186
[INFO] 2021-07-12 19:16:06,023 [run_pretraining.py:  535]:	loss/mlm_loss, 7.079056262969971, 2186
[INFO] 2021-07-12 19:16:06,023 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.184999902965501e-05, 2186
[INFO] 2021-07-12 19:16:06,024 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2186
[INFO] 2021-07-12 19:16:06,024 [run_pretraining.py:  558]:	worker_index: 7, step: 2186, cost: 7.079056, mlm loss: 7.079056, speed: 1.062733 steps/s, speed: 8.501868 samples/s, speed: 4352.956291 tokens/s, learning rate: 2.185e-05, loss_scalings: 3518.437988, pp_loss: 7.326414
[INFO] 2021-07-12 19:16:06,024 [run_pretraining.py:  512]:	********exe.run_2186******* 
[INFO] 2021-07-12 19:16:06,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:06,949 [run_pretraining.py:  534]:	loss/total_loss, 7.036530494689941, 2187
[INFO] 2021-07-12 19:16:06,949 [run_pretraining.py:  535]:	loss/mlm_loss, 7.036530494689941, 2187
[INFO] 2021-07-12 19:16:06,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1859999833395705e-05, 2187
[INFO] 2021-07-12 19:16:06,950 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2187
[INFO] 2021-07-12 19:16:06,950 [run_pretraining.py:  558]:	worker_index: 7, step: 2187, cost: 7.036530, mlm loss: 7.036530, speed: 1.080606 steps/s, speed: 8.644848 samples/s, speed: 4426.162059 tokens/s, learning rate: 2.186e-05, loss_scalings: 3518.437988, pp_loss: 7.306229
[INFO] 2021-07-12 19:16:06,950 [run_pretraining.py:  512]:	********exe.run_2187******* 
[INFO] 2021-07-12 19:16:07,857 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:07,858 [run_pretraining.py:  534]:	loss/total_loss, 6.9124321937561035, 2188
[INFO] 2021-07-12 19:16:07,858 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9124321937561035, 2188
[INFO] 2021-07-12 19:16:07,858 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.18700006371364e-05, 2188
[INFO] 2021-07-12 19:16:07,858 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2188
[INFO] 2021-07-12 19:16:07,858 [run_pretraining.py:  558]:	worker_index: 7, step: 2188, cost: 6.912432, mlm loss: 6.912432, speed: 1.101768 steps/s, speed: 8.814142 samples/s, speed: 4512.840464 tokens/s, learning rate: 2.187e-05, loss_scalings: 3518.437988, pp_loss: 7.204988
[INFO] 2021-07-12 19:16:07,858 [run_pretraining.py:  512]:	********exe.run_2188******* 
[INFO] 2021-07-12 19:16:08,771 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:08,772 [run_pretraining.py:  534]:	loss/total_loss, 8.321919441223145, 2189
[INFO] 2021-07-12 19:16:08,772 [run_pretraining.py:  535]:	loss/mlm_loss, 8.321919441223145, 2189
[INFO] 2021-07-12 19:16:08,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.187999962188769e-05, 2189
[INFO] 2021-07-12 19:16:08,772 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2189
[INFO] 2021-07-12 19:16:08,772 [run_pretraining.py:  558]:	worker_index: 7, step: 2189, cost: 8.321919, mlm loss: 8.321919, speed: 1.094580 steps/s, speed: 8.756636 samples/s, speed: 4483.397780 tokens/s, learning rate: 2.188e-05, loss_scalings: 3518.437988, pp_loss: 7.855538
[INFO] 2021-07-12 19:16:08,772 [run_pretraining.py:  512]:	********exe.run_2189******* 
[INFO] 2021-07-12 19:16:09,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:09,772 [run_pretraining.py:  534]:	loss/total_loss, 7.228572845458984, 2190
[INFO] 2021-07-12 19:16:09,772 [run_pretraining.py:  535]:	loss/mlm_loss, 7.228572845458984, 2190
[INFO] 2021-07-12 19:16:09,772 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1889998606638983e-05, 2190
[INFO] 2021-07-12 19:16:09,772 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2190
[INFO] 2021-07-12 19:16:09,772 [run_pretraining.py:  558]:	worker_index: 7, step: 2190, cost: 7.228573, mlm loss: 7.228573, speed: 1.000433 steps/s, speed: 8.003461 samples/s, speed: 4097.772251 tokens/s, learning rate: 2.189e-05, loss_scalings: 3518.437988, pp_loss: 7.505836
[INFO] 2021-07-12 19:16:09,772 [run_pretraining.py:  512]:	********exe.run_2190******* 
[INFO] 2021-07-12 19:16:10,676 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:10,677 [run_pretraining.py:  534]:	loss/total_loss, 7.1069793701171875, 2191
[INFO] 2021-07-12 19:16:10,677 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1069793701171875, 2191
[INFO] 2021-07-12 19:16:10,677 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1899999410379678e-05, 2191
[INFO] 2021-07-12 19:16:10,677 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2191
[INFO] 2021-07-12 19:16:10,677 [run_pretraining.py:  558]:	worker_index: 7, step: 2191, cost: 7.106979, mlm loss: 7.106979, speed: 1.105923 steps/s, speed: 8.847387 samples/s, speed: 4529.862166 tokens/s, learning rate: 2.190e-05, loss_scalings: 3518.437988, pp_loss: 7.150296
[INFO] 2021-07-12 19:16:10,677 [run_pretraining.py:  512]:	********exe.run_2191******* 
[INFO] 2021-07-12 19:16:11,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:11,586 [run_pretraining.py:  534]:	loss/total_loss, 7.730441570281982, 2192
[INFO] 2021-07-12 19:16:11,586 [run_pretraining.py:  535]:	loss/mlm_loss, 7.730441570281982, 2192
[INFO] 2021-07-12 19:16:11,586 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.190999839513097e-05, 2192
[INFO] 2021-07-12 19:16:11,586 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2192
[INFO] 2021-07-12 19:16:11,586 [run_pretraining.py:  558]:	worker_index: 7, step: 2192, cost: 7.730442, mlm loss: 7.730442, speed: 1.101257 steps/s, speed: 8.810055 samples/s, speed: 4510.747945 tokens/s, learning rate: 2.191e-05, loss_scalings: 3518.437988, pp_loss: 7.509509
[INFO] 2021-07-12 19:16:11,586 [run_pretraining.py:  512]:	********exe.run_2192******* 
[INFO] 2021-07-12 19:16:12,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:12,498 [run_pretraining.py:  534]:	loss/total_loss, 7.827605247497559, 2193
[INFO] 2021-07-12 19:16:12,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.827605247497559, 2193
[INFO] 2021-07-12 19:16:12,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1919999198871665e-05, 2193
[INFO] 2021-07-12 19:16:12,498 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2193
[INFO] 2021-07-12 19:16:12,498 [run_pretraining.py:  558]:	worker_index: 7, step: 2193, cost: 7.827605, mlm loss: 7.827605, speed: 1.097247 steps/s, speed: 8.777979 samples/s, speed: 4494.325461 tokens/s, learning rate: 2.192e-05, loss_scalings: 3518.437988, pp_loss: 7.294906
[INFO] 2021-07-12 19:16:12,498 [run_pretraining.py:  512]:	********exe.run_2193******* 
[INFO] 2021-07-12 19:16:13,415 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:13,415 [run_pretraining.py:  534]:	loss/total_loss, 7.374672889709473, 2194
[INFO] 2021-07-12 19:16:13,415 [run_pretraining.py:  535]:	loss/mlm_loss, 7.374672889709473, 2194
[INFO] 2021-07-12 19:16:13,415 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.193000000261236e-05, 2194
[INFO] 2021-07-12 19:16:13,415 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2194
[INFO] 2021-07-12 19:16:13,416 [run_pretraining.py:  558]:	worker_index: 7, step: 2194, cost: 7.374673, mlm loss: 7.374673, speed: 1.090712 steps/s, speed: 8.725699 samples/s, speed: 4467.557997 tokens/s, learning rate: 2.193e-05, loss_scalings: 3518.437988, pp_loss: 7.328600
[INFO] 2021-07-12 19:16:13,416 [run_pretraining.py:  512]:	********exe.run_2194******* 
[INFO] 2021-07-12 19:16:14,326 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:14,326 [run_pretraining.py:  534]:	loss/total_loss, 6.691964626312256, 2195
[INFO] 2021-07-12 19:16:14,326 [run_pretraining.py:  535]:	loss/mlm_loss, 6.691964626312256, 2195
[INFO] 2021-07-12 19:16:14,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.193999898736365e-05, 2195
[INFO] 2021-07-12 19:16:14,326 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2195
[INFO] 2021-07-12 19:16:14,326 [run_pretraining.py:  558]:	worker_index: 7, step: 2195, cost: 6.691965, mlm loss: 6.691965, speed: 1.098546 steps/s, speed: 8.788367 samples/s, speed: 4499.643715 tokens/s, learning rate: 2.194e-05, loss_scalings: 3518.437988, pp_loss: 6.135911
[INFO] 2021-07-12 19:16:14,327 [run_pretraining.py:  512]:	********exe.run_2195******* 
[INFO] 2021-07-12 19:16:15,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:15,239 [run_pretraining.py:  534]:	loss/total_loss, 7.213098526000977, 2196
[INFO] 2021-07-12 19:16:15,240 [run_pretraining.py:  535]:	loss/mlm_loss, 7.213098526000977, 2196
[INFO] 2021-07-12 19:16:15,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1949999791104347e-05, 2196
[INFO] 2021-07-12 19:16:15,240 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2196
[INFO] 2021-07-12 19:16:15,240 [run_pretraining.py:  558]:	worker_index: 7, step: 2196, cost: 7.213099, mlm loss: 7.213099, speed: 1.095704 steps/s, speed: 8.765629 samples/s, speed: 4488.001866 tokens/s, learning rate: 2.195e-05, loss_scalings: 3518.437988, pp_loss: 6.448290
[INFO] 2021-07-12 19:16:15,240 [run_pretraining.py:  512]:	********exe.run_2196******* 
[INFO] 2021-07-12 19:16:16,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:16,158 [run_pretraining.py:  534]:	loss/total_loss, 6.469470977783203, 2197
[INFO] 2021-07-12 19:16:16,159 [run_pretraining.py:  535]:	loss/mlm_loss, 6.469470977783203, 2197
[INFO] 2021-07-12 19:16:16,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.196000059484504e-05, 2197
[INFO] 2021-07-12 19:16:16,161 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2197
[INFO] 2021-07-12 19:16:16,165 [run_pretraining.py:  558]:	worker_index: 7, step: 2197, cost: 6.469471, mlm loss: 6.469471, speed: 1.088897 steps/s, speed: 8.711179 samples/s, speed: 4460.123437 tokens/s, learning rate: 2.196e-05, loss_scalings: 3518.437988, pp_loss: 7.280964
[INFO] 2021-07-12 19:16:16,165 [run_pretraining.py:  512]:	********exe.run_2197******* 
[INFO] 2021-07-12 19:16:17,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:17,064 [run_pretraining.py:  534]:	loss/total_loss, 7.52325439453125, 2198
[INFO] 2021-07-12 19:16:17,064 [run_pretraining.py:  535]:	loss/mlm_loss, 7.52325439453125, 2198
[INFO] 2021-07-12 19:16:17,064 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1969999579596333e-05, 2198
[INFO] 2021-07-12 19:16:17,064 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2198
[INFO] 2021-07-12 19:16:17,064 [run_pretraining.py:  558]:	worker_index: 7, step: 2198, cost: 7.523254, mlm loss: 7.523254, speed: 1.113454 steps/s, speed: 8.907629 samples/s, speed: 4560.705950 tokens/s, learning rate: 2.197e-05, loss_scalings: 3518.437988, pp_loss: 7.135141
[INFO] 2021-07-12 19:16:17,064 [run_pretraining.py:  512]:	********exe.run_2198******* 
[INFO] 2021-07-12 19:16:17,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:17,973 [run_pretraining.py:  534]:	loss/total_loss, 7.391507148742676, 2199
[INFO] 2021-07-12 19:16:17,973 [run_pretraining.py:  535]:	loss/mlm_loss, 7.391507148742676, 2199
[INFO] 2021-07-12 19:16:17,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.1979998564347625e-05, 2199
[INFO] 2021-07-12 19:16:17,973 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2199
[INFO] 2021-07-12 19:16:17,973 [run_pretraining.py:  558]:	worker_index: 7, step: 2199, cost: 7.391507, mlm loss: 7.391507, speed: 1.100755 steps/s, speed: 8.806043 samples/s, speed: 4508.694047 tokens/s, learning rate: 2.198e-05, loss_scalings: 3518.437988, pp_loss: 7.176852
[INFO] 2021-07-12 19:16:17,973 [run_pretraining.py:  512]:	********exe.run_2199******* 
[INFO] 2021-07-12 19:16:18,887 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  534]:	loss/total_loss, 8.0716552734375, 2200
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0716552734375, 2200
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.198999936808832e-05, 2200
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2200
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  558]:	worker_index: 7, step: 2200, cost: 8.071655, mlm loss: 8.071655, speed: 1.093698 steps/s, speed: 8.749585 samples/s, speed: 4479.787655 tokens/s, learning rate: 2.199e-05, loss_scalings: 3518.437988, pp_loss: 7.698897
[INFO] 2021-07-12 19:16:18,888 [run_pretraining.py:  512]:	********exe.run_2200******* 
[INFO] 2021-07-12 19:16:19,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:19,800 [run_pretraining.py:  534]:	loss/total_loss, 5.207602500915527, 2201
[INFO] 2021-07-12 19:16:19,800 [run_pretraining.py:  535]:	loss/mlm_loss, 5.207602500915527, 2201
[INFO] 2021-07-12 19:16:19,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2000000171829015e-05, 2201
[INFO] 2021-07-12 19:16:19,801 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2201
[INFO] 2021-07-12 19:16:19,801 [run_pretraining.py:  558]:	worker_index: 7, step: 2201, cost: 5.207603, mlm loss: 5.207603, speed: 1.096875 steps/s, speed: 8.775002 samples/s, speed: 4492.801051 tokens/s, learning rate: 2.200e-05, loss_scalings: 3518.437988, pp_loss: 6.543118
[INFO] 2021-07-12 19:16:19,801 [run_pretraining.py:  512]:	********exe.run_2201******* 
[INFO] 2021-07-12 19:16:20,742 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:20,742 [run_pretraining.py:  534]:	loss/total_loss, 7.416128158569336, 2202
[INFO] 2021-07-12 19:16:20,742 [run_pretraining.py:  535]:	loss/mlm_loss, 7.416128158569336, 2202
[INFO] 2021-07-12 19:16:20,743 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2009999156580307e-05, 2202
[INFO] 2021-07-12 19:16:20,743 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2202
[INFO] 2021-07-12 19:16:20,743 [run_pretraining.py:  558]:	worker_index: 7, step: 2202, cost: 7.416128, mlm loss: 7.416128, speed: 1.062204 steps/s, speed: 8.497635 samples/s, speed: 4350.789007 tokens/s, learning rate: 2.201e-05, loss_scalings: 3518.437988, pp_loss: 7.082507
[INFO] 2021-07-12 19:16:20,743 [run_pretraining.py:  512]:	********exe.run_2202******* 
[INFO] 2021-07-12 19:16:21,675 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:21,676 [run_pretraining.py:  534]:	loss/total_loss, 7.27336311340332, 2203
[INFO] 2021-07-12 19:16:21,676 [run_pretraining.py:  535]:	loss/mlm_loss, 7.27336311340332, 2203
[INFO] 2021-07-12 19:16:21,676 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2019999960321002e-05, 2203
[INFO] 2021-07-12 19:16:21,676 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2203
[INFO] 2021-07-12 19:16:21,676 [run_pretraining.py:  558]:	worker_index: 7, step: 2203, cost: 7.273363, mlm loss: 7.273363, speed: 1.071822 steps/s, speed: 8.574578 samples/s, speed: 4390.183797 tokens/s, learning rate: 2.202e-05, loss_scalings: 3518.437988, pp_loss: 7.338694
[INFO] 2021-07-12 19:16:21,676 [run_pretraining.py:  512]:	********exe.run_2203******* 
[INFO] 2021-07-12 19:16:22,584 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:22,585 [run_pretraining.py:  534]:	loss/total_loss, 7.535677909851074, 2204
[INFO] 2021-07-12 19:16:22,585 [run_pretraining.py:  535]:	loss/mlm_loss, 7.535677909851074, 2204
[INFO] 2021-07-12 19:16:22,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2029998945072293e-05, 2204
[INFO] 2021-07-12 19:16:22,585 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2204
[INFO] 2021-07-12 19:16:22,585 [run_pretraining.py:  558]:	worker_index: 7, step: 2204, cost: 7.535678, mlm loss: 7.535678, speed: 1.100942 steps/s, speed: 8.807534 samples/s, speed: 4509.457382 tokens/s, learning rate: 2.203e-05, loss_scalings: 3518.437988, pp_loss: 7.732471
[INFO] 2021-07-12 19:16:22,585 [run_pretraining.py:  512]:	********exe.run_2204******* 
[INFO] 2021-07-12 19:16:23,491 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  534]:	loss/total_loss, 7.523033142089844, 2205
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  535]:	loss/mlm_loss, 7.523033142089844, 2205
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.203999974881299e-05, 2205
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2205
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  558]:	worker_index: 7, step: 2205, cost: 7.523033, mlm loss: 7.523033, speed: 1.103591 steps/s, speed: 8.828731 samples/s, speed: 4520.310421 tokens/s, learning rate: 2.204e-05, loss_scalings: 3518.437988, pp_loss: 7.180001
[INFO] 2021-07-12 19:16:23,492 [run_pretraining.py:  512]:	********exe.run_2205******* 
[INFO] 2021-07-12 19:16:24,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:24,406 [run_pretraining.py:  534]:	loss/total_loss, 7.423569679260254, 2206
[INFO] 2021-07-12 19:16:24,406 [run_pretraining.py:  535]:	loss/mlm_loss, 7.423569679260254, 2206
[INFO] 2021-07-12 19:16:24,406 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2050000552553684e-05, 2206
[INFO] 2021-07-12 19:16:24,406 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2206
[INFO] 2021-07-12 19:16:24,406 [run_pretraining.py:  558]:	worker_index: 7, step: 2206, cost: 7.423570, mlm loss: 7.423570, speed: 1.094482 steps/s, speed: 8.755857 samples/s, speed: 4482.998837 tokens/s, learning rate: 2.205e-05, loss_scalings: 3518.437988, pp_loss: 7.014455
[INFO] 2021-07-12 19:16:24,407 [run_pretraining.py:  512]:	********exe.run_2206******* 
[INFO] 2021-07-12 19:16:25,308 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:25,308 [run_pretraining.py:  534]:	loss/total_loss, 7.183481693267822, 2207
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183481693267822, 2207
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2059999537304975e-05, 2207
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2207
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  558]:	worker_index: 7, step: 2207, cost: 7.183482, mlm loss: 7.183482, speed: 1.108956 steps/s, speed: 8.871649 samples/s, speed: 4542.284465 tokens/s, learning rate: 2.206e-05, loss_scalings: 3518.437988, pp_loss: 7.147072
[INFO] 2021-07-12 19:16:25,309 [run_pretraining.py:  512]:	********exe.run_2207******* 
[INFO] 2021-07-12 19:16:26,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:26,216 [run_pretraining.py:  534]:	loss/total_loss, 7.136943817138672, 2208
[INFO] 2021-07-12 19:16:26,217 [run_pretraining.py:  535]:	loss/mlm_loss, 7.136943817138672, 2208
[INFO] 2021-07-12 19:16:26,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2069998522056267e-05, 2208
[INFO] 2021-07-12 19:16:26,217 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2208
[INFO] 2021-07-12 19:16:26,217 [run_pretraining.py:  558]:	worker_index: 7, step: 2208, cost: 7.136944, mlm loss: 7.136944, speed: 1.102168 steps/s, speed: 8.817347 samples/s, speed: 4514.481712 tokens/s, learning rate: 2.207e-05, loss_scalings: 3518.437988, pp_loss: 7.424457
[INFO] 2021-07-12 19:16:26,217 [run_pretraining.py:  512]:	********exe.run_2208******* 
[INFO] 2021-07-12 19:16:27,123 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:27,124 [run_pretraining.py:  534]:	loss/total_loss, 6.979659080505371, 2209
[INFO] 2021-07-12 19:16:27,124 [run_pretraining.py:  535]:	loss/mlm_loss, 6.979659080505371, 2209
[INFO] 2021-07-12 19:16:27,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2079999325796962e-05, 2209
[INFO] 2021-07-12 19:16:27,124 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2209
[INFO] 2021-07-12 19:16:27,124 [run_pretraining.py:  558]:	worker_index: 7, step: 2209, cost: 6.979659, mlm loss: 6.979659, speed: 1.103079 steps/s, speed: 8.824628 samples/s, speed: 4518.209782 tokens/s, learning rate: 2.208e-05, loss_scalings: 3518.437988, pp_loss: 6.985086
[INFO] 2021-07-12 19:16:27,124 [run_pretraining.py:  512]:	********exe.run_2209******* 
[INFO] 2021-07-12 19:16:28,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:28,028 [run_pretraining.py:  534]:	loss/total_loss, 7.379188060760498, 2210
[INFO] 2021-07-12 19:16:28,028 [run_pretraining.py:  535]:	loss/mlm_loss, 7.379188060760498, 2210
[INFO] 2021-07-12 19:16:28,028 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2090000129537657e-05, 2210
[INFO] 2021-07-12 19:16:28,028 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2210
[INFO] 2021-07-12 19:16:28,028 [run_pretraining.py:  558]:	worker_index: 7, step: 2210, cost: 7.379188, mlm loss: 7.379188, speed: 1.107027 steps/s, speed: 8.856216 samples/s, speed: 4534.382703 tokens/s, learning rate: 2.209e-05, loss_scalings: 3518.437988, pp_loss: 7.280775
[INFO] 2021-07-12 19:16:28,028 [run_pretraining.py:  512]:	********exe.run_2210******* 
[INFO] 2021-07-12 19:16:29,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:29,022 [run_pretraining.py:  534]:	loss/total_loss, 7.728894233703613, 2211
[INFO] 2021-07-12 19:16:29,022 [run_pretraining.py:  535]:	loss/mlm_loss, 7.728894233703613, 2211
[INFO] 2021-07-12 19:16:29,022 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.209999911428895e-05, 2211
[INFO] 2021-07-12 19:16:29,022 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2211
[INFO] 2021-07-12 19:16:29,022 [run_pretraining.py:  558]:	worker_index: 7, step: 2211, cost: 7.728894, mlm loss: 7.728894, speed: 1.006620 steps/s, speed: 8.052959 samples/s, speed: 4123.114839 tokens/s, learning rate: 2.210e-05, loss_scalings: 3518.437988, pp_loss: 7.528953
[INFO] 2021-07-12 19:16:29,022 [run_pretraining.py:  512]:	********exe.run_2211******* 
[INFO] 2021-07-12 19:16:29,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:29,927 [run_pretraining.py:  534]:	loss/total_loss, 4.053117752075195, 2212
[INFO] 2021-07-12 19:16:29,927 [run_pretraining.py:  535]:	loss/mlm_loss, 4.053117752075195, 2212
[INFO] 2021-07-12 19:16:29,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2109999918029644e-05, 2212
[INFO] 2021-07-12 19:16:29,927 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2212
[INFO] 2021-07-12 19:16:29,927 [run_pretraining.py:  558]:	worker_index: 7, step: 2212, cost: 4.053118, mlm loss: 4.053118, speed: 1.105443 steps/s, speed: 8.843544 samples/s, speed: 4527.894648 tokens/s, learning rate: 2.211e-05, loss_scalings: 3518.437988, pp_loss: 6.937395
[INFO] 2021-07-12 19:16:29,927 [run_pretraining.py:  512]:	********exe.run_2212******* 
[INFO] 2021-07-12 19:16:30,835 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:30,836 [run_pretraining.py:  534]:	loss/total_loss, 7.16107177734375, 2213
[INFO] 2021-07-12 19:16:30,836 [run_pretraining.py:  535]:	loss/mlm_loss, 7.16107177734375, 2213
[INFO] 2021-07-12 19:16:30,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.212000072177034e-05, 2213
[INFO] 2021-07-12 19:16:30,836 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2213
[INFO] 2021-07-12 19:16:30,836 [run_pretraining.py:  558]:	worker_index: 7, step: 2213, cost: 7.161072, mlm loss: 7.161072, speed: 1.100960 steps/s, speed: 8.807677 samples/s, speed: 4509.530770 tokens/s, learning rate: 2.212e-05, loss_scalings: 3518.437988, pp_loss: 7.324414
[INFO] 2021-07-12 19:16:30,836 [run_pretraining.py:  512]:	********exe.run_2213******* 
[INFO] 2021-07-12 19:16:31,735 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:31,736 [run_pretraining.py:  534]:	loss/total_loss, 7.033489227294922, 2214
[INFO] 2021-07-12 19:16:31,736 [run_pretraining.py:  535]:	loss/mlm_loss, 7.033489227294922, 2214
[INFO] 2021-07-12 19:16:31,736 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.212999970652163e-05, 2214
[INFO] 2021-07-12 19:16:31,736 [run_pretraining.py:  539]:	lr/loss_scaling, 3518.43798828125, 2214
[INFO] 2021-07-12 19:16:31,736 [run_pretraining.py:  558]:	worker_index: 7, step: 2214, cost: 7.033489, mlm loss: 7.033489, speed: 1.111965 steps/s, speed: 8.895722 samples/s, speed: 4554.609651 tokens/s, learning rate: 2.213e-05, loss_scalings: 3518.437988, pp_loss: 7.014237
[INFO] 2021-07-12 19:16:31,736 [run_pretraining.py:  512]:	********exe.run_2214******* 
[INFO] 2021-07-12 19:16:32,652 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:32,653 [run_pretraining.py:  534]:	loss/total_loss, 7.054211616516113, 2215
[INFO] 2021-07-12 19:16:32,653 [run_pretraining.py:  535]:	loss/mlm_loss, 7.054211616516113, 2215
[INFO] 2021-07-12 19:16:32,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2139998691272922e-05, 2215
[INFO] 2021-07-12 19:16:32,653 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2215
[INFO] 2021-07-12 19:16:32,653 [run_pretraining.py:  558]:	worker_index: 7, step: 2215, cost: 7.054212, mlm loss: 7.054212, speed: 1.091190 steps/s, speed: 8.729520 samples/s, speed: 4469.514113 tokens/s, learning rate: 2.214e-05, loss_scalings: 2814.750488, pp_loss: 6.894115
[INFO] 2021-07-12 19:16:32,653 [run_pretraining.py:  512]:	********exe.run_2215******* 
[INFO] 2021-07-12 19:16:33,566 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:33,567 [run_pretraining.py:  534]:	loss/total_loss, 7.213117599487305, 2216
[INFO] 2021-07-12 19:16:33,567 [run_pretraining.py:  535]:	loss/mlm_loss, 7.213117599487305, 2216
[INFO] 2021-07-12 19:16:33,567 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2149999495013617e-05, 2216
[INFO] 2021-07-12 19:16:33,567 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2216
[INFO] 2021-07-12 19:16:33,567 [run_pretraining.py:  558]:	worker_index: 7, step: 2216, cost: 7.213118, mlm loss: 7.213118, speed: 1.095045 steps/s, speed: 8.760363 samples/s, speed: 4485.305730 tokens/s, learning rate: 2.215e-05, loss_scalings: 2814.750488, pp_loss: 6.891049
[INFO] 2021-07-12 19:16:33,567 [run_pretraining.py:  512]:	********exe.run_2216******* 
[INFO] 2021-07-12 19:16:34,480 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:34,481 [run_pretraining.py:  534]:	loss/total_loss, 6.757331848144531, 2217
[INFO] 2021-07-12 19:16:34,481 [run_pretraining.py:  535]:	loss/mlm_loss, 6.757331848144531, 2217
[INFO] 2021-07-12 19:16:34,481 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.215999847976491e-05, 2217
[INFO] 2021-07-12 19:16:34,481 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2217
[INFO] 2021-07-12 19:16:34,481 [run_pretraining.py:  558]:	worker_index: 7, step: 2217, cost: 6.757332, mlm loss: 6.757332, speed: 1.095195 steps/s, speed: 8.761557 samples/s, speed: 4485.917086 tokens/s, learning rate: 2.216e-05, loss_scalings: 2814.750488, pp_loss: 7.333786
[INFO] 2021-07-12 19:16:34,481 [run_pretraining.py:  512]:	********exe.run_2217******* 
[INFO] 2021-07-12 19:16:35,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:35,403 [run_pretraining.py:  534]:	loss/total_loss, 7.08730411529541, 2218
[INFO] 2021-07-12 19:16:35,403 [run_pretraining.py:  535]:	loss/mlm_loss, 7.08730411529541, 2218
[INFO] 2021-07-12 19:16:35,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2169999283505604e-05, 2218
[INFO] 2021-07-12 19:16:35,403 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2218
[INFO] 2021-07-12 19:16:35,403 [run_pretraining.py:  558]:	worker_index: 7, step: 2218, cost: 7.087304, mlm loss: 7.087304, speed: 1.084979 steps/s, speed: 8.679832 samples/s, speed: 4444.073747 tokens/s, learning rate: 2.217e-05, loss_scalings: 2814.750488, pp_loss: 7.309084
[INFO] 2021-07-12 19:16:35,403 [run_pretraining.py:  512]:	********exe.run_2218******* 
[INFO] 2021-07-12 19:16:36,311 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  534]:	loss/total_loss, 6.697559356689453, 2219
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  535]:	loss/mlm_loss, 6.697559356689453, 2219
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.21800000872463e-05, 2219
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2219
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  558]:	worker_index: 7, step: 2219, cost: 6.697559, mlm loss: 6.697559, speed: 1.100982 steps/s, speed: 8.807858 samples/s, speed: 4509.623101 tokens/s, learning rate: 2.218e-05, loss_scalings: 2814.750488, pp_loss: 7.298466
[INFO] 2021-07-12 19:16:36,312 [run_pretraining.py:  512]:	********exe.run_2219******* 
[INFO] 2021-07-12 19:16:37,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:37,225 [run_pretraining.py:  534]:	loss/total_loss, 7.384973526000977, 2220
[INFO] 2021-07-12 19:16:37,226 [run_pretraining.py:  535]:	loss/mlm_loss, 7.384973526000977, 2220
[INFO] 2021-07-12 19:16:37,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.218999907199759e-05, 2220
[INFO] 2021-07-12 19:16:37,226 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2220
[INFO] 2021-07-12 19:16:37,226 [run_pretraining.py:  558]:	worker_index: 7, step: 2220, cost: 7.384974, mlm loss: 7.384974, speed: 1.095291 steps/s, speed: 8.762328 samples/s, speed: 4486.311862 tokens/s, learning rate: 2.219e-05, loss_scalings: 2814.750488, pp_loss: 7.469142
[INFO] 2021-07-12 19:16:37,226 [run_pretraining.py:  512]:	********exe.run_2220******* 
[INFO] 2021-07-12 19:16:38,142 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:38,143 [run_pretraining.py:  534]:	loss/total_loss, 7.289597511291504, 2221
[INFO] 2021-07-12 19:16:38,143 [run_pretraining.py:  535]:	loss/mlm_loss, 7.289597511291504, 2221
[INFO] 2021-07-12 19:16:38,143 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2199999875738285e-05, 2221
[INFO] 2021-07-12 19:16:38,143 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2221
[INFO] 2021-07-12 19:16:38,143 [run_pretraining.py:  558]:	worker_index: 7, step: 2221, cost: 7.289598, mlm loss: 7.289598, speed: 1.091126 steps/s, speed: 8.729009 samples/s, speed: 4469.252501 tokens/s, learning rate: 2.220e-05, loss_scalings: 2814.750488, pp_loss: 6.768934
[INFO] 2021-07-12 19:16:38,143 [run_pretraining.py:  512]:	********exe.run_2221******* 
[INFO] 2021-07-12 19:16:39,057 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  534]:	loss/total_loss, 7.119346618652344, 2222
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  535]:	loss/mlm_loss, 7.119346618652344, 2222
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.221000067947898e-05, 2222
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2222
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  558]:	worker_index: 7, step: 2222, cost: 7.119347, mlm loss: 7.119347, speed: 1.093294 steps/s, speed: 8.746356 samples/s, speed: 4478.134179 tokens/s, learning rate: 2.221e-05, loss_scalings: 2814.750488, pp_loss: 7.248162
[INFO] 2021-07-12 19:16:39,058 [run_pretraining.py:  512]:	********exe.run_2222******* 
[INFO] 2021-07-12 19:16:39,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:39,973 [run_pretraining.py:  534]:	loss/total_loss, 7.071031093597412, 2223
[INFO] 2021-07-12 19:16:39,973 [run_pretraining.py:  535]:	loss/mlm_loss, 7.071031093597412, 2223
[INFO] 2021-07-12 19:16:39,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2219999664230272e-05, 2223
[INFO] 2021-07-12 19:16:39,973 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2223
[INFO] 2021-07-12 19:16:39,973 [run_pretraining.py:  558]:	worker_index: 7, step: 2223, cost: 7.071031, mlm loss: 7.071031, speed: 1.093866 steps/s, speed: 8.750925 samples/s, speed: 4480.473459 tokens/s, learning rate: 2.222e-05, loss_scalings: 2814.750488, pp_loss: 7.423803
[INFO] 2021-07-12 19:16:39,973 [run_pretraining.py:  512]:	********exe.run_2223******* 
[INFO] 2021-07-12 19:16:40,879 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:40,880 [run_pretraining.py:  534]:	loss/total_loss, 7.181604862213135, 2224
[INFO] 2021-07-12 19:16:40,880 [run_pretraining.py:  535]:	loss/mlm_loss, 7.181604862213135, 2224
[INFO] 2021-07-12 19:16:40,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2229998648981564e-05, 2224
[INFO] 2021-07-12 19:16:40,880 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2224
[INFO] 2021-07-12 19:16:40,880 [run_pretraining.py:  558]:	worker_index: 7, step: 2224, cost: 7.181605, mlm loss: 7.181605, speed: 1.103690 steps/s, speed: 8.829517 samples/s, speed: 4520.712463 tokens/s, learning rate: 2.223e-05, loss_scalings: 2814.750488, pp_loss: 7.492155
[INFO] 2021-07-12 19:16:40,880 [run_pretraining.py:  512]:	********exe.run_2224******* 
[INFO] 2021-07-12 19:16:41,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:41,797 [run_pretraining.py:  534]:	loss/total_loss, 6.750415802001953, 2225
[INFO] 2021-07-12 19:16:41,798 [run_pretraining.py:  535]:	loss/mlm_loss, 6.750415802001953, 2225
[INFO] 2021-07-12 19:16:41,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.223999945272226e-05, 2225
[INFO] 2021-07-12 19:16:41,798 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2225
[INFO] 2021-07-12 19:16:41,798 [run_pretraining.py:  558]:	worker_index: 7, step: 2225, cost: 6.750416, mlm loss: 6.750416, speed: 1.090269 steps/s, speed: 8.722150 samples/s, speed: 4465.740564 tokens/s, learning rate: 2.224e-05, loss_scalings: 2814.750488, pp_loss: 6.846660
[INFO] 2021-07-12 19:16:41,798 [run_pretraining.py:  512]:	********exe.run_2225******* 
[INFO] 2021-07-12 19:16:42,715 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:42,716 [run_pretraining.py:  534]:	loss/total_loss, 7.111673831939697, 2226
[INFO] 2021-07-12 19:16:42,717 [run_pretraining.py:  535]:	loss/mlm_loss, 7.111673831939697, 2226
[INFO] 2021-07-12 19:16:42,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.224999843747355e-05, 2226
[INFO] 2021-07-12 19:16:42,721 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2226
[INFO] 2021-07-12 19:16:42,722 [run_pretraining.py:  558]:	worker_index: 7, step: 2226, cost: 7.111674, mlm loss: 7.111674, speed: 1.089720 steps/s, speed: 8.717760 samples/s, speed: 4463.493176 tokens/s, learning rate: 2.225e-05, loss_scalings: 2814.750488, pp_loss: 6.883219
[INFO] 2021-07-12 19:16:42,722 [run_pretraining.py:  512]:	********exe.run_2226******* 
[INFO] 2021-07-12 19:16:43,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:43,631 [run_pretraining.py:  534]:	loss/total_loss, 7.061816215515137, 2227
[INFO] 2021-07-12 19:16:43,631 [run_pretraining.py:  535]:	loss/mlm_loss, 7.061816215515137, 2227
[INFO] 2021-07-12 19:16:43,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2259999241214246e-05, 2227
[INFO] 2021-07-12 19:16:43,631 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2227
[INFO] 2021-07-12 19:16:43,631 [run_pretraining.py:  558]:	worker_index: 7, step: 2227, cost: 7.061816, mlm loss: 7.061816, speed: 1.101347 steps/s, speed: 8.810779 samples/s, speed: 4511.118675 tokens/s, learning rate: 2.226e-05, loss_scalings: 2814.750488, pp_loss: 7.186574
[INFO] 2021-07-12 19:16:43,631 [run_pretraining.py:  512]:	********exe.run_2227******* 
[INFO] 2021-07-12 19:16:44,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  534]:	loss/total_loss, 7.541043281555176, 2228
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  535]:	loss/mlm_loss, 7.541043281555176, 2228
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.227000004495494e-05, 2228
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2228
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  558]:	worker_index: 7, step: 2228, cost: 7.541043, mlm loss: 7.541043, speed: 1.092488 steps/s, speed: 8.739902 samples/s, speed: 4474.829720 tokens/s, learning rate: 2.227e-05, loss_scalings: 2814.750488, pp_loss: 7.492924
[INFO] 2021-07-12 19:16:44,547 [run_pretraining.py:  512]:	********exe.run_2228******* 
[INFO] 2021-07-12 19:16:45,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:45,461 [run_pretraining.py:  534]:	loss/total_loss, 7.424810409545898, 2229
[INFO] 2021-07-12 19:16:45,461 [run_pretraining.py:  535]:	loss/mlm_loss, 7.424810409545898, 2229
[INFO] 2021-07-12 19:16:45,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2279999029706232e-05, 2229
[INFO] 2021-07-12 19:16:45,461 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2229
[INFO] 2021-07-12 19:16:45,461 [run_pretraining.py:  558]:	worker_index: 7, step: 2229, cost: 7.424810, mlm loss: 7.424810, speed: 1.094812 steps/s, speed: 8.758495 samples/s, speed: 4484.349211 tokens/s, learning rate: 2.228e-05, loss_scalings: 2814.750488, pp_loss: 7.141840
[INFO] 2021-07-12 19:16:45,461 [run_pretraining.py:  512]:	********exe.run_2229******* 
[INFO] 2021-07-12 19:16:46,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:46,379 [run_pretraining.py:  534]:	loss/total_loss, 6.675539016723633, 2230
[INFO] 2021-07-12 19:16:46,379 [run_pretraining.py:  535]:	loss/mlm_loss, 6.675539016723633, 2230
[INFO] 2021-07-12 19:16:46,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2289999833446927e-05, 2230
[INFO] 2021-07-12 19:16:46,379 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2230
[INFO] 2021-07-12 19:16:46,379 [run_pretraining.py:  558]:	worker_index: 7, step: 2230, cost: 6.675539, mlm loss: 6.675539, speed: 1.090111 steps/s, speed: 8.720891 samples/s, speed: 4465.096399 tokens/s, learning rate: 2.229e-05, loss_scalings: 2814.750488, pp_loss: 6.501273
[INFO] 2021-07-12 19:16:46,379 [run_pretraining.py:  512]:	********exe.run_2230******* 
[INFO] 2021-07-12 19:16:47,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:47,294 [run_pretraining.py:  534]:	loss/total_loss, 7.28957462310791, 2231
[INFO] 2021-07-12 19:16:47,294 [run_pretraining.py:  535]:	loss/mlm_loss, 7.28957462310791, 2231
[INFO] 2021-07-12 19:16:47,294 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2300000637187622e-05, 2231
[INFO] 2021-07-12 19:16:47,294 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2231
[INFO] 2021-07-12 19:16:47,294 [run_pretraining.py:  558]:	worker_index: 7, step: 2231, cost: 7.289575, mlm loss: 7.289575, speed: 1.093167 steps/s, speed: 8.745332 samples/s, speed: 4477.610133 tokens/s, learning rate: 2.230e-05, loss_scalings: 2814.750488, pp_loss: 7.244304
[INFO] 2021-07-12 19:16:47,294 [run_pretraining.py:  512]:	********exe.run_2231******* 
[INFO] 2021-07-12 19:16:48,207 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  534]:	loss/total_loss, 7.570427417755127, 2232
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  535]:	loss/mlm_loss, 7.570427417755127, 2232
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2309999621938914e-05, 2232
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2232
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  558]:	worker_index: 7, step: 2232, cost: 7.570427, mlm loss: 7.570427, speed: 1.095436 steps/s, speed: 8.763488 samples/s, speed: 4486.905914 tokens/s, learning rate: 2.231e-05, loss_scalings: 2814.750488, pp_loss: 7.217811
[INFO] 2021-07-12 19:16:48,208 [run_pretraining.py:  512]:	********exe.run_2232******* 
[INFO] 2021-07-12 19:16:49,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:49,116 [run_pretraining.py:  534]:	loss/total_loss, 6.95634126663208, 2233
[INFO] 2021-07-12 19:16:49,117 [run_pretraining.py:  535]:	loss/mlm_loss, 6.95634126663208, 2233
[INFO] 2021-07-12 19:16:49,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2319998606690206e-05, 2233
[INFO] 2021-07-12 19:16:49,117 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2233
[INFO] 2021-07-12 19:16:49,117 [run_pretraining.py:  558]:	worker_index: 7, step: 2233, cost: 6.956341, mlm loss: 6.956341, speed: 1.101107 steps/s, speed: 8.808854 samples/s, speed: 4510.133356 tokens/s, learning rate: 2.232e-05, loss_scalings: 2814.750488, pp_loss: 7.273337
[INFO] 2021-07-12 19:16:49,117 [run_pretraining.py:  512]:	********exe.run_2233******* 
[INFO] 2021-07-12 19:16:50,035 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:50,036 [run_pretraining.py:  534]:	loss/total_loss, 7.168159484863281, 2234
[INFO] 2021-07-12 19:16:50,036 [run_pretraining.py:  535]:	loss/mlm_loss, 7.168159484863281, 2234
[INFO] 2021-07-12 19:16:50,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.23299994104309e-05, 2234
[INFO] 2021-07-12 19:16:50,036 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2234
[INFO] 2021-07-12 19:16:50,036 [run_pretraining.py:  558]:	worker_index: 7, step: 2234, cost: 7.168159, mlm loss: 7.168159, speed: 1.088244 steps/s, speed: 8.705949 samples/s, speed: 4457.445647 tokens/s, learning rate: 2.233e-05, loss_scalings: 2814.750488, pp_loss: 7.043479
[INFO] 2021-07-12 19:16:50,036 [run_pretraining.py:  512]:	********exe.run_2234******* 
[INFO] 2021-07-12 19:16:50,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:50,956 [run_pretraining.py:  534]:	loss/total_loss, 7.695554733276367, 2235
[INFO] 2021-07-12 19:16:50,957 [run_pretraining.py:  535]:	loss/mlm_loss, 7.695554733276367, 2235
[INFO] 2021-07-12 19:16:50,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2339998395182192e-05, 2235
[INFO] 2021-07-12 19:16:50,957 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2235
[INFO] 2021-07-12 19:16:50,957 [run_pretraining.py:  558]:	worker_index: 7, step: 2235, cost: 7.695555, mlm loss: 7.695555, speed: 1.087248 steps/s, speed: 8.697987 samples/s, speed: 4453.369185 tokens/s, learning rate: 2.234e-05, loss_scalings: 2814.750488, pp_loss: 7.382902
[INFO] 2021-07-12 19:16:50,957 [run_pretraining.py:  512]:	********exe.run_2235******* 
[INFO] 2021-07-12 19:16:51,904 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:51,904 [run_pretraining.py:  534]:	loss/total_loss, 7.070439338684082, 2236
[INFO] 2021-07-12 19:16:51,904 [run_pretraining.py:  535]:	loss/mlm_loss, 7.070439338684082, 2236
[INFO] 2021-07-12 19:16:51,904 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2349999198922887e-05, 2236
[INFO] 2021-07-12 19:16:51,904 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2236
[INFO] 2021-07-12 19:16:51,904 [run_pretraining.py:  558]:	worker_index: 7, step: 2236, cost: 7.070439, mlm loss: 7.070439, speed: 1.055917 steps/s, speed: 8.447334 samples/s, speed: 4325.034939 tokens/s, learning rate: 2.235e-05, loss_scalings: 2814.750488, pp_loss: 7.351407
[INFO] 2021-07-12 19:16:51,905 [run_pretraining.py:  512]:	********exe.run_2236******* 
[INFO] 2021-07-12 19:16:52,844 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:52,845 [run_pretraining.py:  534]:	loss/total_loss, 7.306591033935547, 2237
[INFO] 2021-07-12 19:16:52,845 [run_pretraining.py:  535]:	loss/mlm_loss, 7.306591033935547, 2237
[INFO] 2021-07-12 19:16:52,845 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2360000002663583e-05, 2237
[INFO] 2021-07-12 19:16:52,845 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2237
[INFO] 2021-07-12 19:16:52,845 [run_pretraining.py:  558]:	worker_index: 7, step: 2237, cost: 7.306591, mlm loss: 7.306591, speed: 1.064040 steps/s, speed: 8.512322 samples/s, speed: 4358.308777 tokens/s, learning rate: 2.236e-05, loss_scalings: 2814.750488, pp_loss: 7.046576
[INFO] 2021-07-12 19:16:52,845 [run_pretraining.py:  512]:	********exe.run_2237******* 
[INFO] 2021-07-12 19:16:53,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:53,756 [run_pretraining.py:  534]:	loss/total_loss, 7.245253086090088, 2238
[INFO] 2021-07-12 19:16:53,757 [run_pretraining.py:  535]:	loss/mlm_loss, 7.245253086090088, 2238
[INFO] 2021-07-12 19:16:53,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2369998987414874e-05, 2238
[INFO] 2021-07-12 19:16:53,757 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2238
[INFO] 2021-07-12 19:16:53,757 [run_pretraining.py:  558]:	worker_index: 7, step: 2238, cost: 7.245253, mlm loss: 7.245253, speed: 1.097387 steps/s, speed: 8.779098 samples/s, speed: 4494.898117 tokens/s, learning rate: 2.237e-05, loss_scalings: 2814.750488, pp_loss: 7.172743
[INFO] 2021-07-12 19:16:53,757 [run_pretraining.py:  512]:	********exe.run_2238******* 
[INFO] 2021-07-12 19:16:54,667 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:54,668 [run_pretraining.py:  534]:	loss/total_loss, 7.039974212646484, 2239
[INFO] 2021-07-12 19:16:54,668 [run_pretraining.py:  535]:	loss/mlm_loss, 7.039974212646484, 2239
[INFO] 2021-07-12 19:16:54,668 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.237999979115557e-05, 2239
[INFO] 2021-07-12 19:16:54,668 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2239
[INFO] 2021-07-12 19:16:54,668 [run_pretraining.py:  558]:	worker_index: 7, step: 2239, cost: 7.039974, mlm loss: 7.039974, speed: 1.098399 steps/s, speed: 8.787191 samples/s, speed: 4499.041572 tokens/s, learning rate: 2.238e-05, loss_scalings: 2814.750488, pp_loss: 6.661147
[INFO] 2021-07-12 19:16:54,668 [run_pretraining.py:  512]:	********exe.run_2239******* 
[INFO] 2021-07-12 19:16:55,576 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:55,576 [run_pretraining.py:  534]:	loss/total_loss, 8.12574577331543, 2240
[INFO] 2021-07-12 19:16:55,576 [run_pretraining.py:  535]:	loss/mlm_loss, 8.12574577331543, 2240
[INFO] 2021-07-12 19:16:55,576 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2390000594896264e-05, 2240
[INFO] 2021-07-12 19:16:55,576 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2240
[INFO] 2021-07-12 19:16:55,577 [run_pretraining.py:  558]:	worker_index: 7, step: 2240, cost: 8.125746, mlm loss: 8.125746, speed: 1.101350 steps/s, speed: 8.810799 samples/s, speed: 4511.129336 tokens/s, learning rate: 2.239e-05, loss_scalings: 2814.750488, pp_loss: 7.356061
[INFO] 2021-07-12 19:16:55,577 [run_pretraining.py:  512]:	********exe.run_2240******* 
[INFO] 2021-07-12 19:16:56,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  534]:	loss/total_loss, 5.3879828453063965, 2241
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  535]:	loss/mlm_loss, 5.3879828453063965, 2241
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2399999579647556e-05, 2241
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2241
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  558]:	worker_index: 7, step: 2241, cost: 5.387983, mlm loss: 5.387983, speed: 1.099231 steps/s, speed: 8.793851 samples/s, speed: 4502.451518 tokens/s, learning rate: 2.240e-05, loss_scalings: 2814.750488, pp_loss: 6.756627
[INFO] 2021-07-12 19:16:56,487 [run_pretraining.py:  512]:	********exe.run_2241******* 
[INFO] 2021-07-12 19:16:57,394 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:57,394 [run_pretraining.py:  534]:	loss/total_loss, 7.1992902755737305, 2242
[INFO] 2021-07-12 19:16:57,394 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1992902755737305, 2242
[INFO] 2021-07-12 19:16:57,395 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2409998564398848e-05, 2242
[INFO] 2021-07-12 19:16:57,395 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2242
[INFO] 2021-07-12 19:16:57,395 [run_pretraining.py:  558]:	worker_index: 7, step: 2242, cost: 7.199290, mlm loss: 7.199290, speed: 1.102390 steps/s, speed: 8.819120 samples/s, speed: 4515.389417 tokens/s, learning rate: 2.241e-05, loss_scalings: 2814.750488, pp_loss: 7.344312
[INFO] 2021-07-12 19:16:57,395 [run_pretraining.py:  512]:	********exe.run_2242******* 
[INFO] 2021-07-12 19:16:58,303 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:58,304 [run_pretraining.py:  534]:	loss/total_loss, 7.290849685668945, 2243
[INFO] 2021-07-12 19:16:58,304 [run_pretraining.py:  535]:	loss/mlm_loss, 7.290849685668945, 2243
[INFO] 2021-07-12 19:16:58,304 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2419999368139543e-05, 2243
[INFO] 2021-07-12 19:16:58,304 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2243
[INFO] 2021-07-12 19:16:58,304 [run_pretraining.py:  558]:	worker_index: 7, step: 2243, cost: 7.290850, mlm loss: 7.290850, speed: 1.100597 steps/s, speed: 8.804779 samples/s, speed: 4508.046895 tokens/s, learning rate: 2.242e-05, loss_scalings: 2814.750488, pp_loss: 7.398159
[INFO] 2021-07-12 19:16:58,304 [run_pretraining.py:  512]:	********exe.run_2243******* 
[INFO] 2021-07-12 19:16:59,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:16:59,215 [run_pretraining.py:  534]:	loss/total_loss, 7.306272983551025, 2244
[INFO] 2021-07-12 19:16:59,215 [run_pretraining.py:  535]:	loss/mlm_loss, 7.306272983551025, 2244
[INFO] 2021-07-12 19:16:59,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2429998352890834e-05, 2244
[INFO] 2021-07-12 19:16:59,216 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2244
[INFO] 2021-07-12 19:16:59,216 [run_pretraining.py:  558]:	worker_index: 7, step: 2244, cost: 7.306273, mlm loss: 7.306273, speed: 1.097541 steps/s, speed: 8.780329 samples/s, speed: 4495.528559 tokens/s, learning rate: 2.243e-05, loss_scalings: 2814.750488, pp_loss: 7.090950
[INFO] 2021-07-12 19:16:59,216 [run_pretraining.py:  512]:	********exe.run_2244******* 
[INFO] 2021-07-12 19:17:00,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:00,116 [run_pretraining.py:  534]:	loss/total_loss, 4.3198418617248535, 2245
[INFO] 2021-07-12 19:17:00,117 [run_pretraining.py:  535]:	loss/mlm_loss, 4.3198418617248535, 2245
[INFO] 2021-07-12 19:17:00,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.243999915663153e-05, 2245
[INFO] 2021-07-12 19:17:00,117 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2245
[INFO] 2021-07-12 19:17:00,117 [run_pretraining.py:  558]:	worker_index: 7, step: 2245, cost: 4.319842, mlm loss: 4.319842, speed: 1.110514 steps/s, speed: 8.884113 samples/s, speed: 4548.665715 tokens/s, learning rate: 2.244e-05, loss_scalings: 2814.750488, pp_loss: 6.428483
[INFO] 2021-07-12 19:17:00,117 [run_pretraining.py:  512]:	********exe.run_2245******* 
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  534]:	loss/total_loss, 7.392560005187988, 2246
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  535]:	loss/mlm_loss, 7.392560005187988, 2246
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2449999960372224e-05, 2246
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2246
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  558]:	worker_index: 7, step: 2246, cost: 7.392560, mlm loss: 7.392560, speed: 1.116152 steps/s, speed: 8.929216 samples/s, speed: 4571.758713 tokens/s, learning rate: 2.245e-05, loss_scalings: 2814.750488, pp_loss: 7.295307
[INFO] 2021-07-12 19:17:01,013 [run_pretraining.py:  512]:	********exe.run_2246******* 
[INFO] 2021-07-12 19:17:01,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:01,921 [run_pretraining.py:  534]:	loss/total_loss, 6.772188186645508, 2247
[INFO] 2021-07-12 19:17:01,921 [run_pretraining.py:  535]:	loss/mlm_loss, 6.772188186645508, 2247
[INFO] 2021-07-12 19:17:01,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2459998945123516e-05, 2247
[INFO] 2021-07-12 19:17:01,921 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2247
[INFO] 2021-07-12 19:17:01,921 [run_pretraining.py:  558]:	worker_index: 7, step: 2247, cost: 6.772188, mlm loss: 6.772188, speed: 1.102673 steps/s, speed: 8.821387 samples/s, speed: 4516.550387 tokens/s, learning rate: 2.246e-05, loss_scalings: 2814.750488, pp_loss: 7.354452
[INFO] 2021-07-12 19:17:01,921 [run_pretraining.py:  512]:	********exe.run_2247******* 
[INFO] 2021-07-12 19:17:02,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:02,829 [run_pretraining.py:  534]:	loss/total_loss, 7.288779258728027, 2248
[INFO] 2021-07-12 19:17:02,830 [run_pretraining.py:  535]:	loss/mlm_loss, 7.288779258728027, 2248
[INFO] 2021-07-12 19:17:02,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.246999974886421e-05, 2248
[INFO] 2021-07-12 19:17:02,830 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2248
[INFO] 2021-07-12 19:17:02,830 [run_pretraining.py:  558]:	worker_index: 7, step: 2248, cost: 7.288779, mlm loss: 7.288779, speed: 1.101084 steps/s, speed: 8.808674 samples/s, speed: 4510.041004 tokens/s, learning rate: 2.247e-05, loss_scalings: 2814.750488, pp_loss: 7.232695
[INFO] 2021-07-12 19:17:02,830 [run_pretraining.py:  512]:	********exe.run_2248******* 
[INFO] 2021-07-12 19:17:03,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:03,737 [run_pretraining.py:  534]:	loss/total_loss, 7.324994087219238, 2249
[INFO] 2021-07-12 19:17:03,737 [run_pretraining.py:  535]:	loss/mlm_loss, 7.324994087219238, 2249
[INFO] 2021-07-12 19:17:03,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2480000552604906e-05, 2249
[INFO] 2021-07-12 19:17:03,738 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2249
[INFO] 2021-07-12 19:17:03,738 [run_pretraining.py:  558]:	worker_index: 7, step: 2249, cost: 7.324994, mlm loss: 7.324994, speed: 1.102293 steps/s, speed: 8.818341 samples/s, speed: 4514.990694 tokens/s, learning rate: 2.248e-05, loss_scalings: 2814.750488, pp_loss: 7.452867
[INFO] 2021-07-12 19:17:03,738 [run_pretraining.py:  512]:	********exe.run_2249******* 
[INFO] 2021-07-12 19:17:04,647 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:04,647 [run_pretraining.py:  534]:	loss/total_loss, 7.464411735534668, 2250
[INFO] 2021-07-12 19:17:04,647 [run_pretraining.py:  535]:	loss/mlm_loss, 7.464411735534668, 2250
[INFO] 2021-07-12 19:17:04,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2489999537356198e-05, 2250
[INFO] 2021-07-12 19:17:04,647 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2250
[INFO] 2021-07-12 19:17:04,648 [run_pretraining.py:  558]:	worker_index: 7, step: 2250, cost: 7.464412, mlm loss: 7.464412, speed: 1.099885 steps/s, speed: 8.799083 samples/s, speed: 4505.130508 tokens/s, learning rate: 2.249e-05, loss_scalings: 2814.750488, pp_loss: 7.109723
[INFO] 2021-07-12 19:17:04,648 [run_pretraining.py:  512]:	********exe.run_2250******* 
[INFO] 2021-07-12 19:17:05,559 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:05,560 [run_pretraining.py:  534]:	loss/total_loss, 7.772553443908691, 2251
[INFO] 2021-07-12 19:17:05,560 [run_pretraining.py:  535]:	loss/mlm_loss, 7.772553443908691, 2251
[INFO] 2021-07-12 19:17:05,560 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.249999852210749e-05, 2251
[INFO] 2021-07-12 19:17:05,560 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2251
[INFO] 2021-07-12 19:17:05,560 [run_pretraining.py:  558]:	worker_index: 7, step: 2251, cost: 7.772553, mlm loss: 7.772553, speed: 1.096711 steps/s, speed: 8.773687 samples/s, speed: 4492.127913 tokens/s, learning rate: 2.250e-05, loss_scalings: 2814.750488, pp_loss: 7.204140
[INFO] 2021-07-12 19:17:05,560 [run_pretraining.py:  512]:	********exe.run_2251******* 
[INFO] 2021-07-12 19:17:06,460 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:06,461 [run_pretraining.py:  534]:	loss/total_loss, 7.449926376342773, 2252
[INFO] 2021-07-12 19:17:06,461 [run_pretraining.py:  535]:	loss/mlm_loss, 7.449926376342773, 2252
[INFO] 2021-07-12 19:17:06,461 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2509999325848185e-05, 2252
[INFO] 2021-07-12 19:17:06,461 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2252
[INFO] 2021-07-12 19:17:06,461 [run_pretraining.py:  558]:	worker_index: 7, step: 2252, cost: 7.449926, mlm loss: 7.449926, speed: 1.110416 steps/s, speed: 8.883325 samples/s, speed: 4548.262297 tokens/s, learning rate: 2.251e-05, loss_scalings: 2814.750488, pp_loss: 7.601947
[INFO] 2021-07-12 19:17:06,461 [run_pretraining.py:  512]:	********exe.run_2252******* 
[INFO] 2021-07-12 19:17:07,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:07,369 [run_pretraining.py:  534]:	loss/total_loss, 7.723834037780762, 2253
[INFO] 2021-07-12 19:17:07,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.723834037780762, 2253
[INFO] 2021-07-12 19:17:07,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2519998310599476e-05, 2253
[INFO] 2021-07-12 19:17:07,369 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2253
[INFO] 2021-07-12 19:17:07,369 [run_pretraining.py:  558]:	worker_index: 7, step: 2253, cost: 7.723834, mlm loss: 7.723834, speed: 1.102339 steps/s, speed: 8.818710 samples/s, speed: 4515.179366 tokens/s, learning rate: 2.252e-05, loss_scalings: 2814.750488, pp_loss: 7.174293
[INFO] 2021-07-12 19:17:07,369 [run_pretraining.py:  512]:	********exe.run_2253******* 
[INFO] 2021-07-12 19:17:08,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  534]:	loss/total_loss, 7.924435615539551, 2254
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  535]:	loss/mlm_loss, 7.924435615539551, 2254
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.252999911434017e-05, 2254
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2254
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  558]:	worker_index: 7, step: 2254, cost: 7.924436, mlm loss: 7.924436, speed: 1.102218 steps/s, speed: 8.817741 samples/s, speed: 4514.683393 tokens/s, learning rate: 2.253e-05, loss_scalings: 2814.750488, pp_loss: 6.559365
[INFO] 2021-07-12 19:17:08,277 [run_pretraining.py:  512]:	********exe.run_2254******* 
[INFO] 2021-07-12 19:17:09,230 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:09,230 [run_pretraining.py:  534]:	loss/total_loss, 6.922452926635742, 2255
[INFO] 2021-07-12 19:17:09,230 [run_pretraining.py:  535]:	loss/mlm_loss, 6.922452926635742, 2255
[INFO] 2021-07-12 19:17:09,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2539999918080866e-05, 2255
[INFO] 2021-07-12 19:17:09,231 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2255
[INFO] 2021-07-12 19:17:09,231 [run_pretraining.py:  558]:	worker_index: 7, step: 2255, cost: 6.922453, mlm loss: 6.922453, speed: 1.049319 steps/s, speed: 8.394556 samples/s, speed: 4298.012438 tokens/s, learning rate: 2.254e-05, loss_scalings: 2814.750488, pp_loss: 7.311593
[INFO] 2021-07-12 19:17:09,231 [run_pretraining.py:  512]:	********exe.run_2255******* 
[INFO] 2021-07-12 19:17:10,171 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:10,171 [run_pretraining.py:  534]:	loss/total_loss, 8.11285400390625, 2256
[INFO] 2021-07-12 19:17:10,172 [run_pretraining.py:  535]:	loss/mlm_loss, 8.11285400390625, 2256
[INFO] 2021-07-12 19:17:10,172 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2549998902832158e-05, 2256
[INFO] 2021-07-12 19:17:10,172 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2256
[INFO] 2021-07-12 19:17:10,172 [run_pretraining.py:  558]:	worker_index: 7, step: 2256, cost: 8.112854, mlm loss: 8.112854, speed: 1.063267 steps/s, speed: 8.506137 samples/s, speed: 4355.142297 tokens/s, learning rate: 2.255e-05, loss_scalings: 2814.750488, pp_loss: 6.905842
[INFO] 2021-07-12 19:17:10,172 [run_pretraining.py:  512]:	********exe.run_2256******* 
[INFO] 2021-07-12 19:17:11,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:11,087 [run_pretraining.py:  534]:	loss/total_loss, 7.7605485916137695, 2257
[INFO] 2021-07-12 19:17:11,087 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7605485916137695, 2257
[INFO] 2021-07-12 19:17:11,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2559999706572853e-05, 2257
[INFO] 2021-07-12 19:17:11,087 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2257
[INFO] 2021-07-12 19:17:11,087 [run_pretraining.py:  558]:	worker_index: 7, step: 2257, cost: 7.760549, mlm loss: 7.760549, speed: 1.093202 steps/s, speed: 8.745617 samples/s, speed: 4477.756013 tokens/s, learning rate: 2.256e-05, loss_scalings: 2814.750488, pp_loss: 7.386522
[INFO] 2021-07-12 19:17:11,087 [run_pretraining.py:  512]:	********exe.run_2257******* 
[INFO] 2021-07-12 19:17:11,998 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:11,999 [run_pretraining.py:  534]:	loss/total_loss, 7.501104831695557, 2258
[INFO] 2021-07-12 19:17:11,999 [run_pretraining.py:  535]:	loss/mlm_loss, 7.501104831695557, 2258
[INFO] 2021-07-12 19:17:11,999 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2570000510313548e-05, 2258
[INFO] 2021-07-12 19:17:11,999 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2258
[INFO] 2021-07-12 19:17:11,999 [run_pretraining.py:  558]:	worker_index: 7, step: 2258, cost: 7.501105, mlm loss: 7.501105, speed: 1.097614 steps/s, speed: 8.780915 samples/s, speed: 4495.828552 tokens/s, learning rate: 2.257e-05, loss_scalings: 2814.750488, pp_loss: 7.301982
[INFO] 2021-07-12 19:17:11,999 [run_pretraining.py:  512]:	********exe.run_2258******* 
[INFO] 2021-07-12 19:17:12,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:12,913 [run_pretraining.py:  534]:	loss/total_loss, 6.8830976486206055, 2259
[INFO] 2021-07-12 19:17:12,913 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8830976486206055, 2259
[INFO] 2021-07-12 19:17:12,913 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.257999949506484e-05, 2259
[INFO] 2021-07-12 19:17:12,914 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2259
[INFO] 2021-07-12 19:17:12,914 [run_pretraining.py:  558]:	worker_index: 7, step: 2259, cost: 6.883098, mlm loss: 6.883098, speed: 1.094010 steps/s, speed: 8.752082 samples/s, speed: 4481.065966 tokens/s, learning rate: 2.258e-05, loss_scalings: 2814.750488, pp_loss: 7.303512
[INFO] 2021-07-12 19:17:12,914 [run_pretraining.py:  512]:	********exe.run_2259******* 
[INFO] 2021-07-12 19:17:13,826 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:13,827 [run_pretraining.py:  534]:	loss/total_loss, 7.503687858581543, 2260
[INFO] 2021-07-12 19:17:13,827 [run_pretraining.py:  535]:	loss/mlm_loss, 7.503687858581543, 2260
[INFO] 2021-07-12 19:17:13,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.258999847981613e-05, 2260
[INFO] 2021-07-12 19:17:13,827 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2260
[INFO] 2021-07-12 19:17:13,827 [run_pretraining.py:  558]:	worker_index: 7, step: 2260, cost: 7.503688, mlm loss: 7.503688, speed: 1.095762 steps/s, speed: 8.766096 samples/s, speed: 4488.241054 tokens/s, learning rate: 2.259e-05, loss_scalings: 2814.750488, pp_loss: 7.300551
[INFO] 2021-07-12 19:17:13,827 [run_pretraining.py:  512]:	********exe.run_2260******* 
[INFO] 2021-07-12 19:17:14,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:14,738 [run_pretraining.py:  534]:	loss/total_loss, 6.9526896476745605, 2261
[INFO] 2021-07-12 19:17:14,738 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9526896476745605, 2261
[INFO] 2021-07-12 19:17:14,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2599999283556826e-05, 2261
[INFO] 2021-07-12 19:17:14,739 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2261
[INFO] 2021-07-12 19:17:14,739 [run_pretraining.py:  558]:	worker_index: 7, step: 2261, cost: 6.952690, mlm loss: 6.952690, speed: 1.097619 steps/s, speed: 8.780952 samples/s, speed: 4495.847377 tokens/s, learning rate: 2.260e-05, loss_scalings: 2814.750488, pp_loss: 7.177956
[INFO] 2021-07-12 19:17:14,739 [run_pretraining.py:  512]:	********exe.run_2261******* 
[INFO] 2021-07-12 19:17:15,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:15,647 [run_pretraining.py:  534]:	loss/total_loss, 4.010871887207031, 2262
[INFO] 2021-07-12 19:17:15,647 [run_pretraining.py:  535]:	loss/mlm_loss, 4.010871887207031, 2262
[INFO] 2021-07-12 19:17:15,647 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.261000008729752e-05, 2262
[INFO] 2021-07-12 19:17:15,647 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2262
[INFO] 2021-07-12 19:17:15,647 [run_pretraining.py:  558]:	worker_index: 7, step: 2262, cost: 4.010872, mlm loss: 4.010872, speed: 1.101425 steps/s, speed: 8.811399 samples/s, speed: 4511.436153 tokens/s, learning rate: 2.261e-05, loss_scalings: 2814.750488, pp_loss: 6.307811
[INFO] 2021-07-12 19:17:15,647 [run_pretraining.py:  512]:	********exe.run_2262******* 
[INFO] 2021-07-12 19:17:16,562 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:16,562 [run_pretraining.py:  534]:	loss/total_loss, 7.238083839416504, 2263
[INFO] 2021-07-12 19:17:16,562 [run_pretraining.py:  535]:	loss/mlm_loss, 7.238083839416504, 2263
[INFO] 2021-07-12 19:17:16,562 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2619999072048813e-05, 2263
[INFO] 2021-07-12 19:17:16,562 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2263
[INFO] 2021-07-12 19:17:16,563 [run_pretraining.py:  558]:	worker_index: 7, step: 2263, cost: 7.238084, mlm loss: 7.238084, speed: 1.093210 steps/s, speed: 8.745679 samples/s, speed: 4477.787524 tokens/s, learning rate: 2.262e-05, loss_scalings: 2814.750488, pp_loss: 7.292424
[INFO] 2021-07-12 19:17:16,563 [run_pretraining.py:  512]:	********exe.run_2263******* 
[INFO] 2021-07-12 19:17:17,476 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:17,476 [run_pretraining.py:  534]:	loss/total_loss, 6.247154712677002, 2264
[INFO] 2021-07-12 19:17:17,476 [run_pretraining.py:  535]:	loss/mlm_loss, 6.247154712677002, 2264
[INFO] 2021-07-12 19:17:17,476 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2629999875789508e-05, 2264
[INFO] 2021-07-12 19:17:17,476 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2264
[INFO] 2021-07-12 19:17:17,476 [run_pretraining.py:  558]:	worker_index: 7, step: 2264, cost: 6.247155, mlm loss: 6.247155, speed: 1.094987 steps/s, speed: 8.759894 samples/s, speed: 4485.065684 tokens/s, learning rate: 2.263e-05, loss_scalings: 2814.750488, pp_loss: 6.997511
[INFO] 2021-07-12 19:17:17,477 [run_pretraining.py:  512]:	********exe.run_2264******* 
[INFO] 2021-07-12 19:17:18,406 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:18,407 [run_pretraining.py:  534]:	loss/total_loss, 6.95759391784668, 2265
[INFO] 2021-07-12 19:17:18,407 [run_pretraining.py:  535]:	loss/mlm_loss, 6.95759391784668, 2265
[INFO] 2021-07-12 19:17:18,407 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.26399988605408e-05, 2265
[INFO] 2021-07-12 19:17:18,407 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2265
[INFO] 2021-07-12 19:17:18,407 [run_pretraining.py:  558]:	worker_index: 7, step: 2265, cost: 6.957594, mlm loss: 6.957594, speed: 1.075165 steps/s, speed: 8.601321 samples/s, speed: 4403.876257 tokens/s, learning rate: 2.264e-05, loss_scalings: 2814.750488, pp_loss: 6.974569
[INFO] 2021-07-12 19:17:18,407 [run_pretraining.py:  512]:	********exe.run_2265******* 
[INFO] 2021-07-12 19:17:19,317 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:19,317 [run_pretraining.py:  534]:	loss/total_loss, 7.358188629150391, 2266
[INFO] 2021-07-12 19:17:19,318 [run_pretraining.py:  535]:	loss/mlm_loss, 7.358188629150391, 2266
[INFO] 2021-07-12 19:17:19,318 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2649999664281495e-05, 2266
[INFO] 2021-07-12 19:17:19,318 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2266
[INFO] 2021-07-12 19:17:19,318 [run_pretraining.py:  558]:	worker_index: 7, step: 2266, cost: 7.358189, mlm loss: 7.358189, speed: 1.098982 steps/s, speed: 8.791855 samples/s, speed: 4501.429879 tokens/s, learning rate: 2.265e-05, loss_scalings: 2814.750488, pp_loss: 6.286598
[INFO] 2021-07-12 19:17:19,318 [run_pretraining.py:  512]:	********exe.run_2266******* 
[INFO] 2021-07-12 19:17:20,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:20,232 [run_pretraining.py:  534]:	loss/total_loss, 7.274428367614746, 2267
[INFO] 2021-07-12 19:17:20,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.274428367614746, 2267
[INFO] 2021-07-12 19:17:20,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.266000046802219e-05, 2267
[INFO] 2021-07-12 19:17:20,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2267
[INFO] 2021-07-12 19:17:20,232 [run_pretraining.py:  558]:	worker_index: 7, step: 2267, cost: 7.274428, mlm loss: 7.274428, speed: 1.094373 steps/s, speed: 8.754982 samples/s, speed: 4482.550842 tokens/s, learning rate: 2.266e-05, loss_scalings: 2814.750488, pp_loss: 7.275060
[INFO] 2021-07-12 19:17:20,232 [run_pretraining.py:  512]:	********exe.run_2267******* 
[INFO] 2021-07-12 19:17:21,141 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:21,142 [run_pretraining.py:  534]:	loss/total_loss, 7.36423397064209, 2268
[INFO] 2021-07-12 19:17:21,142 [run_pretraining.py:  535]:	loss/mlm_loss, 7.36423397064209, 2268
[INFO] 2021-07-12 19:17:21,142 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.266999945277348e-05, 2268
[INFO] 2021-07-12 19:17:21,142 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2268
[INFO] 2021-07-12 19:17:21,142 [run_pretraining.py:  558]:	worker_index: 7, step: 2268, cost: 7.364234, mlm loss: 7.364234, speed: 1.099803 steps/s, speed: 8.798425 samples/s, speed: 4504.793836 tokens/s, learning rate: 2.267e-05, loss_scalings: 2814.750488, pp_loss: 6.753529
[INFO] 2021-07-12 19:17:21,142 [run_pretraining.py:  512]:	********exe.run_2268******* 
[INFO] 2021-07-12 19:17:22,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:22,058 [run_pretraining.py:  534]:	loss/total_loss, 7.3740434646606445, 2269
[INFO] 2021-07-12 19:17:22,058 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3740434646606445, 2269
[INFO] 2021-07-12 19:17:22,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2679998437524773e-05, 2269
[INFO] 2021-07-12 19:17:22,059 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2269
[INFO] 2021-07-12 19:17:22,059 [run_pretraining.py:  558]:	worker_index: 7, step: 2269, cost: 7.374043, mlm loss: 7.374043, speed: 1.091825 steps/s, speed: 8.734599 samples/s, speed: 4472.114458 tokens/s, learning rate: 2.268e-05, loss_scalings: 2814.750488, pp_loss: 7.569027
[INFO] 2021-07-12 19:17:22,059 [run_pretraining.py:  512]:	********exe.run_2269******* 
[INFO] 2021-07-12 19:17:22,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:22,970 [run_pretraining.py:  534]:	loss/total_loss, 7.26969051361084, 2270
[INFO] 2021-07-12 19:17:22,970 [run_pretraining.py:  535]:	loss/mlm_loss, 7.26969051361084, 2270
[INFO] 2021-07-12 19:17:22,970 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2689999241265468e-05, 2270
[INFO] 2021-07-12 19:17:22,971 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2270
[INFO] 2021-07-12 19:17:22,971 [run_pretraining.py:  558]:	worker_index: 7, step: 2270, cost: 7.269691, mlm loss: 7.269691, speed: 1.097227 steps/s, speed: 8.777819 samples/s, speed: 4494.243161 tokens/s, learning rate: 2.269e-05, loss_scalings: 2814.750488, pp_loss: 7.445096
[INFO] 2021-07-12 19:17:22,971 [run_pretraining.py:  512]:	********exe.run_2270******* 
[INFO] 2021-07-12 19:17:23,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:23,914 [run_pretraining.py:  534]:	loss/total_loss, 7.571887016296387, 2271
[INFO] 2021-07-12 19:17:23,915 [run_pretraining.py:  535]:	loss/mlm_loss, 7.571887016296387, 2271
[INFO] 2021-07-12 19:17:23,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2700000045006163e-05, 2271
[INFO] 2021-07-12 19:17:23,915 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2271
[INFO] 2021-07-12 19:17:23,915 [run_pretraining.py:  558]:	worker_index: 7, step: 2271, cost: 7.571887, mlm loss: 7.571887, speed: 1.059919 steps/s, speed: 8.479352 samples/s, speed: 4341.428175 tokens/s, learning rate: 2.270e-05, loss_scalings: 2814.750488, pp_loss: 7.526088
[INFO] 2021-07-12 19:17:23,915 [run_pretraining.py:  512]:	********exe.run_2271******* 
[INFO] 2021-07-12 19:17:24,820 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:24,820 [run_pretraining.py:  534]:	loss/total_loss, 6.830416679382324, 2272
[INFO] 2021-07-12 19:17:24,820 [run_pretraining.py:  535]:	loss/mlm_loss, 6.830416679382324, 2272
[INFO] 2021-07-12 19:17:24,820 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2709999029757455e-05, 2272
[INFO] 2021-07-12 19:17:24,820 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2272
[INFO] 2021-07-12 19:17:24,820 [run_pretraining.py:  558]:	worker_index: 7, step: 2272, cost: 6.830417, mlm loss: 6.830417, speed: 1.104886 steps/s, speed: 8.839088 samples/s, speed: 4525.612894 tokens/s, learning rate: 2.271e-05, loss_scalings: 2814.750488, pp_loss: 7.126991
[INFO] 2021-07-12 19:17:24,821 [run_pretraining.py:  512]:	********exe.run_2272******* 
[INFO] 2021-07-12 19:17:25,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:25,729 [run_pretraining.py:  534]:	loss/total_loss, 6.980954170227051, 2273
[INFO] 2021-07-12 19:17:25,729 [run_pretraining.py:  535]:	loss/mlm_loss, 6.980954170227051, 2273
[INFO] 2021-07-12 19:17:25,729 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.271999983349815e-05, 2273
[INFO] 2021-07-12 19:17:25,730 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2273
[INFO] 2021-07-12 19:17:25,730 [run_pretraining.py:  558]:	worker_index: 7, step: 2273, cost: 6.980954, mlm loss: 6.980954, speed: 1.100732 steps/s, speed: 8.805856 samples/s, speed: 4508.598205 tokens/s, learning rate: 2.272e-05, loss_scalings: 2814.750488, pp_loss: 6.981213
[INFO] 2021-07-12 19:17:25,730 [run_pretraining.py:  512]:	********exe.run_2273******* 
[INFO] 2021-07-12 19:17:26,646 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:26,646 [run_pretraining.py:  534]:	loss/total_loss, 7.94482946395874, 2274
[INFO] 2021-07-12 19:17:26,646 [run_pretraining.py:  535]:	loss/mlm_loss, 7.94482946395874, 2274
[INFO] 2021-07-12 19:17:26,646 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2730000637238845e-05, 2274
[INFO] 2021-07-12 19:17:26,647 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2274
[INFO] 2021-07-12 19:17:26,647 [run_pretraining.py:  558]:	worker_index: 7, step: 2274, cost: 7.944829, mlm loss: 7.944829, speed: 1.091295 steps/s, speed: 8.730362 samples/s, speed: 4469.945550 tokens/s, learning rate: 2.273e-05, loss_scalings: 2814.750488, pp_loss: 7.597413
[INFO] 2021-07-12 19:17:26,647 [run_pretraining.py:  512]:	********exe.run_2274******* 
[INFO] 2021-07-12 19:17:52,513 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:52,514 [run_pretraining.py:  534]:	loss/total_loss, 7.912195682525635, 2275
[INFO] 2021-07-12 19:17:52,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.912195682525635, 2275
[INFO] 2021-07-12 19:17:52,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2739999621990137e-05, 2275
[INFO] 2021-07-12 19:17:52,514 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2275
[INFO] 2021-07-12 19:17:52,514 [run_pretraining.py:  558]:	worker_index: 7, step: 2275, cost: 7.912196, mlm loss: 7.912196, speed: 0.038659 steps/s, speed: 0.309274 samples/s, speed: 158.348226 tokens/s, learning rate: 2.274e-05, loss_scalings: 2814.750488, pp_loss: 7.273505
[INFO] 2021-07-12 19:17:52,514 [run_pretraining.py:  512]:	********exe.run_2275******* 
[INFO] 2021-07-12 19:17:53,425 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:53,426 [run_pretraining.py:  534]:	loss/total_loss, 6.6658735275268555, 2276
[INFO] 2021-07-12 19:17:53,426 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6658735275268555, 2276
[INFO] 2021-07-12 19:17:53,426 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2750000425730832e-05, 2276
[INFO] 2021-07-12 19:17:53,426 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2276
[INFO] 2021-07-12 19:17:53,426 [run_pretraining.py:  558]:	worker_index: 7, step: 2276, cost: 6.665874, mlm loss: 6.665874, speed: 1.097431 steps/s, speed: 8.779447 samples/s, speed: 4495.076881 tokens/s, learning rate: 2.275e-05, loss_scalings: 2814.750488, pp_loss: 7.230752
[INFO] 2021-07-12 19:17:53,426 [run_pretraining.py:  512]:	********exe.run_2276******* 
[INFO] 2021-07-12 19:17:54,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:54,338 [run_pretraining.py:  534]:	loss/total_loss, 6.9060378074646, 2277
[INFO] 2021-07-12 19:17:54,338 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9060378074646, 2277
[INFO] 2021-07-12 19:17:54,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2759999410482123e-05, 2277
[INFO] 2021-07-12 19:17:54,338 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2277
[INFO] 2021-07-12 19:17:54,338 [run_pretraining.py:  558]:	worker_index: 7, step: 2277, cost: 6.906038, mlm loss: 6.906038, speed: 1.097028 steps/s, speed: 8.776221 samples/s, speed: 4493.425029 tokens/s, learning rate: 2.276e-05, loss_scalings: 2814.750488, pp_loss: 7.077848
[INFO] 2021-07-12 19:17:54,339 [run_pretraining.py:  512]:	********exe.run_2277******* 
[INFO] 2021-07-12 19:17:55,250 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:55,250 [run_pretraining.py:  534]:	loss/total_loss, 7.449496746063232, 2278
[INFO] 2021-07-12 19:17:55,250 [run_pretraining.py:  535]:	loss/mlm_loss, 7.449496746063232, 2278
[INFO] 2021-07-12 19:17:55,250 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2769998395233415e-05, 2278
[INFO] 2021-07-12 19:17:55,250 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2278
[INFO] 2021-07-12 19:17:55,251 [run_pretraining.py:  558]:	worker_index: 7, step: 2278, cost: 7.449497, mlm loss: 7.449497, speed: 1.097094 steps/s, speed: 8.776753 samples/s, speed: 4493.697707 tokens/s, learning rate: 2.277e-05, loss_scalings: 2814.750488, pp_loss: 7.300251
[INFO] 2021-07-12 19:17:55,251 [run_pretraining.py:  512]:	********exe.run_2278******* 
[INFO] 2021-07-12 19:17:56,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:56,164 [run_pretraining.py:  534]:	loss/total_loss, 7.432067394256592, 2279
[INFO] 2021-07-12 19:17:56,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.432067394256592, 2279
[INFO] 2021-07-12 19:17:56,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.277999919897411e-05, 2279
[INFO] 2021-07-12 19:17:56,165 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2279
[INFO] 2021-07-12 19:17:56,165 [run_pretraining.py:  558]:	worker_index: 7, step: 2279, cost: 7.432067, mlm loss: 7.432067, speed: 1.094842 steps/s, speed: 8.758735 samples/s, speed: 4484.472119 tokens/s, learning rate: 2.278e-05, loss_scalings: 2814.750488, pp_loss: 7.325084
[INFO] 2021-07-12 19:17:56,165 [run_pretraining.py:  512]:	********exe.run_2279******* 
[INFO] 2021-07-12 19:17:57,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:57,075 [run_pretraining.py:  534]:	loss/total_loss, 6.71803092956543, 2280
[INFO] 2021-07-12 19:17:57,075 [run_pretraining.py:  535]:	loss/mlm_loss, 6.71803092956543, 2280
[INFO] 2021-07-12 19:17:57,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2790000002714805e-05, 2280
[INFO] 2021-07-12 19:17:57,075 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2280
[INFO] 2021-07-12 19:17:57,076 [run_pretraining.py:  558]:	worker_index: 7, step: 2280, cost: 6.718031, mlm loss: 6.718031, speed: 1.098509 steps/s, speed: 8.788074 samples/s, speed: 4499.494048 tokens/s, learning rate: 2.279e-05, loss_scalings: 2814.750488, pp_loss: 7.240585
[INFO] 2021-07-12 19:17:57,076 [run_pretraining.py:  512]:	********exe.run_2280******* 
[INFO] 2021-07-12 19:17:57,981 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:57,981 [run_pretraining.py:  534]:	loss/total_loss, 5.1865620613098145, 2281
[INFO] 2021-07-12 19:17:57,982 [run_pretraining.py:  535]:	loss/mlm_loss, 5.1865620613098145, 2281
[INFO] 2021-07-12 19:17:57,982 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2799998987466097e-05, 2281
[INFO] 2021-07-12 19:17:57,982 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2281
[INFO] 2021-07-12 19:17:57,982 [run_pretraining.py:  558]:	worker_index: 7, step: 2281, cost: 5.186562, mlm loss: 5.186562, speed: 1.104273 steps/s, speed: 8.834184 samples/s, speed: 4523.102404 tokens/s, learning rate: 2.280e-05, loss_scalings: 2814.750488, pp_loss: 5.870017
[INFO] 2021-07-12 19:17:57,982 [run_pretraining.py:  512]:	********exe.run_2281******* 
[INFO] 2021-07-12 19:17:58,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:58,923 [run_pretraining.py:  534]:	loss/total_loss, 7.39258337020874, 2282
[INFO] 2021-07-12 19:17:58,923 [run_pretraining.py:  535]:	loss/mlm_loss, 7.39258337020874, 2282
[INFO] 2021-07-12 19:17:58,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2809999791206792e-05, 2282
[INFO] 2021-07-12 19:17:58,923 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2282
[INFO] 2021-07-12 19:17:58,923 [run_pretraining.py:  558]:	worker_index: 7, step: 2282, cost: 7.392583, mlm loss: 7.392583, speed: 1.062897 steps/s, speed: 8.503178 samples/s, speed: 4353.626977 tokens/s, learning rate: 2.281e-05, loss_scalings: 2814.750488, pp_loss: 7.308826
[INFO] 2021-07-12 19:17:58,923 [run_pretraining.py:  512]:	********exe.run_2282******* 
[INFO] 2021-07-12 19:17:59,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:17:59,838 [run_pretraining.py:  534]:	loss/total_loss, 7.272424697875977, 2283
[INFO] 2021-07-12 19:17:59,838 [run_pretraining.py:  535]:	loss/mlm_loss, 7.272424697875977, 2283
[INFO] 2021-07-12 19:17:59,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2820000594947487e-05, 2283
[INFO] 2021-07-12 19:17:59,838 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2283
[INFO] 2021-07-12 19:17:59,838 [run_pretraining.py:  558]:	worker_index: 7, step: 2283, cost: 7.272425, mlm loss: 7.272425, speed: 1.093838 steps/s, speed: 8.750708 samples/s, speed: 4480.362454 tokens/s, learning rate: 2.282e-05, loss_scalings: 2814.750488, pp_loss: 7.275579
[INFO] 2021-07-12 19:17:59,838 [run_pretraining.py:  512]:	********exe.run_2283******* 
[INFO] 2021-07-12 19:18:00,754 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:00,755 [run_pretraining.py:  534]:	loss/total_loss, 7.035750865936279, 2284
[INFO] 2021-07-12 19:18:00,755 [run_pretraining.py:  535]:	loss/mlm_loss, 7.035750865936279, 2284
[INFO] 2021-07-12 19:18:00,755 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.282999957969878e-05, 2284
[INFO] 2021-07-12 19:18:00,755 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2284
[INFO] 2021-07-12 19:18:00,755 [run_pretraining.py:  558]:	worker_index: 7, step: 2284, cost: 7.035751, mlm loss: 7.035751, speed: 1.091155 steps/s, speed: 8.729240 samples/s, speed: 4469.371095 tokens/s, learning rate: 2.283e-05, loss_scalings: 2814.750488, pp_loss: 7.399115
[INFO] 2021-07-12 19:18:00,755 [run_pretraining.py:  512]:	********exe.run_2284******* 
[INFO] 2021-07-12 19:18:01,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:01,672 [run_pretraining.py:  534]:	loss/total_loss, 7.735945701599121, 2285
[INFO] 2021-07-12 19:18:01,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.735945701599121, 2285
[INFO] 2021-07-12 19:18:01,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2840000383439474e-05, 2285
[INFO] 2021-07-12 19:18:01,672 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2285
[INFO] 2021-07-12 19:18:01,672 [run_pretraining.py:  558]:	worker_index: 7, step: 2285, cost: 7.735946, mlm loss: 7.735946, speed: 1.091219 steps/s, speed: 8.729749 samples/s, speed: 4469.631558 tokens/s, learning rate: 2.284e-05, loss_scalings: 2814.750488, pp_loss: 7.594533
[INFO] 2021-07-12 19:18:01,672 [run_pretraining.py:  512]:	********exe.run_2285******* 
[INFO] 2021-07-12 19:18:02,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:02,585 [run_pretraining.py:  534]:	loss/total_loss, 7.758453369140625, 2286
[INFO] 2021-07-12 19:18:02,585 [run_pretraining.py:  535]:	loss/mlm_loss, 7.758453369140625, 2286
[INFO] 2021-07-12 19:18:02,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2849999368190765e-05, 2286
[INFO] 2021-07-12 19:18:02,585 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2286
[INFO] 2021-07-12 19:18:02,586 [run_pretraining.py:  558]:	worker_index: 7, step: 2286, cost: 7.758453, mlm loss: 7.758453, speed: 1.095817 steps/s, speed: 8.766538 samples/s, speed: 4488.467368 tokens/s, learning rate: 2.285e-05, loss_scalings: 2814.750488, pp_loss: 7.174833
[INFO] 2021-07-12 19:18:02,586 [run_pretraining.py:  512]:	********exe.run_2286******* 
[INFO] 2021-07-12 19:18:03,494 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:03,495 [run_pretraining.py:  534]:	loss/total_loss, 7.269352436065674, 2287
[INFO] 2021-07-12 19:18:03,495 [run_pretraining.py:  535]:	loss/mlm_loss, 7.269352436065674, 2287
[INFO] 2021-07-12 19:18:03,495 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2859998352942057e-05, 2287
[INFO] 2021-07-12 19:18:03,495 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2287
[INFO] 2021-07-12 19:18:03,495 [run_pretraining.py:  558]:	worker_index: 7, step: 2287, cost: 7.269352, mlm loss: 7.269352, speed: 1.099989 steps/s, speed: 8.799909 samples/s, speed: 4505.553487 tokens/s, learning rate: 2.286e-05, loss_scalings: 2814.750488, pp_loss: 7.397780
[INFO] 2021-07-12 19:18:03,495 [run_pretraining.py:  512]:	********exe.run_2287******* 
[INFO] 2021-07-12 19:18:04,403 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:04,404 [run_pretraining.py:  534]:	loss/total_loss, 7.389269828796387, 2288
[INFO] 2021-07-12 19:18:04,404 [run_pretraining.py:  535]:	loss/mlm_loss, 7.389269828796387, 2288
[INFO] 2021-07-12 19:18:04,404 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2869999156682752e-05, 2288
[INFO] 2021-07-12 19:18:04,404 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2288
[INFO] 2021-07-12 19:18:04,404 [run_pretraining.py:  558]:	worker_index: 7, step: 2288, cost: 7.389270, mlm loss: 7.389270, speed: 1.101028 steps/s, speed: 8.808223 samples/s, speed: 4509.810141 tokens/s, learning rate: 2.287e-05, loss_scalings: 2814.750488, pp_loss: 7.234875
[INFO] 2021-07-12 19:18:04,404 [run_pretraining.py:  512]:	********exe.run_2288******* 
[INFO] 2021-07-12 19:18:05,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:05,321 [run_pretraining.py:  534]:	loss/total_loss, 8.943455696105957, 2289
[INFO] 2021-07-12 19:18:05,321 [run_pretraining.py:  535]:	loss/mlm_loss, 8.943455696105957, 2289
[INFO] 2021-07-12 19:18:05,321 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2879999960423447e-05, 2289
[INFO] 2021-07-12 19:18:05,321 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2289
[INFO] 2021-07-12 19:18:05,321 [run_pretraining.py:  558]:	worker_index: 7, step: 2289, cost: 8.943456, mlm loss: 8.943456, speed: 1.091600 steps/s, speed: 8.732800 samples/s, speed: 4471.193811 tokens/s, learning rate: 2.288e-05, loss_scalings: 2814.750488, pp_loss: 7.837555
[INFO] 2021-07-12 19:18:05,321 [run_pretraining.py:  512]:	********exe.run_2289******* 
[INFO] 2021-07-12 19:18:06,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:06,234 [run_pretraining.py:  534]:	loss/total_loss, 6.565230369567871, 2290
[INFO] 2021-07-12 19:18:06,234 [run_pretraining.py:  535]:	loss/mlm_loss, 6.565230369567871, 2290
[INFO] 2021-07-12 19:18:06,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.288999894517474e-05, 2290
[INFO] 2021-07-12 19:18:06,234 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2290
[INFO] 2021-07-12 19:18:06,234 [run_pretraining.py:  558]:	worker_index: 7, step: 2290, cost: 6.565230, mlm loss: 6.565230, speed: 1.095442 steps/s, speed: 8.763538 samples/s, speed: 4486.931695 tokens/s, learning rate: 2.289e-05, loss_scalings: 2814.750488, pp_loss: 7.280612
[INFO] 2021-07-12 19:18:06,235 [run_pretraining.py:  512]:	********exe.run_2290******* 
[INFO] 2021-07-12 19:18:07,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:07,173 [run_pretraining.py:  534]:	loss/total_loss, 7.9284772872924805, 2291
[INFO] 2021-07-12 19:18:07,173 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9284772872924805, 2291
[INFO] 2021-07-12 19:18:07,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2899999748915434e-05, 2291
[INFO] 2021-07-12 19:18:07,173 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2291
[INFO] 2021-07-12 19:18:07,173 [run_pretraining.py:  558]:	worker_index: 7, step: 2291, cost: 7.928477, mlm loss: 7.928477, speed: 1.066368 steps/s, speed: 8.530940 samples/s, speed: 4367.841455 tokens/s, learning rate: 2.290e-05, loss_scalings: 2814.750488, pp_loss: 7.633308
[INFO] 2021-07-12 19:18:07,173 [run_pretraining.py:  512]:	********exe.run_2291******* 
[INFO] 2021-07-12 19:18:08,086 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:08,087 [run_pretraining.py:  534]:	loss/total_loss, 8.113280296325684, 2292
[INFO] 2021-07-12 19:18:08,087 [run_pretraining.py:  535]:	loss/mlm_loss, 8.113280296325684, 2292
[INFO] 2021-07-12 19:18:08,087 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.291000055265613e-05, 2292
[INFO] 2021-07-12 19:18:08,087 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2292
[INFO] 2021-07-12 19:18:08,087 [run_pretraining.py:  558]:	worker_index: 7, step: 2292, cost: 8.113280, mlm loss: 8.113280, speed: 1.094598 steps/s, speed: 8.756787 samples/s, speed: 4483.475002 tokens/s, learning rate: 2.291e-05, loss_scalings: 2814.750488, pp_loss: 7.454061
[INFO] 2021-07-12 19:18:08,087 [run_pretraining.py:  512]:	********exe.run_2292******* 
[INFO] 2021-07-12 19:18:09,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:09,007 [run_pretraining.py:  534]:	loss/total_loss, 3.892230749130249, 2293
[INFO] 2021-07-12 19:18:09,008 [run_pretraining.py:  535]:	loss/mlm_loss, 3.892230749130249, 2293
[INFO] 2021-07-12 19:18:09,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.291999953740742e-05, 2293
[INFO] 2021-07-12 19:18:09,008 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2293
[INFO] 2021-07-12 19:18:09,008 [run_pretraining.py:  558]:	worker_index: 7, step: 2293, cost: 3.892231, mlm loss: 3.892231, speed: 1.086911 steps/s, speed: 8.695284 samples/s, speed: 4451.985485 tokens/s, learning rate: 2.292e-05, loss_scalings: 2814.750488, pp_loss: 6.272639
[INFO] 2021-07-12 19:18:09,008 [run_pretraining.py:  512]:	********exe.run_2293******* 
[INFO] 2021-07-12 19:18:09,922 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:09,923 [run_pretraining.py:  534]:	loss/total_loss, 7.385107517242432, 2294
[INFO] 2021-07-12 19:18:09,923 [run_pretraining.py:  535]:	loss/mlm_loss, 7.385107517242432, 2294
[INFO] 2021-07-12 19:18:09,923 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2930000341148116e-05, 2294
[INFO] 2021-07-12 19:18:09,923 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2294
[INFO] 2021-07-12 19:18:09,923 [run_pretraining.py:  558]:	worker_index: 7, step: 2294, cost: 7.385108, mlm loss: 7.385108, speed: 1.093117 steps/s, speed: 8.744933 samples/s, speed: 4477.405916 tokens/s, learning rate: 2.293e-05, loss_scalings: 2814.750488, pp_loss: 7.456426
[INFO] 2021-07-12 19:18:09,923 [run_pretraining.py:  512]:	********exe.run_2294******* 
[INFO] 2021-07-12 19:18:10,850 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:10,851 [run_pretraining.py:  534]:	loss/total_loss, 7.604220867156982, 2295
[INFO] 2021-07-12 19:18:10,851 [run_pretraining.py:  535]:	loss/mlm_loss, 7.604220867156982, 2295
[INFO] 2021-07-12 19:18:10,851 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2939999325899407e-05, 2295
[INFO] 2021-07-12 19:18:10,851 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2295
[INFO] 2021-07-12 19:18:10,851 [run_pretraining.py:  558]:	worker_index: 7, step: 2295, cost: 7.604221, mlm loss: 7.604221, speed: 1.078317 steps/s, speed: 8.626539 samples/s, speed: 4416.787825 tokens/s, learning rate: 2.294e-05, loss_scalings: 2814.750488, pp_loss: 7.527720
[INFO] 2021-07-12 19:18:10,851 [run_pretraining.py:  512]:	********exe.run_2295******* 
[INFO] 2021-07-12 19:18:11,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:11,913 [run_pretraining.py:  534]:	loss/total_loss, 7.057815074920654, 2296
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  535]:	loss/mlm_loss, 7.057815074920654, 2296
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.29499983106507e-05, 2296
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2296
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  558]:	worker_index: 7, step: 2296, cost: 7.057815, mlm loss: 7.057815, speed: 0.941750 steps/s, speed: 7.533997 samples/s, speed: 3857.406273 tokens/s, learning rate: 2.295e-05, loss_scalings: 2814.750488, pp_loss: 7.486793
[INFO] 2021-07-12 19:18:11,914 [run_pretraining.py:  512]:	********exe.run_2296******* 
[INFO] 2021-07-12 19:18:12,957 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:12,958 [run_pretraining.py:  534]:	loss/total_loss, 7.693273544311523, 2297
[INFO] 2021-07-12 19:18:12,958 [run_pretraining.py:  535]:	loss/mlm_loss, 7.693273544311523, 2297
[INFO] 2021-07-12 19:18:12,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2959999114391394e-05, 2297
[INFO] 2021-07-12 19:18:12,958 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2297
[INFO] 2021-07-12 19:18:12,958 [run_pretraining.py:  558]:	worker_index: 7, step: 2297, cost: 7.693274, mlm loss: 7.693274, speed: 0.958363 steps/s, speed: 7.666901 samples/s, speed: 3925.453558 tokens/s, learning rate: 2.296e-05, loss_scalings: 2814.750488, pp_loss: 7.302838
[INFO] 2021-07-12 19:18:12,958 [run_pretraining.py:  512]:	********exe.run_2297******* 
[INFO] 2021-07-12 19:18:14,007 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:14,008 [run_pretraining.py:  534]:	loss/total_loss, 7.191128730773926, 2298
[INFO] 2021-07-12 19:18:14,008 [run_pretraining.py:  535]:	loss/mlm_loss, 7.191128730773926, 2298
[INFO] 2021-07-12 19:18:14,008 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.296999991813209e-05, 2298
[INFO] 2021-07-12 19:18:14,008 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2298
[INFO] 2021-07-12 19:18:14,008 [run_pretraining.py:  558]:	worker_index: 7, step: 2298, cost: 7.191129, mlm loss: 7.191129, speed: 0.952767 steps/s, speed: 7.622136 samples/s, speed: 3902.533414 tokens/s, learning rate: 2.297e-05, loss_scalings: 2814.750488, pp_loss: 7.246914
[INFO] 2021-07-12 19:18:14,008 [run_pretraining.py:  512]:	********exe.run_2298******* 
[INFO] 2021-07-12 19:18:15,060 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:15,061 [run_pretraining.py:  534]:	loss/total_loss, 6.295802116394043, 2299
[INFO] 2021-07-12 19:18:15,061 [run_pretraining.py:  535]:	loss/mlm_loss, 6.295802116394043, 2299
[INFO] 2021-07-12 19:18:15,061 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.297999890288338e-05, 2299
[INFO] 2021-07-12 19:18:15,061 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2299
[INFO] 2021-07-12 19:18:15,061 [run_pretraining.py:  558]:	worker_index: 7, step: 2299, cost: 6.295802, mlm loss: 6.295802, speed: 0.950199 steps/s, speed: 7.601594 samples/s, speed: 3892.016160 tokens/s, learning rate: 2.298e-05, loss_scalings: 2814.750488, pp_loss: 7.119693
[INFO] 2021-07-12 19:18:15,061 [run_pretraining.py:  512]:	********exe.run_2299******* 
[INFO] 2021-07-12 19:18:40,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:40,231 [run_pretraining.py:  534]:	loss/total_loss, 6.356405258178711, 2300
[INFO] 2021-07-12 19:18:40,231 [run_pretraining.py:  535]:	loss/mlm_loss, 6.356405258178711, 2300
[INFO] 2021-07-12 19:18:40,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.2989999706624076e-05, 2300
[INFO] 2021-07-12 19:18:40,231 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2300
[INFO] 2021-07-12 19:18:40,232 [run_pretraining.py:  558]:	worker_index: 7, step: 2300, cost: 6.356405, mlm loss: 6.356405, speed: 0.039730 steps/s, speed: 0.317842 samples/s, speed: 162.735330 tokens/s, learning rate: 2.299e-05, loss_scalings: 2814.750488, pp_loss: 6.881843
[INFO] 2021-07-12 19:18:40,232 [run_pretraining.py:  512]:	********exe.run_2300******* 
[INFO] 2021-07-12 19:18:41,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:41,159 [run_pretraining.py:  534]:	loss/total_loss, 7.016366958618164, 2301
[INFO] 2021-07-12 19:18:41,159 [run_pretraining.py:  535]:	loss/mlm_loss, 7.016366958618164, 2301
[INFO] 2021-07-12 19:18:41,159 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.300000051036477e-05, 2301
[INFO] 2021-07-12 19:18:41,160 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2301
[INFO] 2021-07-12 19:18:41,160 [run_pretraining.py:  558]:	worker_index: 7, step: 2301, cost: 7.016367, mlm loss: 7.016367, speed: 1.078314 steps/s, speed: 8.626514 samples/s, speed: 4416.775335 tokens/s, learning rate: 2.300e-05, loss_scalings: 2814.750488, pp_loss: 6.867857
[INFO] 2021-07-12 19:18:41,160 [run_pretraining.py:  512]:	********exe.run_2301******* 
[INFO] 2021-07-12 19:18:42,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  534]:	loss/total_loss, 7.189388751983643, 2302
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  535]:	loss/mlm_loss, 7.189388751983643, 2302
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3009999495116062e-05, 2302
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2302
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  558]:	worker_index: 7, step: 2302, cost: 7.189389, mlm loss: 7.189389, speed: 1.096928 steps/s, speed: 8.775427 samples/s, speed: 4493.018425 tokens/s, learning rate: 2.301e-05, loss_scalings: 2814.750488, pp_loss: 7.126752
[INFO] 2021-07-12 19:18:42,072 [run_pretraining.py:  512]:	********exe.run_2302******* 
[INFO] 2021-07-12 19:18:42,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  534]:	loss/total_loss, 3.9208145141601562, 2303
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  535]:	loss/mlm_loss, 3.9208145141601562, 2303
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3019998479867354e-05, 2303
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2303
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  558]:	worker_index: 7, step: 2303, cost: 3.920815, mlm loss: 3.920815, speed: 1.088469 steps/s, speed: 8.707749 samples/s, speed: 4458.367582 tokens/s, learning rate: 2.302e-05, loss_scalings: 2814.750488, pp_loss: 6.405186
[INFO] 2021-07-12 19:18:42,991 [run_pretraining.py:  512]:	********exe.run_2303******* 
[INFO] 2021-07-12 19:18:43,911 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:43,912 [run_pretraining.py:  534]:	loss/total_loss, 7.083141326904297, 2304
[INFO] 2021-07-12 19:18:43,912 [run_pretraining.py:  535]:	loss/mlm_loss, 7.083141326904297, 2304
[INFO] 2021-07-12 19:18:43,912 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.302999928360805e-05, 2304
[INFO] 2021-07-12 19:18:43,912 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2304
[INFO] 2021-07-12 19:18:43,912 [run_pretraining.py:  558]:	worker_index: 7, step: 2304, cost: 7.083141, mlm loss: 7.083141, speed: 1.086956 steps/s, speed: 8.695647 samples/s, speed: 4452.171236 tokens/s, learning rate: 2.303e-05, loss_scalings: 2814.750488, pp_loss: 7.306388
[INFO] 2021-07-12 19:18:43,912 [run_pretraining.py:  512]:	********exe.run_2304******* 
[INFO] 2021-07-12 19:18:44,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:44,828 [run_pretraining.py:  534]:	loss/total_loss, 6.852393627166748, 2305
[INFO] 2021-07-12 19:18:44,828 [run_pretraining.py:  535]:	loss/mlm_loss, 6.852393627166748, 2305
[INFO] 2021-07-12 19:18:44,828 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.303999826835934e-05, 2305
[INFO] 2021-07-12 19:18:44,828 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2305
[INFO] 2021-07-12 19:18:44,828 [run_pretraining.py:  558]:	worker_index: 7, step: 2305, cost: 6.852394, mlm loss: 6.852394, speed: 1.092194 steps/s, speed: 8.737549 samples/s, speed: 4473.624860 tokens/s, learning rate: 2.304e-05, loss_scalings: 2814.750488, pp_loss: 7.268688
[INFO] 2021-07-12 19:18:44,828 [run_pretraining.py:  512]:	********exe.run_2305******* 
[INFO] 2021-07-12 19:18:45,746 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:45,746 [run_pretraining.py:  534]:	loss/total_loss, 6.594283580780029, 2306
[INFO] 2021-07-12 19:18:45,746 [run_pretraining.py:  535]:	loss/mlm_loss, 6.594283580780029, 2306
[INFO] 2021-07-12 19:18:45,746 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3049999072100036e-05, 2306
[INFO] 2021-07-12 19:18:45,746 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2306
[INFO] 2021-07-12 19:18:45,747 [run_pretraining.py:  558]:	worker_index: 7, step: 2306, cost: 6.594284, mlm loss: 6.594284, speed: 1.089770 steps/s, speed: 8.718161 samples/s, speed: 4463.698445 tokens/s, learning rate: 2.305e-05, loss_scalings: 2814.750488, pp_loss: 6.668814
[INFO] 2021-07-12 19:18:45,747 [run_pretraining.py:  512]:	********exe.run_2306******* 
[INFO] 2021-07-12 19:18:46,664 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:46,664 [run_pretraining.py:  534]:	loss/total_loss, 7.940895080566406, 2307
[INFO] 2021-07-12 19:18:46,665 [run_pretraining.py:  535]:	loss/mlm_loss, 7.940895080566406, 2307
[INFO] 2021-07-12 19:18:46,665 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.305999987584073e-05, 2307
[INFO] 2021-07-12 19:18:46,665 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2307
[INFO] 2021-07-12 19:18:46,665 [run_pretraining.py:  558]:	worker_index: 7, step: 2307, cost: 7.940895, mlm loss: 7.940895, speed: 1.089730 steps/s, speed: 8.717839 samples/s, speed: 4463.533764 tokens/s, learning rate: 2.306e-05, loss_scalings: 2814.750488, pp_loss: 7.544127
[INFO] 2021-07-12 19:18:46,665 [run_pretraining.py:  512]:	********exe.run_2307******* 
[INFO] 2021-07-12 19:18:47,583 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:47,583 [run_pretraining.py:  534]:	loss/total_loss, 7.61959981918335, 2308
[INFO] 2021-07-12 19:18:47,583 [run_pretraining.py:  535]:	loss/mlm_loss, 7.61959981918335, 2308
[INFO] 2021-07-12 19:18:47,583 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3069998860592023e-05, 2308
[INFO] 2021-07-12 19:18:47,583 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2308
[INFO] 2021-07-12 19:18:47,584 [run_pretraining.py:  558]:	worker_index: 7, step: 2308, cost: 7.619600, mlm loss: 7.619600, speed: 1.089286 steps/s, speed: 8.714292 samples/s, speed: 4461.717287 tokens/s, learning rate: 2.307e-05, loss_scalings: 2814.750488, pp_loss: 7.423465
[INFO] 2021-07-12 19:18:47,584 [run_pretraining.py:  512]:	********exe.run_2308******* 
[INFO] 2021-07-12 19:18:48,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:48,514 [run_pretraining.py:  534]:	loss/total_loss, 6.619433403015137, 2309
[INFO] 2021-07-12 19:18:48,515 [run_pretraining.py:  535]:	loss/mlm_loss, 6.619433403015137, 2309
[INFO] 2021-07-12 19:18:48,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3079999664332718e-05, 2309
[INFO] 2021-07-12 19:18:48,515 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2309
[INFO] 2021-07-12 19:18:48,515 [run_pretraining.py:  558]:	worker_index: 7, step: 2309, cost: 6.619433, mlm loss: 6.619433, speed: 1.074496 steps/s, speed: 8.595969 samples/s, speed: 4401.135897 tokens/s, learning rate: 2.308e-05, loss_scalings: 2814.750488, pp_loss: 7.224010
[INFO] 2021-07-12 19:18:48,515 [run_pretraining.py:  512]:	********exe.run_2309******* 
[INFO] 2021-07-12 19:18:49,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:49,430 [run_pretraining.py:  534]:	loss/total_loss, 7.367029190063477, 2310
[INFO] 2021-07-12 19:18:49,430 [run_pretraining.py:  535]:	loss/mlm_loss, 7.367029190063477, 2310
[INFO] 2021-07-12 19:18:49,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3090000468073413e-05, 2310
[INFO] 2021-07-12 19:18:49,430 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2310
[INFO] 2021-07-12 19:18:49,431 [run_pretraining.py:  558]:	worker_index: 7, step: 2310, cost: 7.367029, mlm loss: 7.367029, speed: 1.092858 steps/s, speed: 8.742862 samples/s, speed: 4476.345457 tokens/s, learning rate: 2.309e-05, loss_scalings: 2814.750488, pp_loss: 7.045380
[INFO] 2021-07-12 19:18:49,431 [run_pretraining.py:  512]:	********exe.run_2310******* 
[INFO] 2021-07-12 19:18:50,353 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:50,353 [run_pretraining.py:  534]:	loss/total_loss, 7.195863246917725, 2311
[INFO] 2021-07-12 19:18:50,353 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195863246917725, 2311
[INFO] 2021-07-12 19:18:50,354 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3099999452824704e-05, 2311
[INFO] 2021-07-12 19:18:50,354 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2311
[INFO] 2021-07-12 19:18:50,354 [run_pretraining.py:  558]:	worker_index: 7, step: 2311, cost: 7.195863, mlm loss: 7.195863, speed: 1.084061 steps/s, speed: 8.672489 samples/s, speed: 4440.314325 tokens/s, learning rate: 2.310e-05, loss_scalings: 2814.750488, pp_loss: 7.275450
[INFO] 2021-07-12 19:18:50,354 [run_pretraining.py:  512]:	********exe.run_2311******* 
[INFO] 2021-07-12 19:18:51,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  534]:	loss/total_loss, 7.611201763153076, 2312
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  535]:	loss/mlm_loss, 7.611201763153076, 2312
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3109998437575996e-05, 2312
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2312
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  558]:	worker_index: 7, step: 2312, cost: 7.611202, mlm loss: 7.611202, speed: 1.086184 steps/s, speed: 8.689475 samples/s, speed: 4449.010964 tokens/s, learning rate: 2.311e-05, loss_scalings: 2814.750488, pp_loss: 7.287086
[INFO] 2021-07-12 19:18:51,275 [run_pretraining.py:  512]:	********exe.run_2312******* 
[INFO] 2021-07-12 19:18:52,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:52,194 [run_pretraining.py:  534]:	loss/total_loss, 7.270291328430176, 2313
[INFO] 2021-07-12 19:18:52,194 [run_pretraining.py:  535]:	loss/mlm_loss, 7.270291328430176, 2313
[INFO] 2021-07-12 19:18:52,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.311999924131669e-05, 2313
[INFO] 2021-07-12 19:18:52,195 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2313
[INFO] 2021-07-12 19:18:52,195 [run_pretraining.py:  558]:	worker_index: 7, step: 2313, cost: 7.270291, mlm loss: 7.270291, speed: 1.088081 steps/s, speed: 8.704645 samples/s, speed: 4456.778436 tokens/s, learning rate: 2.312e-05, loss_scalings: 2814.750488, pp_loss: 7.149581
[INFO] 2021-07-12 19:18:52,195 [run_pretraining.py:  512]:	********exe.run_2313******* 
[INFO] 2021-07-12 19:18:53,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:53,124 [run_pretraining.py:  534]:	loss/total_loss, 7.357751846313477, 2314
[INFO] 2021-07-12 19:18:53,125 [run_pretraining.py:  535]:	loss/mlm_loss, 7.357751846313477, 2314
[INFO] 2021-07-12 19:18:53,125 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3129998226067983e-05, 2314
[INFO] 2021-07-12 19:18:53,125 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2314
[INFO] 2021-07-12 19:18:53,125 [run_pretraining.py:  558]:	worker_index: 7, step: 2314, cost: 7.357752, mlm loss: 7.357752, speed: 1.075870 steps/s, speed: 8.606962 samples/s, speed: 4406.764713 tokens/s, learning rate: 2.313e-05, loss_scalings: 2814.750488, pp_loss: 6.987782
[INFO] 2021-07-12 19:18:53,125 [run_pretraining.py:  512]:	********exe.run_2314******* 
[INFO] 2021-07-12 19:18:54,047 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:54,048 [run_pretraining.py:  534]:	loss/total_loss, 7.515446186065674, 2315
[INFO] 2021-07-12 19:18:54,048 [run_pretraining.py:  535]:	loss/mlm_loss, 7.515446186065674, 2315
[INFO] 2021-07-12 19:18:54,048 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3139999029808678e-05, 2315
[INFO] 2021-07-12 19:18:54,048 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2315
[INFO] 2021-07-12 19:18:54,048 [run_pretraining.py:  558]:	worker_index: 7, step: 2315, cost: 7.515446, mlm loss: 7.515446, speed: 1.084123 steps/s, speed: 8.672982 samples/s, speed: 4440.566821 tokens/s, learning rate: 2.314e-05, loss_scalings: 2814.750488, pp_loss: 7.307699
[INFO] 2021-07-12 19:18:54,048 [run_pretraining.py:  512]:	********exe.run_2315******* 
[INFO] 2021-07-12 19:18:54,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:54,964 [run_pretraining.py:  534]:	loss/total_loss, 6.904207229614258, 2316
[INFO] 2021-07-12 19:18:54,964 [run_pretraining.py:  535]:	loss/mlm_loss, 6.904207229614258, 2316
[INFO] 2021-07-12 19:18:54,964 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3149999833549373e-05, 2316
[INFO] 2021-07-12 19:18:54,964 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2316
[INFO] 2021-07-12 19:18:54,964 [run_pretraining.py:  558]:	worker_index: 7, step: 2316, cost: 6.904207, mlm loss: 6.904207, speed: 1.092437 steps/s, speed: 8.739492 samples/s, speed: 4474.619930 tokens/s, learning rate: 2.315e-05, loss_scalings: 2814.750488, pp_loss: 6.829184
[INFO] 2021-07-12 19:18:54,964 [run_pretraining.py:  512]:	********exe.run_2316******* 
[INFO] 2021-07-12 19:18:55,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:55,883 [run_pretraining.py:  534]:	loss/total_loss, 7.114469528198242, 2317
[INFO] 2021-07-12 19:18:55,883 [run_pretraining.py:  535]:	loss/mlm_loss, 7.114469528198242, 2317
[INFO] 2021-07-12 19:18:55,883 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3159998818300664e-05, 2317
[INFO] 2021-07-12 19:18:55,883 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2317
[INFO] 2021-07-12 19:18:55,884 [run_pretraining.py:  558]:	worker_index: 7, step: 2317, cost: 7.114470, mlm loss: 7.114470, speed: 1.088098 steps/s, speed: 8.704781 samples/s, speed: 4456.847808 tokens/s, learning rate: 2.316e-05, loss_scalings: 2814.750488, pp_loss: 7.149609
[INFO] 2021-07-12 19:18:55,884 [run_pretraining.py:  512]:	********exe.run_2317******* 
[INFO] 2021-07-12 19:18:56,800 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:56,801 [run_pretraining.py:  534]:	loss/total_loss, 7.012280464172363, 2318
[INFO] 2021-07-12 19:18:56,801 [run_pretraining.py:  535]:	loss/mlm_loss, 7.012280464172363, 2318
[INFO] 2021-07-12 19:18:56,801 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.316999962204136e-05, 2318
[INFO] 2021-07-12 19:18:56,801 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2318
[INFO] 2021-07-12 19:18:56,801 [run_pretraining.py:  558]:	worker_index: 7, step: 2318, cost: 7.012280, mlm loss: 7.012280, speed: 1.090552 steps/s, speed: 8.724417 samples/s, speed: 4466.901692 tokens/s, learning rate: 2.317e-05, loss_scalings: 2814.750488, pp_loss: 7.136997
[INFO] 2021-07-12 19:18:56,801 [run_pretraining.py:  512]:	********exe.run_2318******* 
[INFO] 2021-07-12 19:18:57,716 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  534]:	loss/total_loss, 8.221257209777832, 2319
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  535]:	loss/mlm_loss, 8.221257209777832, 2319
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3180000425782055e-05, 2319
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2319
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  558]:	worker_index: 7, step: 2319, cost: 8.221257, mlm loss: 8.221257, speed: 1.092540 steps/s, speed: 8.740318 samples/s, speed: 4475.043027 tokens/s, learning rate: 2.318e-05, loss_scalings: 2814.750488, pp_loss: 7.840851
[INFO] 2021-07-12 19:18:57,717 [run_pretraining.py:  512]:	********exe.run_2319******* 
[INFO] 2021-07-12 19:18:58,630 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:58,630 [run_pretraining.py:  534]:	loss/total_loss, 7.65728759765625, 2320
[INFO] 2021-07-12 19:18:58,630 [run_pretraining.py:  535]:	loss/mlm_loss, 7.65728759765625, 2320
[INFO] 2021-07-12 19:18:58,631 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3189999410533346e-05, 2320
[INFO] 2021-07-12 19:18:58,631 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2320
[INFO] 2021-07-12 19:18:58,631 [run_pretraining.py:  558]:	worker_index: 7, step: 2320, cost: 7.657288, mlm loss: 7.657288, speed: 1.095350 steps/s, speed: 8.762802 samples/s, speed: 4486.554385 tokens/s, learning rate: 2.319e-05, loss_scalings: 2814.750488, pp_loss: 7.581076
[INFO] 2021-07-12 19:18:58,631 [run_pretraining.py:  512]:	********exe.run_2320******* 
[INFO] 2021-07-12 19:18:59,546 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:18:59,546 [run_pretraining.py:  534]:	loss/total_loss, 7.434265613555908, 2321
[INFO] 2021-07-12 19:18:59,546 [run_pretraining.py:  535]:	loss/mlm_loss, 7.434265613555908, 2321
[INFO] 2021-07-12 19:18:59,546 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3199998395284638e-05, 2321
[INFO] 2021-07-12 19:18:59,547 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2321
[INFO] 2021-07-12 19:18:59,547 [run_pretraining.py:  558]:	worker_index: 7, step: 2321, cost: 7.434266, mlm loss: 7.434266, speed: 1.092668 steps/s, speed: 8.741345 samples/s, speed: 4475.568805 tokens/s, learning rate: 2.320e-05, loss_scalings: 2814.750488, pp_loss: 7.471783
[INFO] 2021-07-12 19:18:59,547 [run_pretraining.py:  512]:	********exe.run_2321******* 
[INFO] 2021-07-12 19:19:00,464 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:00,465 [run_pretraining.py:  534]:	loss/total_loss, 6.745212554931641, 2322
[INFO] 2021-07-12 19:19:00,465 [run_pretraining.py:  535]:	loss/mlm_loss, 6.745212554931641, 2322
[INFO] 2021-07-12 19:19:00,465 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3209999199025333e-05, 2322
[INFO] 2021-07-12 19:19:00,465 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2322
[INFO] 2021-07-12 19:19:00,465 [run_pretraining.py:  558]:	worker_index: 7, step: 2322, cost: 6.745213, mlm loss: 6.745213, speed: 1.089305 steps/s, speed: 8.714436 samples/s, speed: 4461.791447 tokens/s, learning rate: 2.321e-05, loss_scalings: 2814.750488, pp_loss: 6.753918
[INFO] 2021-07-12 19:19:00,465 [run_pretraining.py:  512]:	********exe.run_2322******* 
[INFO] 2021-07-12 19:19:01,387 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:01,387 [run_pretraining.py:  534]:	loss/total_loss, 7.594948768615723, 2323
[INFO] 2021-07-12 19:19:01,387 [run_pretraining.py:  535]:	loss/mlm_loss, 7.594948768615723, 2323
[INFO] 2021-07-12 19:19:01,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3219998183776625e-05, 2323
[INFO] 2021-07-12 19:19:01,387 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2323
[INFO] 2021-07-12 19:19:01,388 [run_pretraining.py:  558]:	worker_index: 7, step: 2323, cost: 7.594949, mlm loss: 7.594949, speed: 1.085059 steps/s, speed: 8.680471 samples/s, speed: 4444.401404 tokens/s, learning rate: 2.322e-05, loss_scalings: 2814.750488, pp_loss: 7.168252
[INFO] 2021-07-12 19:19:01,388 [run_pretraining.py:  512]:	********exe.run_2323******* 
[INFO] 2021-07-12 19:19:02,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:02,305 [run_pretraining.py:  534]:	loss/total_loss, 7.100366592407227, 2324
[INFO] 2021-07-12 19:19:02,305 [run_pretraining.py:  535]:	loss/mlm_loss, 7.100366592407227, 2324
[INFO] 2021-07-12 19:19:02,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.322999898751732e-05, 2324
[INFO] 2021-07-12 19:19:02,305 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2324
[INFO] 2021-07-12 19:19:02,305 [run_pretraining.py:  558]:	worker_index: 7, step: 2324, cost: 7.100367, mlm loss: 7.100367, speed: 1.090696 steps/s, speed: 8.725568 samples/s, speed: 4467.490615 tokens/s, learning rate: 2.323e-05, loss_scalings: 2814.750488, pp_loss: 7.423059
[INFO] 2021-07-12 19:19:02,305 [run_pretraining.py:  512]:	********exe.run_2324******* 
[INFO] 2021-07-12 19:19:03,219 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:03,220 [run_pretraining.py:  534]:	loss/total_loss, 6.739189624786377, 2325
[INFO] 2021-07-12 19:19:03,220 [run_pretraining.py:  535]:	loss/mlm_loss, 6.739189624786377, 2325
[INFO] 2021-07-12 19:19:03,220 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3239999791258015e-05, 2325
[INFO] 2021-07-12 19:19:03,220 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2325
[INFO] 2021-07-12 19:19:03,220 [run_pretraining.py:  558]:	worker_index: 7, step: 2325, cost: 6.739190, mlm loss: 6.739190, speed: 1.093456 steps/s, speed: 8.747646 samples/s, speed: 4478.794956 tokens/s, learning rate: 2.324e-05, loss_scalings: 2814.750488, pp_loss: 7.207675
[INFO] 2021-07-12 19:19:03,220 [run_pretraining.py:  512]:	********exe.run_2325******* 
[INFO] 2021-07-12 19:19:04,135 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:04,135 [run_pretraining.py:  534]:	loss/total_loss, 6.57397985458374, 2326
[INFO] 2021-07-12 19:19:04,135 [run_pretraining.py:  535]:	loss/mlm_loss, 6.57397985458374, 2326
[INFO] 2021-07-12 19:19:04,135 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3249998776009306e-05, 2326
[INFO] 2021-07-12 19:19:04,136 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2326
[INFO] 2021-07-12 19:19:04,136 [run_pretraining.py:  558]:	worker_index: 7, step: 2326, cost: 6.573980, mlm loss: 6.573980, speed: 1.093184 steps/s, speed: 8.745474 samples/s, speed: 4477.682488 tokens/s, learning rate: 2.325e-05, loss_scalings: 2814.750488, pp_loss: 6.890505
[INFO] 2021-07-12 19:19:04,136 [run_pretraining.py:  512]:	********exe.run_2326******* 
[INFO] 2021-07-12 19:19:05,043 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:05,044 [run_pretraining.py:  534]:	loss/total_loss, 6.801422119140625, 2327
[INFO] 2021-07-12 19:19:05,044 [run_pretraining.py:  535]:	loss/mlm_loss, 6.801422119140625, 2327
[INFO] 2021-07-12 19:19:05,044 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.325999957975e-05, 2327
[INFO] 2021-07-12 19:19:05,044 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2327
[INFO] 2021-07-12 19:19:05,044 [run_pretraining.py:  558]:	worker_index: 7, step: 2327, cost: 6.801422, mlm loss: 6.801422, speed: 1.101503 steps/s, speed: 8.812026 samples/s, speed: 4511.757231 tokens/s, learning rate: 2.326e-05, loss_scalings: 2814.750488, pp_loss: 7.333574
[INFO] 2021-07-12 19:19:05,044 [run_pretraining.py:  512]:	********exe.run_2327******* 
[INFO] 2021-07-12 19:19:05,963 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:05,963 [run_pretraining.py:  534]:	loss/total_loss, 7.355921268463135, 2328
[INFO] 2021-07-12 19:19:05,963 [run_pretraining.py:  535]:	loss/mlm_loss, 7.355921268463135, 2328
[INFO] 2021-07-12 19:19:05,963 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3270000383490697e-05, 2328
[INFO] 2021-07-12 19:19:05,964 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2328
[INFO] 2021-07-12 19:19:05,964 [run_pretraining.py:  558]:	worker_index: 7, step: 2328, cost: 7.355921, mlm loss: 7.355921, speed: 1.088378 steps/s, speed: 8.707022 samples/s, speed: 4457.995061 tokens/s, learning rate: 2.327e-05, loss_scalings: 2814.750488, pp_loss: 7.410353
[INFO] 2021-07-12 19:19:05,964 [run_pretraining.py:  512]:	********exe.run_2328******* 
[INFO] 2021-07-12 19:19:06,876 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:06,877 [run_pretraining.py:  534]:	loss/total_loss, 6.617439270019531, 2329
[INFO] 2021-07-12 19:19:06,877 [run_pretraining.py:  535]:	loss/mlm_loss, 6.617439270019531, 2329
[INFO] 2021-07-12 19:19:06,877 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3279999368241988e-05, 2329
[INFO] 2021-07-12 19:19:06,877 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2329
[INFO] 2021-07-12 19:19:06,877 [run_pretraining.py:  558]:	worker_index: 7, step: 2329, cost: 6.617439, mlm loss: 6.617439, speed: 1.095611 steps/s, speed: 8.764889 samples/s, speed: 4487.623204 tokens/s, learning rate: 2.328e-05, loss_scalings: 2814.750488, pp_loss: 6.947435
[INFO] 2021-07-12 19:19:06,877 [run_pretraining.py:  512]:	********exe.run_2329******* 
[INFO] 2021-07-12 19:19:07,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:07,794 [run_pretraining.py:  534]:	loss/total_loss, 6.770145893096924, 2330
[INFO] 2021-07-12 19:19:07,794 [run_pretraining.py:  535]:	loss/mlm_loss, 6.770145893096924, 2330
[INFO] 2021-07-12 19:19:07,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.328999835299328e-05, 2330
[INFO] 2021-07-12 19:19:07,794 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2330
[INFO] 2021-07-12 19:19:07,794 [run_pretraining.py:  558]:	worker_index: 7, step: 2330, cost: 6.770146, mlm loss: 6.770146, speed: 1.091023 steps/s, speed: 8.728182 samples/s, speed: 4468.829336 tokens/s, learning rate: 2.329e-05, loss_scalings: 2814.750488, pp_loss: 6.969729
[INFO] 2021-07-12 19:19:07,794 [run_pretraining.py:  512]:	********exe.run_2330******* 
[INFO] 2021-07-12 19:19:08,711 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:08,712 [run_pretraining.py:  534]:	loss/total_loss, 7.2905988693237305, 2331
[INFO] 2021-07-12 19:19:08,712 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2905988693237305, 2331
[INFO] 2021-07-12 19:19:08,712 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3299999156733975e-05, 2331
[INFO] 2021-07-12 19:19:08,712 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2331
[INFO] 2021-07-12 19:19:08,712 [run_pretraining.py:  558]:	worker_index: 7, step: 2331, cost: 7.290599, mlm loss: 7.290599, speed: 1.089947 steps/s, speed: 8.719579 samples/s, speed: 4464.424576 tokens/s, learning rate: 2.330e-05, loss_scalings: 2814.750488, pp_loss: 6.413406
[INFO] 2021-07-12 19:19:08,712 [run_pretraining.py:  512]:	********exe.run_2331******* 
[INFO] 2021-07-12 19:19:09,632 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:09,633 [run_pretraining.py:  534]:	loss/total_loss, 7.456970691680908, 2332
[INFO] 2021-07-12 19:19:09,633 [run_pretraining.py:  535]:	loss/mlm_loss, 7.456970691680908, 2332
[INFO] 2021-07-12 19:19:09,633 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.330999996047467e-05, 2332
[INFO] 2021-07-12 19:19:09,633 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2332
[INFO] 2021-07-12 19:19:09,633 [run_pretraining.py:  558]:	worker_index: 7, step: 2332, cost: 7.456971, mlm loss: 7.456971, speed: 1.087063 steps/s, speed: 8.696508 samples/s, speed: 4452.612025 tokens/s, learning rate: 2.331e-05, loss_scalings: 2814.750488, pp_loss: 7.438309
[INFO] 2021-07-12 19:19:09,633 [run_pretraining.py:  512]:	********exe.run_2332******* 
[INFO] 2021-07-12 19:19:10,549 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:10,549 [run_pretraining.py:  534]:	loss/total_loss, 7.463194847106934, 2333
[INFO] 2021-07-12 19:19:10,549 [run_pretraining.py:  535]:	loss/mlm_loss, 7.463194847106934, 2333
[INFO] 2021-07-12 19:19:10,550 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.331999894522596e-05, 2333
[INFO] 2021-07-12 19:19:10,550 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2333
[INFO] 2021-07-12 19:19:10,550 [run_pretraining.py:  558]:	worker_index: 7, step: 2333, cost: 7.463195, mlm loss: 7.463195, speed: 1.091542 steps/s, speed: 8.732335 samples/s, speed: 4470.955273 tokens/s, learning rate: 2.332e-05, loss_scalings: 2814.750488, pp_loss: 7.638999
[INFO] 2021-07-12 19:19:10,550 [run_pretraining.py:  512]:	********exe.run_2333******* 
[INFO] 2021-07-12 19:19:36,264 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:36,265 [run_pretraining.py:  534]:	loss/total_loss, 6.76224946975708, 2334
[INFO] 2021-07-12 19:19:36,265 [run_pretraining.py:  535]:	loss/mlm_loss, 6.76224946975708, 2334
[INFO] 2021-07-12 19:19:36,265 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3329999748966657e-05, 2334
[INFO] 2021-07-12 19:19:36,265 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2334
[INFO] 2021-07-12 19:19:36,265 [run_pretraining.py:  558]:	worker_index: 7, step: 2334, cost: 6.762249, mlm loss: 6.762249, speed: 0.038888 steps/s, speed: 0.311103 samples/s, speed: 159.284899 tokens/s, learning rate: 2.333e-05, loss_scalings: 2814.750488, pp_loss: 6.948796
[INFO] 2021-07-12 19:19:36,265 [run_pretraining.py:  512]:	********exe.run_2334******* 
[INFO] 2021-07-12 19:19:37,178 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:37,179 [run_pretraining.py:  534]:	loss/total_loss, 6.996891975402832, 2335
[INFO] 2021-07-12 19:19:37,179 [run_pretraining.py:  535]:	loss/mlm_loss, 6.996891975402832, 2335
[INFO] 2021-07-12 19:19:37,179 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3339998733717948e-05, 2335
[INFO] 2021-07-12 19:19:37,179 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2335
[INFO] 2021-07-12 19:19:37,179 [run_pretraining.py:  558]:	worker_index: 7, step: 2335, cost: 6.996892, mlm loss: 6.996892, speed: 1.094956 steps/s, speed: 8.759652 samples/s, speed: 4484.941572 tokens/s, learning rate: 2.334e-05, loss_scalings: 2814.750488, pp_loss: 7.238437
[INFO] 2021-07-12 19:19:37,179 [run_pretraining.py:  512]:	********exe.run_2335******* 
[INFO] 2021-07-12 19:19:38,098 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:38,099 [run_pretraining.py:  534]:	loss/total_loss, 7.624920845031738, 2336
[INFO] 2021-07-12 19:19:38,099 [run_pretraining.py:  535]:	loss/mlm_loss, 7.624920845031738, 2336
[INFO] 2021-07-12 19:19:38,099 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3349999537458643e-05, 2336
[INFO] 2021-07-12 19:19:38,099 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2336
[INFO] 2021-07-12 19:19:38,099 [run_pretraining.py:  558]:	worker_index: 7, step: 2336, cost: 7.624921, mlm loss: 7.624921, speed: 1.087909 steps/s, speed: 8.703268 samples/s, speed: 4456.073284 tokens/s, learning rate: 2.335e-05, loss_scalings: 2814.750488, pp_loss: 7.013183
[INFO] 2021-07-12 19:19:38,099 [run_pretraining.py:  512]:	********exe.run_2336******* 
[INFO] 2021-07-12 19:19:39,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:39,010 [run_pretraining.py:  534]:	loss/total_loss, 7.017128944396973, 2337
[INFO] 2021-07-12 19:19:39,010 [run_pretraining.py:  535]:	loss/mlm_loss, 7.017128944396973, 2337
[INFO] 2021-07-12 19:19:39,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.336000034119934e-05, 2337
[INFO] 2021-07-12 19:19:39,010 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2337
[INFO] 2021-07-12 19:19:39,010 [run_pretraining.py:  558]:	worker_index: 7, step: 2337, cost: 7.017129, mlm loss: 7.017129, speed: 1.098327 steps/s, speed: 8.786613 samples/s, speed: 4498.745863 tokens/s, learning rate: 2.336e-05, loss_scalings: 2814.750488, pp_loss: 7.087707
[INFO] 2021-07-12 19:19:39,010 [run_pretraining.py:  512]:	********exe.run_2337******* 
[INFO] 2021-07-12 19:19:39,920 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:39,921 [run_pretraining.py:  534]:	loss/total_loss, 7.6643829345703125, 2338
[INFO] 2021-07-12 19:19:39,921 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6643829345703125, 2338
[INFO] 2021-07-12 19:19:39,921 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.336999932595063e-05, 2338
[INFO] 2021-07-12 19:19:39,921 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2338
[INFO] 2021-07-12 19:19:39,921 [run_pretraining.py:  558]:	worker_index: 7, step: 2338, cost: 7.664383, mlm loss: 7.664383, speed: 1.098589 steps/s, speed: 8.788710 samples/s, speed: 4499.819321 tokens/s, learning rate: 2.337e-05, loss_scalings: 2814.750488, pp_loss: 7.272147
[INFO] 2021-07-12 19:19:39,921 [run_pretraining.py:  512]:	********exe.run_2338******* 
[INFO] 2021-07-12 19:19:40,841 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:40,841 [run_pretraining.py:  534]:	loss/total_loss, 7.2132062911987305, 2339
[INFO] 2021-07-12 19:19:40,841 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2132062911987305, 2339
[INFO] 2021-07-12 19:19:40,841 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.337999831070192e-05, 2339
[INFO] 2021-07-12 19:19:40,842 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2339
[INFO] 2021-07-12 19:19:40,842 [run_pretraining.py:  558]:	worker_index: 7, step: 2339, cost: 7.213206, mlm loss: 7.213206, speed: 1.087069 steps/s, speed: 8.696551 samples/s, speed: 4452.633951 tokens/s, learning rate: 2.338e-05, loss_scalings: 2814.750488, pp_loss: 7.592504
[INFO] 2021-07-12 19:19:40,842 [run_pretraining.py:  512]:	********exe.run_2339******* 
[INFO] 2021-07-12 19:19:41,752 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:41,753 [run_pretraining.py:  534]:	loss/total_loss, 7.211430549621582, 2340
[INFO] 2021-07-12 19:19:41,753 [run_pretraining.py:  535]:	loss/mlm_loss, 7.211430549621582, 2340
[INFO] 2021-07-12 19:19:41,753 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3389999114442617e-05, 2340
[INFO] 2021-07-12 19:19:41,753 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2340
[INFO] 2021-07-12 19:19:41,753 [run_pretraining.py:  558]:	worker_index: 7, step: 2340, cost: 7.211431, mlm loss: 7.211431, speed: 1.097642 steps/s, speed: 8.781138 samples/s, speed: 4495.942678 tokens/s, learning rate: 2.339e-05, loss_scalings: 2814.750488, pp_loss: 7.285310
[INFO] 2021-07-12 19:19:41,753 [run_pretraining.py:  512]:	********exe.run_2340******* 
[INFO] 2021-07-12 19:19:42,669 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:42,670 [run_pretraining.py:  534]:	loss/total_loss, 7.142706871032715, 2341
[INFO] 2021-07-12 19:19:42,670 [run_pretraining.py:  535]:	loss/mlm_loss, 7.142706871032715, 2341
[INFO] 2021-07-12 19:19:42,670 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3399999918183312e-05, 2341
[INFO] 2021-07-12 19:19:42,670 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2341
[INFO] 2021-07-12 19:19:42,670 [run_pretraining.py:  558]:	worker_index: 7, step: 2341, cost: 7.142707, mlm loss: 7.142707, speed: 1.091700 steps/s, speed: 8.733598 samples/s, speed: 4471.602294 tokens/s, learning rate: 2.340e-05, loss_scalings: 2814.750488, pp_loss: 7.118985
[INFO] 2021-07-12 19:19:42,670 [run_pretraining.py:  512]:	********exe.run_2341******* 
[INFO] 2021-07-12 19:19:43,585 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:43,585 [run_pretraining.py:  534]:	loss/total_loss, 6.356445789337158, 2342
[INFO] 2021-07-12 19:19:43,585 [run_pretraining.py:  535]:	loss/mlm_loss, 6.356445789337158, 2342
[INFO] 2021-07-12 19:19:43,585 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3409998902934603e-05, 2342
[INFO] 2021-07-12 19:19:43,585 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2342
[INFO] 2021-07-12 19:19:43,585 [run_pretraining.py:  558]:	worker_index: 7, step: 2342, cost: 6.356446, mlm loss: 6.356446, speed: 1.093094 steps/s, speed: 8.744751 samples/s, speed: 4477.312566 tokens/s, learning rate: 2.341e-05, loss_scalings: 2814.750488, pp_loss: 7.049414
[INFO] 2021-07-12 19:19:43,586 [run_pretraining.py:  512]:	********exe.run_2342******* 
[INFO] 2021-07-12 19:19:44,504 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:44,505 [run_pretraining.py:  534]:	loss/total_loss, 7.048671722412109, 2343
[INFO] 2021-07-12 19:19:44,505 [run_pretraining.py:  535]:	loss/mlm_loss, 7.048671722412109, 2343
[INFO] 2021-07-12 19:19:44,505 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.34199997066753e-05, 2343
[INFO] 2021-07-12 19:19:44,505 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2343
[INFO] 2021-07-12 19:19:44,505 [run_pretraining.py:  558]:	worker_index: 7, step: 2343, cost: 7.048672, mlm loss: 7.048672, speed: 1.087943 steps/s, speed: 8.703544 samples/s, speed: 4456.214296 tokens/s, learning rate: 2.342e-05, loss_scalings: 2814.750488, pp_loss: 6.931763
[INFO] 2021-07-12 19:19:44,505 [run_pretraining.py:  512]:	********exe.run_2343******* 
[INFO] 2021-07-12 19:19:45,420 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  534]:	loss/total_loss, 7.500043869018555, 2344
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  535]:	loss/mlm_loss, 7.500043869018555, 2344
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3430000510415994e-05, 2344
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2344
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  558]:	worker_index: 7, step: 2344, cost: 7.500044, mlm loss: 7.500044, speed: 1.092328 steps/s, speed: 8.738623 samples/s, speed: 4474.174774 tokens/s, learning rate: 2.343e-05, loss_scalings: 2814.750488, pp_loss: 7.197118
[INFO] 2021-07-12 19:19:45,421 [run_pretraining.py:  512]:	********exe.run_2344******* 
[INFO] 2021-07-12 19:19:46,340 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:46,340 [run_pretraining.py:  534]:	loss/total_loss, 6.515878200531006, 2345
[INFO] 2021-07-12 19:19:46,340 [run_pretraining.py:  535]:	loss/mlm_loss, 6.515878200531006, 2345
[INFO] 2021-07-12 19:19:46,341 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3439999495167285e-05, 2345
[INFO] 2021-07-12 19:19:46,341 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2345
[INFO] 2021-07-12 19:19:46,341 [run_pretraining.py:  558]:	worker_index: 7, step: 2345, cost: 6.515878, mlm loss: 6.515878, speed: 1.088483 steps/s, speed: 8.707864 samples/s, speed: 4458.426590 tokens/s, learning rate: 2.344e-05, loss_scalings: 2814.750488, pp_loss: 7.088231
[INFO] 2021-07-12 19:19:46,341 [run_pretraining.py:  512]:	********exe.run_2345******* 
[INFO] 2021-07-12 19:19:47,274 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:47,275 [run_pretraining.py:  534]:	loss/total_loss, 6.818284511566162, 2346
[INFO] 2021-07-12 19:19:47,275 [run_pretraining.py:  535]:	loss/mlm_loss, 6.818284511566162, 2346
[INFO] 2021-07-12 19:19:47,275 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.345000029890798e-05, 2346
[INFO] 2021-07-12 19:19:47,275 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2346
[INFO] 2021-07-12 19:19:47,275 [run_pretraining.py:  558]:	worker_index: 7, step: 2346, cost: 6.818285, mlm loss: 6.818285, speed: 1.071088 steps/s, speed: 8.568705 samples/s, speed: 4387.176982 tokens/s, learning rate: 2.345e-05, loss_scalings: 2814.750488, pp_loss: 7.080701
[INFO] 2021-07-12 19:19:47,275 [run_pretraining.py:  512]:	********exe.run_2346******* 
[INFO] 2021-07-12 19:19:48,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:48,193 [run_pretraining.py:  534]:	loss/total_loss, 6.815515518188477, 2347
[INFO] 2021-07-12 19:19:48,193 [run_pretraining.py:  535]:	loss/mlm_loss, 6.815515518188477, 2347
[INFO] 2021-07-12 19:19:48,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3459999283659272e-05, 2347
[INFO] 2021-07-12 19:19:48,193 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2347
[INFO] 2021-07-12 19:19:48,193 [run_pretraining.py:  558]:	worker_index: 7, step: 2347, cost: 6.815516, mlm loss: 6.815516, speed: 1.089496 steps/s, speed: 8.715969 samples/s, speed: 4462.576075 tokens/s, learning rate: 2.346e-05, loss_scalings: 2814.750488, pp_loss: 6.034311
[INFO] 2021-07-12 19:19:48,194 [run_pretraining.py:  512]:	********exe.run_2347******* 
[INFO] 2021-07-12 19:19:49,113 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:49,114 [run_pretraining.py:  534]:	loss/total_loss, 7.054917335510254, 2348
[INFO] 2021-07-12 19:19:49,114 [run_pretraining.py:  535]:	loss/mlm_loss, 7.054917335510254, 2348
[INFO] 2021-07-12 19:19:49,114 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3469998268410563e-05, 2348
[INFO] 2021-07-12 19:19:49,114 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2348
[INFO] 2021-07-12 19:19:49,114 [run_pretraining.py:  558]:	worker_index: 7, step: 2348, cost: 7.054917, mlm loss: 7.054917, speed: 1.087089 steps/s, speed: 8.696711 samples/s, speed: 4452.715888 tokens/s, learning rate: 2.347e-05, loss_scalings: 2814.750488, pp_loss: 7.138921
[INFO] 2021-07-12 19:19:49,114 [run_pretraining.py:  512]:	********exe.run_2348******* 
[INFO] 2021-07-12 19:19:50,025 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:50,026 [run_pretraining.py:  534]:	loss/total_loss, 6.930594444274902, 2349
[INFO] 2021-07-12 19:19:50,026 [run_pretraining.py:  535]:	loss/mlm_loss, 6.930594444274902, 2349
[INFO] 2021-07-12 19:19:50,026 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.347999907215126e-05, 2349
[INFO] 2021-07-12 19:19:50,026 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2349
[INFO] 2021-07-12 19:19:50,026 [run_pretraining.py:  558]:	worker_index: 7, step: 2349, cost: 6.930594, mlm loss: 6.930594, speed: 1.097460 steps/s, speed: 8.779684 samples/s, speed: 4495.198025 tokens/s, learning rate: 2.348e-05, loss_scalings: 2814.750488, pp_loss: 7.391065
[INFO] 2021-07-12 19:19:50,026 [run_pretraining.py:  512]:	********exe.run_2349******* 
[INFO] 2021-07-12 19:19:50,940 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:50,940 [run_pretraining.py:  534]:	loss/total_loss, 6.864627361297607, 2350
[INFO] 2021-07-12 19:19:50,940 [run_pretraining.py:  535]:	loss/mlm_loss, 6.864627361297607, 2350
[INFO] 2021-07-12 19:19:50,940 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3489999875891954e-05, 2350
[INFO] 2021-07-12 19:19:50,940 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2350
[INFO] 2021-07-12 19:19:50,940 [run_pretraining.py:  558]:	worker_index: 7, step: 2350, cost: 6.864627, mlm loss: 6.864627, speed: 1.094132 steps/s, speed: 8.753052 samples/s, speed: 4481.562764 tokens/s, learning rate: 2.349e-05, loss_scalings: 2814.750488, pp_loss: 6.697195
[INFO] 2021-07-12 19:19:50,941 [run_pretraining.py:  512]:	********exe.run_2350******* 
[INFO] 2021-07-12 19:19:51,854 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:51,855 [run_pretraining.py:  534]:	loss/total_loss, 7.046250343322754, 2351
[INFO] 2021-07-12 19:19:51,855 [run_pretraining.py:  535]:	loss/mlm_loss, 7.046250343322754, 2351
[INFO] 2021-07-12 19:19:51,855 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3499998860643245e-05, 2351
[INFO] 2021-07-12 19:19:51,855 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2351
[INFO] 2021-07-12 19:19:51,855 [run_pretraining.py:  558]:	worker_index: 7, step: 2351, cost: 7.046250, mlm loss: 7.046250, speed: 1.094047 steps/s, speed: 8.752379 samples/s, speed: 4481.217916 tokens/s, learning rate: 2.350e-05, loss_scalings: 2814.750488, pp_loss: 7.253374
[INFO] 2021-07-12 19:19:51,855 [run_pretraining.py:  512]:	********exe.run_2351******* 
[INFO] 2021-07-12 19:19:52,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:52,768 [run_pretraining.py:  534]:	loss/total_loss, 7.754203796386719, 2352
[INFO] 2021-07-12 19:19:52,768 [run_pretraining.py:  535]:	loss/mlm_loss, 7.754203796386719, 2352
[INFO] 2021-07-12 19:19:52,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.350999966438394e-05, 2352
[INFO] 2021-07-12 19:19:52,768 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2352
[INFO] 2021-07-12 19:19:52,768 [run_pretraining.py:  558]:	worker_index: 7, step: 2352, cost: 7.754204, mlm loss: 7.754204, speed: 1.096090 steps/s, speed: 8.768721 samples/s, speed: 4489.585203 tokens/s, learning rate: 2.351e-05, loss_scalings: 2814.750488, pp_loss: 7.320938
[INFO] 2021-07-12 19:19:52,768 [run_pretraining.py:  512]:	********exe.run_2352******* 
[INFO] 2021-07-12 19:19:53,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  534]:	loss/total_loss, 4.7215189933776855, 2353
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  535]:	loss/mlm_loss, 4.7215189933776855, 2353
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3520000468124636e-05, 2353
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2353
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  558]:	worker_index: 7, step: 2353, cost: 4.721519, mlm loss: 4.721519, speed: 1.098441 steps/s, speed: 8.787531 samples/s, speed: 4499.215953 tokens/s, learning rate: 2.352e-05, loss_scalings: 2814.750488, pp_loss: 6.906680
[INFO] 2021-07-12 19:19:53,679 [run_pretraining.py:  512]:	********exe.run_2353******* 
[INFO] 2021-07-12 19:19:54,591 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:54,592 [run_pretraining.py:  534]:	loss/total_loss, 7.101405620574951, 2354
[INFO] 2021-07-12 19:19:54,592 [run_pretraining.py:  535]:	loss/mlm_loss, 7.101405620574951, 2354
[INFO] 2021-07-12 19:19:54,592 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3529999452875927e-05, 2354
[INFO] 2021-07-12 19:19:54,592 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2354
[INFO] 2021-07-12 19:19:54,592 [run_pretraining.py:  558]:	worker_index: 7, step: 2354, cost: 7.101406, mlm loss: 7.101406, speed: 1.096335 steps/s, speed: 8.770676 samples/s, speed: 4490.586213 tokens/s, learning rate: 2.353e-05, loss_scalings: 2814.750488, pp_loss: 7.476214
[INFO] 2021-07-12 19:19:54,592 [run_pretraining.py:  512]:	********exe.run_2354******* 
[INFO] 2021-07-12 19:19:55,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:55,509 [run_pretraining.py:  534]:	loss/total_loss, 7.071649551391602, 2355
[INFO] 2021-07-12 19:19:55,509 [run_pretraining.py:  535]:	loss/mlm_loss, 7.071649551391602, 2355
[INFO] 2021-07-12 19:19:55,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3540000256616622e-05, 2355
[INFO] 2021-07-12 19:19:55,510 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2355
[INFO] 2021-07-12 19:19:55,510 [run_pretraining.py:  558]:	worker_index: 7, step: 2355, cost: 7.071650, mlm loss: 7.071650, speed: 1.090478 steps/s, speed: 8.723823 samples/s, speed: 4466.597418 tokens/s, learning rate: 2.354e-05, loss_scalings: 2814.750488, pp_loss: 7.090397
[INFO] 2021-07-12 19:19:55,510 [run_pretraining.py:  512]:	********exe.run_2355******* 
[INFO] 2021-07-12 19:19:56,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:56,424 [run_pretraining.py:  534]:	loss/total_loss, 7.536386489868164, 2356
[INFO] 2021-07-12 19:19:56,424 [run_pretraining.py:  535]:	loss/mlm_loss, 7.536386489868164, 2356
[INFO] 2021-07-12 19:19:56,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3549999241367914e-05, 2356
[INFO] 2021-07-12 19:19:56,424 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2356
[INFO] 2021-07-12 19:19:56,424 [run_pretraining.py:  558]:	worker_index: 7, step: 2356, cost: 7.536386, mlm loss: 7.536386, speed: 1.094630 steps/s, speed: 8.757043 samples/s, speed: 4483.606053 tokens/s, learning rate: 2.355e-05, loss_scalings: 2814.750488, pp_loss: 7.202973
[INFO] 2021-07-12 19:19:56,424 [run_pretraining.py:  512]:	********exe.run_2356******* 
[INFO] 2021-07-12 19:19:57,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:57,345 [run_pretraining.py:  534]:	loss/total_loss, 7.656896114349365, 2357
[INFO] 2021-07-12 19:19:57,345 [run_pretraining.py:  535]:	loss/mlm_loss, 7.656896114349365, 2357
[INFO] 2021-07-12 19:19:57,345 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3559998226119205e-05, 2357
[INFO] 2021-07-12 19:19:57,345 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2357
[INFO] 2021-07-12 19:19:57,346 [run_pretraining.py:  558]:	worker_index: 7, step: 2357, cost: 7.656896, mlm loss: 7.656896, speed: 1.085702 steps/s, speed: 8.685617 samples/s, speed: 4447.035913 tokens/s, learning rate: 2.356e-05, loss_scalings: 2814.750488, pp_loss: 7.363054
[INFO] 2021-07-12 19:19:57,346 [run_pretraining.py:  512]:	********exe.run_2357******* 
[INFO] 2021-07-12 19:19:58,259 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:58,260 [run_pretraining.py:  534]:	loss/total_loss, 8.006926536560059, 2358
[INFO] 2021-07-12 19:19:58,260 [run_pretraining.py:  535]:	loss/mlm_loss, 8.006926536560059, 2358
[INFO] 2021-07-12 19:19:58,260 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.35699990298599e-05, 2358
[INFO] 2021-07-12 19:19:58,260 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2358
[INFO] 2021-07-12 19:19:58,260 [run_pretraining.py:  558]:	worker_index: 7, step: 2358, cost: 8.006927, mlm loss: 8.006927, speed: 1.094463 steps/s, speed: 8.755706 samples/s, speed: 4482.921630 tokens/s, learning rate: 2.357e-05, loss_scalings: 2814.750488, pp_loss: 7.471401
[INFO] 2021-07-12 19:19:58,260 [run_pretraining.py:  512]:	********exe.run_2358******* 
[INFO] 2021-07-12 19:19:59,222 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:19:59,222 [run_pretraining.py:  534]:	loss/total_loss, 7.963515758514404, 2359
[INFO] 2021-07-12 19:19:59,222 [run_pretraining.py:  535]:	loss/mlm_loss, 7.963515758514404, 2359
[INFO] 2021-07-12 19:19:59,222 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3579999833600596e-05, 2359
[INFO] 2021-07-12 19:19:59,222 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2359
[INFO] 2021-07-12 19:19:59,223 [run_pretraining.py:  558]:	worker_index: 7, step: 2359, cost: 7.963516, mlm loss: 7.963516, speed: 1.039543 steps/s, speed: 8.316343 samples/s, speed: 4257.967686 tokens/s, learning rate: 2.358e-05, loss_scalings: 2814.750488, pp_loss: 7.552037
[INFO] 2021-07-12 19:19:59,223 [run_pretraining.py:  512]:	********exe.run_2359******* 
[INFO] 2021-07-12 19:20:00,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:00,235 [run_pretraining.py:  534]:	loss/total_loss, 7.659585952758789, 2360
[INFO] 2021-07-12 19:20:00,235 [run_pretraining.py:  535]:	loss/mlm_loss, 7.659585952758789, 2360
[INFO] 2021-07-12 19:20:00,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3589998818351887e-05, 2360
[INFO] 2021-07-12 19:20:00,235 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2360
[INFO] 2021-07-12 19:20:00,235 [run_pretraining.py:  558]:	worker_index: 7, step: 2360, cost: 7.659586, mlm loss: 7.659586, speed: 0.988141 steps/s, speed: 7.905127 samples/s, speed: 4047.424773 tokens/s, learning rate: 2.359e-05, loss_scalings: 2814.750488, pp_loss: 6.758059
[INFO] 2021-07-12 19:20:00,235 [run_pretraining.py:  512]:	********exe.run_2360******* 
[INFO] 2021-07-12 19:20:01,203 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:01,204 [run_pretraining.py:  534]:	loss/total_loss, 7.373109817504883, 2361
[INFO] 2021-07-12 19:20:01,204 [run_pretraining.py:  535]:	loss/mlm_loss, 7.373109817504883, 2361
[INFO] 2021-07-12 19:20:01,204 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3599999622092582e-05, 2361
[INFO] 2021-07-12 19:20:01,204 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2361
[INFO] 2021-07-12 19:20:01,204 [run_pretraining.py:  558]:	worker_index: 7, step: 2361, cost: 7.373110, mlm loss: 7.373110, speed: 1.032914 steps/s, speed: 8.263315 samples/s, speed: 4230.817525 tokens/s, learning rate: 2.360e-05, loss_scalings: 2814.750488, pp_loss: 7.323946
[INFO] 2021-07-12 19:20:01,204 [run_pretraining.py:  512]:	********exe.run_2361******* 
[INFO] 2021-07-12 19:20:02,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:02,182 [run_pretraining.py:  534]:	loss/total_loss, 7.645387649536133, 2362
[INFO] 2021-07-12 19:20:02,182 [run_pretraining.py:  535]:	loss/mlm_loss, 7.645387649536133, 2362
[INFO] 2021-07-12 19:20:02,182 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3610000425833277e-05, 2362
[INFO] 2021-07-12 19:20:02,182 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2362
[INFO] 2021-07-12 19:20:02,183 [run_pretraining.py:  558]:	worker_index: 7, step: 2362, cost: 7.645388, mlm loss: 7.645388, speed: 1.022492 steps/s, speed: 8.179940 samples/s, speed: 4188.129168 tokens/s, learning rate: 2.361e-05, loss_scalings: 2814.750488, pp_loss: 7.005379
[INFO] 2021-07-12 19:20:02,183 [run_pretraining.py:  512]:	********exe.run_2362******* 
[INFO] 2021-07-12 19:20:03,159 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:03,160 [run_pretraining.py:  534]:	loss/total_loss, 7.556793212890625, 2363
[INFO] 2021-07-12 19:20:03,160 [run_pretraining.py:  535]:	loss/mlm_loss, 7.556793212890625, 2363
[INFO] 2021-07-12 19:20:03,160 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.361999941058457e-05, 2363
[INFO] 2021-07-12 19:20:03,160 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2363
[INFO] 2021-07-12 19:20:03,160 [run_pretraining.py:  558]:	worker_index: 7, step: 2363, cost: 7.556793, mlm loss: 7.556793, speed: 1.023755 steps/s, speed: 8.190036 samples/s, speed: 4193.298673 tokens/s, learning rate: 2.362e-05, loss_scalings: 2814.750488, pp_loss: 7.042960
[INFO] 2021-07-12 19:20:03,160 [run_pretraining.py:  512]:	********exe.run_2363******* 
[INFO] 2021-07-12 19:20:04,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:04,139 [run_pretraining.py:  534]:	loss/total_loss, 6.97554874420166, 2364
[INFO] 2021-07-12 19:20:04,139 [run_pretraining.py:  535]:	loss/mlm_loss, 6.97554874420166, 2364
[INFO] 2021-07-12 19:20:04,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3630000214325264e-05, 2364
[INFO] 2021-07-12 19:20:04,139 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2364
[INFO] 2021-07-12 19:20:04,139 [run_pretraining.py:  558]:	worker_index: 7, step: 2364, cost: 6.975549, mlm loss: 6.975549, speed: 1.021703 steps/s, speed: 8.173621 samples/s, speed: 4184.894118 tokens/s, learning rate: 2.363e-05, loss_scalings: 2814.750488, pp_loss: 7.188936
[INFO] 2021-07-12 19:20:04,140 [run_pretraining.py:  512]:	********exe.run_2364******* 
[INFO] 2021-07-12 19:20:05,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:05,110 [run_pretraining.py:  534]:	loss/total_loss, 7.4831862449646, 2365
[INFO] 2021-07-12 19:20:05,110 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4831862449646, 2365
[INFO] 2021-07-12 19:20:05,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3639999199076556e-05, 2365
[INFO] 2021-07-12 19:20:05,110 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2365
[INFO] 2021-07-12 19:20:05,111 [run_pretraining.py:  558]:	worker_index: 7, step: 2365, cost: 7.483186, mlm loss: 7.483186, speed: 1.030410 steps/s, speed: 8.243277 samples/s, speed: 4220.557807 tokens/s, learning rate: 2.364e-05, loss_scalings: 2814.750488, pp_loss: 7.196862
[INFO] 2021-07-12 19:20:05,111 [run_pretraining.py:  512]:	********exe.run_2365******* 
[INFO] 2021-07-12 19:20:06,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:06,085 [run_pretraining.py:  534]:	loss/total_loss, 7.191636562347412, 2366
[INFO] 2021-07-12 19:20:06,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.191636562347412, 2366
[INFO] 2021-07-12 19:20:06,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3649998183827847e-05, 2366
[INFO] 2021-07-12 19:20:06,085 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2366
[INFO] 2021-07-12 19:20:06,085 [run_pretraining.py:  558]:	worker_index: 7, step: 2366, cost: 7.191637, mlm loss: 7.191637, speed: 1.026658 steps/s, speed: 8.213267 samples/s, speed: 4205.192739 tokens/s, learning rate: 2.365e-05, loss_scalings: 2814.750488, pp_loss: 7.079287
[INFO] 2021-07-12 19:20:06,085 [run_pretraining.py:  512]:	********exe.run_2366******* 
[INFO] 2021-07-12 19:20:07,063 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:07,063 [run_pretraining.py:  534]:	loss/total_loss, 7.302096843719482, 2367
[INFO] 2021-07-12 19:20:07,063 [run_pretraining.py:  535]:	loss/mlm_loss, 7.302096843719482, 2367
[INFO] 2021-07-12 19:20:07,063 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3659998987568542e-05, 2367
[INFO] 2021-07-12 19:20:07,064 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2367
[INFO] 2021-07-12 19:20:07,064 [run_pretraining.py:  558]:	worker_index: 7, step: 2367, cost: 7.302097, mlm loss: 7.302097, speed: 1.022792 steps/s, speed: 8.182335 samples/s, speed: 4189.355733 tokens/s, learning rate: 2.366e-05, loss_scalings: 2814.750488, pp_loss: 7.121741
[INFO] 2021-07-12 19:20:07,064 [run_pretraining.py:  512]:	********exe.run_2367******* 
[INFO] 2021-07-12 19:20:08,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:08,037 [run_pretraining.py:  534]:	loss/total_loss, 7.49067497253418, 2368
[INFO] 2021-07-12 19:20:08,037 [run_pretraining.py:  535]:	loss/mlm_loss, 7.49067497253418, 2368
[INFO] 2021-07-12 19:20:08,037 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3669999791309237e-05, 2368
[INFO] 2021-07-12 19:20:08,037 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2368
[INFO] 2021-07-12 19:20:08,037 [run_pretraining.py:  558]:	worker_index: 7, step: 2368, cost: 7.490675, mlm loss: 7.490675, speed: 1.027928 steps/s, speed: 8.223422 samples/s, speed: 4210.392097 tokens/s, learning rate: 2.367e-05, loss_scalings: 2814.750488, pp_loss: 7.282084
[INFO] 2021-07-12 19:20:08,037 [run_pretraining.py:  512]:	********exe.run_2368******* 
[INFO] 2021-07-12 19:20:09,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:09,016 [run_pretraining.py:  534]:	loss/total_loss, 7.065700531005859, 2369
[INFO] 2021-07-12 19:20:09,016 [run_pretraining.py:  535]:	loss/mlm_loss, 7.065700531005859, 2369
[INFO] 2021-07-12 19:20:09,016 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.367999877606053e-05, 2369
[INFO] 2021-07-12 19:20:09,016 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2369
[INFO] 2021-07-12 19:20:09,016 [run_pretraining.py:  558]:	worker_index: 7, step: 2369, cost: 7.065701, mlm loss: 7.065701, speed: 1.021743 steps/s, speed: 8.173942 samples/s, speed: 4185.058250 tokens/s, learning rate: 2.368e-05, loss_scalings: 2814.750488, pp_loss: 7.452774
[INFO] 2021-07-12 19:20:09,017 [run_pretraining.py:  512]:	********exe.run_2369******* 
[INFO] 2021-07-12 19:20:09,996 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:09,997 [run_pretraining.py:  534]:	loss/total_loss, 8.194133758544922, 2370
[INFO] 2021-07-12 19:20:09,997 [run_pretraining.py:  535]:	loss/mlm_loss, 8.194133758544922, 2370
[INFO] 2021-07-12 19:20:09,997 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3689999579801224e-05, 2370
[INFO] 2021-07-12 19:20:09,997 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2370
[INFO] 2021-07-12 19:20:09,997 [run_pretraining.py:  558]:	worker_index: 7, step: 2370, cost: 8.194134, mlm loss: 8.194134, speed: 1.020368 steps/s, speed: 8.162945 samples/s, speed: 4179.428052 tokens/s, learning rate: 2.369e-05, loss_scalings: 2814.750488, pp_loss: 7.615200
[INFO] 2021-07-12 19:20:09,997 [run_pretraining.py:  512]:	********exe.run_2370******* 
[INFO] 2021-07-12 19:20:11,009 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:11,010 [run_pretraining.py:  534]:	loss/total_loss, 7.446420669555664, 2371
[INFO] 2021-07-12 19:20:11,010 [run_pretraining.py:  535]:	loss/mlm_loss, 7.446420669555664, 2371
[INFO] 2021-07-12 19:20:11,010 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.370000038354192e-05, 2371
[INFO] 2021-07-12 19:20:11,010 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2371
[INFO] 2021-07-12 19:20:11,010 [run_pretraining.py:  558]:	worker_index: 7, step: 2371, cost: 7.446421, mlm loss: 7.446421, speed: 0.988108 steps/s, speed: 7.904866 samples/s, speed: 4047.291282 tokens/s, learning rate: 2.370e-05, loss_scalings: 2814.750488, pp_loss: 7.100559
[INFO] 2021-07-12 19:20:11,010 [run_pretraining.py:  512]:	********exe.run_2371******* 
[INFO] 2021-07-12 19:20:11,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:11,983 [run_pretraining.py:  534]:	loss/total_loss, 6.956599235534668, 2372
[INFO] 2021-07-12 19:20:11,983 [run_pretraining.py:  535]:	loss/mlm_loss, 6.956599235534668, 2372
[INFO] 2021-07-12 19:20:11,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.370999936829321e-05, 2372
[INFO] 2021-07-12 19:20:11,983 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2372
[INFO] 2021-07-12 19:20:11,983 [run_pretraining.py:  558]:	worker_index: 7, step: 2372, cost: 6.956599, mlm loss: 6.956599, speed: 1.028009 steps/s, speed: 8.224071 samples/s, speed: 4210.724386 tokens/s, learning rate: 2.371e-05, loss_scalings: 2814.750488, pp_loss: 7.252552
[INFO] 2021-07-12 19:20:11,983 [run_pretraining.py:  512]:	********exe.run_2372******* 
[INFO] 2021-07-12 19:20:12,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:12,954 [run_pretraining.py:  534]:	loss/total_loss, 7.363379955291748, 2373
[INFO] 2021-07-12 19:20:12,954 [run_pretraining.py:  535]:	loss/mlm_loss, 7.363379955291748, 2373
[INFO] 2021-07-12 19:20:12,954 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3720000172033906e-05, 2373
[INFO] 2021-07-12 19:20:12,954 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2373
[INFO] 2021-07-12 19:20:12,954 [run_pretraining.py:  558]:	worker_index: 7, step: 2373, cost: 7.363380, mlm loss: 7.363380, speed: 1.030509 steps/s, speed: 8.244075 samples/s, speed: 4220.966369 tokens/s, learning rate: 2.372e-05, loss_scalings: 2814.750488, pp_loss: 7.166846
[INFO] 2021-07-12 19:20:12,954 [run_pretraining.py:  512]:	********exe.run_2373******* 
[INFO] 2021-07-12 19:20:13,925 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:13,926 [run_pretraining.py:  534]:	loss/total_loss, 7.03050422668457, 2374
[INFO] 2021-07-12 19:20:13,926 [run_pretraining.py:  535]:	loss/mlm_loss, 7.03050422668457, 2374
[INFO] 2021-07-12 19:20:13,926 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3729999156785198e-05, 2374
[INFO] 2021-07-12 19:20:13,926 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2374
[INFO] 2021-07-12 19:20:13,926 [run_pretraining.py:  558]:	worker_index: 7, step: 2374, cost: 7.030504, mlm loss: 7.030504, speed: 1.029707 steps/s, speed: 8.237657 samples/s, speed: 4217.680411 tokens/s, learning rate: 2.373e-05, loss_scalings: 2814.750488, pp_loss: 7.033291
[INFO] 2021-07-12 19:20:13,926 [run_pretraining.py:  512]:	********exe.run_2374******* 
[INFO] 2021-07-12 19:20:14,906 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:14,907 [run_pretraining.py:  534]:	loss/total_loss, 7.279654026031494, 2375
[INFO] 2021-07-12 19:20:14,907 [run_pretraining.py:  535]:	loss/mlm_loss, 7.279654026031494, 2375
[INFO] 2021-07-12 19:20:14,907 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.373999814153649e-05, 2375
[INFO] 2021-07-12 19:20:14,907 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2375
[INFO] 2021-07-12 19:20:14,907 [run_pretraining.py:  558]:	worker_index: 7, step: 2375, cost: 7.279654, mlm loss: 7.279654, speed: 1.020087 steps/s, speed: 8.160698 samples/s, speed: 4178.277409 tokens/s, learning rate: 2.374e-05, loss_scalings: 2814.750488, pp_loss: 7.151886
[INFO] 2021-07-12 19:20:14,907 [run_pretraining.py:  512]:	********exe.run_2375******* 
[INFO] 2021-07-12 19:20:15,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:15,890 [run_pretraining.py:  534]:	loss/total_loss, 7.439626693725586, 2376
[INFO] 2021-07-12 19:20:15,890 [run_pretraining.py:  535]:	loss/mlm_loss, 7.439626693725586, 2376
[INFO] 2021-07-12 19:20:15,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3749998945277184e-05, 2376
[INFO] 2021-07-12 19:20:15,890 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2376
[INFO] 2021-07-12 19:20:15,890 [run_pretraining.py:  558]:	worker_index: 7, step: 2376, cost: 7.439627, mlm loss: 7.439627, speed: 1.017869 steps/s, speed: 8.142951 samples/s, speed: 4169.191138 tokens/s, learning rate: 2.375e-05, loss_scalings: 2814.750488, pp_loss: 7.212554
[INFO] 2021-07-12 19:20:15,890 [run_pretraining.py:  512]:	********exe.run_2376******* 
[INFO] 2021-07-12 19:20:16,860 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:16,861 [run_pretraining.py:  534]:	loss/total_loss, 7.029539108276367, 2377
[INFO] 2021-07-12 19:20:16,861 [run_pretraining.py:  535]:	loss/mlm_loss, 7.029539108276367, 2377
[INFO] 2021-07-12 19:20:16,861 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.375999974901788e-05, 2377
[INFO] 2021-07-12 19:20:16,861 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2377
[INFO] 2021-07-12 19:20:16,861 [run_pretraining.py:  558]:	worker_index: 7, step: 2377, cost: 7.029539, mlm loss: 7.029539, speed: 1.030616 steps/s, speed: 8.244926 samples/s, speed: 4221.401979 tokens/s, learning rate: 2.376e-05, loss_scalings: 2814.750488, pp_loss: 7.074859
[INFO] 2021-07-12 19:20:16,861 [run_pretraining.py:  512]:	********exe.run_2377******* 
[INFO] 2021-07-12 19:20:17,828 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:17,829 [run_pretraining.py:  534]:	loss/total_loss, 5.336886405944824, 2378
[INFO] 2021-07-12 19:20:17,829 [run_pretraining.py:  535]:	loss/mlm_loss, 5.336886405944824, 2378
[INFO] 2021-07-12 19:20:17,829 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.376999873376917e-05, 2378
[INFO] 2021-07-12 19:20:17,829 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2378
[INFO] 2021-07-12 19:20:17,829 [run_pretraining.py:  558]:	worker_index: 7, step: 2378, cost: 5.336886, mlm loss: 5.336886, speed: 1.033599 steps/s, speed: 8.268793 samples/s, speed: 4233.622112 tokens/s, learning rate: 2.377e-05, loss_scalings: 2814.750488, pp_loss: 6.612514
[INFO] 2021-07-12 19:20:17,829 [run_pretraining.py:  512]:	********exe.run_2378******* 
[INFO] 2021-07-12 19:20:18,736 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:18,737 [run_pretraining.py:  534]:	loss/total_loss, 7.524043083190918, 2379
[INFO] 2021-07-12 19:20:18,737 [run_pretraining.py:  535]:	loss/mlm_loss, 7.524043083190918, 2379
[INFO] 2021-07-12 19:20:18,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3779999537509866e-05, 2379
[INFO] 2021-07-12 19:20:18,737 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2379
[INFO] 2021-07-12 19:20:18,737 [run_pretraining.py:  558]:	worker_index: 7, step: 2379, cost: 7.524043, mlm loss: 7.524043, speed: 1.102092 steps/s, speed: 8.816735 samples/s, speed: 4514.168550 tokens/s, learning rate: 2.378e-05, loss_scalings: 2814.750488, pp_loss: 7.133765
[INFO] 2021-07-12 19:20:18,737 [run_pretraining.py:  512]:	********exe.run_2379******* 
[INFO] 2021-07-12 19:20:19,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:19,686 [run_pretraining.py:  534]:	loss/total_loss, 7.401153087615967, 2380
[INFO] 2021-07-12 19:20:19,686 [run_pretraining.py:  535]:	loss/mlm_loss, 7.401153087615967, 2380
[INFO] 2021-07-12 19:20:19,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.379000034125056e-05, 2380
[INFO] 2021-07-12 19:20:19,686 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2380
[INFO] 2021-07-12 19:20:19,686 [run_pretraining.py:  558]:	worker_index: 7, step: 2380, cost: 7.401153, mlm loss: 7.401153, speed: 1.054799 steps/s, speed: 8.438395 samples/s, speed: 4320.457998 tokens/s, learning rate: 2.379e-05, loss_scalings: 2814.750488, pp_loss: 7.391090
[INFO] 2021-07-12 19:20:19,686 [run_pretraining.py:  512]:	********exe.run_2380******* 
[INFO] 2021-07-12 19:20:20,610 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:20,610 [run_pretraining.py:  534]:	loss/total_loss, 6.421023368835449, 2381
[INFO] 2021-07-12 19:20:20,610 [run_pretraining.py:  535]:	loss/mlm_loss, 6.421023368835449, 2381
[INFO] 2021-07-12 19:20:20,611 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3799999326001853e-05, 2381
[INFO] 2021-07-12 19:20:20,611 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2381
[INFO] 2021-07-12 19:20:20,611 [run_pretraining.py:  558]:	worker_index: 7, step: 2381, cost: 6.421023, mlm loss: 6.421023, speed: 1.082159 steps/s, speed: 8.657271 samples/s, speed: 4432.522887 tokens/s, learning rate: 2.380e-05, loss_scalings: 2814.750488, pp_loss: 6.445469
[INFO] 2021-07-12 19:20:20,611 [run_pretraining.py:  512]:	********exe.run_2381******* 
[INFO] 2021-07-12 19:20:21,516 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:21,516 [run_pretraining.py:  534]:	loss/total_loss, 7.4464240074157715, 2382
[INFO] 2021-07-12 19:20:21,516 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4464240074157715, 2382
[INFO] 2021-07-12 19:20:21,516 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3810000129742548e-05, 2382
[INFO] 2021-07-12 19:20:21,516 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2382
[INFO] 2021-07-12 19:20:21,516 [run_pretraining.py:  558]:	worker_index: 7, step: 2382, cost: 7.446424, mlm loss: 7.446424, speed: 1.104774 steps/s, speed: 8.838194 samples/s, speed: 4525.155151 tokens/s, learning rate: 2.381e-05, loss_scalings: 2814.750488, pp_loss: 7.484187
[INFO] 2021-07-12 19:20:21,517 [run_pretraining.py:  512]:	********exe.run_2382******* 
[INFO] 2021-07-12 19:20:22,423 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:22,423 [run_pretraining.py:  534]:	loss/total_loss, 7.144193172454834, 2383
[INFO] 2021-07-12 19:20:22,424 [run_pretraining.py:  535]:	loss/mlm_loss, 7.144193172454834, 2383
[INFO] 2021-07-12 19:20:22,424 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.381999911449384e-05, 2383
[INFO] 2021-07-12 19:20:22,424 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2383
[INFO] 2021-07-12 19:20:22,424 [run_pretraining.py:  558]:	worker_index: 7, step: 2383, cost: 7.144193, mlm loss: 7.144193, speed: 1.102901 steps/s, speed: 8.823211 samples/s, speed: 4517.483870 tokens/s, learning rate: 2.382e-05, loss_scalings: 2814.750488, pp_loss: 7.196570
[INFO] 2021-07-12 19:20:22,424 [run_pretraining.py:  512]:	********exe.run_2383******* 
[INFO] 2021-07-12 19:20:23,332 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:23,333 [run_pretraining.py:  534]:	loss/total_loss, 7.890865802764893, 2384
[INFO] 2021-07-12 19:20:23,333 [run_pretraining.py:  535]:	loss/mlm_loss, 7.890865802764893, 2384
[INFO] 2021-07-12 19:20:23,333 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.382999809924513e-05, 2384
[INFO] 2021-07-12 19:20:23,333 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2384
[INFO] 2021-07-12 19:20:23,333 [run_pretraining.py:  558]:	worker_index: 7, step: 2384, cost: 7.890866, mlm loss: 7.890866, speed: 1.100801 steps/s, speed: 8.806411 samples/s, speed: 4508.882194 tokens/s, learning rate: 2.383e-05, loss_scalings: 2814.750488, pp_loss: 6.879223
[INFO] 2021-07-12 19:20:23,333 [run_pretraining.py:  512]:	********exe.run_2384******* 
[INFO] 2021-07-12 19:20:24,237 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:24,237 [run_pretraining.py:  534]:	loss/total_loss, 7.721683502197266, 2385
[INFO] 2021-07-12 19:20:24,237 [run_pretraining.py:  535]:	loss/mlm_loss, 7.721683502197266, 2385
[INFO] 2021-07-12 19:20:24,237 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3839998902985826e-05, 2385
[INFO] 2021-07-12 19:20:24,237 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2385
[INFO] 2021-07-12 19:20:24,237 [run_pretraining.py:  558]:	worker_index: 7, step: 2385, cost: 7.721684, mlm loss: 7.721684, speed: 1.106269 steps/s, speed: 8.850155 samples/s, speed: 4531.279169 tokens/s, learning rate: 2.384e-05, loss_scalings: 2814.750488, pp_loss: 6.632380
[INFO] 2021-07-12 19:20:24,238 [run_pretraining.py:  512]:	********exe.run_2385******* 
[INFO] 2021-07-12 19:20:25,138 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:25,139 [run_pretraining.py:  534]:	loss/total_loss, 6.982841968536377, 2386
[INFO] 2021-07-12 19:20:25,139 [run_pretraining.py:  535]:	loss/mlm_loss, 6.982841968536377, 2386
[INFO] 2021-07-12 19:20:25,139 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.384999970672652e-05, 2386
[INFO] 2021-07-12 19:20:25,139 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2386
[INFO] 2021-07-12 19:20:25,139 [run_pretraining.py:  558]:	worker_index: 7, step: 2386, cost: 6.982842, mlm loss: 6.982842, speed: 1.109613 steps/s, speed: 8.876907 samples/s, speed: 4544.976211 tokens/s, learning rate: 2.385e-05, loss_scalings: 2814.750488, pp_loss: 7.142187
[INFO] 2021-07-12 19:20:25,139 [run_pretraining.py:  512]:	********exe.run_2386******* 
[INFO] 2021-07-12 19:20:26,050 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:26,050 [run_pretraining.py:  534]:	loss/total_loss, 4.633663177490234, 2387
[INFO] 2021-07-12 19:20:26,050 [run_pretraining.py:  535]:	loss/mlm_loss, 4.633663177490234, 2387
[INFO] 2021-07-12 19:20:26,050 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3859998691477813e-05, 2387
[INFO] 2021-07-12 19:20:26,050 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2387
[INFO] 2021-07-12 19:20:26,050 [run_pretraining.py:  558]:	worker_index: 7, step: 2387, cost: 4.633663, mlm loss: 4.633663, speed: 1.098387 steps/s, speed: 8.787099 samples/s, speed: 4498.994445 tokens/s, learning rate: 2.386e-05, loss_scalings: 2814.750488, pp_loss: 5.549050
[INFO] 2021-07-12 19:20:26,051 [run_pretraining.py:  512]:	********exe.run_2387******* 
[INFO] 2021-07-12 19:20:26,953 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:26,954 [run_pretraining.py:  534]:	loss/total_loss, 7.838415622711182, 2388
[INFO] 2021-07-12 19:20:26,954 [run_pretraining.py:  535]:	loss/mlm_loss, 7.838415622711182, 2388
[INFO] 2021-07-12 19:20:26,954 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3869999495218508e-05, 2388
[INFO] 2021-07-12 19:20:26,954 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2388
[INFO] 2021-07-12 19:20:26,954 [run_pretraining.py:  558]:	worker_index: 7, step: 2388, cost: 7.838416, mlm loss: 7.838416, speed: 1.107355 steps/s, speed: 8.858842 samples/s, speed: 4535.727092 tokens/s, learning rate: 2.387e-05, loss_scalings: 2814.750488, pp_loss: 7.767761
[INFO] 2021-07-12 19:20:26,954 [run_pretraining.py:  512]:	********exe.run_2388******* 
[INFO] 2021-07-12 19:20:27,859 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:27,860 [run_pretraining.py:  534]:	loss/total_loss, 7.486865520477295, 2389
[INFO] 2021-07-12 19:20:27,860 [run_pretraining.py:  535]:	loss/mlm_loss, 7.486865520477295, 2389
[INFO] 2021-07-12 19:20:27,860 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3880000298959203e-05, 2389
[INFO] 2021-07-12 19:20:27,860 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2389
[INFO] 2021-07-12 19:20:27,860 [run_pretraining.py:  558]:	worker_index: 7, step: 2389, cost: 7.486866, mlm loss: 7.486866, speed: 1.104668 steps/s, speed: 8.837344 samples/s, speed: 4524.720142 tokens/s, learning rate: 2.388e-05, loss_scalings: 2814.750488, pp_loss: 6.647950
[INFO] 2021-07-12 19:20:27,860 [run_pretraining.py:  512]:	********exe.run_2389******* 
[INFO] 2021-07-12 19:20:28,801 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:28,801 [run_pretraining.py:  534]:	loss/total_loss, 6.753053188323975, 2390
[INFO] 2021-07-12 19:20:28,802 [run_pretraining.py:  535]:	loss/mlm_loss, 6.753053188323975, 2390
[INFO] 2021-07-12 19:20:28,802 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3889999283710495e-05, 2390
[INFO] 2021-07-12 19:20:28,802 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2390
[INFO] 2021-07-12 19:20:28,802 [run_pretraining.py:  558]:	worker_index: 7, step: 2390, cost: 6.753053, mlm loss: 6.753053, speed: 1.062557 steps/s, speed: 8.500457 samples/s, speed: 4352.233991 tokens/s, learning rate: 2.389e-05, loss_scalings: 2814.750488, pp_loss: 7.215772
[INFO] 2021-07-12 19:20:28,802 [run_pretraining.py:  512]:	********exe.run_2390******* 
[INFO] 2021-07-12 19:20:29,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:29,720 [run_pretraining.py:  534]:	loss/total_loss, 8.297490119934082, 2391
[INFO] 2021-07-12 19:20:29,720 [run_pretraining.py:  535]:	loss/mlm_loss, 8.297490119934082, 2391
[INFO] 2021-07-12 19:20:29,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3899998268461786e-05, 2391
[INFO] 2021-07-12 19:20:29,720 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2391
[INFO] 2021-07-12 19:20:29,720 [run_pretraining.py:  558]:	worker_index: 7, step: 2391, cost: 8.297490, mlm loss: 8.297490, speed: 1.089672 steps/s, speed: 8.717373 samples/s, speed: 4463.294883 tokens/s, learning rate: 2.390e-05, loss_scalings: 2814.750488, pp_loss: 6.989677
[INFO] 2021-07-12 19:20:29,720 [run_pretraining.py:  512]:	********exe.run_2391******* 
[INFO] 2021-07-12 19:20:30,629 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:30,630 [run_pretraining.py:  534]:	loss/total_loss, 7.406562805175781, 2392
[INFO] 2021-07-12 19:20:30,630 [run_pretraining.py:  535]:	loss/mlm_loss, 7.406562805175781, 2392
[INFO] 2021-07-12 19:20:30,630 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.390999907220248e-05, 2392
[INFO] 2021-07-12 19:20:30,630 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2392
[INFO] 2021-07-12 19:20:30,630 [run_pretraining.py:  558]:	worker_index: 7, step: 2392, cost: 7.406563, mlm loss: 7.406563, speed: 1.099920 steps/s, speed: 8.799358 samples/s, speed: 4505.271098 tokens/s, learning rate: 2.391e-05, loss_scalings: 2814.750488, pp_loss: 7.279727
[INFO] 2021-07-12 19:20:30,630 [run_pretraining.py:  512]:	********exe.run_2392******* 
[INFO] 2021-07-12 19:20:31,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:31,536 [run_pretraining.py:  534]:	loss/total_loss, 6.817085266113281, 2393
[INFO] 2021-07-12 19:20:31,536 [run_pretraining.py:  535]:	loss/mlm_loss, 6.817085266113281, 2393
[INFO] 2021-07-12 19:20:31,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3919999875943176e-05, 2393
[INFO] 2021-07-12 19:20:31,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2393
[INFO] 2021-07-12 19:20:31,537 [run_pretraining.py:  558]:	worker_index: 7, step: 2393, cost: 6.817085, mlm loss: 6.817085, speed: 1.103859 steps/s, speed: 8.830874 samples/s, speed: 4521.407285 tokens/s, learning rate: 2.392e-05, loss_scalings: 2814.750488, pp_loss: 7.109582
[INFO] 2021-07-12 19:20:31,537 [run_pretraining.py:  512]:	********exe.run_2393******* 
[INFO] 2021-07-12 19:20:32,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:32,442 [run_pretraining.py:  534]:	loss/total_loss, 6.917777061462402, 2394
[INFO] 2021-07-12 19:20:32,442 [run_pretraining.py:  535]:	loss/mlm_loss, 6.917777061462402, 2394
[INFO] 2021-07-12 19:20:32,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3929998860694468e-05, 2394
[INFO] 2021-07-12 19:20:32,442 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2394
[INFO] 2021-07-12 19:20:32,442 [run_pretraining.py:  558]:	worker_index: 7, step: 2394, cost: 6.917777, mlm loss: 6.917777, speed: 1.105288 steps/s, speed: 8.842304 samples/s, speed: 4527.259868 tokens/s, learning rate: 2.393e-05, loss_scalings: 2814.750488, pp_loss: 6.956053
[INFO] 2021-07-12 19:20:32,442 [run_pretraining.py:  512]:	********exe.run_2394******* 
[INFO] 2021-07-12 19:20:33,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:33,355 [run_pretraining.py:  534]:	loss/total_loss, 7.256229400634766, 2395
[INFO] 2021-07-12 19:20:33,355 [run_pretraining.py:  535]:	loss/mlm_loss, 7.256229400634766, 2395
[INFO] 2021-07-12 19:20:33,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3939999664435163e-05, 2395
[INFO] 2021-07-12 19:20:33,355 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2395
[INFO] 2021-07-12 19:20:33,355 [run_pretraining.py:  558]:	worker_index: 7, step: 2395, cost: 7.256229, mlm loss: 7.256229, speed: 1.095840 steps/s, speed: 8.766721 samples/s, speed: 4488.561184 tokens/s, learning rate: 2.394e-05, loss_scalings: 2814.750488, pp_loss: 6.389690
[INFO] 2021-07-12 19:20:33,355 [run_pretraining.py:  512]:	********exe.run_2395******* 
[INFO] 2021-07-12 19:20:34,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:34,262 [run_pretraining.py:  534]:	loss/total_loss, 6.857524871826172, 2396
[INFO] 2021-07-12 19:20:34,263 [run_pretraining.py:  535]:	loss/mlm_loss, 6.857524871826172, 2396
[INFO] 2021-07-12 19:20:34,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3949998649186455e-05, 2396
[INFO] 2021-07-12 19:20:34,263 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2396
[INFO] 2021-07-12 19:20:34,263 [run_pretraining.py:  558]:	worker_index: 7, step: 2396, cost: 6.857525, mlm loss: 6.857525, speed: 1.102556 steps/s, speed: 8.820446 samples/s, speed: 4516.068358 tokens/s, learning rate: 2.395e-05, loss_scalings: 2814.750488, pp_loss: 7.274076
[INFO] 2021-07-12 19:20:34,263 [run_pretraining.py:  512]:	********exe.run_2396******* 
[INFO] 2021-07-12 19:20:35,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  534]:	loss/total_loss, 7.1273322105407715, 2397
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1273322105407715, 2397
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.395999945292715e-05, 2397
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2397
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  558]:	worker_index: 7, step: 2397, cost: 7.127332, mlm loss: 7.127332, speed: 1.103105 steps/s, speed: 8.824840 samples/s, speed: 4518.317917 tokens/s, learning rate: 2.396e-05, loss_scalings: 2814.750488, pp_loss: 7.537946
[INFO] 2021-07-12 19:20:35,170 [run_pretraining.py:  512]:	********exe.run_2397******* 
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  534]:	loss/total_loss, 6.937384605407715, 2398
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  535]:	loss/mlm_loss, 6.937384605407715, 2398
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3970000256667845e-05, 2398
[INFO] 2021-07-12 19:20:36,075 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2398
[INFO] 2021-07-12 19:20:36,076 [run_pretraining.py:  558]:	worker_index: 7, step: 2398, cost: 6.937385, mlm loss: 6.937385, speed: 1.105156 steps/s, speed: 8.841244 samples/s, speed: 4526.717105 tokens/s, learning rate: 2.397e-05, loss_scalings: 2814.750488, pp_loss: 7.394201
[INFO] 2021-07-12 19:20:36,076 [run_pretraining.py:  512]:	********exe.run_2398******* 
[INFO] 2021-07-12 19:20:36,980 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:36,981 [run_pretraining.py:  534]:	loss/total_loss, 7.094383239746094, 2399
[INFO] 2021-07-12 19:20:36,981 [run_pretraining.py:  535]:	loss/mlm_loss, 7.094383239746094, 2399
[INFO] 2021-07-12 19:20:36,981 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3979999241419137e-05, 2399
[INFO] 2021-07-12 19:20:36,981 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2399
[INFO] 2021-07-12 19:20:36,981 [run_pretraining.py:  558]:	worker_index: 7, step: 2399, cost: 7.094383, mlm loss: 7.094383, speed: 1.104720 steps/s, speed: 8.837756 samples/s, speed: 4524.931081 tokens/s, learning rate: 2.398e-05, loss_scalings: 2814.750488, pp_loss: 7.272181
[INFO] 2021-07-12 19:20:36,981 [run_pretraining.py:  512]:	********exe.run_2399******* 
[INFO] 2021-07-12 19:20:37,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:37,881 [run_pretraining.py:  534]:	loss/total_loss, 6.971047401428223, 2400
[INFO] 2021-07-12 19:20:37,881 [run_pretraining.py:  535]:	loss/mlm_loss, 6.971047401428223, 2400
[INFO] 2021-07-12 19:20:37,882 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3989998226170428e-05, 2400
[INFO] 2021-07-12 19:20:37,882 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2400
[INFO] 2021-07-12 19:20:37,882 [run_pretraining.py:  558]:	worker_index: 7, step: 2400, cost: 6.971047, mlm loss: 6.971047, speed: 1.111442 steps/s, speed: 8.891538 samples/s, speed: 4552.467370 tokens/s, learning rate: 2.399e-05, loss_scalings: 2814.750488, pp_loss: 6.973660
[INFO] 2021-07-12 19:20:37,882 [run_pretraining.py:  512]:	********exe.run_2400******* 
[INFO] 2021-07-12 19:20:38,785 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:38,786 [run_pretraining.py:  534]:	loss/total_loss, 7.709259033203125, 2401
[INFO] 2021-07-12 19:20:38,786 [run_pretraining.py:  535]:	loss/mlm_loss, 7.709259033203125, 2401
[INFO] 2021-07-12 19:20:38,786 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.3999999029911123e-05, 2401
[INFO] 2021-07-12 19:20:38,786 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2401
[INFO] 2021-07-12 19:20:38,786 [run_pretraining.py:  558]:	worker_index: 7, step: 2401, cost: 7.709259, mlm loss: 7.709259, speed: 1.106240 steps/s, speed: 8.849917 samples/s, speed: 4531.157267 tokens/s, learning rate: 2.400e-05, loss_scalings: 2814.750488, pp_loss: 7.363311
[INFO] 2021-07-12 19:20:38,786 [run_pretraining.py:  512]:	********exe.run_2401******* 
[INFO] 2021-07-12 19:20:39,691 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:39,691 [run_pretraining.py:  534]:	loss/total_loss, 7.442530632019043, 2402
[INFO] 2021-07-12 19:20:39,691 [run_pretraining.py:  535]:	loss/mlm_loss, 7.442530632019043, 2402
[INFO] 2021-07-12 19:20:39,691 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.400999983365182e-05, 2402
[INFO] 2021-07-12 19:20:39,691 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2402
[INFO] 2021-07-12 19:20:39,691 [run_pretraining.py:  558]:	worker_index: 7, step: 2402, cost: 7.442531, mlm loss: 7.442531, speed: 1.105587 steps/s, speed: 8.844698 samples/s, speed: 4528.485440 tokens/s, learning rate: 2.401e-05, loss_scalings: 2814.750488, pp_loss: 7.291913
[INFO] 2021-07-12 19:20:39,692 [run_pretraining.py:  512]:	********exe.run_2402******* 
[INFO] 2021-07-12 19:20:40,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:40,599 [run_pretraining.py:  534]:	loss/total_loss, 7.049100875854492, 2403
[INFO] 2021-07-12 19:20:40,600 [run_pretraining.py:  535]:	loss/mlm_loss, 7.049100875854492, 2403
[INFO] 2021-07-12 19:20:40,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.401999881840311e-05, 2403
[INFO] 2021-07-12 19:20:40,600 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2403
[INFO] 2021-07-12 19:20:40,600 [run_pretraining.py:  558]:	worker_index: 7, step: 2403, cost: 7.049101, mlm loss: 7.049101, speed: 1.101801 steps/s, speed: 8.814405 samples/s, speed: 4512.975609 tokens/s, learning rate: 2.402e-05, loss_scalings: 2814.750488, pp_loss: 7.031533
[INFO] 2021-07-12 19:20:40,600 [run_pretraining.py:  512]:	********exe.run_2403******* 
[INFO] 2021-07-12 19:20:41,502 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:41,503 [run_pretraining.py:  534]:	loss/total_loss, 7.458274841308594, 2404
[INFO] 2021-07-12 19:20:41,503 [run_pretraining.py:  535]:	loss/mlm_loss, 7.458274841308594, 2404
[INFO] 2021-07-12 19:20:41,503 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4029999622143805e-05, 2404
[INFO] 2021-07-12 19:20:41,503 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2404
[INFO] 2021-07-12 19:20:41,503 [run_pretraining.py:  558]:	worker_index: 7, step: 2404, cost: 7.458275, mlm loss: 7.458275, speed: 1.107969 steps/s, speed: 8.863754 samples/s, speed: 4538.242029 tokens/s, learning rate: 2.403e-05, loss_scalings: 2814.750488, pp_loss: 7.522527
[INFO] 2021-07-12 19:20:41,503 [run_pretraining.py:  512]:	********exe.run_2404******* 
[INFO] 2021-07-12 19:20:42,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:42,414 [run_pretraining.py:  534]:	loss/total_loss, 7.287341594696045, 2405
[INFO] 2021-07-12 19:20:42,414 [run_pretraining.py:  535]:	loss/mlm_loss, 7.287341594696045, 2405
[INFO] 2021-07-12 19:20:42,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.40400004258845e-05, 2405
[INFO] 2021-07-12 19:20:42,414 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2405
[INFO] 2021-07-12 19:20:42,415 [run_pretraining.py:  558]:	worker_index: 7, step: 2405, cost: 7.287342, mlm loss: 7.287342, speed: 1.097788 steps/s, speed: 8.782303 samples/s, speed: 4496.539283 tokens/s, learning rate: 2.404e-05, loss_scalings: 2814.750488, pp_loss: 6.754764
[INFO] 2021-07-12 19:20:42,415 [run_pretraining.py:  512]:	********exe.run_2405******* 
[INFO] 2021-07-12 19:20:43,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:43,355 [run_pretraining.py:  534]:	loss/total_loss, 7.8145623207092285, 2406
[INFO] 2021-07-12 19:20:43,355 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8145623207092285, 2406
[INFO] 2021-07-12 19:20:43,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4049999410635792e-05, 2406
[INFO] 2021-07-12 19:20:43,355 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2406
[INFO] 2021-07-12 19:20:43,355 [run_pretraining.py:  558]:	worker_index: 7, step: 2406, cost: 7.814562, mlm loss: 7.814562, speed: 1.063723 steps/s, speed: 8.509787 samples/s, speed: 4357.011135 tokens/s, learning rate: 2.405e-05, loss_scalings: 2814.750488, pp_loss: 7.266973
[INFO] 2021-07-12 19:20:43,355 [run_pretraining.py:  512]:	********exe.run_2406******* 
[INFO] 2021-07-12 19:20:44,261 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:44,262 [run_pretraining.py:  534]:	loss/total_loss, 7.601750373840332, 2407
[INFO] 2021-07-12 19:20:44,262 [run_pretraining.py:  535]:	loss/mlm_loss, 7.601750373840332, 2407
[INFO] 2021-07-12 19:20:44,262 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4060000214376487e-05, 2407
[INFO] 2021-07-12 19:20:44,262 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2407
[INFO] 2021-07-12 19:20:44,262 [run_pretraining.py:  558]:	worker_index: 7, step: 2407, cost: 7.601750, mlm loss: 7.601750, speed: 1.103262 steps/s, speed: 8.826098 samples/s, speed: 4518.962079 tokens/s, learning rate: 2.406e-05, loss_scalings: 2814.750488, pp_loss: 7.178510
[INFO] 2021-07-12 19:20:44,262 [run_pretraining.py:  512]:	********exe.run_2407******* 
[INFO] 2021-07-12 19:20:45,167 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:45,167 [run_pretraining.py:  534]:	loss/total_loss, 6.8591508865356445, 2408
[INFO] 2021-07-12 19:20:45,168 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8591508865356445, 2408
[INFO] 2021-07-12 19:20:45,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.406999919912778e-05, 2408
[INFO] 2021-07-12 19:20:45,168 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2408
[INFO] 2021-07-12 19:20:45,168 [run_pretraining.py:  558]:	worker_index: 7, step: 2408, cost: 6.859151, mlm loss: 6.859151, speed: 1.105209 steps/s, speed: 8.841673 samples/s, speed: 4526.936580 tokens/s, learning rate: 2.407e-05, loss_scalings: 2814.750488, pp_loss: 6.817112
[INFO] 2021-07-12 19:20:45,168 [run_pretraining.py:  512]:	********exe.run_2408******* 
[INFO] 2021-07-12 19:20:46,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:46,068 [run_pretraining.py:  534]:	loss/total_loss, 7.031723499298096, 2409
[INFO] 2021-07-12 19:20:46,069 [run_pretraining.py:  535]:	loss/mlm_loss, 7.031723499298096, 2409
[INFO] 2021-07-12 19:20:46,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.407999818387907e-05, 2409
[INFO] 2021-07-12 19:20:46,069 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2409
[INFO] 2021-07-12 19:20:46,069 [run_pretraining.py:  558]:	worker_index: 7, step: 2409, cost: 7.031723, mlm loss: 7.031723, speed: 1.110686 steps/s, speed: 8.885489 samples/s, speed: 4549.370361 tokens/s, learning rate: 2.408e-05, loss_scalings: 2814.750488, pp_loss: 7.051866
[INFO] 2021-07-12 19:20:46,069 [run_pretraining.py:  512]:	********exe.run_2409******* 
[INFO] 2021-07-12 19:20:46,973 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:46,974 [run_pretraining.py:  534]:	loss/total_loss, 7.047450542449951, 2410
[INFO] 2021-07-12 19:20:46,974 [run_pretraining.py:  535]:	loss/mlm_loss, 7.047450542449951, 2410
[INFO] 2021-07-12 19:20:46,974 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4089998987619765e-05, 2410
[INFO] 2021-07-12 19:20:46,974 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2410
[INFO] 2021-07-12 19:20:46,974 [run_pretraining.py:  558]:	worker_index: 7, step: 2410, cost: 7.047451, mlm loss: 7.047451, speed: 1.105365 steps/s, speed: 8.842920 samples/s, speed: 4527.574850 tokens/s, learning rate: 2.409e-05, loss_scalings: 2814.750488, pp_loss: 7.034788
[INFO] 2021-07-12 19:20:46,974 [run_pretraining.py:  512]:	********exe.run_2410******* 
[INFO] 2021-07-12 19:20:47,885 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:47,886 [run_pretraining.py:  534]:	loss/total_loss, 7.39552116394043, 2411
[INFO] 2021-07-12 19:20:47,886 [run_pretraining.py:  535]:	loss/mlm_loss, 7.39552116394043, 2411
[INFO] 2021-07-12 19:20:47,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.409999979136046e-05, 2411
[INFO] 2021-07-12 19:20:47,886 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2411
[INFO] 2021-07-12 19:20:47,886 [run_pretraining.py:  558]:	worker_index: 7, step: 2411, cost: 7.395521, mlm loss: 7.395521, speed: 1.097609 steps/s, speed: 8.780871 samples/s, speed: 4495.806198 tokens/s, learning rate: 2.410e-05, loss_scalings: 2814.750488, pp_loss: 7.520645
[INFO] 2021-07-12 19:20:47,886 [run_pretraining.py:  512]:	********exe.run_2411******* 
[INFO] 2021-07-12 19:20:48,793 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:48,794 [run_pretraining.py:  534]:	loss/total_loss, 7.615685939788818, 2412
[INFO] 2021-07-12 19:20:48,794 [run_pretraining.py:  535]:	loss/mlm_loss, 7.615685939788818, 2412
[INFO] 2021-07-12 19:20:48,794 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4109998776111752e-05, 2412
[INFO] 2021-07-12 19:20:48,794 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2412
[INFO] 2021-07-12 19:20:48,794 [run_pretraining.py:  558]:	worker_index: 7, step: 2412, cost: 7.615686, mlm loss: 7.615686, speed: 1.101783 steps/s, speed: 8.814267 samples/s, speed: 4512.904479 tokens/s, learning rate: 2.411e-05, loss_scalings: 2814.750488, pp_loss: 6.840222
[INFO] 2021-07-12 19:20:48,794 [run_pretraining.py:  512]:	********exe.run_2412******* 
[INFO] 2021-07-12 19:20:49,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:49,700 [run_pretraining.py:  534]:	loss/total_loss, 7.08057165145874, 2413
[INFO] 2021-07-12 19:20:49,700 [run_pretraining.py:  535]:	loss/mlm_loss, 7.08057165145874, 2413
[INFO] 2021-07-12 19:20:49,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4119999579852447e-05, 2413
[INFO] 2021-07-12 19:20:49,701 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2413
[INFO] 2021-07-12 19:20:49,701 [run_pretraining.py:  558]:	worker_index: 7, step: 2413, cost: 7.080572, mlm loss: 7.080572, speed: 1.103806 steps/s, speed: 8.830451 samples/s, speed: 4521.190725 tokens/s, learning rate: 2.412e-05, loss_scalings: 2814.750488, pp_loss: 7.215131
[INFO] 2021-07-12 19:20:49,701 [run_pretraining.py:  512]:	********exe.run_2413******* 
[INFO] 2021-07-12 19:20:50,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:50,606 [run_pretraining.py:  534]:	loss/total_loss, 7.277931213378906, 2414
[INFO] 2021-07-12 19:20:50,606 [run_pretraining.py:  535]:	loss/mlm_loss, 7.277931213378906, 2414
[INFO] 2021-07-12 19:20:50,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4130000383593142e-05, 2414
[INFO] 2021-07-12 19:20:50,606 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2414
[INFO] 2021-07-12 19:20:50,607 [run_pretraining.py:  558]:	worker_index: 7, step: 2414, cost: 7.277931, mlm loss: 7.277931, speed: 1.104787 steps/s, speed: 8.838294 samples/s, speed: 4525.206404 tokens/s, learning rate: 2.413e-05, loss_scalings: 2814.750488, pp_loss: 6.624657
[INFO] 2021-07-12 19:20:50,607 [run_pretraining.py:  512]:	********exe.run_2414******* 
[INFO] 2021-07-12 19:20:51,511 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  534]:	loss/total_loss, 6.862217426300049, 2415
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  535]:	loss/mlm_loss, 6.862217426300049, 2415
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4139999368344434e-05, 2415
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2415
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  558]:	worker_index: 7, step: 2415, cost: 6.862217, mlm loss: 6.862217, speed: 1.104963 steps/s, speed: 8.839700 samples/s, speed: 4525.926454 tokens/s, learning rate: 2.414e-05, loss_scalings: 2814.750488, pp_loss: 7.280421
[INFO] 2021-07-12 19:20:51,512 [run_pretraining.py:  512]:	********exe.run_2415******* 
[INFO] 2021-07-12 19:20:52,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:52,418 [run_pretraining.py:  534]:	loss/total_loss, 7.431756019592285, 2416
[INFO] 2021-07-12 19:20:52,418 [run_pretraining.py:  535]:	loss/mlm_loss, 7.431756019592285, 2416
[INFO] 2021-07-12 19:20:52,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.415000017208513e-05, 2416
[INFO] 2021-07-12 19:20:52,418 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2416
[INFO] 2021-07-12 19:20:52,418 [run_pretraining.py:  558]:	worker_index: 7, step: 2416, cost: 7.431756, mlm loss: 7.431756, speed: 1.104422 steps/s, speed: 8.835373 samples/s, speed: 4523.711005 tokens/s, learning rate: 2.415e-05, loss_scalings: 2814.750488, pp_loss: 7.334168
[INFO] 2021-07-12 19:20:52,418 [run_pretraining.py:  512]:	********exe.run_2416******* 
[INFO] 2021-07-12 19:20:53,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:53,378 [run_pretraining.py:  534]:	loss/total_loss, 6.482637405395508, 2417
[INFO] 2021-07-12 19:20:53,378 [run_pretraining.py:  535]:	loss/mlm_loss, 6.482637405395508, 2417
[INFO] 2021-07-12 19:20:53,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4160000975825824e-05, 2417
[INFO] 2021-07-12 19:20:53,378 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2417
[INFO] 2021-07-12 19:20:53,379 [run_pretraining.py:  558]:	worker_index: 7, step: 2417, cost: 6.482637, mlm loss: 6.482637, speed: 1.042110 steps/s, speed: 8.336884 samples/s, speed: 4268.484551 tokens/s, learning rate: 2.416e-05, loss_scalings: 2814.750488, pp_loss: 7.070154
[INFO] 2021-07-12 19:20:53,379 [run_pretraining.py:  512]:	********exe.run_2417******* 
[INFO] 2021-07-12 19:20:54,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:54,308 [run_pretraining.py:  534]:	loss/total_loss, 6.9553399085998535, 2418
[INFO] 2021-07-12 19:20:54,308 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9553399085998535, 2418
[INFO] 2021-07-12 19:20:54,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4169998141587712e-05, 2418
[INFO] 2021-07-12 19:20:54,308 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2418
[INFO] 2021-07-12 19:20:54,308 [run_pretraining.py:  558]:	worker_index: 7, step: 2418, cost: 6.955340, mlm loss: 6.955340, speed: 1.076670 steps/s, speed: 8.613356 samples/s, speed: 4410.038429 tokens/s, learning rate: 2.417e-05, loss_scalings: 2814.750488, pp_loss: 7.221313
[INFO] 2021-07-12 19:20:54,308 [run_pretraining.py:  512]:	********exe.run_2418******* 
[INFO] 2021-07-12 19:20:55,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:55,214 [run_pretraining.py:  534]:	loss/total_loss, 7.681986331939697, 2419
[INFO] 2021-07-12 19:20:55,214 [run_pretraining.py:  535]:	loss/mlm_loss, 7.681986331939697, 2419
[INFO] 2021-07-12 19:20:55,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4179998945328407e-05, 2419
[INFO] 2021-07-12 19:20:55,214 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2419
[INFO] 2021-07-12 19:20:55,214 [run_pretraining.py:  558]:	worker_index: 7, step: 2419, cost: 7.681986, mlm loss: 7.681986, speed: 1.104077 steps/s, speed: 8.832617 samples/s, speed: 4522.299921 tokens/s, learning rate: 2.418e-05, loss_scalings: 2814.750488, pp_loss: 7.253604
[INFO] 2021-07-12 19:20:55,214 [run_pretraining.py:  512]:	********exe.run_2419******* 
[INFO] 2021-07-12 19:20:56,124 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:56,124 [run_pretraining.py:  534]:	loss/total_loss, 7.680894374847412, 2420
[INFO] 2021-07-12 19:20:56,124 [run_pretraining.py:  535]:	loss/mlm_loss, 7.680894374847412, 2420
[INFO] 2021-07-12 19:20:56,124 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4189999749069102e-05, 2420
[INFO] 2021-07-12 19:20:56,124 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2420
[INFO] 2021-07-12 19:20:56,125 [run_pretraining.py:  558]:	worker_index: 7, step: 2420, cost: 7.680894, mlm loss: 7.680894, speed: 1.099536 steps/s, speed: 8.796290 samples/s, speed: 4503.700294 tokens/s, learning rate: 2.419e-05, loss_scalings: 2814.750488, pp_loss: 7.425862
[INFO] 2021-07-12 19:20:56,125 [run_pretraining.py:  512]:	********exe.run_2420******* 
[INFO] 2021-07-12 19:20:57,039 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:57,039 [run_pretraining.py:  534]:	loss/total_loss, 7.19287633895874, 2421
[INFO] 2021-07-12 19:20:57,039 [run_pretraining.py:  535]:	loss/mlm_loss, 7.19287633895874, 2421
[INFO] 2021-07-12 19:20:57,039 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4199998733820394e-05, 2421
[INFO] 2021-07-12 19:20:57,039 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2421
[INFO] 2021-07-12 19:20:57,039 [run_pretraining.py:  558]:	worker_index: 7, step: 2421, cost: 7.192876, mlm loss: 7.192876, speed: 1.093764 steps/s, speed: 8.750110 samples/s, speed: 4480.056344 tokens/s, learning rate: 2.420e-05, loss_scalings: 2814.750488, pp_loss: 7.154227
[INFO] 2021-07-12 19:20:57,040 [run_pretraining.py:  512]:	********exe.run_2421******* 
[INFO] 2021-07-12 19:20:57,956 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:57,956 [run_pretraining.py:  534]:	loss/total_loss, 7.852067947387695, 2422
[INFO] 2021-07-12 19:20:57,956 [run_pretraining.py:  535]:	loss/mlm_loss, 7.852067947387695, 2422
[INFO] 2021-07-12 19:20:57,957 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.420999953756109e-05, 2422
[INFO] 2021-07-12 19:20:57,957 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2422
[INFO] 2021-07-12 19:20:57,957 [run_pretraining.py:  558]:	worker_index: 7, step: 2422, cost: 7.852068, mlm loss: 7.852068, speed: 1.091074 steps/s, speed: 8.728591 samples/s, speed: 4469.038583 tokens/s, learning rate: 2.421e-05, loss_scalings: 2814.750488, pp_loss: 7.589603
[INFO] 2021-07-12 19:20:57,957 [run_pretraining.py:  512]:	********exe.run_2422******* 
[INFO] 2021-07-12 19:20:58,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:58,878 [run_pretraining.py:  534]:	loss/total_loss, 7.850118160247803, 2423
[INFO] 2021-07-12 19:20:58,878 [run_pretraining.py:  535]:	loss/mlm_loss, 7.850118160247803, 2423
[INFO] 2021-07-12 19:20:58,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4220000341301784e-05, 2423
[INFO] 2021-07-12 19:20:58,879 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2423
[INFO] 2021-07-12 19:20:58,879 [run_pretraining.py:  558]:	worker_index: 7, step: 2423, cost: 7.850118, mlm loss: 7.850118, speed: 1.085286 steps/s, speed: 8.682291 samples/s, speed: 4445.332904 tokens/s, learning rate: 2.422e-05, loss_scalings: 2814.750488, pp_loss: 7.576914
[INFO] 2021-07-12 19:20:58,879 [run_pretraining.py:  512]:	********exe.run_2423******* 
[INFO] 2021-07-12 19:20:59,790 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:20:59,790 [run_pretraining.py:  534]:	loss/total_loss, 7.429389953613281, 2424
[INFO] 2021-07-12 19:20:59,790 [run_pretraining.py:  535]:	loss/mlm_loss, 7.429389953613281, 2424
[INFO] 2021-07-12 19:20:59,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4229999326053075e-05, 2424
[INFO] 2021-07-12 19:20:59,790 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2424
[INFO] 2021-07-12 19:20:59,791 [run_pretraining.py:  558]:	worker_index: 7, step: 2424, cost: 7.429390, mlm loss: 7.429390, speed: 1.097485 steps/s, speed: 8.779884 samples/s, speed: 4495.300356 tokens/s, learning rate: 2.423e-05, loss_scalings: 2814.750488, pp_loss: 7.963439
[INFO] 2021-07-12 19:20:59,791 [run_pretraining.py:  512]:	********exe.run_2424******* 
[INFO] 2021-07-12 19:21:00,703 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:00,704 [run_pretraining.py:  534]:	loss/total_loss, 7.47175407409668, 2425
[INFO] 2021-07-12 19:21:00,704 [run_pretraining.py:  535]:	loss/mlm_loss, 7.47175407409668, 2425
[INFO] 2021-07-12 19:21:00,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.424000012979377e-05, 2425
[INFO] 2021-07-12 19:21:00,704 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2425
[INFO] 2021-07-12 19:21:00,704 [run_pretraining.py:  558]:	worker_index: 7, step: 2425, cost: 7.471754, mlm loss: 7.471754, speed: 1.095216 steps/s, speed: 8.761726 samples/s, speed: 4486.003766 tokens/s, learning rate: 2.424e-05, loss_scalings: 2814.750488, pp_loss: 7.628525
[INFO] 2021-07-12 19:21:00,704 [run_pretraining.py:  512]:	********exe.run_2425******* 
[INFO] 2021-07-12 19:21:01,620 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:01,620 [run_pretraining.py:  534]:	loss/total_loss, 7.351980686187744, 2426
[INFO] 2021-07-12 19:21:01,620 [run_pretraining.py:  535]:	loss/mlm_loss, 7.351980686187744, 2426
[INFO] 2021-07-12 19:21:01,620 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4250000933534466e-05, 2426
[INFO] 2021-07-12 19:21:01,621 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2426
[INFO] 2021-07-12 19:21:01,621 [run_pretraining.py:  558]:	worker_index: 7, step: 2426, cost: 7.351981, mlm loss: 7.351981, speed: 1.092097 steps/s, speed: 8.736773 samples/s, speed: 4473.227655 tokens/s, learning rate: 2.425e-05, loss_scalings: 2814.750488, pp_loss: 7.285151
[INFO] 2021-07-12 19:21:01,621 [run_pretraining.py:  512]:	********exe.run_2426******* 
[INFO] 2021-07-12 19:21:02,537 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:02,538 [run_pretraining.py:  534]:	loss/total_loss, 7.586142539978027, 2427
[INFO] 2021-07-12 19:21:02,538 [run_pretraining.py:  535]:	loss/mlm_loss, 7.586142539978027, 2427
[INFO] 2021-07-12 19:21:02,538 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4259998099296354e-05, 2427
[INFO] 2021-07-12 19:21:02,538 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2427
[INFO] 2021-07-12 19:21:02,538 [run_pretraining.py:  558]:	worker_index: 7, step: 2427, cost: 7.586143, mlm loss: 7.586143, speed: 1.090837 steps/s, speed: 8.726693 samples/s, speed: 4468.066910 tokens/s, learning rate: 2.426e-05, loss_scalings: 2814.750488, pp_loss: 7.205080
[INFO] 2021-07-12 19:21:02,538 [run_pretraining.py:  512]:	********exe.run_2427******* 
[INFO] 2021-07-12 19:21:03,462 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:03,462 [run_pretraining.py:  534]:	loss/total_loss, 7.649614334106445, 2428
[INFO] 2021-07-12 19:21:03,463 [run_pretraining.py:  535]:	loss/mlm_loss, 7.649614334106445, 2428
[INFO] 2021-07-12 19:21:03,463 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.426999890303705e-05, 2428
[INFO] 2021-07-12 19:21:03,463 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2428
[INFO] 2021-07-12 19:21:03,463 [run_pretraining.py:  558]:	worker_index: 7, step: 2428, cost: 7.649614, mlm loss: 7.649614, speed: 1.082108 steps/s, speed: 8.656867 samples/s, speed: 4432.315901 tokens/s, learning rate: 2.427e-05, loss_scalings: 2814.750488, pp_loss: 7.516067
[INFO] 2021-07-12 19:21:03,463 [run_pretraining.py:  512]:	********exe.run_2428******* 
[INFO] 2021-07-12 19:21:04,372 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  534]:	loss/total_loss, 7.34972620010376, 2429
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  535]:	loss/mlm_loss, 7.34972620010376, 2429
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4279999706777744e-05, 2429
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2429
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  558]:	worker_index: 7, step: 2429, cost: 7.349726, mlm loss: 7.349726, speed: 1.099435 steps/s, speed: 8.795480 samples/s, speed: 4503.285925 tokens/s, learning rate: 2.428e-05, loss_scalings: 2814.750488, pp_loss: 7.603292
[INFO] 2021-07-12 19:21:04,373 [run_pretraining.py:  512]:	********exe.run_2429******* 
[INFO] 2021-07-12 19:21:05,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:05,285 [run_pretraining.py:  534]:	loss/total_loss, 6.858269214630127, 2430
[INFO] 2021-07-12 19:21:05,285 [run_pretraining.py:  535]:	loss/mlm_loss, 6.858269214630127, 2430
[INFO] 2021-07-12 19:21:05,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4289998691529036e-05, 2430
[INFO] 2021-07-12 19:21:05,286 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2430
[INFO] 2021-07-12 19:21:05,286 [run_pretraining.py:  558]:	worker_index: 7, step: 2430, cost: 6.858269, mlm loss: 6.858269, speed: 1.096390 steps/s, speed: 8.771121 samples/s, speed: 4490.813937 tokens/s, learning rate: 2.429e-05, loss_scalings: 2814.750488, pp_loss: 7.197362
[INFO] 2021-07-12 19:21:05,286 [run_pretraining.py:  512]:	********exe.run_2430******* 
[INFO] 2021-07-12 19:21:06,198 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:06,199 [run_pretraining.py:  534]:	loss/total_loss, 7.128887176513672, 2431
[INFO] 2021-07-12 19:21:06,199 [run_pretraining.py:  535]:	loss/mlm_loss, 7.128887176513672, 2431
[INFO] 2021-07-12 19:21:06,199 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.429999949526973e-05, 2431
[INFO] 2021-07-12 19:21:06,199 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2431
[INFO] 2021-07-12 19:21:06,199 [run_pretraining.py:  558]:	worker_index: 7, step: 2431, cost: 7.128887, mlm loss: 7.128887, speed: 1.095618 steps/s, speed: 8.764944 samples/s, speed: 4487.651338 tokens/s, learning rate: 2.430e-05, loss_scalings: 2814.750488, pp_loss: 6.416012
[INFO] 2021-07-12 19:21:06,199 [run_pretraining.py:  512]:	********exe.run_2431******* 
[INFO] 2021-07-12 19:21:07,110 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:07,110 [run_pretraining.py:  534]:	loss/total_loss, 7.751992225646973, 2432
[INFO] 2021-07-12 19:21:07,111 [run_pretraining.py:  535]:	loss/mlm_loss, 7.751992225646973, 2432
[INFO] 2021-07-12 19:21:07,111 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4310000299010426e-05, 2432
[INFO] 2021-07-12 19:21:07,111 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2432
[INFO] 2021-07-12 19:21:07,111 [run_pretraining.py:  558]:	worker_index: 7, step: 2432, cost: 7.751992, mlm loss: 7.751992, speed: 1.097679 steps/s, speed: 8.781430 samples/s, speed: 4496.092108 tokens/s, learning rate: 2.431e-05, loss_scalings: 2814.750488, pp_loss: 7.307046
[INFO] 2021-07-12 19:21:07,111 [run_pretraining.py:  512]:	********exe.run_2432******* 
[INFO] 2021-07-12 19:21:08,019 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:08,020 [run_pretraining.py:  534]:	loss/total_loss, 7.024745941162109, 2433
[INFO] 2021-07-12 19:21:08,020 [run_pretraining.py:  535]:	loss/mlm_loss, 7.024745941162109, 2433
[INFO] 2021-07-12 19:21:08,020 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4319999283761717e-05, 2433
[INFO] 2021-07-12 19:21:08,020 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2433
[INFO] 2021-07-12 19:21:08,020 [run_pretraining.py:  558]:	worker_index: 7, step: 2433, cost: 7.024746, mlm loss: 7.024746, speed: 1.100516 steps/s, speed: 8.804125 samples/s, speed: 4507.712152 tokens/s, learning rate: 2.432e-05, loss_scalings: 2814.750488, pp_loss: 7.101215
[INFO] 2021-07-12 19:21:08,020 [run_pretraining.py:  512]:	********exe.run_2433******* 
[INFO] 2021-07-12 19:21:08,928 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:08,928 [run_pretraining.py:  534]:	loss/total_loss, 8.567520141601562, 2434
[INFO] 2021-07-12 19:21:08,928 [run_pretraining.py:  535]:	loss/mlm_loss, 8.567520141601562, 2434
[INFO] 2021-07-12 19:21:08,928 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4330000087502412e-05, 2434
[INFO] 2021-07-12 19:21:08,928 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2434
[INFO] 2021-07-12 19:21:08,929 [run_pretraining.py:  558]:	worker_index: 7, step: 2434, cost: 8.567520, mlm loss: 8.567520, speed: 1.101487 steps/s, speed: 8.811894 samples/s, speed: 4511.689694 tokens/s, learning rate: 2.433e-05, loss_scalings: 2814.750488, pp_loss: 7.678636
[INFO] 2021-07-12 19:21:08,929 [run_pretraining.py:  512]:	********exe.run_2434******* 
[INFO] 2021-07-12 19:21:09,842 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:09,842 [run_pretraining.py:  534]:	loss/total_loss, 6.790035724639893, 2435
[INFO] 2021-07-12 19:21:09,842 [run_pretraining.py:  535]:	loss/mlm_loss, 6.790035724639893, 2435
[INFO] 2021-07-12 19:21:09,842 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4339999072253704e-05, 2435
[INFO] 2021-07-12 19:21:09,842 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2435
[INFO] 2021-07-12 19:21:09,843 [run_pretraining.py:  558]:	worker_index: 7, step: 2435, cost: 6.790036, mlm loss: 6.790036, speed: 1.094891 steps/s, speed: 8.759126 samples/s, speed: 4484.672298 tokens/s, learning rate: 2.434e-05, loss_scalings: 2814.750488, pp_loss: 6.996684
[INFO] 2021-07-12 19:21:09,843 [run_pretraining.py:  512]:	********exe.run_2435******* 
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  534]:	loss/total_loss, 7.085506439208984, 2436
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  535]:	loss/mlm_loss, 7.085506439208984, 2436
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4349998057004996e-05, 2436
[INFO] 2021-07-12 19:21:10,750 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2436
[INFO] 2021-07-12 19:21:10,751 [run_pretraining.py:  558]:	worker_index: 7, step: 2436, cost: 7.085506, mlm loss: 7.085506, speed: 1.102013 steps/s, speed: 8.816105 samples/s, speed: 4513.845943 tokens/s, learning rate: 2.435e-05, loss_scalings: 2814.750488, pp_loss: 7.285598
[INFO] 2021-07-12 19:21:10,751 [run_pretraining.py:  512]:	********exe.run_2436******* 
[INFO] 2021-07-12 19:21:11,660 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:11,660 [run_pretraining.py:  534]:	loss/total_loss, 7.294240474700928, 2437
[INFO] 2021-07-12 19:21:11,660 [run_pretraining.py:  535]:	loss/mlm_loss, 7.294240474700928, 2437
[INFO] 2021-07-12 19:21:11,661 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.435999886074569e-05, 2437
[INFO] 2021-07-12 19:21:11,661 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2437
[INFO] 2021-07-12 19:21:11,661 [run_pretraining.py:  558]:	worker_index: 7, step: 2437, cost: 7.294240, mlm loss: 7.294240, speed: 1.099541 steps/s, speed: 8.796329 samples/s, speed: 4503.720365 tokens/s, learning rate: 2.436e-05, loss_scalings: 2814.750488, pp_loss: 7.353911
[INFO] 2021-07-12 19:21:11,661 [run_pretraining.py:  512]:	********exe.run_2437******* 
[INFO] 2021-07-12 19:21:12,570 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:12,570 [run_pretraining.py:  534]:	loss/total_loss, 7.187450885772705, 2438
[INFO] 2021-07-12 19:21:12,570 [run_pretraining.py:  535]:	loss/mlm_loss, 7.187450885772705, 2438
[INFO] 2021-07-12 19:21:12,571 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4369999664486386e-05, 2438
[INFO] 2021-07-12 19:21:12,571 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2438
[INFO] 2021-07-12 19:21:12,571 [run_pretraining.py:  558]:	worker_index: 7, step: 2438, cost: 7.187451, mlm loss: 7.187451, speed: 1.099707 steps/s, speed: 8.797655 samples/s, speed: 4504.399343 tokens/s, learning rate: 2.437e-05, loss_scalings: 2814.750488, pp_loss: 6.863955
[INFO] 2021-07-12 19:21:12,571 [run_pretraining.py:  512]:	********exe.run_2438******* 
[INFO] 2021-07-12 19:21:13,478 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:13,478 [run_pretraining.py:  534]:	loss/total_loss, 6.457016468048096, 2439
[INFO] 2021-07-12 19:21:13,478 [run_pretraining.py:  535]:	loss/mlm_loss, 6.457016468048096, 2439
[INFO] 2021-07-12 19:21:13,479 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4379998649237677e-05, 2439
[INFO] 2021-07-12 19:21:13,479 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2439
[INFO] 2021-07-12 19:21:13,479 [run_pretraining.py:  558]:	worker_index: 7, step: 2439, cost: 6.457016, mlm loss: 6.457016, speed: 1.102089 steps/s, speed: 8.816710 samples/s, speed: 4514.155502 tokens/s, learning rate: 2.438e-05, loss_scalings: 2814.750488, pp_loss: 7.349198
[INFO] 2021-07-12 19:21:13,479 [run_pretraining.py:  512]:	********exe.run_2439******* 
[INFO] 2021-07-12 19:21:14,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:14,390 [run_pretraining.py:  534]:	loss/total_loss, 7.475821495056152, 2440
[INFO] 2021-07-12 19:21:14,390 [run_pretraining.py:  535]:	loss/mlm_loss, 7.475821495056152, 2440
[INFO] 2021-07-12 19:21:14,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4389999452978373e-05, 2440
[INFO] 2021-07-12 19:21:14,390 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2440
[INFO] 2021-07-12 19:21:14,390 [run_pretraining.py:  558]:	worker_index: 7, step: 2440, cost: 7.475821, mlm loss: 7.475821, speed: 1.097743 steps/s, speed: 8.781940 samples/s, speed: 4496.353342 tokens/s, learning rate: 2.439e-05, loss_scalings: 2814.750488, pp_loss: 7.207950
[INFO] 2021-07-12 19:21:14,390 [run_pretraining.py:  512]:	********exe.run_2440******* 
[INFO] 2021-07-12 19:21:15,301 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:15,302 [run_pretraining.py:  534]:	loss/total_loss, 7.29678201675415, 2441
[INFO] 2021-07-12 19:21:15,302 [run_pretraining.py:  535]:	loss/mlm_loss, 7.29678201675415, 2441
[INFO] 2021-07-12 19:21:15,302 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4400000256719068e-05, 2441
[INFO] 2021-07-12 19:21:15,302 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2441
[INFO] 2021-07-12 19:21:15,302 [run_pretraining.py:  558]:	worker_index: 7, step: 2441, cost: 7.296782, mlm loss: 7.296782, speed: 1.097589 steps/s, speed: 8.780708 samples/s, speed: 4495.722668 tokens/s, learning rate: 2.440e-05, loss_scalings: 2814.750488, pp_loss: 7.079360
[INFO] 2021-07-12 19:21:15,302 [run_pretraining.py:  512]:	********exe.run_2441******* 
[INFO] 2021-07-12 19:21:16,262 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:16,263 [run_pretraining.py:  534]:	loss/total_loss, 7.5139007568359375, 2442
[INFO] 2021-07-12 19:21:16,263 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5139007568359375, 2442
[INFO] 2021-07-12 19:21:16,263 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.440999924147036e-05, 2442
[INFO] 2021-07-12 19:21:16,263 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2442
[INFO] 2021-07-12 19:21:16,263 [run_pretraining.py:  558]:	worker_index: 7, step: 2442, cost: 7.513901, mlm loss: 7.513901, speed: 1.041319 steps/s, speed: 8.330550 samples/s, speed: 4265.241760 tokens/s, learning rate: 2.441e-05, loss_scalings: 2814.750488, pp_loss: 7.278007
[INFO] 2021-07-12 19:21:16,263 [run_pretraining.py:  512]:	********exe.run_2442******* 
[INFO] 2021-07-12 19:21:17,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:17,168 [run_pretraining.py:  534]:	loss/total_loss, 7.1607537269592285, 2443
[INFO] 2021-07-12 19:21:17,168 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1607537269592285, 2443
[INFO] 2021-07-12 19:21:17,168 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4420000045211054e-05, 2443
[INFO] 2021-07-12 19:21:17,168 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2443
[INFO] 2021-07-12 19:21:17,168 [run_pretraining.py:  558]:	worker_index: 7, step: 2443, cost: 7.160754, mlm loss: 7.160754, speed: 1.105380 steps/s, speed: 8.843038 samples/s, speed: 4527.635703 tokens/s, learning rate: 2.442e-05, loss_scalings: 2814.750488, pp_loss: 7.298507
[INFO] 2021-07-12 19:21:17,168 [run_pretraining.py:  512]:	********exe.run_2443******* 
[INFO] 2021-07-12 19:21:18,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:18,074 [run_pretraining.py:  534]:	loss/total_loss, 7.528199195861816, 2444
[INFO] 2021-07-12 19:21:18,074 [run_pretraining.py:  535]:	loss/mlm_loss, 7.528199195861816, 2444
[INFO] 2021-07-12 19:21:18,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4429999029962346e-05, 2444
[INFO] 2021-07-12 19:21:18,074 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2444
[INFO] 2021-07-12 19:21:18,074 [run_pretraining.py:  558]:	worker_index: 7, step: 2444, cost: 7.528199, mlm loss: 7.528199, speed: 1.104936 steps/s, speed: 8.839491 samples/s, speed: 4525.819148 tokens/s, learning rate: 2.443e-05, loss_scalings: 2814.750488, pp_loss: 7.142716
[INFO] 2021-07-12 19:21:18,074 [run_pretraining.py:  512]:	********exe.run_2444******* 
[INFO] 2021-07-12 19:21:42,697 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:42,698 [run_pretraining.py:  534]:	loss/total_loss, 7.482851505279541, 2445
[INFO] 2021-07-12 19:21:42,698 [run_pretraining.py:  535]:	loss/mlm_loss, 7.482851505279541, 2445
[INFO] 2021-07-12 19:21:42,698 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4439998014713638e-05, 2445
[INFO] 2021-07-12 19:21:42,698 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2445
[INFO] 2021-07-12 19:21:42,698 [run_pretraining.py:  558]:	worker_index: 7, step: 2445, cost: 7.482852, mlm loss: 7.482852, speed: 0.040612 steps/s, speed: 0.324897 samples/s, speed: 166.347013 tokens/s, learning rate: 2.444e-05, loss_scalings: 2814.750488, pp_loss: 7.054612
[INFO] 2021-07-12 19:21:42,698 [run_pretraining.py:  512]:	********exe.run_2445******* 
[INFO] 2021-07-12 19:21:43,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:43,617 [run_pretraining.py:  534]:	loss/total_loss, 6.290135383605957, 2446
[INFO] 2021-07-12 19:21:43,617 [run_pretraining.py:  535]:	loss/mlm_loss, 6.290135383605957, 2446
[INFO] 2021-07-12 19:21:43,617 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4449998818454333e-05, 2446
[INFO] 2021-07-12 19:21:43,617 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2446
[INFO] 2021-07-12 19:21:43,617 [run_pretraining.py:  558]:	worker_index: 7, step: 2446, cost: 6.290135, mlm loss: 6.290135, speed: 1.088568 steps/s, speed: 8.708540 samples/s, speed: 4458.772568 tokens/s, learning rate: 2.445e-05, loss_scalings: 2814.750488, pp_loss: 6.810452
[INFO] 2021-07-12 19:21:43,617 [run_pretraining.py:  512]:	********exe.run_2446******* 
[INFO] 2021-07-12 19:21:44,529 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:44,530 [run_pretraining.py:  534]:	loss/total_loss, 7.574768543243408, 2447
[INFO] 2021-07-12 19:21:44,530 [run_pretraining.py:  535]:	loss/mlm_loss, 7.574768543243408, 2447
[INFO] 2021-07-12 19:21:44,530 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4459999622195028e-05, 2447
[INFO] 2021-07-12 19:21:44,530 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2447
[INFO] 2021-07-12 19:21:44,530 [run_pretraining.py:  558]:	worker_index: 7, step: 2447, cost: 7.574769, mlm loss: 7.574769, speed: 1.096179 steps/s, speed: 8.769432 samples/s, speed: 4489.948941 tokens/s, learning rate: 2.446e-05, loss_scalings: 2814.750488, pp_loss: 6.973566
[INFO] 2021-07-12 19:21:44,530 [run_pretraining.py:  512]:	********exe.run_2447******* 
[INFO] 2021-07-12 19:21:45,451 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:45,451 [run_pretraining.py:  534]:	loss/total_loss, 6.850971221923828, 2448
[INFO] 2021-07-12 19:21:45,451 [run_pretraining.py:  535]:	loss/mlm_loss, 6.850971221923828, 2448
[INFO] 2021-07-12 19:21:45,451 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.446999860694632e-05, 2448
[INFO] 2021-07-12 19:21:45,451 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2448
[INFO] 2021-07-12 19:21:45,451 [run_pretraining.py:  558]:	worker_index: 7, step: 2448, cost: 6.850971, mlm loss: 6.850971, speed: 1.086220 steps/s, speed: 8.689763 samples/s, speed: 4449.158443 tokens/s, learning rate: 2.447e-05, loss_scalings: 2814.750488, pp_loss: 7.025163
[INFO] 2021-07-12 19:21:45,452 [run_pretraining.py:  512]:	********exe.run_2448******* 
[INFO] 2021-07-12 19:21:46,370 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:46,371 [run_pretraining.py:  534]:	loss/total_loss, 7.098695278167725, 2449
[INFO] 2021-07-12 19:21:46,371 [run_pretraining.py:  535]:	loss/mlm_loss, 7.098695278167725, 2449
[INFO] 2021-07-12 19:21:46,371 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4479999410687014e-05, 2449
[INFO] 2021-07-12 19:21:46,371 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2449
[INFO] 2021-07-12 19:21:46,371 [run_pretraining.py:  558]:	worker_index: 7, step: 2449, cost: 7.098695, mlm loss: 7.098695, speed: 1.087990 steps/s, speed: 8.703921 samples/s, speed: 4456.407336 tokens/s, learning rate: 2.448e-05, loss_scalings: 2814.750488, pp_loss: 7.031373
[INFO] 2021-07-12 19:21:46,371 [run_pretraining.py:  512]:	********exe.run_2449******* 
[INFO] 2021-07-12 19:21:47,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:47,288 [run_pretraining.py:  534]:	loss/total_loss, 7.496410369873047, 2450
[INFO] 2021-07-12 19:21:47,288 [run_pretraining.py:  535]:	loss/mlm_loss, 7.496410369873047, 2450
[INFO] 2021-07-12 19:21:47,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.449000021442771e-05, 2450
[INFO] 2021-07-12 19:21:47,288 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2450
[INFO] 2021-07-12 19:21:47,289 [run_pretraining.py:  558]:	worker_index: 7, step: 2450, cost: 7.496410, mlm loss: 7.496410, speed: 1.090898 steps/s, speed: 8.727188 samples/s, speed: 4468.320248 tokens/s, learning rate: 2.449e-05, loss_scalings: 2814.750488, pp_loss: 7.094615
[INFO] 2021-07-12 19:21:47,289 [run_pretraining.py:  512]:	********exe.run_2450******* 
[INFO] 2021-07-12 19:21:48,208 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:48,209 [run_pretraining.py:  534]:	loss/total_loss, 7.476835250854492, 2451
[INFO] 2021-07-12 19:21:48,209 [run_pretraining.py:  535]:	loss/mlm_loss, 7.476835250854492, 2451
[INFO] 2021-07-12 19:21:48,209 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4499999199179e-05, 2451
[INFO] 2021-07-12 19:21:48,209 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2451
[INFO] 2021-07-12 19:21:48,209 [run_pretraining.py:  558]:	worker_index: 7, step: 2451, cost: 7.476835, mlm loss: 7.476835, speed: 1.087047 steps/s, speed: 8.696379 samples/s, speed: 4452.546247 tokens/s, learning rate: 2.450e-05, loss_scalings: 2814.750488, pp_loss: 6.878736
[INFO] 2021-07-12 19:21:48,209 [run_pretraining.py:  512]:	********exe.run_2451******* 
[INFO] 2021-07-12 19:21:49,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:49,133 [run_pretraining.py:  534]:	loss/total_loss, 7.60676383972168, 2452
[INFO] 2021-07-12 19:21:49,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.60676383972168, 2452
[INFO] 2021-07-12 19:21:49,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4510000002919696e-05, 2452
[INFO] 2021-07-12 19:21:49,133 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2452
[INFO] 2021-07-12 19:21:49,134 [run_pretraining.py:  558]:	worker_index: 7, step: 2452, cost: 7.606764, mlm loss: 7.606764, speed: 1.082535 steps/s, speed: 8.660279 samples/s, speed: 4434.062735 tokens/s, learning rate: 2.451e-05, loss_scalings: 2814.750488, pp_loss: 7.665974
[INFO] 2021-07-12 19:21:49,134 [run_pretraining.py:  512]:	********exe.run_2452******* 
[INFO] 2021-07-12 19:21:50,051 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:50,051 [run_pretraining.py:  534]:	loss/total_loss, 7.230797290802002, 2453
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  535]:	loss/mlm_loss, 7.230797290802002, 2453
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4519998987670988e-05, 2453
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2453
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  558]:	worker_index: 7, step: 2453, cost: 7.230797, mlm loss: 7.230797, speed: 1.089801 steps/s, speed: 8.718408 samples/s, speed: 4463.824863 tokens/s, learning rate: 2.452e-05, loss_scalings: 2814.750488, pp_loss: 7.068745
[INFO] 2021-07-12 19:21:50,052 [run_pretraining.py:  512]:	********exe.run_2453******* 
[INFO] 2021-07-12 19:21:50,972 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:50,972 [run_pretraining.py:  534]:	loss/total_loss, 7.098730087280273, 2454
[INFO] 2021-07-12 19:21:50,973 [run_pretraining.py:  535]:	loss/mlm_loss, 7.098730087280273, 2454
[INFO] 2021-07-12 19:21:50,973 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.452999797242228e-05, 2454
[INFO] 2021-07-12 19:21:50,973 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2454
[INFO] 2021-07-12 19:21:50,973 [run_pretraining.py:  558]:	worker_index: 7, step: 2454, cost: 7.098730, mlm loss: 7.098730, speed: 1.086547 steps/s, speed: 8.692378 samples/s, speed: 4450.497727 tokens/s, learning rate: 2.453e-05, loss_scalings: 2814.750488, pp_loss: 7.163598
[INFO] 2021-07-12 19:21:50,973 [run_pretraining.py:  512]:	********exe.run_2454******* 
[INFO] 2021-07-12 19:21:51,898 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:51,899 [run_pretraining.py:  534]:	loss/total_loss, 6.553091526031494, 2455
[INFO] 2021-07-12 19:21:51,899 [run_pretraining.py:  535]:	loss/mlm_loss, 6.553091526031494, 2455
[INFO] 2021-07-12 19:21:51,899 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4539998776162975e-05, 2455
[INFO] 2021-07-12 19:21:51,899 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2455
[INFO] 2021-07-12 19:21:51,899 [run_pretraining.py:  558]:	worker_index: 7, step: 2455, cost: 6.553092, mlm loss: 6.553092, speed: 1.079997 steps/s, speed: 8.639973 samples/s, speed: 4423.666120 tokens/s, learning rate: 2.454e-05, loss_scalings: 2814.750488, pp_loss: 7.116020
[INFO] 2021-07-12 19:21:51,899 [run_pretraining.py:  512]:	********exe.run_2455******* 
[INFO] 2021-07-12 19:21:52,818 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:52,819 [run_pretraining.py:  534]:	loss/total_loss, 7.174750804901123, 2456
[INFO] 2021-07-12 19:21:52,819 [run_pretraining.py:  535]:	loss/mlm_loss, 7.174750804901123, 2456
[INFO] 2021-07-12 19:21:52,819 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.454999957990367e-05, 2456
[INFO] 2021-07-12 19:21:52,819 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2456
[INFO] 2021-07-12 19:21:52,819 [run_pretraining.py:  558]:	worker_index: 7, step: 2456, cost: 7.174751, mlm loss: 7.174751, speed: 1.087774 steps/s, speed: 8.702191 samples/s, speed: 4455.522032 tokens/s, learning rate: 2.455e-05, loss_scalings: 2814.750488, pp_loss: 7.300902
[INFO] 2021-07-12 19:21:52,819 [run_pretraining.py:  512]:	********exe.run_2456******* 
[INFO] 2021-07-12 19:21:53,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:53,768 [run_pretraining.py:  534]:	loss/total_loss, 7.176758766174316, 2457
[INFO] 2021-07-12 19:21:53,768 [run_pretraining.py:  535]:	loss/mlm_loss, 7.176758766174316, 2457
[INFO] 2021-07-12 19:21:53,768 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.455999856465496e-05, 2457
[INFO] 2021-07-12 19:21:53,768 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2457
[INFO] 2021-07-12 19:21:53,768 [run_pretraining.py:  558]:	worker_index: 7, step: 2457, cost: 7.176759, mlm loss: 7.176759, speed: 1.054534 steps/s, speed: 8.436269 samples/s, speed: 4319.369574 tokens/s, learning rate: 2.456e-05, loss_scalings: 2814.750488, pp_loss: 7.127864
[INFO] 2021-07-12 19:21:53,768 [run_pretraining.py:  512]:	********exe.run_2457******* 
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  534]:	loss/total_loss, 7.876734256744385, 2458
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  535]:	loss/mlm_loss, 7.876734256744385, 2458
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4569999368395656e-05, 2458
[INFO] 2021-07-12 19:21:54,692 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2458
[INFO] 2021-07-12 19:21:54,693 [run_pretraining.py:  558]:	worker_index: 7, step: 2458, cost: 7.876734, mlm loss: 7.876734, speed: 1.082726 steps/s, speed: 8.661810 samples/s, speed: 4434.846799 tokens/s, learning rate: 2.457e-05, loss_scalings: 2814.750488, pp_loss: 7.143849
[INFO] 2021-07-12 19:21:54,693 [run_pretraining.py:  512]:	********exe.run_2458******* 
[INFO] 2021-07-12 19:21:55,616 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:55,617 [run_pretraining.py:  534]:	loss/total_loss, 7.018146991729736, 2459
[INFO] 2021-07-12 19:21:55,617 [run_pretraining.py:  535]:	loss/mlm_loss, 7.018146991729736, 2459
[INFO] 2021-07-12 19:21:55,617 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.458000017213635e-05, 2459
[INFO] 2021-07-12 19:21:55,617 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2459
[INFO] 2021-07-12 19:21:55,617 [run_pretraining.py:  558]:	worker_index: 7, step: 2459, cost: 7.018147, mlm loss: 7.018147, speed: 1.082169 steps/s, speed: 8.657352 samples/s, speed: 4432.564058 tokens/s, learning rate: 2.458e-05, loss_scalings: 2814.750488, pp_loss: 6.938247
[INFO] 2021-07-12 19:21:55,617 [run_pretraining.py:  512]:	********exe.run_2459******* 
[INFO] 2021-07-12 19:21:56,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:56,533 [run_pretraining.py:  534]:	loss/total_loss, 7.412088394165039, 2460
[INFO] 2021-07-12 19:21:56,533 [run_pretraining.py:  535]:	loss/mlm_loss, 7.412088394165039, 2460
[INFO] 2021-07-12 19:21:56,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4589999156887643e-05, 2460
[INFO] 2021-07-12 19:21:56,533 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2460
[INFO] 2021-07-12 19:21:56,533 [run_pretraining.py:  558]:	worker_index: 7, step: 2460, cost: 7.412088, mlm loss: 7.412088, speed: 1.092747 steps/s, speed: 8.741978 samples/s, speed: 4475.892960 tokens/s, learning rate: 2.459e-05, loss_scalings: 2814.750488, pp_loss: 7.060961
[INFO] 2021-07-12 19:21:56,533 [run_pretraining.py:  512]:	********exe.run_2460******* 
[INFO] 2021-07-12 19:21:57,441 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:57,442 [run_pretraining.py:  534]:	loss/total_loss, 7.068124771118164, 2461
[INFO] 2021-07-12 19:21:57,442 [run_pretraining.py:  535]:	loss/mlm_loss, 7.068124771118164, 2461
[INFO] 2021-07-12 19:21:57,442 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4599999960628338e-05, 2461
[INFO] 2021-07-12 19:21:57,442 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2461
[INFO] 2021-07-12 19:21:57,442 [run_pretraining.py:  558]:	worker_index: 7, step: 2461, cost: 7.068125, mlm loss: 7.068125, speed: 1.100853 steps/s, speed: 8.806827 samples/s, speed: 4509.095209 tokens/s, learning rate: 2.460e-05, loss_scalings: 2814.750488, pp_loss: 7.052241
[INFO] 2021-07-12 19:21:57,442 [run_pretraining.py:  512]:	********exe.run_2461******* 
[INFO] 2021-07-12 19:21:58,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:58,356 [run_pretraining.py:  534]:	loss/total_loss, 7.300335884094238, 2462
[INFO] 2021-07-12 19:21:58,356 [run_pretraining.py:  535]:	loss/mlm_loss, 7.300335884094238, 2462
[INFO] 2021-07-12 19:21:58,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.460999894537963e-05, 2462
[INFO] 2021-07-12 19:21:58,356 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2462
[INFO] 2021-07-12 19:21:58,356 [run_pretraining.py:  558]:	worker_index: 7, step: 2462, cost: 7.300336, mlm loss: 7.300336, speed: 1.094792 steps/s, speed: 8.758332 samples/s, speed: 4484.266105 tokens/s, learning rate: 2.461e-05, loss_scalings: 2814.750488, pp_loss: 7.345637
[INFO] 2021-07-12 19:21:58,356 [run_pretraining.py:  512]:	********exe.run_2462******* 
[INFO] 2021-07-12 19:21:59,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  534]:	loss/total_loss, 7.366069316864014, 2463
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  535]:	loss/mlm_loss, 7.366069316864014, 2463
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4619999749120325e-05, 2463
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2463
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  558]:	worker_index: 7, step: 2463, cost: 7.366069, mlm loss: 7.366069, speed: 1.091111 steps/s, speed: 8.728888 samples/s, speed: 4469.190881 tokens/s, learning rate: 2.462e-05, loss_scalings: 2814.750488, pp_loss: 7.178383
[INFO] 2021-07-12 19:21:59,273 [run_pretraining.py:  512]:	********exe.run_2463******* 
[INFO] 2021-07-12 19:22:00,193 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:00,193 [run_pretraining.py:  534]:	loss/total_loss, 6.838787078857422, 2464
[INFO] 2021-07-12 19:22:00,194 [run_pretraining.py:  535]:	loss/mlm_loss, 6.838787078857422, 2464
[INFO] 2021-07-12 19:22:00,194 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4629998733871616e-05, 2464
[INFO] 2021-07-12 19:22:00,194 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2464
[INFO] 2021-07-12 19:22:00,194 [run_pretraining.py:  558]:	worker_index: 7, step: 2464, cost: 6.838787, mlm loss: 6.838787, speed: 1.087107 steps/s, speed: 8.696857 samples/s, speed: 4452.790904 tokens/s, learning rate: 2.463e-05, loss_scalings: 2814.750488, pp_loss: 6.999442
[INFO] 2021-07-12 19:22:00,194 [run_pretraining.py:  512]:	********exe.run_2464******* 
[INFO] 2021-07-12 19:22:01,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:01,101 [run_pretraining.py:  534]:	loss/total_loss, 7.723207473754883, 2465
[INFO] 2021-07-12 19:22:01,101 [run_pretraining.py:  535]:	loss/mlm_loss, 7.723207473754883, 2465
[INFO] 2021-07-12 19:22:01,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.463999953761231e-05, 2465
[INFO] 2021-07-12 19:22:01,101 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2465
[INFO] 2021-07-12 19:22:01,101 [run_pretraining.py:  558]:	worker_index: 7, step: 2465, cost: 7.723207, mlm loss: 7.723207, speed: 1.102540 steps/s, speed: 8.820318 samples/s, speed: 4516.003066 tokens/s, learning rate: 2.464e-05, loss_scalings: 2814.750488, pp_loss: 7.625138
[INFO] 2021-07-12 19:22:01,102 [run_pretraining.py:  512]:	********exe.run_2465******* 
[INFO] 2021-07-12 19:22:02,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:02,019 [run_pretraining.py:  534]:	loss/total_loss, 7.330271244049072, 2466
[INFO] 2021-07-12 19:22:02,019 [run_pretraining.py:  535]:	loss/mlm_loss, 7.330271244049072, 2466
[INFO] 2021-07-12 19:22:02,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4649998522363603e-05, 2466
[INFO] 2021-07-12 19:22:02,019 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2466
[INFO] 2021-07-12 19:22:02,019 [run_pretraining.py:  558]:	worker_index: 7, step: 2466, cost: 7.330271, mlm loss: 7.330271, speed: 1.090584 steps/s, speed: 8.724676 samples/s, speed: 4467.034099 tokens/s, learning rate: 2.465e-05, loss_scalings: 2814.750488, pp_loss: 7.426655
[INFO] 2021-07-12 19:22:02,019 [run_pretraining.py:  512]:	********exe.run_2466******* 
[INFO] 2021-07-12 19:22:02,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:02,950 [run_pretraining.py:  534]:	loss/total_loss, 7.172357559204102, 2467
[INFO] 2021-07-12 19:22:02,951 [run_pretraining.py:  535]:	loss/mlm_loss, 7.172357559204102, 2467
[INFO] 2021-07-12 19:22:02,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4659999326104298e-05, 2467
[INFO] 2021-07-12 19:22:02,959 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2467
[INFO] 2021-07-12 19:22:02,961 [run_pretraining.py:  558]:	worker_index: 7, step: 2467, cost: 7.172358, mlm loss: 7.172358, speed: 1.074051 steps/s, speed: 8.592405 samples/s, speed: 4399.311260 tokens/s, learning rate: 2.466e-05, loss_scalings: 2814.750488, pp_loss: 7.343597
[INFO] 2021-07-12 19:22:02,962 [run_pretraining.py:  512]:	********exe.run_2467******* 
[INFO] 2021-07-12 19:22:03,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:03,863 [run_pretraining.py:  534]:	loss/total_loss, 3.715071439743042, 2468
[INFO] 2021-07-12 19:22:03,863 [run_pretraining.py:  535]:	loss/mlm_loss, 3.715071439743042, 2468
[INFO] 2021-07-12 19:22:03,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4670000129844993e-05, 2468
[INFO] 2021-07-12 19:22:03,863 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2468
[INFO] 2021-07-12 19:22:03,863 [run_pretraining.py:  558]:	worker_index: 7, step: 2468, cost: 3.715071, mlm loss: 3.715071, speed: 1.110256 steps/s, speed: 8.882048 samples/s, speed: 4547.608552 tokens/s, learning rate: 2.467e-05, loss_scalings: 2814.750488, pp_loss: 5.615824
[INFO] 2021-07-12 19:22:03,863 [run_pretraining.py:  512]:	********exe.run_2468******* 
[INFO] 2021-07-12 19:22:04,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:04,775 [run_pretraining.py:  534]:	loss/total_loss, 6.697227478027344, 2469
[INFO] 2021-07-12 19:22:04,775 [run_pretraining.py:  535]:	loss/mlm_loss, 6.697227478027344, 2469
[INFO] 2021-07-12 19:22:04,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4679999114596285e-05, 2469
[INFO] 2021-07-12 19:22:04,776 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2469
[INFO] 2021-07-12 19:22:04,776 [run_pretraining.py:  558]:	worker_index: 7, step: 2469, cost: 6.697227, mlm loss: 6.697227, speed: 1.096969 steps/s, speed: 8.775753 samples/s, speed: 4493.185288 tokens/s, learning rate: 2.468e-05, loss_scalings: 2814.750488, pp_loss: 7.184157
[INFO] 2021-07-12 19:22:04,776 [run_pretraining.py:  512]:	********exe.run_2469******* 
[INFO] 2021-07-12 19:22:05,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:05,693 [run_pretraining.py:  534]:	loss/total_loss, 7.7128729820251465, 2470
[INFO] 2021-07-12 19:22:05,694 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7128729820251465, 2470
[INFO] 2021-07-12 19:22:05,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.468999991833698e-05, 2470
[INFO] 2021-07-12 19:22:05,694 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2470
[INFO] 2021-07-12 19:22:05,694 [run_pretraining.py:  558]:	worker_index: 7, step: 2470, cost: 7.712873, mlm loss: 7.712873, speed: 1.089870 steps/s, speed: 8.718961 samples/s, speed: 4464.107879 tokens/s, learning rate: 2.469e-05, loss_scalings: 2814.750488, pp_loss: 7.514722
[INFO] 2021-07-12 19:22:05,694 [run_pretraining.py:  512]:	********exe.run_2470******* 
[INFO] 2021-07-12 19:22:06,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:06,604 [run_pretraining.py:  534]:	loss/total_loss, 7.289938926696777, 2471
[INFO] 2021-07-12 19:22:06,604 [run_pretraining.py:  535]:	loss/mlm_loss, 7.289938926696777, 2471
[INFO] 2021-07-12 19:22:06,604 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.469999890308827e-05, 2471
[INFO] 2021-07-12 19:22:06,604 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2471
[INFO] 2021-07-12 19:22:06,604 [run_pretraining.py:  558]:	worker_index: 7, step: 2471, cost: 7.289939, mlm loss: 7.289939, speed: 1.099185 steps/s, speed: 8.793477 samples/s, speed: 4502.260368 tokens/s, learning rate: 2.470e-05, loss_scalings: 2814.750488, pp_loss: 7.447719
[INFO] 2021-07-12 19:22:06,604 [run_pretraining.py:  512]:	********exe.run_2471******* 
[INFO] 2021-07-12 19:22:07,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:07,520 [run_pretraining.py:  534]:	loss/total_loss, 6.648233413696289, 2472
[INFO] 2021-07-12 19:22:07,520 [run_pretraining.py:  535]:	loss/mlm_loss, 6.648233413696289, 2472
[INFO] 2021-07-12 19:22:07,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4709999706828967e-05, 2472
[INFO] 2021-07-12 19:22:07,521 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2472
[INFO] 2021-07-12 19:22:07,521 [run_pretraining.py:  558]:	worker_index: 7, step: 2472, cost: 6.648233, mlm loss: 6.648233, speed: 1.091984 steps/s, speed: 8.735874 samples/s, speed: 4472.767637 tokens/s, learning rate: 2.471e-05, loss_scalings: 2814.750488, pp_loss: 6.943772
[INFO] 2021-07-12 19:22:07,521 [run_pretraining.py:  512]:	********exe.run_2472******* 
[INFO] 2021-07-12 19:22:08,435 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  534]:	loss/total_loss, 7.160149097442627, 2473
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  535]:	loss/mlm_loss, 7.160149097442627, 2473
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.471999869158026e-05, 2473
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2473
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  558]:	worker_index: 7, step: 2473, cost: 7.160149, mlm loss: 7.160149, speed: 1.093170 steps/s, speed: 8.745357 samples/s, speed: 4477.622970 tokens/s, learning rate: 2.472e-05, loss_scalings: 2814.750488, pp_loss: 7.244668
[INFO] 2021-07-12 19:22:08,436 [run_pretraining.py:  512]:	********exe.run_2473******* 
[INFO] 2021-07-12 19:22:09,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:09,351 [run_pretraining.py:  534]:	loss/total_loss, 7.8142991065979, 2474
[INFO] 2021-07-12 19:22:09,352 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8142991065979, 2474
[INFO] 2021-07-12 19:22:09,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4729999495320953e-05, 2474
[INFO] 2021-07-12 19:22:09,352 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2474
[INFO] 2021-07-12 19:22:09,352 [run_pretraining.py:  558]:	worker_index: 7, step: 2474, cost: 7.814299, mlm loss: 7.814299, speed: 1.092803 steps/s, speed: 8.742423 samples/s, speed: 4476.120363 tokens/s, learning rate: 2.473e-05, loss_scalings: 2814.750488, pp_loss: 7.575042
[INFO] 2021-07-12 19:22:09,352 [run_pretraining.py:  512]:	********exe.run_2474******* 
[INFO] 2021-07-12 19:22:10,269 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:10,270 [run_pretraining.py:  534]:	loss/total_loss, 6.885611534118652, 2475
[INFO] 2021-07-12 19:22:10,270 [run_pretraining.py:  535]:	loss/mlm_loss, 6.885611534118652, 2475
[INFO] 2021-07-12 19:22:10,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.474000029906165e-05, 2475
[INFO] 2021-07-12 19:22:10,270 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2475
[INFO] 2021-07-12 19:22:10,270 [run_pretraining.py:  558]:	worker_index: 7, step: 2475, cost: 6.885612, mlm loss: 6.885612, speed: 1.089723 steps/s, speed: 8.717783 samples/s, speed: 4463.504773 tokens/s, learning rate: 2.474e-05, loss_scalings: 2814.750488, pp_loss: 6.985362
[INFO] 2021-07-12 19:22:10,270 [run_pretraining.py:  512]:	********exe.run_2475******* 
[INFO] 2021-07-12 19:22:11,182 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:11,183 [run_pretraining.py:  534]:	loss/total_loss, 7.558755397796631, 2476
[INFO] 2021-07-12 19:22:11,183 [run_pretraining.py:  535]:	loss/mlm_loss, 7.558755397796631, 2476
[INFO] 2021-07-12 19:22:11,183 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.474999928381294e-05, 2476
[INFO] 2021-07-12 19:22:11,183 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2476
[INFO] 2021-07-12 19:22:11,183 [run_pretraining.py:  558]:	worker_index: 7, step: 2476, cost: 7.558755, mlm loss: 7.558755, speed: 1.096029 steps/s, speed: 8.768233 samples/s, speed: 4489.335313 tokens/s, learning rate: 2.475e-05, loss_scalings: 2814.750488, pp_loss: 6.550221
[INFO] 2021-07-12 19:22:11,183 [run_pretraining.py:  512]:	********exe.run_2476******* 
[INFO] 2021-07-12 19:22:12,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:12,100 [run_pretraining.py:  534]:	loss/total_loss, 6.483656883239746, 2477
[INFO] 2021-07-12 19:22:12,100 [run_pretraining.py:  535]:	loss/mlm_loss, 6.483656883239746, 2477
[INFO] 2021-07-12 19:22:12,100 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4760000087553635e-05, 2477
[INFO] 2021-07-12 19:22:12,100 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2477
[INFO] 2021-07-12 19:22:12,101 [run_pretraining.py:  558]:	worker_index: 7, step: 2477, cost: 6.483657, mlm loss: 6.483657, speed: 1.090807 steps/s, speed: 8.726459 samples/s, speed: 4467.947224 tokens/s, learning rate: 2.476e-05, loss_scalings: 2814.750488, pp_loss: 7.403881
[INFO] 2021-07-12 19:22:12,101 [run_pretraining.py:  512]:	********exe.run_2477******* 
[INFO] 2021-07-12 19:22:13,021 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:13,021 [run_pretraining.py:  534]:	loss/total_loss, 7.234107494354248, 2478
[INFO] 2021-07-12 19:22:13,021 [run_pretraining.py:  535]:	loss/mlm_loss, 7.234107494354248, 2478
[INFO] 2021-07-12 19:22:13,021 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4769999072304927e-05, 2478
[INFO] 2021-07-12 19:22:13,021 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2478
[INFO] 2021-07-12 19:22:13,022 [run_pretraining.py:  558]:	worker_index: 7, step: 2478, cost: 7.234107, mlm loss: 7.234107, speed: 1.086527 steps/s, speed: 8.692218 samples/s, speed: 4450.415872 tokens/s, learning rate: 2.477e-05, loss_scalings: 2814.750488, pp_loss: 7.691084
[INFO] 2021-07-12 19:22:13,022 [run_pretraining.py:  512]:	********exe.run_2478******* 
[INFO] 2021-07-12 19:22:13,942 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:13,943 [run_pretraining.py:  534]:	loss/total_loss, 7.402596473693848, 2479
[INFO] 2021-07-12 19:22:13,943 [run_pretraining.py:  535]:	loss/mlm_loss, 7.402596473693848, 2479
[INFO] 2021-07-12 19:22:13,943 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.477999805705622e-05, 2479
[INFO] 2021-07-12 19:22:13,943 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2479
[INFO] 2021-07-12 19:22:13,943 [run_pretraining.py:  558]:	worker_index: 7, step: 2479, cost: 7.402596, mlm loss: 7.402596, speed: 1.086103 steps/s, speed: 8.688822 samples/s, speed: 4448.676867 tokens/s, learning rate: 2.478e-05, loss_scalings: 2814.750488, pp_loss: 7.536214
[INFO] 2021-07-12 19:22:13,943 [run_pretraining.py:  512]:	********exe.run_2479******* 
[INFO] 2021-07-12 19:22:14,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:14,858 [run_pretraining.py:  534]:	loss/total_loss, 6.840256214141846, 2480
[INFO] 2021-07-12 19:22:14,858 [run_pretraining.py:  535]:	loss/mlm_loss, 6.840256214141846, 2480
[INFO] 2021-07-12 19:22:14,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4789998860796914e-05, 2480
[INFO] 2021-07-12 19:22:14,859 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2480
[INFO] 2021-07-12 19:22:14,859 [run_pretraining.py:  558]:	worker_index: 7, step: 2480, cost: 6.840256, mlm loss: 6.840256, speed: 1.092827 steps/s, speed: 8.742616 samples/s, speed: 4476.219495 tokens/s, learning rate: 2.479e-05, loss_scalings: 2814.750488, pp_loss: 7.346565
[INFO] 2021-07-12 19:22:14,859 [run_pretraining.py:  512]:	********exe.run_2480******* 
[INFO] 2021-07-12 19:22:15,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:15,773 [run_pretraining.py:  534]:	loss/total_loss, 7.722409725189209, 2481
[INFO] 2021-07-12 19:22:15,773 [run_pretraining.py:  535]:	loss/mlm_loss, 7.722409725189209, 2481
[INFO] 2021-07-12 19:22:15,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.479999966453761e-05, 2481
[INFO] 2021-07-12 19:22:15,773 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2481
[INFO] 2021-07-12 19:22:15,773 [run_pretraining.py:  558]:	worker_index: 7, step: 2481, cost: 7.722410, mlm loss: 7.722410, speed: 1.094125 steps/s, speed: 8.752997 samples/s, speed: 4481.534706 tokens/s, learning rate: 2.480e-05, loss_scalings: 2814.750488, pp_loss: 7.475905
[INFO] 2021-07-12 19:22:15,773 [run_pretraining.py:  512]:	********exe.run_2481******* 
[INFO] 2021-07-12 19:22:16,693 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:16,693 [run_pretraining.py:  534]:	loss/total_loss, 7.32521915435791, 2482
[INFO] 2021-07-12 19:22:16,693 [run_pretraining.py:  535]:	loss/mlm_loss, 7.32521915435791, 2482
[INFO] 2021-07-12 19:22:16,693 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.48099986492889e-05, 2482
[INFO] 2021-07-12 19:22:16,693 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2482
[INFO] 2021-07-12 19:22:16,693 [run_pretraining.py:  558]:	worker_index: 7, step: 2482, cost: 7.325219, mlm loss: 7.325219, speed: 1.087575 steps/s, speed: 8.700601 samples/s, speed: 4454.707540 tokens/s, learning rate: 2.481e-05, loss_scalings: 2814.750488, pp_loss: 7.196361
[INFO] 2021-07-12 19:22:16,694 [run_pretraining.py:  512]:	********exe.run_2482******* 
[INFO] 2021-07-12 19:22:42,910 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:42,910 [run_pretraining.py:  534]:	loss/total_loss, 7.747081756591797, 2483
[INFO] 2021-07-12 19:22:42,910 [run_pretraining.py:  535]:	loss/mlm_loss, 7.747081756591797, 2483
[INFO] 2021-07-12 19:22:42,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4819999453029595e-05, 2483
[INFO] 2021-07-12 19:22:42,911 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2483
[INFO] 2021-07-12 19:22:42,911 [run_pretraining.py:  558]:	worker_index: 7, step: 2483, cost: 7.747082, mlm loss: 7.747082, speed: 0.038144 steps/s, speed: 0.305151 samples/s, speed: 156.237437 tokens/s, learning rate: 2.482e-05, loss_scalings: 2814.750488, pp_loss: 7.509260
[INFO] 2021-07-12 19:22:42,911 [run_pretraining.py:  512]:	********exe.run_2483******* 
[INFO] 2021-07-12 19:22:43,837 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:43,837 [run_pretraining.py:  534]:	loss/total_loss, 7.855846881866455, 2484
[INFO] 2021-07-12 19:22:43,838 [run_pretraining.py:  535]:	loss/mlm_loss, 7.855846881866455, 2484
[INFO] 2021-07-12 19:22:43,838 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.483000025677029e-05, 2484
[INFO] 2021-07-12 19:22:43,838 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2484
[INFO] 2021-07-12 19:22:43,838 [run_pretraining.py:  558]:	worker_index: 7, step: 2484, cost: 7.855847, mlm loss: 7.855847, speed: 1.079348 steps/s, speed: 8.634784 samples/s, speed: 4421.009162 tokens/s, learning rate: 2.483e-05, loss_scalings: 2814.750488, pp_loss: 7.411079
[INFO] 2021-07-12 19:22:43,838 [run_pretraining.py:  512]:	********exe.run_2484******* 
[INFO] 2021-07-12 19:22:44,758 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:44,758 [run_pretraining.py:  534]:	loss/total_loss, 7.378483772277832, 2485
[INFO] 2021-07-12 19:22:44,758 [run_pretraining.py:  535]:	loss/mlm_loss, 7.378483772277832, 2485
[INFO] 2021-07-12 19:22:44,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4839999241521582e-05, 2485
[INFO] 2021-07-12 19:22:44,758 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2485
[INFO] 2021-07-12 19:22:44,758 [run_pretraining.py:  558]:	worker_index: 7, step: 2485, cost: 7.378484, mlm loss: 7.378484, speed: 1.086927 steps/s, speed: 8.695413 samples/s, speed: 4452.051246 tokens/s, learning rate: 2.484e-05, loss_scalings: 2814.750488, pp_loss: 6.851922
[INFO] 2021-07-12 19:22:44,758 [run_pretraining.py:  512]:	********exe.run_2485******* 
[INFO] 2021-07-12 19:22:45,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:45,681 [run_pretraining.py:  534]:	loss/total_loss, 7.574055194854736, 2486
[INFO] 2021-07-12 19:22:45,681 [run_pretraining.py:  535]:	loss/mlm_loss, 7.574055194854736, 2486
[INFO] 2021-07-12 19:22:45,681 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4850000045262277e-05, 2486
[INFO] 2021-07-12 19:22:45,681 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2486
[INFO] 2021-07-12 19:22:45,681 [run_pretraining.py:  558]:	worker_index: 7, step: 2486, cost: 7.574055, mlm loss: 7.574055, speed: 1.084288 steps/s, speed: 8.674305 samples/s, speed: 4441.244112 tokens/s, learning rate: 2.485e-05, loss_scalings: 2814.750488, pp_loss: 7.574062
[INFO] 2021-07-12 19:22:45,681 [run_pretraining.py:  512]:	********exe.run_2486******* 
[INFO] 2021-07-12 19:22:46,603 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:46,603 [run_pretraining.py:  534]:	loss/total_loss, 6.7638702392578125, 2487
[INFO] 2021-07-12 19:22:46,603 [run_pretraining.py:  535]:	loss/mlm_loss, 6.7638702392578125, 2487
[INFO] 2021-07-12 19:22:46,603 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4860000849002972e-05, 2487
[INFO] 2021-07-12 19:22:46,604 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2487
[INFO] 2021-07-12 19:22:46,604 [run_pretraining.py:  558]:	worker_index: 7, step: 2487, cost: 6.763870, mlm loss: 6.763870, speed: 1.085069 steps/s, speed: 8.680552 samples/s, speed: 4444.442796 tokens/s, learning rate: 2.486e-05, loss_scalings: 2814.750488, pp_loss: 7.466376
[INFO] 2021-07-12 19:22:46,604 [run_pretraining.py:  512]:	********exe.run_2487******* 
[INFO] 2021-07-12 19:22:47,534 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:47,535 [run_pretraining.py:  534]:	loss/total_loss, 6.93754243850708, 2488
[INFO] 2021-07-12 19:22:47,535 [run_pretraining.py:  535]:	loss/mlm_loss, 6.93754243850708, 2488
[INFO] 2021-07-12 19:22:47,535 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.486999801476486e-05, 2488
[INFO] 2021-07-12 19:22:47,535 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2488
[INFO] 2021-07-12 19:22:47,535 [run_pretraining.py:  558]:	worker_index: 7, step: 2488, cost: 6.937542, mlm loss: 6.937542, speed: 1.074145 steps/s, speed: 8.593160 samples/s, speed: 4399.697700 tokens/s, learning rate: 2.487e-05, loss_scalings: 2814.750488, pp_loss: 7.241319
[INFO] 2021-07-12 19:22:47,535 [run_pretraining.py:  512]:	********exe.run_2488******* 
[INFO] 2021-07-12 19:22:48,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:48,469 [run_pretraining.py:  534]:	loss/total_loss, 7.270925998687744, 2489
[INFO] 2021-07-12 19:22:48,469 [run_pretraining.py:  535]:	loss/mlm_loss, 7.270925998687744, 2489
[INFO] 2021-07-12 19:22:48,469 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4879998818505555e-05, 2489
[INFO] 2021-07-12 19:22:48,470 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2489
[INFO] 2021-07-12 19:22:48,470 [run_pretraining.py:  558]:	worker_index: 7, step: 2489, cost: 7.270926, mlm loss: 7.270926, speed: 1.070984 steps/s, speed: 8.567876 samples/s, speed: 4386.752413 tokens/s, learning rate: 2.488e-05, loss_scalings: 2814.750488, pp_loss: 7.713002
[INFO] 2021-07-12 19:22:48,470 [run_pretraining.py:  512]:	********exe.run_2489******* 
[INFO] 2021-07-12 19:22:49,396 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:49,396 [run_pretraining.py:  534]:	loss/total_loss, 7.545574188232422, 2490
[INFO] 2021-07-12 19:22:49,396 [run_pretraining.py:  535]:	loss/mlm_loss, 7.545574188232422, 2490
[INFO] 2021-07-12 19:22:49,396 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.488999962224625e-05, 2490
[INFO] 2021-07-12 19:22:49,396 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2490
[INFO] 2021-07-12 19:22:49,397 [run_pretraining.py:  558]:	worker_index: 7, step: 2490, cost: 7.545574, mlm loss: 7.545574, speed: 1.079546 steps/s, speed: 8.636370 samples/s, speed: 4421.821620 tokens/s, learning rate: 2.489e-05, loss_scalings: 2814.750488, pp_loss: 7.532553
[INFO] 2021-07-12 19:22:49,397 [run_pretraining.py:  512]:	********exe.run_2490******* 
[INFO] 2021-07-12 19:22:50,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:50,339 [run_pretraining.py:  534]:	loss/total_loss, 6.378886699676514, 2491
[INFO] 2021-07-12 19:22:50,339 [run_pretraining.py:  535]:	loss/mlm_loss, 6.378886699676514, 2491
[INFO] 2021-07-12 19:22:50,339 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4899998606997542e-05, 2491
[INFO] 2021-07-12 19:22:50,339 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2491
[INFO] 2021-07-12 19:22:50,339 [run_pretraining.py:  558]:	worker_index: 7, step: 2491, cost: 6.378887, mlm loss: 6.378887, speed: 1.061780 steps/s, speed: 8.494240 samples/s, speed: 4349.051007 tokens/s, learning rate: 2.490e-05, loss_scalings: 2814.750488, pp_loss: 7.101949
[INFO] 2021-07-12 19:22:50,339 [run_pretraining.py:  512]:	********exe.run_2491******* 
[INFO] 2021-07-12 19:22:51,256 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:51,257 [run_pretraining.py:  534]:	loss/total_loss, 7.7125420570373535, 2492
[INFO] 2021-07-12 19:22:51,257 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7125420570373535, 2492
[INFO] 2021-07-12 19:22:51,257 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4909999410738237e-05, 2492
[INFO] 2021-07-12 19:22:51,257 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2492
[INFO] 2021-07-12 19:22:51,257 [run_pretraining.py:  558]:	worker_index: 7, step: 2492, cost: 7.712542, mlm loss: 7.712542, speed: 1.090085 steps/s, speed: 8.720683 samples/s, speed: 4464.989636 tokens/s, learning rate: 2.491e-05, loss_scalings: 2814.750488, pp_loss: 7.260852
[INFO] 2021-07-12 19:22:51,257 [run_pretraining.py:  512]:	********exe.run_2492******* 
[INFO] 2021-07-12 19:22:52,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:52,174 [run_pretraining.py:  534]:	loss/total_loss, 7.170889377593994, 2493
[INFO] 2021-07-12 19:22:52,175 [run_pretraining.py:  535]:	loss/mlm_loss, 7.170889377593994, 2493
[INFO] 2021-07-12 19:22:52,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4920000214478932e-05, 2493
[INFO] 2021-07-12 19:22:52,175 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2493
[INFO] 2021-07-12 19:22:52,175 [run_pretraining.py:  558]:	worker_index: 7, step: 2493, cost: 7.170889, mlm loss: 7.170889, speed: 1.090381 steps/s, speed: 8.723052 samples/s, speed: 4466.202621 tokens/s, learning rate: 2.492e-05, loss_scalings: 2814.750488, pp_loss: 6.914693
[INFO] 2021-07-12 19:22:52,175 [run_pretraining.py:  512]:	********exe.run_2493******* 
[INFO] 2021-07-12 19:22:53,101 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:53,101 [run_pretraining.py:  534]:	loss/total_loss, 3.8996918201446533, 2494
[INFO] 2021-07-12 19:22:53,101 [run_pretraining.py:  535]:	loss/mlm_loss, 3.8996918201446533, 2494
[INFO] 2021-07-12 19:22:53,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4929999199230224e-05, 2494
[INFO] 2021-07-12 19:22:53,101 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2494
[INFO] 2021-07-12 19:22:53,101 [run_pretraining.py:  558]:	worker_index: 7, step: 2494, cost: 3.899692, mlm loss: 3.899692, speed: 1.079968 steps/s, speed: 8.639744 samples/s, speed: 4423.548801 tokens/s, learning rate: 2.493e-05, loss_scalings: 2814.750488, pp_loss: 6.340898
[INFO] 2021-07-12 19:22:53,101 [run_pretraining.py:  512]:	********exe.run_2494******* 
[INFO] 2021-07-12 19:22:54,026 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:54,027 [run_pretraining.py:  534]:	loss/total_loss, 7.449377059936523, 2495
[INFO] 2021-07-12 19:22:54,027 [run_pretraining.py:  535]:	loss/mlm_loss, 7.449377059936523, 2495
[INFO] 2021-07-12 19:22:54,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.494000000297092e-05, 2495
[INFO] 2021-07-12 19:22:54,027 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2495
[INFO] 2021-07-12 19:22:54,027 [run_pretraining.py:  558]:	worker_index: 7, step: 2495, cost: 7.449377, mlm loss: 7.449377, speed: 1.081075 steps/s, speed: 8.648600 samples/s, speed: 4428.083227 tokens/s, learning rate: 2.494e-05, loss_scalings: 2814.750488, pp_loss: 7.315188
[INFO] 2021-07-12 19:22:54,027 [run_pretraining.py:  512]:	********exe.run_2495******* 
[INFO] 2021-07-12 19:22:54,947 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:54,948 [run_pretraining.py:  534]:	loss/total_loss, 7.4741950035095215, 2496
[INFO] 2021-07-12 19:22:54,948 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4741950035095215, 2496
[INFO] 2021-07-12 19:22:54,948 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4950000806711614e-05, 2496
[INFO] 2021-07-12 19:22:54,948 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2496
[INFO] 2021-07-12 19:22:54,948 [run_pretraining.py:  558]:	worker_index: 7, step: 2496, cost: 7.474195, mlm loss: 7.474195, speed: 1.086319 steps/s, speed: 8.690548 samples/s, speed: 4449.560605 tokens/s, learning rate: 2.495e-05, loss_scalings: 2814.750488, pp_loss: 7.416918
[INFO] 2021-07-12 19:22:54,948 [run_pretraining.py:  512]:	********exe.run_2496******* 
[INFO] 2021-07-12 19:22:55,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:55,871 [run_pretraining.py:  534]:	loss/total_loss, 7.700870513916016, 2497
[INFO] 2021-07-12 19:22:55,871 [run_pretraining.py:  535]:	loss/mlm_loss, 7.700870513916016, 2497
[INFO] 2021-07-12 19:22:55,871 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4959997972473502e-05, 2497
[INFO] 2021-07-12 19:22:55,871 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2497
[INFO] 2021-07-12 19:22:55,871 [run_pretraining.py:  558]:	worker_index: 7, step: 2497, cost: 7.700871, mlm loss: 7.700871, speed: 1.084636 steps/s, speed: 8.677091 samples/s, speed: 4442.670542 tokens/s, learning rate: 2.496e-05, loss_scalings: 2814.750488, pp_loss: 6.773649
[INFO] 2021-07-12 19:22:55,871 [run_pretraining.py:  512]:	********exe.run_2497******* 
[INFO] 2021-07-12 19:22:56,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:56,797 [run_pretraining.py:  534]:	loss/total_loss, 7.244027137756348, 2498
[INFO] 2021-07-12 19:22:56,797 [run_pretraining.py:  535]:	loss/mlm_loss, 7.244027137756348, 2498
[INFO] 2021-07-12 19:22:56,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4969998776214197e-05, 2498
[INFO] 2021-07-12 19:22:56,797 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2498
[INFO] 2021-07-12 19:22:56,797 [run_pretraining.py:  558]:	worker_index: 7, step: 2498, cost: 7.244027, mlm loss: 7.244027, speed: 1.080451 steps/s, speed: 8.643607 samples/s, speed: 4425.526980 tokens/s, learning rate: 2.497e-05, loss_scalings: 2814.750488, pp_loss: 7.547255
[INFO] 2021-07-12 19:22:56,797 [run_pretraining.py:  512]:	********exe.run_2498******* 
[INFO] 2021-07-12 19:22:57,722 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:57,723 [run_pretraining.py:  534]:	loss/total_loss, 7.814294338226318, 2499
[INFO] 2021-07-12 19:22:57,723 [run_pretraining.py:  535]:	loss/mlm_loss, 7.814294338226318, 2499
[INFO] 2021-07-12 19:22:57,723 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4979999579954892e-05, 2499
[INFO] 2021-07-12 19:22:57,723 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2499
[INFO] 2021-07-12 19:22:57,723 [run_pretraining.py:  558]:	worker_index: 7, step: 2499, cost: 7.814294, mlm loss: 7.814294, speed: 1.080544 steps/s, speed: 8.644353 samples/s, speed: 4425.908918 tokens/s, learning rate: 2.498e-05, loss_scalings: 2814.750488, pp_loss: 7.615081
[INFO] 2021-07-12 19:22:57,723 [run_pretraining.py:  512]:	********exe.run_2499******* 
[INFO] 2021-07-12 19:22:58,653 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:58,653 [run_pretraining.py:  534]:	loss/total_loss, 7.062551498413086, 2500
[INFO] 2021-07-12 19:22:58,653 [run_pretraining.py:  535]:	loss/mlm_loss, 7.062551498413086, 2500
[INFO] 2021-07-12 19:22:58,653 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.4989998564706184e-05, 2500
[INFO] 2021-07-12 19:22:58,653 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2500
[INFO] 2021-07-12 19:22:58,654 [run_pretraining.py:  558]:	worker_index: 7, step: 2500, cost: 7.062551, mlm loss: 7.062551, speed: 1.075633 steps/s, speed: 8.605064 samples/s, speed: 4405.792811 tokens/s, learning rate: 2.499e-05, loss_scalings: 2814.750488, pp_loss: 7.419920
[INFO] 2021-07-12 19:22:58,654 [run_pretraining.py:  512]:	********exe.run_2500******* 
[INFO] 2021-07-12 19:22:59,574 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:22:59,574 [run_pretraining.py:  534]:	loss/total_loss, 7.128663063049316, 2501
[INFO] 2021-07-12 19:22:59,574 [run_pretraining.py:  535]:	loss/mlm_loss, 7.128663063049316, 2501
[INFO] 2021-07-12 19:22:59,574 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.499999936844688e-05, 2501
[INFO] 2021-07-12 19:22:59,574 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2501
[INFO] 2021-07-12 19:22:59,574 [run_pretraining.py:  558]:	worker_index: 7, step: 2501, cost: 7.128663, mlm loss: 7.128663, speed: 1.086656 steps/s, speed: 8.693248 samples/s, speed: 4450.942797 tokens/s, learning rate: 2.500e-05, loss_scalings: 2814.750488, pp_loss: 7.270766
[INFO] 2021-07-12 19:22:59,574 [run_pretraining.py:  512]:	********exe.run_2501******* 
[INFO] 2021-07-12 19:23:00,498 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:00,499 [run_pretraining.py:  534]:	loss/total_loss, 7.712205410003662, 2502
[INFO] 2021-07-12 19:23:00,499 [run_pretraining.py:  535]:	loss/mlm_loss, 7.712205410003662, 2502
[INFO] 2021-07-12 19:23:00,499 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.500999835319817e-05, 2502
[INFO] 2021-07-12 19:23:00,499 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2502
[INFO] 2021-07-12 19:23:00,499 [run_pretraining.py:  558]:	worker_index: 7, step: 2502, cost: 7.712205, mlm loss: 7.712205, speed: 1.082350 steps/s, speed: 8.658804 samples/s, speed: 4433.307550 tokens/s, learning rate: 2.501e-05, loss_scalings: 2814.750488, pp_loss: 7.123403
[INFO] 2021-07-12 19:23:00,499 [run_pretraining.py:  512]:	********exe.run_2502******* 
[INFO] 2021-07-12 19:23:01,412 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:01,413 [run_pretraining.py:  534]:	loss/total_loss, 6.702370643615723, 2503
[INFO] 2021-07-12 19:23:01,413 [run_pretraining.py:  535]:	loss/mlm_loss, 6.702370643615723, 2503
[INFO] 2021-07-12 19:23:01,413 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5019999156938866e-05, 2503
[INFO] 2021-07-12 19:23:01,413 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2503
[INFO] 2021-07-12 19:23:01,413 [run_pretraining.py:  558]:	worker_index: 7, step: 2503, cost: 6.702371, mlm loss: 6.702371, speed: 1.094764 steps/s, speed: 8.758115 samples/s, speed: 4484.154913 tokens/s, learning rate: 2.502e-05, loss_scalings: 2814.750488, pp_loss: 6.796494
[INFO] 2021-07-12 19:23:01,413 [run_pretraining.py:  512]:	********exe.run_2503******* 
[INFO] 2021-07-12 19:23:02,336 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:02,337 [run_pretraining.py:  534]:	loss/total_loss, 7.304754257202148, 2504
[INFO] 2021-07-12 19:23:02,337 [run_pretraining.py:  535]:	loss/mlm_loss, 7.304754257202148, 2504
[INFO] 2021-07-12 19:23:02,337 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5029998141690157e-05, 2504
[INFO] 2021-07-12 19:23:02,337 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2504
[INFO] 2021-07-12 19:23:02,337 [run_pretraining.py:  558]:	worker_index: 7, step: 2504, cost: 7.304754, mlm loss: 7.304754, speed: 1.083084 steps/s, speed: 8.664669 samples/s, speed: 4436.310362 tokens/s, learning rate: 2.503e-05, loss_scalings: 2814.750488, pp_loss: 7.160460
[INFO] 2021-07-12 19:23:02,337 [run_pretraining.py:  512]:	********exe.run_2504******* 
[INFO] 2021-07-12 19:23:03,259 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:03,259 [run_pretraining.py:  534]:	loss/total_loss, 7.249402046203613, 2505
[INFO] 2021-07-12 19:23:03,259 [run_pretraining.py:  535]:	loss/mlm_loss, 7.249402046203613, 2505
[INFO] 2021-07-12 19:23:03,259 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5040000764420256e-05, 2505
[INFO] 2021-07-12 19:23:03,259 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2505
[INFO] 2021-07-12 19:23:03,259 [run_pretraining.py:  558]:	worker_index: 7, step: 2505, cost: 7.249402, mlm loss: 7.249402, speed: 1.084845 steps/s, speed: 8.678761 samples/s, speed: 4443.525461 tokens/s, learning rate: 2.504e-05, loss_scalings: 2814.750488, pp_loss: 7.405604
[INFO] 2021-07-12 19:23:03,260 [run_pretraining.py:  512]:	********exe.run_2505******* 
[INFO] 2021-07-12 19:23:04,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:04,184 [run_pretraining.py:  534]:	loss/total_loss, 6.911691188812256, 2506
[INFO] 2021-07-12 19:23:04,184 [run_pretraining.py:  535]:	loss/mlm_loss, 6.911691188812256, 2506
[INFO] 2021-07-12 19:23:04,184 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5049997930182144e-05, 2506
[INFO] 2021-07-12 19:23:04,184 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2506
[INFO] 2021-07-12 19:23:04,184 [run_pretraining.py:  558]:	worker_index: 7, step: 2506, cost: 6.911691, mlm loss: 6.911691, speed: 1.082472 steps/s, speed: 8.659778 samples/s, speed: 4433.806401 tokens/s, learning rate: 2.505e-05, loss_scalings: 2814.750488, pp_loss: 7.214535
[INFO] 2021-07-12 19:23:04,184 [run_pretraining.py:  512]:	********exe.run_2506******* 
[INFO] 2021-07-12 19:23:05,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:05,104 [run_pretraining.py:  534]:	loss/total_loss, 7.717091083526611, 2507
[INFO] 2021-07-12 19:23:05,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.717091083526611, 2507
[INFO] 2021-07-12 19:23:05,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5060000552912243e-05, 2507
[INFO] 2021-07-12 19:23:05,104 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2507
[INFO] 2021-07-12 19:23:05,104 [run_pretraining.py:  558]:	worker_index: 7, step: 2507, cost: 7.717091, mlm loss: 7.717091, speed: 1.087260 steps/s, speed: 8.698084 samples/s, speed: 4453.418824 tokens/s, learning rate: 2.506e-05, loss_scalings: 2814.750488, pp_loss: 7.101718
[INFO] 2021-07-12 19:23:05,104 [run_pretraining.py:  512]:	********exe.run_2507******* 
[INFO] 2021-07-12 19:23:06,024 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:06,024 [run_pretraining.py:  534]:	loss/total_loss, 7.164255619049072, 2508
[INFO] 2021-07-12 19:23:06,024 [run_pretraining.py:  535]:	loss/mlm_loss, 7.164255619049072, 2508
[INFO] 2021-07-12 19:23:06,024 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5069999537663534e-05, 2508
[INFO] 2021-07-12 19:23:06,025 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2508
[INFO] 2021-07-12 19:23:06,025 [run_pretraining.py:  558]:	worker_index: 7, step: 2508, cost: 7.164256, mlm loss: 7.164256, speed: 1.087383 steps/s, speed: 8.699060 samples/s, speed: 4453.918748 tokens/s, learning rate: 2.507e-05, loss_scalings: 2814.750488, pp_loss: 6.813131
[INFO] 2021-07-12 19:23:06,025 [run_pretraining.py:  512]:	********exe.run_2508******* 
[INFO] 2021-07-12 19:23:06,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:06,941 [run_pretraining.py:  534]:	loss/total_loss, 7.3475470542907715, 2509
[INFO] 2021-07-12 19:23:06,942 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3475470542907715, 2509
[INFO] 2021-07-12 19:23:06,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.508000034140423e-05, 2509
[INFO] 2021-07-12 19:23:06,942 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2509
[INFO] 2021-07-12 19:23:06,942 [run_pretraining.py:  558]:	worker_index: 7, step: 2509, cost: 7.347547, mlm loss: 7.347547, speed: 1.091021 steps/s, speed: 8.728169 samples/s, speed: 4468.822361 tokens/s, learning rate: 2.508e-05, loss_scalings: 2814.750488, pp_loss: 7.398551
[INFO] 2021-07-12 19:23:06,942 [run_pretraining.py:  512]:	********exe.run_2509******* 
[INFO] 2021-07-12 19:23:07,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:07,862 [run_pretraining.py:  534]:	loss/total_loss, 7.557985782623291, 2510
[INFO] 2021-07-12 19:23:07,862 [run_pretraining.py:  535]:	loss/mlm_loss, 7.557985782623291, 2510
[INFO] 2021-07-12 19:23:07,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.508999932615552e-05, 2510
[INFO] 2021-07-12 19:23:07,862 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2510
[INFO] 2021-07-12 19:23:07,862 [run_pretraining.py:  558]:	worker_index: 7, step: 2510, cost: 7.557986, mlm loss: 7.557986, speed: 1.087029 steps/s, speed: 8.696233 samples/s, speed: 4452.471240 tokens/s, learning rate: 2.509e-05, loss_scalings: 2814.750488, pp_loss: 7.392165
[INFO] 2021-07-12 19:23:07,862 [run_pretraining.py:  512]:	********exe.run_2510******* 
[INFO] 2021-07-12 19:23:08,778 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:08,778 [run_pretraining.py:  534]:	loss/total_loss, 7.453130722045898, 2511
[INFO] 2021-07-12 19:23:08,778 [run_pretraining.py:  535]:	loss/mlm_loss, 7.453130722045898, 2511
[INFO] 2021-07-12 19:23:08,778 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5099998310906813e-05, 2511
[INFO] 2021-07-12 19:23:08,778 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2511
[INFO] 2021-07-12 19:23:08,779 [run_pretraining.py:  558]:	worker_index: 7, step: 2511, cost: 7.453131, mlm loss: 7.453131, speed: 1.092290 steps/s, speed: 8.738322 samples/s, speed: 4474.020971 tokens/s, learning rate: 2.510e-05, loss_scalings: 2814.750488, pp_loss: 7.331057
[INFO] 2021-07-12 19:23:08,779 [run_pretraining.py:  512]:	********exe.run_2511******* 
[INFO] 2021-07-12 19:23:09,700 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:09,701 [run_pretraining.py:  534]:	loss/total_loss, 6.6734771728515625, 2512
[INFO] 2021-07-12 19:23:09,701 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6734771728515625, 2512
[INFO] 2021-07-12 19:23:09,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5109999114647508e-05, 2512
[INFO] 2021-07-12 19:23:09,701 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2512
[INFO] 2021-07-12 19:23:09,701 [run_pretraining.py:  558]:	worker_index: 7, step: 2512, cost: 6.673477, mlm loss: 6.673477, speed: 1.084884 steps/s, speed: 8.679068 samples/s, speed: 4443.682921 tokens/s, learning rate: 2.511e-05, loss_scalings: 2814.750488, pp_loss: 6.243650
[INFO] 2021-07-12 19:23:09,701 [run_pretraining.py:  512]:	********exe.run_2512******* 
[INFO] 2021-07-12 19:23:10,619 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:10,619 [run_pretraining.py:  534]:	loss/total_loss, 7.318643569946289, 2513
[INFO] 2021-07-12 19:23:10,619 [run_pretraining.py:  535]:	loss/mlm_loss, 7.318643569946289, 2513
[INFO] 2021-07-12 19:23:10,620 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.51199980993988e-05, 2513
[INFO] 2021-07-12 19:23:10,620 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2513
[INFO] 2021-07-12 19:23:10,620 [run_pretraining.py:  558]:	worker_index: 7, step: 2513, cost: 7.318644, mlm loss: 7.318644, speed: 1.089270 steps/s, speed: 8.714160 samples/s, speed: 4461.650081 tokens/s, learning rate: 2.512e-05, loss_scalings: 2814.750488, pp_loss: 7.206053
[INFO] 2021-07-12 19:23:10,620 [run_pretraining.py:  512]:	********exe.run_2513******* 
[INFO] 2021-07-12 19:23:11,540 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:11,541 [run_pretraining.py:  534]:	loss/total_loss, 5.653099060058594, 2514
[INFO] 2021-07-12 19:23:11,541 [run_pretraining.py:  535]:	loss/mlm_loss, 5.653099060058594, 2514
[INFO] 2021-07-12 19:23:11,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5130000722128898e-05, 2514
[INFO] 2021-07-12 19:23:11,541 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2514
[INFO] 2021-07-12 19:23:11,541 [run_pretraining.py:  558]:	worker_index: 7, step: 2514, cost: 5.653099, mlm loss: 5.653099, speed: 1.086120 steps/s, speed: 8.688957 samples/s, speed: 4448.745986 tokens/s, learning rate: 2.513e-05, loss_scalings: 2814.750488, pp_loss: 6.726191
[INFO] 2021-07-12 19:23:11,541 [run_pretraining.py:  512]:	********exe.run_2514******* 
[INFO] 2021-07-12 19:23:12,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:12,459 [run_pretraining.py:  534]:	loss/total_loss, 7.1183576583862305, 2515
[INFO] 2021-07-12 19:23:12,459 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1183576583862305, 2515
[INFO] 2021-07-12 19:23:12,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5139997887890786e-05, 2515
[INFO] 2021-07-12 19:23:12,460 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2515
[INFO] 2021-07-12 19:23:12,460 [run_pretraining.py:  558]:	worker_index: 7, step: 2515, cost: 7.118358, mlm loss: 7.118358, speed: 1.089318 steps/s, speed: 8.714541 samples/s, speed: 4461.844752 tokens/s, learning rate: 2.514e-05, loss_scalings: 2814.750488, pp_loss: 7.245027
[INFO] 2021-07-12 19:23:12,460 [run_pretraining.py:  512]:	********exe.run_2515******* 
[INFO] 2021-07-12 19:23:13,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:13,378 [run_pretraining.py:  534]:	loss/total_loss, 7.615137100219727, 2516
[INFO] 2021-07-12 19:23:13,378 [run_pretraining.py:  535]:	loss/mlm_loss, 7.615137100219727, 2516
[INFO] 2021-07-12 19:23:13,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5150000510620885e-05, 2516
[INFO] 2021-07-12 19:23:13,378 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2516
[INFO] 2021-07-12 19:23:13,378 [run_pretraining.py:  558]:	worker_index: 7, step: 2516, cost: 7.615137, mlm loss: 7.615137, speed: 1.089300 steps/s, speed: 8.714400 samples/s, speed: 4461.772907 tokens/s, learning rate: 2.515e-05, loss_scalings: 2814.750488, pp_loss: 7.358634
[INFO] 2021-07-12 19:23:13,378 [run_pretraining.py:  512]:	********exe.run_2516******* 
[INFO] 2021-07-12 19:23:14,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:14,301 [run_pretraining.py:  534]:	loss/total_loss, 7.450324058532715, 2517
[INFO] 2021-07-12 19:23:14,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.450324058532715, 2517
[INFO] 2021-07-12 19:23:14,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5159999495372176e-05, 2517
[INFO] 2021-07-12 19:23:14,301 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2517
[INFO] 2021-07-12 19:23:14,301 [run_pretraining.py:  558]:	worker_index: 7, step: 2517, cost: 7.450324, mlm loss: 7.450324, speed: 1.084604 steps/s, speed: 8.676828 samples/s, speed: 4442.536129 tokens/s, learning rate: 2.516e-05, loss_scalings: 2814.750488, pp_loss: 7.441475
[INFO] 2021-07-12 19:23:14,301 [run_pretraining.py:  512]:	********exe.run_2517******* 
[INFO] 2021-07-12 19:23:15,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:15,247 [run_pretraining.py:  534]:	loss/total_loss, 6.903983116149902, 2518
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  535]:	loss/mlm_loss, 6.903983116149902, 2518
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.517000029911287e-05, 2518
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2518
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  558]:	worker_index: 7, step: 2518, cost: 6.903983, mlm loss: 6.903983, speed: 1.057008 steps/s, speed: 8.456066 samples/s, speed: 4329.505930 tokens/s, learning rate: 2.517e-05, loss_scalings: 2814.750488, pp_loss: 7.286695
[INFO] 2021-07-12 19:23:15,248 [run_pretraining.py:  512]:	********exe.run_2518******* 
[INFO] 2021-07-12 19:23:16,165 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:16,166 [run_pretraining.py:  534]:	loss/total_loss, 7.24219274520874, 2519
[INFO] 2021-07-12 19:23:16,166 [run_pretraining.py:  535]:	loss/mlm_loss, 7.24219274520874, 2519
[INFO] 2021-07-12 19:23:16,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5179999283864163e-05, 2519
[INFO] 2021-07-12 19:23:16,166 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2519
[INFO] 2021-07-12 19:23:16,166 [run_pretraining.py:  558]:	worker_index: 7, step: 2519, cost: 7.242193, mlm loss: 7.242193, speed: 1.089771 steps/s, speed: 8.718168 samples/s, speed: 4463.701924 tokens/s, learning rate: 2.518e-05, loss_scalings: 2814.750488, pp_loss: 7.149192
[INFO] 2021-07-12 19:23:16,166 [run_pretraining.py:  512]:	********exe.run_2519******* 
[INFO] 2021-07-12 19:23:17,088 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:17,089 [run_pretraining.py:  534]:	loss/total_loss, 7.744542121887207, 2520
[INFO] 2021-07-12 19:23:17,089 [run_pretraining.py:  535]:	loss/mlm_loss, 7.744542121887207, 2520
[INFO] 2021-07-12 19:23:17,089 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5189998268615454e-05, 2520
[INFO] 2021-07-12 19:23:17,089 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2520
[INFO] 2021-07-12 19:23:17,089 [run_pretraining.py:  558]:	worker_index: 7, step: 2520, cost: 7.744542, mlm loss: 7.744542, speed: 1.083977 steps/s, speed: 8.671819 samples/s, speed: 4439.971206 tokens/s, learning rate: 2.519e-05, loss_scalings: 2814.750488, pp_loss: 7.635365
[INFO] 2021-07-12 19:23:17,089 [run_pretraining.py:  512]:	********exe.run_2520******* 
[INFO] 2021-07-12 19:23:18,012 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:18,013 [run_pretraining.py:  534]:	loss/total_loss, 7.434645652770996, 2521
[INFO] 2021-07-12 19:23:18,013 [run_pretraining.py:  535]:	loss/mlm_loss, 7.434645652770996, 2521
[INFO] 2021-07-12 19:23:18,013 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.519999907235615e-05, 2521
[INFO] 2021-07-12 19:23:18,013 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2521
[INFO] 2021-07-12 19:23:18,013 [run_pretraining.py:  558]:	worker_index: 7, step: 2521, cost: 7.434646, mlm loss: 7.434646, speed: 1.083121 steps/s, speed: 8.664964 samples/s, speed: 4436.461584 tokens/s, learning rate: 2.520e-05, loss_scalings: 2814.750488, pp_loss: 7.405263
[INFO] 2021-07-12 19:23:18,013 [run_pretraining.py:  512]:	********exe.run_2521******* 
[INFO] 2021-07-12 19:23:18,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:18,942 [run_pretraining.py:  534]:	loss/total_loss, 7.426724910736084, 2522
[INFO] 2021-07-12 19:23:18,942 [run_pretraining.py:  535]:	loss/mlm_loss, 7.426724910736084, 2522
[INFO] 2021-07-12 19:23:18,942 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.520999805710744e-05, 2522
[INFO] 2021-07-12 19:23:18,942 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2522
[INFO] 2021-07-12 19:23:18,942 [run_pretraining.py:  558]:	worker_index: 7, step: 2522, cost: 7.426725, mlm loss: 7.426725, speed: 1.076932 steps/s, speed: 8.615457 samples/s, speed: 4411.114137 tokens/s, learning rate: 2.521e-05, loss_scalings: 2814.750488, pp_loss: 7.336335
[INFO] 2021-07-12 19:23:18,942 [run_pretraining.py:  512]:	********exe.run_2522******* 
[INFO] 2021-07-12 19:23:19,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:19,894 [run_pretraining.py:  534]:	loss/total_loss, 7.367156028747559, 2523
[INFO] 2021-07-12 19:23:19,899 [run_pretraining.py:  535]:	loss/mlm_loss, 7.367156028747559, 2523
[INFO] 2021-07-12 19:23:19,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.522000067983754e-05, 2523
[INFO] 2021-07-12 19:23:19,910 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2523
[INFO] 2021-07-12 19:23:19,915 [run_pretraining.py:  558]:	worker_index: 7, step: 2523, cost: 7.367156, mlm loss: 7.367156, speed: 1.050880 steps/s, speed: 8.407043 samples/s, speed: 4304.405782 tokens/s, learning rate: 2.522e-05, loss_scalings: 2814.750488, pp_loss: 7.626052
[INFO] 2021-07-12 19:23:19,920 [run_pretraining.py:  512]:	********exe.run_2523******* 
[INFO] 2021-07-12 19:23:20,858 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:20,859 [run_pretraining.py:  534]:	loss/total_loss, 6.9069061279296875, 2524
[INFO] 2021-07-12 19:23:20,859 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9069061279296875, 2524
[INFO] 2021-07-12 19:23:20,859 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.522999966458883e-05, 2524
[INFO] 2021-07-12 19:23:20,859 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2524
[INFO] 2021-07-12 19:23:20,859 [run_pretraining.py:  558]:	worker_index: 7, step: 2524, cost: 6.906906, mlm loss: 6.906906, speed: 1.065697 steps/s, speed: 8.525573 samples/s, speed: 4365.093616 tokens/s, learning rate: 2.523e-05, loss_scalings: 2814.750488, pp_loss: 7.088806
[INFO] 2021-07-12 19:23:20,859 [run_pretraining.py:  512]:	********exe.run_2524******* 
[INFO] 2021-07-12 19:23:21,786 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:21,786 [run_pretraining.py:  534]:	loss/total_loss, 7.017732620239258, 2525
[INFO] 2021-07-12 19:23:21,786 [run_pretraining.py:  535]:	loss/mlm_loss, 7.017732620239258, 2525
[INFO] 2021-07-12 19:23:21,786 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5240000468329526e-05, 2525
[INFO] 2021-07-12 19:23:21,787 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2525
[INFO] 2021-07-12 19:23:21,787 [run_pretraining.py:  558]:	worker_index: 7, step: 2525, cost: 7.017733, mlm loss: 7.017733, speed: 1.078887 steps/s, speed: 8.631092 samples/s, speed: 4419.119134 tokens/s, learning rate: 2.524e-05, loss_scalings: 2814.750488, pp_loss: 7.010233
[INFO] 2021-07-12 19:23:21,787 [run_pretraining.py:  512]:	********exe.run_2525******* 
[INFO] 2021-07-12 19:23:22,739 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:22,739 [run_pretraining.py:  534]:	loss/total_loss, 7.794761657714844, 2526
[INFO] 2021-07-12 19:23:22,740 [run_pretraining.py:  535]:	loss/mlm_loss, 7.794761657714844, 2526
[INFO] 2021-07-12 19:23:22,740 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5249999453080818e-05, 2526
[INFO] 2021-07-12 19:23:22,740 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2526
[INFO] 2021-07-12 19:23:22,740 [run_pretraining.py:  558]:	worker_index: 7, step: 2526, cost: 7.794762, mlm loss: 7.794762, speed: 1.049900 steps/s, speed: 8.399199 samples/s, speed: 4300.390088 tokens/s, learning rate: 2.525e-05, loss_scalings: 2814.750488, pp_loss: 7.095231
[INFO] 2021-07-12 19:23:22,740 [run_pretraining.py:  512]:	********exe.run_2526******* 
[INFO] 2021-07-12 19:23:23,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:23,654 [run_pretraining.py:  534]:	loss/total_loss, 7.187831401824951, 2527
[INFO] 2021-07-12 19:23:23,654 [run_pretraining.py:  535]:	loss/mlm_loss, 7.187831401824951, 2527
[INFO] 2021-07-12 19:23:23,654 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5260000256821513e-05, 2527
[INFO] 2021-07-12 19:23:23,654 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2527
[INFO] 2021-07-12 19:23:23,655 [run_pretraining.py:  558]:	worker_index: 7, step: 2527, cost: 7.187831, mlm loss: 7.187831, speed: 1.093934 steps/s, speed: 8.751472 samples/s, speed: 4480.753916 tokens/s, learning rate: 2.526e-05, loss_scalings: 2814.750488, pp_loss: 7.180088
[INFO] 2021-07-12 19:23:23,655 [run_pretraining.py:  512]:	********exe.run_2527******* 
[INFO] 2021-07-12 19:23:24,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:24,566 [run_pretraining.py:  534]:	loss/total_loss, 6.450052261352539, 2528
[INFO] 2021-07-12 19:23:24,566 [run_pretraining.py:  535]:	loss/mlm_loss, 6.450052261352539, 2528
[INFO] 2021-07-12 19:23:24,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5269999241572805e-05, 2528
[INFO] 2021-07-12 19:23:24,566 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2528
[INFO] 2021-07-12 19:23:24,566 [run_pretraining.py:  558]:	worker_index: 7, step: 2528, cost: 6.450052, mlm loss: 6.450052, speed: 1.097992 steps/s, speed: 8.783936 samples/s, speed: 4497.375032 tokens/s, learning rate: 2.527e-05, loss_scalings: 2814.750488, pp_loss: 7.128117
[INFO] 2021-07-12 19:23:24,566 [run_pretraining.py:  512]:	********exe.run_2528******* 
[INFO] 2021-07-12 19:23:25,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:25,487 [run_pretraining.py:  534]:	loss/total_loss, 7.232728004455566, 2529
[INFO] 2021-07-12 19:23:25,487 [run_pretraining.py:  535]:	loss/mlm_loss, 7.232728004455566, 2529
[INFO] 2021-07-12 19:23:25,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5279998226324096e-05, 2529
[INFO] 2021-07-12 19:23:25,488 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2529
[INFO] 2021-07-12 19:23:25,488 [run_pretraining.py:  558]:	worker_index: 7, step: 2529, cost: 7.232728, mlm loss: 7.232728, speed: 1.085744 steps/s, speed: 8.685952 samples/s, speed: 4447.207436 tokens/s, learning rate: 2.528e-05, loss_scalings: 2814.750488, pp_loss: 7.414783
[INFO] 2021-07-12 19:23:25,488 [run_pretraining.py:  512]:	********exe.run_2529******* 
[INFO] 2021-07-12 19:23:26,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:26,402 [run_pretraining.py:  534]:	loss/total_loss, 7.386804103851318, 2530
[INFO] 2021-07-12 19:23:26,402 [run_pretraining.py:  535]:	loss/mlm_loss, 7.386804103851318, 2530
[INFO] 2021-07-12 19:23:26,402 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.528999903006479e-05, 2530
[INFO] 2021-07-12 19:23:26,402 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2530
[INFO] 2021-07-12 19:23:26,402 [run_pretraining.py:  558]:	worker_index: 7, step: 2530, cost: 7.386804, mlm loss: 7.386804, speed: 1.093884 steps/s, speed: 8.751073 samples/s, speed: 4480.549412 tokens/s, learning rate: 2.529e-05, loss_scalings: 2814.750488, pp_loss: 7.496975
[INFO] 2021-07-12 19:23:26,403 [run_pretraining.py:  512]:	********exe.run_2530******* 
[INFO] 2021-07-12 19:23:27,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:27,320 [run_pretraining.py:  534]:	loss/total_loss, 7.247218132019043, 2531
[INFO] 2021-07-12 19:23:27,320 [run_pretraining.py:  535]:	loss/mlm_loss, 7.247218132019043, 2531
[INFO] 2021-07-12 19:23:27,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5299998014816083e-05, 2531
[INFO] 2021-07-12 19:23:27,321 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2531
[INFO] 2021-07-12 19:23:27,321 [run_pretraining.py:  558]:	worker_index: 7, step: 2531, cost: 7.247218, mlm loss: 7.247218, speed: 1.089874 steps/s, speed: 8.718990 samples/s, speed: 4464.122959 tokens/s, learning rate: 2.530e-05, loss_scalings: 2814.750488, pp_loss: 7.263574
[INFO] 2021-07-12 19:23:27,321 [run_pretraining.py:  512]:	********exe.run_2531******* 
[INFO] 2021-07-12 19:23:28,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:28,232 [run_pretraining.py:  534]:	loss/total_loss, 5.264007091522217, 2532
[INFO] 2021-07-12 19:23:28,232 [run_pretraining.py:  535]:	loss/mlm_loss, 5.264007091522217, 2532
[INFO] 2021-07-12 19:23:28,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.531000063754618e-05, 2532
[INFO] 2021-07-12 19:23:28,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2532
[INFO] 2021-07-12 19:23:28,232 [run_pretraining.py:  558]:	worker_index: 7, step: 2532, cost: 5.264007, mlm loss: 5.264007, speed: 1.097991 steps/s, speed: 8.783926 samples/s, speed: 4497.370323 tokens/s, learning rate: 2.531e-05, loss_scalings: 2814.750488, pp_loss: 7.012767
[INFO] 2021-07-12 19:23:28,232 [run_pretraining.py:  512]:	********exe.run_2532******* 
[INFO] 2021-07-12 19:23:29,145 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:29,146 [run_pretraining.py:  534]:	loss/total_loss, 7.301041603088379, 2533
[INFO] 2021-07-12 19:23:29,146 [run_pretraining.py:  535]:	loss/mlm_loss, 7.301041603088379, 2533
[INFO] 2021-07-12 19:23:29,146 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5319999622297473e-05, 2533
[INFO] 2021-07-12 19:23:29,146 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2533
[INFO] 2021-07-12 19:23:29,146 [run_pretraining.py:  558]:	worker_index: 7, step: 2533, cost: 7.301042, mlm loss: 7.301042, speed: 1.094968 steps/s, speed: 8.759743 samples/s, speed: 4484.988406 tokens/s, learning rate: 2.532e-05, loss_scalings: 2814.750488, pp_loss: 6.913929
[INFO] 2021-07-12 19:23:29,146 [run_pretraining.py:  512]:	********exe.run_2533******* 
[INFO] 2021-07-12 19:23:30,055 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  534]:	loss/total_loss, 7.15540885925293, 2534
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  535]:	loss/mlm_loss, 7.15540885925293, 2534
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.533000042603817e-05, 2534
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2534
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  558]:	worker_index: 7, step: 2534, cost: 7.155409, mlm loss: 7.155409, speed: 1.099547 steps/s, speed: 8.796377 samples/s, speed: 4503.745158 tokens/s, learning rate: 2.533e-05, loss_scalings: 2814.750488, pp_loss: 6.913691
[INFO] 2021-07-12 19:23:30,056 [run_pretraining.py:  512]:	********exe.run_2534******* 
[INFO] 2021-07-12 19:23:30,970 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:30,970 [run_pretraining.py:  534]:	loss/total_loss, 6.868048667907715, 2535
[INFO] 2021-07-12 19:23:30,971 [run_pretraining.py:  535]:	loss/mlm_loss, 6.868048667907715, 2535
[INFO] 2021-07-12 19:23:30,971 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.533999941078946e-05, 2535
[INFO] 2021-07-12 19:23:30,971 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2535
[INFO] 2021-07-12 19:23:30,971 [run_pretraining.py:  558]:	worker_index: 7, step: 2535, cost: 6.868049, mlm loss: 6.868049, speed: 1.094015 steps/s, speed: 8.752121 samples/s, speed: 4481.085835 tokens/s, learning rate: 2.534e-05, loss_scalings: 2814.750488, pp_loss: 7.090589
[INFO] 2021-07-12 19:23:30,971 [run_pretraining.py:  512]:	********exe.run_2535******* 
[INFO] 2021-07-12 19:23:31,881 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:31,881 [run_pretraining.py:  534]:	loss/total_loss, 7.135339260101318, 2536
[INFO] 2021-07-12 19:23:31,881 [run_pretraining.py:  535]:	loss/mlm_loss, 7.135339260101318, 2536
[INFO] 2021-07-12 19:23:31,881 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5350000214530155e-05, 2536
[INFO] 2021-07-12 19:23:31,881 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2536
[INFO] 2021-07-12 19:23:31,881 [run_pretraining.py:  558]:	worker_index: 7, step: 2536, cost: 7.135339, mlm loss: 7.135339, speed: 1.098889 steps/s, speed: 8.791109 samples/s, speed: 4501.047768 tokens/s, learning rate: 2.535e-05, loss_scalings: 2814.750488, pp_loss: 7.294848
[INFO] 2021-07-12 19:23:31,882 [run_pretraining.py:  512]:	********exe.run_2536******* 
[INFO] 2021-07-12 19:23:32,799 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:32,800 [run_pretraining.py:  534]:	loss/total_loss, 7.258124351501465, 2537
[INFO] 2021-07-12 19:23:32,800 [run_pretraining.py:  535]:	loss/mlm_loss, 7.258124351501465, 2537
[INFO] 2021-07-12 19:23:32,800 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5359999199281447e-05, 2537
[INFO] 2021-07-12 19:23:32,800 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2537
[INFO] 2021-07-12 19:23:32,800 [run_pretraining.py:  558]:	worker_index: 7, step: 2537, cost: 7.258124, mlm loss: 7.258124, speed: 1.089678 steps/s, speed: 8.717423 samples/s, speed: 4463.320394 tokens/s, learning rate: 2.536e-05, loss_scalings: 2814.750488, pp_loss: 8.076728
[INFO] 2021-07-12 19:23:32,800 [run_pretraining.py:  512]:	********exe.run_2537******* 
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  534]:	loss/total_loss, 7.333133697509766, 2538
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  535]:	loss/mlm_loss, 7.333133697509766, 2538
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5369998184032738e-05, 2538
[INFO] 2021-07-12 19:23:33,737 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2538
[INFO] 2021-07-12 19:23:33,738 [run_pretraining.py:  558]:	worker_index: 7, step: 2538, cost: 7.333134, mlm loss: 7.333134, speed: 1.067176 steps/s, speed: 8.537411 samples/s, speed: 4371.154330 tokens/s, learning rate: 2.537e-05, loss_scalings: 2814.750488, pp_loss: 6.564732
[INFO] 2021-07-12 19:23:33,738 [run_pretraining.py:  512]:	********exe.run_2538******* 
[INFO] 2021-07-12 19:23:34,678 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:34,678 [run_pretraining.py:  534]:	loss/total_loss, 7.715169906616211, 2539
[INFO] 2021-07-12 19:23:34,679 [run_pretraining.py:  535]:	loss/mlm_loss, 7.715169906616211, 2539
[INFO] 2021-07-12 19:23:34,679 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5379998987773433e-05, 2539
[INFO] 2021-07-12 19:23:34,679 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2539
[INFO] 2021-07-12 19:23:34,679 [run_pretraining.py:  558]:	worker_index: 7, step: 2539, cost: 7.715170, mlm loss: 7.715170, speed: 1.063112 steps/s, speed: 8.504895 samples/s, speed: 4354.506463 tokens/s, learning rate: 2.538e-05, loss_scalings: 2814.750488, pp_loss: 7.396389
[INFO] 2021-07-12 19:23:34,679 [run_pretraining.py:  512]:	********exe.run_2539******* 
[INFO] 2021-07-12 19:23:35,729 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:35,730 [run_pretraining.py:  534]:	loss/total_loss, 6.649375915527344, 2540
[INFO] 2021-07-12 19:23:35,730 [run_pretraining.py:  535]:	loss/mlm_loss, 6.649375915527344, 2540
[INFO] 2021-07-12 19:23:35,730 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5389997972524725e-05, 2540
[INFO] 2021-07-12 19:23:35,730 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2540
[INFO] 2021-07-12 19:23:35,730 [run_pretraining.py:  558]:	worker_index: 7, step: 2540, cost: 6.649376, mlm loss: 6.649376, speed: 0.951570 steps/s, speed: 7.612559 samples/s, speed: 3897.630206 tokens/s, learning rate: 2.539e-05, loss_scalings: 2814.750488, pp_loss: 7.122746
[INFO] 2021-07-12 19:23:35,730 [run_pretraining.py:  512]:	********exe.run_2540******* 
[INFO] 2021-07-12 19:23:36,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:36,790 [run_pretraining.py:  534]:	loss/total_loss, 7.1542649269104, 2541
[INFO] 2021-07-12 19:23:36,790 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1542649269104, 2541
[INFO] 2021-07-12 19:23:36,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5400000595254824e-05, 2541
[INFO] 2021-07-12 19:23:36,790 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2541
[INFO] 2021-07-12 19:23:36,790 [run_pretraining.py:  558]:	worker_index: 7, step: 2541, cost: 7.154265, mlm loss: 7.154265, speed: 0.944332 steps/s, speed: 7.554657 samples/s, speed: 3867.984369 tokens/s, learning rate: 2.540e-05, loss_scalings: 2814.750488, pp_loss: 7.584620
[INFO] 2021-07-12 19:23:36,790 [run_pretraining.py:  512]:	********exe.run_2541******* 
[INFO] 2021-07-12 19:23:37,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:37,830 [run_pretraining.py:  534]:	loss/total_loss, 6.809821128845215, 2542
[INFO] 2021-07-12 19:23:37,830 [run_pretraining.py:  535]:	loss/mlm_loss, 6.809821128845215, 2542
[INFO] 2021-07-12 19:23:37,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5409999580006115e-05, 2542
[INFO] 2021-07-12 19:23:37,830 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2542
[INFO] 2021-07-12 19:23:37,830 [run_pretraining.py:  558]:	worker_index: 7, step: 2542, cost: 6.809821, mlm loss: 6.809821, speed: 0.962199 steps/s, speed: 7.697593 samples/s, speed: 3941.167687 tokens/s, learning rate: 2.541e-05, loss_scalings: 2814.750488, pp_loss: 7.133925
[INFO] 2021-07-12 19:23:37,830 [run_pretraining.py:  512]:	********exe.run_2542******* 
[INFO] 2021-07-12 19:23:38,878 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:38,879 [run_pretraining.py:  534]:	loss/total_loss, 7.588011741638184, 2543
[INFO] 2021-07-12 19:23:38,879 [run_pretraining.py:  535]:	loss/mlm_loss, 7.588011741638184, 2543
[INFO] 2021-07-12 19:23:38,879 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.542000038374681e-05, 2543
[INFO] 2021-07-12 19:23:38,879 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2543
[INFO] 2021-07-12 19:23:38,879 [run_pretraining.py:  558]:	worker_index: 7, step: 2543, cost: 7.588012, mlm loss: 7.588012, speed: 0.953520 steps/s, speed: 7.628164 samples/s, speed: 3905.619949 tokens/s, learning rate: 2.542e-05, loss_scalings: 2814.750488, pp_loss: 7.578812
[INFO] 2021-07-12 19:23:38,879 [run_pretraining.py:  512]:	********exe.run_2543******* 
[INFO] 2021-07-12 19:23:39,932 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:39,933 [run_pretraining.py:  534]:	loss/total_loss, 7.047055244445801, 2544
[INFO] 2021-07-12 19:23:39,933 [run_pretraining.py:  535]:	loss/mlm_loss, 7.047055244445801, 2544
[INFO] 2021-07-12 19:23:39,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5429999368498102e-05, 2544
[INFO] 2021-07-12 19:23:39,933 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2544
[INFO] 2021-07-12 19:23:39,933 [run_pretraining.py:  558]:	worker_index: 7, step: 2544, cost: 7.047055, mlm loss: 7.047055, speed: 0.949671 steps/s, speed: 7.597369 samples/s, speed: 3889.852747 tokens/s, learning rate: 2.543e-05, loss_scalings: 2814.750488, pp_loss: 7.120094
[INFO] 2021-07-12 19:23:39,933 [run_pretraining.py:  512]:	********exe.run_2544******* 
[INFO] 2021-07-12 19:23:40,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:40,984 [run_pretraining.py:  534]:	loss/total_loss, 6.593929767608643, 2545
[INFO] 2021-07-12 19:23:40,984 [run_pretraining.py:  535]:	loss/mlm_loss, 6.593929767608643, 2545
[INFO] 2021-07-12 19:23:40,984 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5440000172238797e-05, 2545
[INFO] 2021-07-12 19:23:40,984 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2545
[INFO] 2021-07-12 19:23:40,984 [run_pretraining.py:  558]:	worker_index: 7, step: 2545, cost: 6.593930, mlm loss: 6.593930, speed: 0.952054 steps/s, speed: 7.616430 samples/s, speed: 3899.611962 tokens/s, learning rate: 2.544e-05, loss_scalings: 2814.750488, pp_loss: 7.113186
[INFO] 2021-07-12 19:23:40,984 [run_pretraining.py:  512]:	********exe.run_2545******* 
[INFO] 2021-07-12 19:23:42,034 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:42,035 [run_pretraining.py:  534]:	loss/total_loss, 6.742956638336182, 2546
[INFO] 2021-07-12 19:23:42,035 [run_pretraining.py:  535]:	loss/mlm_loss, 6.742956638336182, 2546
[INFO] 2021-07-12 19:23:42,035 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.544999915699009e-05, 2546
[INFO] 2021-07-12 19:23:42,035 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2546
[INFO] 2021-07-12 19:23:42,035 [run_pretraining.py:  558]:	worker_index: 7, step: 2546, cost: 6.742957, mlm loss: 6.742957, speed: 0.951948 steps/s, speed: 7.615581 samples/s, speed: 3899.177395 tokens/s, learning rate: 2.545e-05, loss_scalings: 2814.750488, pp_loss: 7.013511
[INFO] 2021-07-12 19:23:42,035 [run_pretraining.py:  512]:	********exe.run_2546******* 
[INFO] 2021-07-12 19:23:43,094 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:43,094 [run_pretraining.py:  534]:	loss/total_loss, 6.161545276641846, 2547
[INFO] 2021-07-12 19:23:43,094 [run_pretraining.py:  535]:	loss/mlm_loss, 6.161545276641846, 2547
[INFO] 2021-07-12 19:23:43,094 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.545999814174138e-05, 2547
[INFO] 2021-07-12 19:23:43,094 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2547
[INFO] 2021-07-12 19:23:43,094 [run_pretraining.py:  558]:	worker_index: 7, step: 2547, cost: 6.161545, mlm loss: 6.161545, speed: 0.944561 steps/s, speed: 7.556484 samples/s, speed: 3868.919902 tokens/s, learning rate: 2.546e-05, loss_scalings: 2814.750488, pp_loss: 6.726325
[INFO] 2021-07-12 19:23:43,095 [run_pretraining.py:  512]:	********exe.run_2547******* 
[INFO] 2021-07-12 19:23:44,148 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:44,148 [run_pretraining.py:  534]:	loss/total_loss, 7.182452201843262, 2548
[INFO] 2021-07-12 19:23:44,148 [run_pretraining.py:  535]:	loss/mlm_loss, 7.182452201843262, 2548
[INFO] 2021-07-12 19:23:44,149 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.547000076447148e-05, 2548
[INFO] 2021-07-12 19:23:44,149 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2548
[INFO] 2021-07-12 19:23:44,149 [run_pretraining.py:  558]:	worker_index: 7, step: 2548, cost: 7.182452, mlm loss: 7.182452, speed: 0.949105 steps/s, speed: 7.592840 samples/s, speed: 3887.534267 tokens/s, learning rate: 2.547e-05, loss_scalings: 2814.750488, pp_loss: 7.396114
[INFO] 2021-07-12 19:23:44,149 [run_pretraining.py:  512]:	********exe.run_2548******* 
[INFO] 2021-07-12 19:23:45,216 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:45,216 [run_pretraining.py:  534]:	loss/total_loss, 7.480817794799805, 2549
[INFO] 2021-07-12 19:23:45,217 [run_pretraining.py:  535]:	loss/mlm_loss, 7.480817794799805, 2549
[INFO] 2021-07-12 19:23:45,217 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5479997930233367e-05, 2549
[INFO] 2021-07-12 19:23:45,217 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2549
[INFO] 2021-07-12 19:23:45,217 [run_pretraining.py:  558]:	worker_index: 7, step: 2549, cost: 7.480818, mlm loss: 7.480818, speed: 0.936865 steps/s, speed: 7.494916 samples/s, speed: 3837.397033 tokens/s, learning rate: 2.548e-05, loss_scalings: 2814.750488, pp_loss: 7.184446
[INFO] 2021-07-12 19:23:45,217 [run_pretraining.py:  512]:	********exe.run_2549******* 
[INFO] 2021-07-12 19:23:46,292 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:46,292 [run_pretraining.py:  534]:	loss/total_loss, 7.47821044921875, 2550
[INFO] 2021-07-12 19:23:46,292 [run_pretraining.py:  535]:	loss/mlm_loss, 7.47821044921875, 2550
[INFO] 2021-07-12 19:23:46,292 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5490000552963465e-05, 2550
[INFO] 2021-07-12 19:23:46,292 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2550
[INFO] 2021-07-12 19:23:46,292 [run_pretraining.py:  558]:	worker_index: 7, step: 2550, cost: 7.478210, mlm loss: 7.478210, speed: 0.930238 steps/s, speed: 7.441901 samples/s, speed: 3810.253516 tokens/s, learning rate: 2.549e-05, loss_scalings: 2814.750488, pp_loss: 7.341145
[INFO] 2021-07-12 19:23:46,292 [run_pretraining.py:  512]:	********exe.run_2550******* 
[INFO] 2021-07-12 19:23:47,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:47,348 [run_pretraining.py:  534]:	loss/total_loss, 6.861946105957031, 2551
[INFO] 2021-07-12 19:23:47,348 [run_pretraining.py:  535]:	loss/mlm_loss, 6.861946105957031, 2551
[INFO] 2021-07-12 19:23:47,348 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5499999537714757e-05, 2551
[INFO] 2021-07-12 19:23:47,348 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2551
[INFO] 2021-07-12 19:23:47,348 [run_pretraining.py:  558]:	worker_index: 7, step: 2551, cost: 6.861946, mlm loss: 6.861946, speed: 0.947490 steps/s, speed: 7.579916 samples/s, speed: 3880.917102 tokens/s, learning rate: 2.550e-05, loss_scalings: 2814.750488, pp_loss: 6.996799
[INFO] 2021-07-12 19:23:47,349 [run_pretraining.py:  512]:	********exe.run_2551******* 
[INFO] 2021-07-12 19:23:48,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:48,403 [run_pretraining.py:  534]:	loss/total_loss, 6.660604953765869, 2552
[INFO] 2021-07-12 19:23:48,403 [run_pretraining.py:  535]:	loss/mlm_loss, 6.660604953765869, 2552
[INFO] 2021-07-12 19:23:48,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5510000341455452e-05, 2552
[INFO] 2021-07-12 19:23:48,403 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2552
[INFO] 2021-07-12 19:23:48,403 [run_pretraining.py:  558]:	worker_index: 7, step: 2552, cost: 6.660605, mlm loss: 6.660605, speed: 0.948934 steps/s, speed: 7.591475 samples/s, speed: 3886.835041 tokens/s, learning rate: 2.551e-05, loss_scalings: 2814.750488, pp_loss: 7.092144
[INFO] 2021-07-12 19:23:48,403 [run_pretraining.py:  512]:	********exe.run_2552******* 
[INFO] 2021-07-12 19:23:49,459 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:49,460 [run_pretraining.py:  534]:	loss/total_loss, 7.797600746154785, 2553
[INFO] 2021-07-12 19:23:49,460 [run_pretraining.py:  535]:	loss/mlm_loss, 7.797600746154785, 2553
[INFO] 2021-07-12 19:23:49,460 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5519999326206744e-05, 2553
[INFO] 2021-07-12 19:23:49,460 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2553
[INFO] 2021-07-12 19:23:49,460 [run_pretraining.py:  558]:	worker_index: 7, step: 2553, cost: 7.797601, mlm loss: 7.797601, speed: 0.946674 steps/s, speed: 7.573393 samples/s, speed: 3877.577138 tokens/s, learning rate: 2.552e-05, loss_scalings: 2814.750488, pp_loss: 7.609547
[INFO] 2021-07-12 19:23:49,460 [run_pretraining.py:  512]:	********exe.run_2553******* 
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  534]:	loss/total_loss, 6.708158493041992, 2554
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  535]:	loss/mlm_loss, 6.708158493041992, 2554
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5529998310958035e-05, 2554
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2554
[INFO] 2021-07-12 19:23:50,509 [run_pretraining.py:  558]:	worker_index: 7, step: 2554, cost: 6.708158, mlm loss: 6.708158, speed: 0.953334 steps/s, speed: 7.626669 samples/s, speed: 3904.854736 tokens/s, learning rate: 2.553e-05, loss_scalings: 2814.750488, pp_loss: 7.008930
[INFO] 2021-07-12 19:23:50,510 [run_pretraining.py:  512]:	********exe.run_2554******* 
[INFO] 2021-07-12 19:23:51,561 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:51,561 [run_pretraining.py:  534]:	loss/total_loss, 7.200835704803467, 2555
[INFO] 2021-07-12 19:23:51,561 [run_pretraining.py:  535]:	loss/mlm_loss, 7.200835704803467, 2555
[INFO] 2021-07-12 19:23:51,561 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.553999911469873e-05, 2555
[INFO] 2021-07-12 19:23:51,561 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2555
[INFO] 2021-07-12 19:23:51,561 [run_pretraining.py:  558]:	worker_index: 7, step: 2555, cost: 7.200836, mlm loss: 7.200836, speed: 0.951208 steps/s, speed: 7.609666 samples/s, speed: 3896.148744 tokens/s, learning rate: 2.554e-05, loss_scalings: 2814.750488, pp_loss: 7.092885
[INFO] 2021-07-12 19:23:51,562 [run_pretraining.py:  512]:	********exe.run_2555******* 
[INFO] 2021-07-12 19:23:52,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  534]:	loss/total_loss, 7.284019470214844, 2556
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  535]:	loss/mlm_loss, 7.284019470214844, 2556
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5549998099450022e-05, 2556
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2556
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  558]:	worker_index: 7, step: 2556, cost: 7.284019, mlm loss: 7.284019, speed: 1.018270 steps/s, speed: 8.146164 samples/s, speed: 4170.835920 tokens/s, learning rate: 2.555e-05, loss_scalings: 2814.750488, pp_loss: 7.425215
[INFO] 2021-07-12 19:23:52,544 [run_pretraining.py:  512]:	********exe.run_2556******* 
[INFO] 2021-07-12 19:23:53,510 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:53,511 [run_pretraining.py:  534]:	loss/total_loss, 7.619953632354736, 2557
[INFO] 2021-07-12 19:23:53,511 [run_pretraining.py:  535]:	loss/mlm_loss, 7.619953632354736, 2557
[INFO] 2021-07-12 19:23:53,511 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.556000072218012e-05, 2557
[INFO] 2021-07-12 19:23:53,511 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2557
[INFO] 2021-07-12 19:23:53,511 [run_pretraining.py:  558]:	worker_index: 7, step: 2557, cost: 7.619954, mlm loss: 7.619954, speed: 1.034629 steps/s, speed: 8.277032 samples/s, speed: 4237.840151 tokens/s, learning rate: 2.556e-05, loss_scalings: 2814.750488, pp_loss: 7.397552
[INFO] 2021-07-12 19:23:53,511 [run_pretraining.py:  512]:	********exe.run_2557******* 
[INFO] 2021-07-12 19:23:54,486 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:54,487 [run_pretraining.py:  534]:	loss/total_loss, 6.689062595367432, 2558
[INFO] 2021-07-12 19:23:54,487 [run_pretraining.py:  535]:	loss/mlm_loss, 6.689062595367432, 2558
[INFO] 2021-07-12 19:23:54,487 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.556999788794201e-05, 2558
[INFO] 2021-07-12 19:23:54,487 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2558
[INFO] 2021-07-12 19:23:54,487 [run_pretraining.py:  558]:	worker_index: 7, step: 2558, cost: 6.689063, mlm loss: 6.689063, speed: 1.025439 steps/s, speed: 8.203508 samples/s, speed: 4200.196170 tokens/s, learning rate: 2.557e-05, loss_scalings: 2814.750488, pp_loss: 7.276985
[INFO] 2021-07-12 19:23:54,487 [run_pretraining.py:  512]:	********exe.run_2558******* 
[INFO] 2021-07-12 19:23:55,469 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:55,470 [run_pretraining.py:  534]:	loss/total_loss, 6.988919734954834, 2559
[INFO] 2021-07-12 19:23:55,470 [run_pretraining.py:  535]:	loss/mlm_loss, 6.988919734954834, 2559
[INFO] 2021-07-12 19:23:55,470 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5580000510672107e-05, 2559
[INFO] 2021-07-12 19:23:55,470 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2559
[INFO] 2021-07-12 19:23:55,470 [run_pretraining.py:  558]:	worker_index: 7, step: 2559, cost: 6.988920, mlm loss: 6.988920, speed: 1.018139 steps/s, speed: 8.145114 samples/s, speed: 4170.298313 tokens/s, learning rate: 2.558e-05, loss_scalings: 2814.750488, pp_loss: 7.053038
[INFO] 2021-07-12 19:23:55,470 [run_pretraining.py:  512]:	********exe.run_2559******* 
[INFO] 2021-07-12 19:23:56,439 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:56,440 [run_pretraining.py:  534]:	loss/total_loss, 6.961167812347412, 2560
[INFO] 2021-07-12 19:23:56,440 [run_pretraining.py:  535]:	loss/mlm_loss, 6.961167812347412, 2560
[INFO] 2021-07-12 19:23:56,440 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.55899994954234e-05, 2560
[INFO] 2021-07-12 19:23:56,440 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2560
[INFO] 2021-07-12 19:23:56,440 [run_pretraining.py:  558]:	worker_index: 7, step: 2560, cost: 6.961168, mlm loss: 6.961168, speed: 1.031778 steps/s, speed: 8.254227 samples/s, speed: 4226.164285 tokens/s, learning rate: 2.559e-05, loss_scalings: 2814.750488, pp_loss: 7.382720
[INFO] 2021-07-12 19:23:56,440 [run_pretraining.py:  512]:	********exe.run_2560******* 
[INFO] 2021-07-12 19:23:57,411 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:57,412 [run_pretraining.py:  534]:	loss/total_loss, 7.712163925170898, 2561
[INFO] 2021-07-12 19:23:57,412 [run_pretraining.py:  535]:	loss/mlm_loss, 7.712163925170898, 2561
[INFO] 2021-07-12 19:23:57,412 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5600000299164094e-05, 2561
[INFO] 2021-07-12 19:23:57,412 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2561
[INFO] 2021-07-12 19:23:57,412 [run_pretraining.py:  558]:	worker_index: 7, step: 2561, cost: 7.712164, mlm loss: 7.712164, speed: 1.029116 steps/s, speed: 8.232931 samples/s, speed: 4215.260927 tokens/s, learning rate: 2.560e-05, loss_scalings: 2814.750488, pp_loss: 7.181475
[INFO] 2021-07-12 19:23:57,412 [run_pretraining.py:  512]:	********exe.run_2561******* 
[INFO] 2021-07-12 19:23:58,401 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:58,401 [run_pretraining.py:  534]:	loss/total_loss, 7.000906944274902, 2562
[INFO] 2021-07-12 19:23:58,401 [run_pretraining.py:  535]:	loss/mlm_loss, 7.000906944274902, 2562
[INFO] 2021-07-12 19:23:58,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5609999283915386e-05, 2562
[INFO] 2021-07-12 19:23:58,401 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2562
[INFO] 2021-07-12 19:23:58,402 [run_pretraining.py:  558]:	worker_index: 7, step: 2562, cost: 7.000907, mlm loss: 7.000907, speed: 1.011517 steps/s, speed: 8.092134 samples/s, speed: 4143.172837 tokens/s, learning rate: 2.561e-05, loss_scalings: 2814.750488, pp_loss: 6.841873
[INFO] 2021-07-12 19:23:58,402 [run_pretraining.py:  512]:	********exe.run_2562******* 
[INFO] 2021-07-12 19:23:59,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:23:59,389 [run_pretraining.py:  534]:	loss/total_loss, 6.6098551750183105, 2563
[INFO] 2021-07-12 19:23:59,390 [run_pretraining.py:  535]:	loss/mlm_loss, 6.6098551750183105, 2563
[INFO] 2021-07-12 19:23:59,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5619998268666677e-05, 2563
[INFO] 2021-07-12 19:23:59,390 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2563
[INFO] 2021-07-12 19:23:59,390 [run_pretraining.py:  558]:	worker_index: 7, step: 2563, cost: 6.609855, mlm loss: 6.609855, speed: 1.012507 steps/s, speed: 8.100060 samples/s, speed: 4147.230504 tokens/s, learning rate: 2.562e-05, loss_scalings: 2814.750488, pp_loss: 7.016095
[INFO] 2021-07-12 19:23:59,390 [run_pretraining.py:  512]:	********exe.run_2563******* 
[INFO] 2021-07-12 19:24:00,367 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  534]:	loss/total_loss, 7.004575729370117, 2564
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  535]:	loss/mlm_loss, 7.004575729370117, 2564
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5629999072407372e-05, 2564
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2564
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  558]:	worker_index: 7, step: 2564, cost: 7.004576, mlm loss: 7.004576, speed: 1.023140 steps/s, speed: 8.185122 samples/s, speed: 4190.782351 tokens/s, learning rate: 2.563e-05, loss_scalings: 2814.750488, pp_loss: 7.332241
[INFO] 2021-07-12 19:24:00,368 [run_pretraining.py:  512]:	********exe.run_2564******* 
[INFO] 2021-07-12 19:24:01,358 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:01,359 [run_pretraining.py:  534]:	loss/total_loss, 7.300565242767334, 2565
[INFO] 2021-07-12 19:24:01,359 [run_pretraining.py:  535]:	loss/mlm_loss, 7.300565242767334, 2565
[INFO] 2021-07-12 19:24:01,359 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5639998057158664e-05, 2565
[INFO] 2021-07-12 19:24:01,359 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2565
[INFO] 2021-07-12 19:24:01,359 [run_pretraining.py:  558]:	worker_index: 7, step: 2565, cost: 7.300565, mlm loss: 7.300565, speed: 1.009496 steps/s, speed: 8.075967 samples/s, speed: 4134.895167 tokens/s, learning rate: 2.564e-05, loss_scalings: 2814.750488, pp_loss: 7.219134
[INFO] 2021-07-12 19:24:01,359 [run_pretraining.py:  512]:	********exe.run_2565******* 
[INFO] 2021-07-12 19:24:02,334 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:02,334 [run_pretraining.py:  534]:	loss/total_loss, 7.392230033874512, 2566
[INFO] 2021-07-12 19:24:02,334 [run_pretraining.py:  535]:	loss/mlm_loss, 7.392230033874512, 2566
[INFO] 2021-07-12 19:24:02,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5650000679888763e-05, 2566
[INFO] 2021-07-12 19:24:02,334 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2566
[INFO] 2021-07-12 19:24:02,334 [run_pretraining.py:  558]:	worker_index: 7, step: 2566, cost: 7.392230, mlm loss: 7.392230, speed: 1.025960 steps/s, speed: 8.207682 samples/s, speed: 4202.333165 tokens/s, learning rate: 2.565e-05, loss_scalings: 2814.750488, pp_loss: 7.480130
[INFO] 2021-07-12 19:24:02,335 [run_pretraining.py:  512]:	********exe.run_2566******* 
[INFO] 2021-07-12 19:24:03,305 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:03,306 [run_pretraining.py:  534]:	loss/total_loss, 6.831969261169434, 2567
[INFO] 2021-07-12 19:24:03,306 [run_pretraining.py:  535]:	loss/mlm_loss, 6.831969261169434, 2567
[INFO] 2021-07-12 19:24:03,306 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.565999784565065e-05, 2567
[INFO] 2021-07-12 19:24:03,306 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2567
[INFO] 2021-07-12 19:24:03,306 [run_pretraining.py:  558]:	worker_index: 7, step: 2567, cost: 6.831969, mlm loss: 6.831969, speed: 1.030100 steps/s, speed: 8.240797 samples/s, speed: 4219.288036 tokens/s, learning rate: 2.566e-05, loss_scalings: 2814.750488, pp_loss: 7.093399
[INFO] 2021-07-12 19:24:03,306 [run_pretraining.py:  512]:	********exe.run_2567******* 
[INFO] 2021-07-12 19:24:04,279 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  534]:	loss/total_loss, 7.687307834625244, 2568
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  535]:	loss/mlm_loss, 7.687307834625244, 2568
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.567000046838075e-05, 2568
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2568
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  558]:	worker_index: 7, step: 2568, cost: 7.687308, mlm loss: 7.687308, speed: 1.027165 steps/s, speed: 8.217318 samples/s, speed: 4207.266819 tokens/s, learning rate: 2.567e-05, loss_scalings: 2814.750488, pp_loss: 7.225435
[INFO] 2021-07-12 19:24:04,280 [run_pretraining.py:  512]:	********exe.run_2568******* 
[INFO] 2021-07-12 19:24:05,248 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:05,248 [run_pretraining.py:  534]:	loss/total_loss, 7.453196048736572, 2569
[INFO] 2021-07-12 19:24:05,248 [run_pretraining.py:  535]:	loss/mlm_loss, 7.453196048736572, 2569
[INFO] 2021-07-12 19:24:05,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.567999945313204e-05, 2569
[INFO] 2021-07-12 19:24:05,248 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2569
[INFO] 2021-07-12 19:24:05,248 [run_pretraining.py:  558]:	worker_index: 7, step: 2569, cost: 7.453196, mlm loss: 7.453196, speed: 1.033379 steps/s, speed: 8.267035 samples/s, speed: 4232.721945 tokens/s, learning rate: 2.568e-05, loss_scalings: 2814.750488, pp_loss: 7.349852
[INFO] 2021-07-12 19:24:05,249 [run_pretraining.py:  512]:	********exe.run_2569******* 
[INFO] 2021-07-12 19:24:06,239 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:06,240 [run_pretraining.py:  534]:	loss/total_loss, 6.748946189880371, 2570
[INFO] 2021-07-12 19:24:06,240 [run_pretraining.py:  535]:	loss/mlm_loss, 6.748946189880371, 2570
[INFO] 2021-07-12 19:24:06,240 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5690000256872736e-05, 2570
[INFO] 2021-07-12 19:24:06,240 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2570
[INFO] 2021-07-12 19:24:06,240 [run_pretraining.py:  558]:	worker_index: 7, step: 2570, cost: 6.748946, mlm loss: 6.748946, speed: 1.009305 steps/s, speed: 8.074440 samples/s, speed: 4134.113090 tokens/s, learning rate: 2.569e-05, loss_scalings: 2814.750488, pp_loss: 7.124698
[INFO] 2021-07-12 19:24:06,240 [run_pretraining.py:  512]:	********exe.run_2570******* 
[INFO] 2021-07-12 19:24:07,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:07,234 [run_pretraining.py:  534]:	loss/total_loss, 7.563365936279297, 2571
[INFO] 2021-07-12 19:24:07,235 [run_pretraining.py:  535]:	loss/mlm_loss, 7.563365936279297, 2571
[INFO] 2021-07-12 19:24:07,235 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5699999241624027e-05, 2571
[INFO] 2021-07-12 19:24:07,235 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2571
[INFO] 2021-07-12 19:24:07,235 [run_pretraining.py:  558]:	worker_index: 7, step: 2571, cost: 7.563366, mlm loss: 7.563366, speed: 1.005846 steps/s, speed: 8.046765 samples/s, speed: 4119.943842 tokens/s, learning rate: 2.570e-05, loss_scalings: 2814.750488, pp_loss: 7.390538
[INFO] 2021-07-12 19:24:07,235 [run_pretraining.py:  512]:	********exe.run_2571******* 
[INFO] 2021-07-12 19:24:08,213 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  534]:	loss/total_loss, 7.195373058319092, 2572
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  535]:	loss/mlm_loss, 7.195373058319092, 2572
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.570999822637532e-05, 2572
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2572
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  558]:	worker_index: 7, step: 2572, cost: 7.195373, mlm loss: 7.195373, speed: 1.021521 steps/s, speed: 8.172166 samples/s, speed: 4184.149062 tokens/s, learning rate: 2.571e-05, loss_scalings: 2814.750488, pp_loss: 7.116499
[INFO] 2021-07-12 19:24:08,214 [run_pretraining.py:  512]:	********exe.run_2572******* 
[INFO] 2021-07-12 19:24:09,194 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:09,195 [run_pretraining.py:  534]:	loss/total_loss, 6.589648246765137, 2573
[INFO] 2021-07-12 19:24:09,195 [run_pretraining.py:  535]:	loss/mlm_loss, 6.589648246765137, 2573
[INFO] 2021-07-12 19:24:09,195 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5719999030116014e-05, 2573
[INFO] 2021-07-12 19:24:09,195 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2573
[INFO] 2021-07-12 19:24:09,195 [run_pretraining.py:  558]:	worker_index: 7, step: 2573, cost: 6.589648, mlm loss: 6.589648, speed: 1.020200 steps/s, speed: 8.161599 samples/s, speed: 4178.738810 tokens/s, learning rate: 2.572e-05, loss_scalings: 2814.750488, pp_loss: 7.116129
[INFO] 2021-07-12 19:24:09,195 [run_pretraining.py:  512]:	********exe.run_2573******* 
[INFO] 2021-07-12 19:24:10,168 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:10,169 [run_pretraining.py:  534]:	loss/total_loss, 7.245909690856934, 2574
[INFO] 2021-07-12 19:24:10,169 [run_pretraining.py:  535]:	loss/mlm_loss, 7.245909690856934, 2574
[INFO] 2021-07-12 19:24:10,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5729998014867306e-05, 2574
[INFO] 2021-07-12 19:24:10,169 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2574
[INFO] 2021-07-12 19:24:10,169 [run_pretraining.py:  558]:	worker_index: 7, step: 2574, cost: 7.245910, mlm loss: 7.245910, speed: 1.027493 steps/s, speed: 8.219945 samples/s, speed: 4208.611842 tokens/s, learning rate: 2.573e-05, loss_scalings: 2814.750488, pp_loss: 7.268715
[INFO] 2021-07-12 19:24:10,169 [run_pretraining.py:  512]:	********exe.run_2574******* 
[INFO] 2021-07-12 19:24:11,128 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:11,129 [run_pretraining.py:  534]:	loss/total_loss, 6.892135143280029, 2575
[INFO] 2021-07-12 19:24:11,129 [run_pretraining.py:  535]:	loss/mlm_loss, 6.892135143280029, 2575
[INFO] 2021-07-12 19:24:11,129 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5740000637597404e-05, 2575
[INFO] 2021-07-12 19:24:11,129 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2575
[INFO] 2021-07-12 19:24:11,129 [run_pretraining.py:  558]:	worker_index: 7, step: 2575, cost: 6.892135, mlm loss: 6.892135, speed: 1.042422 steps/s, speed: 8.339372 samples/s, speed: 4269.758641 tokens/s, learning rate: 2.574e-05, loss_scalings: 2814.750488, pp_loss: 7.047576
[INFO] 2021-07-12 19:24:11,129 [run_pretraining.py:  512]:	********exe.run_2575******* 
[INFO] 2021-07-12 19:24:12,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:12,036 [run_pretraining.py:  534]:	loss/total_loss, 7.526761054992676, 2576
[INFO] 2021-07-12 19:24:12,036 [run_pretraining.py:  535]:	loss/mlm_loss, 7.526761054992676, 2576
[INFO] 2021-07-12 19:24:12,036 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5749997803359292e-05, 2576
[INFO] 2021-07-12 19:24:12,036 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2576
[INFO] 2021-07-12 19:24:12,037 [run_pretraining.py:  558]:	worker_index: 7, step: 2576, cost: 7.526761, mlm loss: 7.526761, speed: 1.102660 steps/s, speed: 8.821278 samples/s, speed: 4516.494580 tokens/s, learning rate: 2.575e-05, loss_scalings: 2814.750488, pp_loss: 7.349711
[INFO] 2021-07-12 19:24:12,037 [run_pretraining.py:  512]:	********exe.run_2576******* 
[INFO] 2021-07-12 19:24:12,944 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:12,945 [run_pretraining.py:  534]:	loss/total_loss, 7.009067535400391, 2577
[INFO] 2021-07-12 19:24:12,945 [run_pretraining.py:  535]:	loss/mlm_loss, 7.009067535400391, 2577
[INFO] 2021-07-12 19:24:12,945 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.576000042608939e-05, 2577
[INFO] 2021-07-12 19:24:12,945 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2577
[INFO] 2021-07-12 19:24:12,945 [run_pretraining.py:  558]:	worker_index: 7, step: 2577, cost: 7.009068, mlm loss: 7.009068, speed: 1.101455 steps/s, speed: 8.811639 samples/s, speed: 4511.559366 tokens/s, learning rate: 2.576e-05, loss_scalings: 2814.750488, pp_loss: 6.994872
[INFO] 2021-07-12 19:24:12,945 [run_pretraining.py:  512]:	********exe.run_2577******* 
[INFO] 2021-07-12 19:24:13,852 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  534]:	loss/total_loss, 6.764126777648926, 2578
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  535]:	loss/mlm_loss, 6.764126777648926, 2578
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5769999410840683e-05, 2578
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2578
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  558]:	worker_index: 7, step: 2578, cost: 6.764127, mlm loss: 6.764127, speed: 1.101900 steps/s, speed: 8.815202 samples/s, speed: 4513.383462 tokens/s, learning rate: 2.577e-05, loss_scalings: 2814.750488, pp_loss: 7.206697
[INFO] 2021-07-12 19:24:13,853 [run_pretraining.py:  512]:	********exe.run_2578******* 
[INFO] 2021-07-12 19:24:14,770 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:14,770 [run_pretraining.py:  534]:	loss/total_loss, 7.198057651519775, 2579
[INFO] 2021-07-12 19:24:14,770 [run_pretraining.py:  535]:	loss/mlm_loss, 7.198057651519775, 2579
[INFO] 2021-07-12 19:24:14,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5780000214581378e-05, 2579
[INFO] 2021-07-12 19:24:14,770 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2579
[INFO] 2021-07-12 19:24:14,770 [run_pretraining.py:  558]:	worker_index: 7, step: 2579, cost: 7.198058, mlm loss: 7.198058, speed: 1.091038 steps/s, speed: 8.728307 samples/s, speed: 4468.893270 tokens/s, learning rate: 2.578e-05, loss_scalings: 2814.750488, pp_loss: 7.205164
[INFO] 2021-07-12 19:24:14,771 [run_pretraining.py:  512]:	********exe.run_2579******* 
[INFO] 2021-07-12 19:24:15,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:15,680 [run_pretraining.py:  534]:	loss/total_loss, 7.70540189743042, 2580
[INFO] 2021-07-12 19:24:15,680 [run_pretraining.py:  535]:	loss/mlm_loss, 7.70540189743042, 2580
[INFO] 2021-07-12 19:24:15,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.578999919933267e-05, 2580
[INFO] 2021-07-12 19:24:15,680 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2580
[INFO] 2021-07-12 19:24:15,680 [run_pretraining.py:  558]:	worker_index: 7, step: 2580, cost: 7.705402, mlm loss: 7.705402, speed: 1.100186 steps/s, speed: 8.801486 samples/s, speed: 4506.360675 tokens/s, learning rate: 2.579e-05, loss_scalings: 2814.750488, pp_loss: 7.514239
[INFO] 2021-07-12 19:24:15,680 [run_pretraining.py:  512]:	********exe.run_2580******* 
[INFO] 2021-07-12 19:24:16,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:16,587 [run_pretraining.py:  534]:	loss/total_loss, 6.817678928375244, 2581
[INFO] 2021-07-12 19:24:16,587 [run_pretraining.py:  535]:	loss/mlm_loss, 6.817678928375244, 2581
[INFO] 2021-07-12 19:24:16,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.579999818408396e-05, 2581
[INFO] 2021-07-12 19:24:16,587 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2581
[INFO] 2021-07-12 19:24:16,587 [run_pretraining.py:  558]:	worker_index: 7, step: 2581, cost: 6.817679, mlm loss: 6.817679, speed: 1.102868 steps/s, speed: 8.822944 samples/s, speed: 4517.347267 tokens/s, learning rate: 2.580e-05, loss_scalings: 2814.750488, pp_loss: 7.306306
[INFO] 2021-07-12 19:24:16,588 [run_pretraining.py:  512]:	********exe.run_2581******* 
[INFO] 2021-07-12 19:24:17,501 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:17,502 [run_pretraining.py:  534]:	loss/total_loss, 7.58551549911499, 2582
[INFO] 2021-07-12 19:24:17,502 [run_pretraining.py:  535]:	loss/mlm_loss, 7.58551549911499, 2582
[INFO] 2021-07-12 19:24:17,502 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5809998987824656e-05, 2582
[INFO] 2021-07-12 19:24:17,502 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2582
[INFO] 2021-07-12 19:24:17,502 [run_pretraining.py:  558]:	worker_index: 7, step: 2582, cost: 7.585515, mlm loss: 7.585515, speed: 1.094295 steps/s, speed: 8.754363 samples/s, speed: 4482.233908 tokens/s, learning rate: 2.581e-05, loss_scalings: 2814.750488, pp_loss: 6.944022
[INFO] 2021-07-12 19:24:17,502 [run_pretraining.py:  512]:	********exe.run_2582******* 
[INFO] 2021-07-12 19:24:18,414 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:18,414 [run_pretraining.py:  534]:	loss/total_loss, 7.10581111907959, 2583
[INFO] 2021-07-12 19:24:18,414 [run_pretraining.py:  535]:	loss/mlm_loss, 7.10581111907959, 2583
[INFO] 2021-07-12 19:24:18,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5819997972575948e-05, 2583
[INFO] 2021-07-12 19:24:18,414 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2583
[INFO] 2021-07-12 19:24:18,414 [run_pretraining.py:  558]:	worker_index: 7, step: 2583, cost: 7.105811, mlm loss: 7.105811, speed: 1.096722 steps/s, speed: 8.773777 samples/s, speed: 4492.173722 tokens/s, learning rate: 2.582e-05, loss_scalings: 2814.750488, pp_loss: 7.478905
[INFO] 2021-07-12 19:24:18,414 [run_pretraining.py:  512]:	********exe.run_2583******* 
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  534]:	loss/total_loss, 7.252202987670898, 2584
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  535]:	loss/mlm_loss, 7.252202987670898, 2584
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5830000595306046e-05, 2584
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2584
[INFO] 2021-07-12 19:24:19,338 [run_pretraining.py:  558]:	worker_index: 7, step: 2584, cost: 7.252203, mlm loss: 7.252203, speed: 1.082909 steps/s, speed: 8.663273 samples/s, speed: 4435.595638 tokens/s, learning rate: 2.583e-05, loss_scalings: 2814.750488, pp_loss: 7.049264
[INFO] 2021-07-12 19:24:19,339 [run_pretraining.py:  512]:	********exe.run_2584******* 
[INFO] 2021-07-12 19:24:20,247 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:20,248 [run_pretraining.py:  534]:	loss/total_loss, 7.439974784851074, 2585
[INFO] 2021-07-12 19:24:20,248 [run_pretraining.py:  535]:	loss/mlm_loss, 7.439974784851074, 2585
[INFO] 2021-07-12 19:24:20,248 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5839997761067934e-05, 2585
[INFO] 2021-07-12 19:24:20,248 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2585
[INFO] 2021-07-12 19:24:20,248 [run_pretraining.py:  558]:	worker_index: 7, step: 2585, cost: 7.439975, mlm loss: 7.439975, speed: 1.100018 steps/s, speed: 8.800142 samples/s, speed: 4505.672833 tokens/s, learning rate: 2.584e-05, loss_scalings: 2814.750488, pp_loss: 7.615093
[INFO] 2021-07-12 19:24:20,248 [run_pretraining.py:  512]:	********exe.run_2585******* 
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  534]:	loss/total_loss, 6.195086479187012, 2586
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  535]:	loss/mlm_loss, 6.195086479187012, 2586
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5850000383798033e-05, 2586
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2586
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  558]:	worker_index: 7, step: 2586, cost: 6.195086, mlm loss: 6.195086, speed: 1.099490 steps/s, speed: 8.795918 samples/s, speed: 4503.510218 tokens/s, learning rate: 2.585e-05, loss_scalings: 2814.750488, pp_loss: 6.582336
[INFO] 2021-07-12 19:24:21,158 [run_pretraining.py:  512]:	********exe.run_2586******* 
[INFO] 2021-07-12 19:24:22,072 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:22,073 [run_pretraining.py:  534]:	loss/total_loss, 7.251315593719482, 2587
[INFO] 2021-07-12 19:24:22,073 [run_pretraining.py:  535]:	loss/mlm_loss, 7.251315593719482, 2587
[INFO] 2021-07-12 19:24:22,073 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5859999368549325e-05, 2587
[INFO] 2021-07-12 19:24:22,073 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2587
[INFO] 2021-07-12 19:24:22,073 [run_pretraining.py:  558]:	worker_index: 7, step: 2587, cost: 7.251316, mlm loss: 7.251316, speed: 1.094318 steps/s, speed: 8.754541 samples/s, speed: 4482.325124 tokens/s, learning rate: 2.586e-05, loss_scalings: 2814.750488, pp_loss: 7.670723
[INFO] 2021-07-12 19:24:22,073 [run_pretraining.py:  512]:	********exe.run_2587******* 
[INFO] 2021-07-12 19:24:22,982 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:22,982 [run_pretraining.py:  534]:	loss/total_loss, 7.672533988952637, 2588
[INFO] 2021-07-12 19:24:22,982 [run_pretraining.py:  535]:	loss/mlm_loss, 7.672533988952637, 2588
[INFO] 2021-07-12 19:24:22,983 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.587000017229002e-05, 2588
[INFO] 2021-07-12 19:24:22,983 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2588
[INFO] 2021-07-12 19:24:22,983 [run_pretraining.py:  558]:	worker_index: 7, step: 2588, cost: 7.672534, mlm loss: 7.672534, speed: 1.099819 steps/s, speed: 8.798552 samples/s, speed: 4504.858804 tokens/s, learning rate: 2.587e-05, loss_scalings: 2814.750488, pp_loss: 7.647620
[INFO] 2021-07-12 19:24:22,983 [run_pretraining.py:  512]:	********exe.run_2588******* 
[INFO] 2021-07-12 19:24:23,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:23,890 [run_pretraining.py:  534]:	loss/total_loss, 7.660625457763672, 2589
[INFO] 2021-07-12 19:24:23,890 [run_pretraining.py:  535]:	loss/mlm_loss, 7.660625457763672, 2589
[INFO] 2021-07-12 19:24:23,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.587999915704131e-05, 2589
[INFO] 2021-07-12 19:24:23,890 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2589
[INFO] 2021-07-12 19:24:23,890 [run_pretraining.py:  558]:	worker_index: 7, step: 2589, cost: 7.660625, mlm loss: 7.660625, speed: 1.103092 steps/s, speed: 8.824735 samples/s, speed: 4518.264443 tokens/s, learning rate: 2.588e-05, loss_scalings: 2814.750488, pp_loss: 7.048304
[INFO] 2021-07-12 19:24:23,890 [run_pretraining.py:  512]:	********exe.run_2589******* 
[INFO] 2021-07-12 19:24:24,886 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:24,886 [run_pretraining.py:  534]:	loss/total_loss, 6.994344711303711, 2590
[INFO] 2021-07-12 19:24:24,886 [run_pretraining.py:  535]:	loss/mlm_loss, 6.994344711303711, 2590
[INFO] 2021-07-12 19:24:24,886 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5889998141792603e-05, 2590
[INFO] 2021-07-12 19:24:24,886 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2590
[INFO] 2021-07-12 19:24:24,886 [run_pretraining.py:  558]:	worker_index: 7, step: 2590, cost: 6.994345, mlm loss: 6.994345, speed: 1.004200 steps/s, speed: 8.033603 samples/s, speed: 4113.204777 tokens/s, learning rate: 2.589e-05, loss_scalings: 2814.750488, pp_loss: 7.224720
[INFO] 2021-07-12 19:24:24,886 [run_pretraining.py:  512]:	********exe.run_2590******* 
[INFO] 2021-07-12 19:24:25,945 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:25,946 [run_pretraining.py:  534]:	loss/total_loss, 7.40267276763916, 2591
[INFO] 2021-07-12 19:24:25,946 [run_pretraining.py:  535]:	loss/mlm_loss, 7.40267276763916, 2591
[INFO] 2021-07-12 19:24:25,946 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5899998945533298e-05, 2591
[INFO] 2021-07-12 19:24:25,946 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2591
[INFO] 2021-07-12 19:24:25,946 [run_pretraining.py:  558]:	worker_index: 7, step: 2591, cost: 7.402673, mlm loss: 7.402673, speed: 0.944203 steps/s, speed: 7.553621 samples/s, speed: 3867.454087 tokens/s, learning rate: 2.590e-05, loss_scalings: 2814.750488, pp_loss: 7.297832
[INFO] 2021-07-12 19:24:25,946 [run_pretraining.py:  512]:	********exe.run_2591******* 
[INFO] 2021-07-12 19:24:27,001 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:27,001 [run_pretraining.py:  534]:	loss/total_loss, 6.962085723876953, 2592
[INFO] 2021-07-12 19:24:27,002 [run_pretraining.py:  535]:	loss/mlm_loss, 6.962085723876953, 2592
[INFO] 2021-07-12 19:24:27,002 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.590999793028459e-05, 2592
[INFO] 2021-07-12 19:24:27,002 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2592
[INFO] 2021-07-12 19:24:27,002 [run_pretraining.py:  558]:	worker_index: 7, step: 2592, cost: 6.962086, mlm loss: 6.962086, speed: 0.947814 steps/s, speed: 7.582515 samples/s, speed: 3882.247505 tokens/s, learning rate: 2.591e-05, loss_scalings: 2814.750488, pp_loss: 7.211464
[INFO] 2021-07-12 19:24:27,002 [run_pretraining.py:  512]:	********exe.run_2592******* 
[INFO] 2021-07-12 19:24:28,054 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:28,054 [run_pretraining.py:  534]:	loss/total_loss, 6.793949127197266, 2593
[INFO] 2021-07-12 19:24:28,054 [run_pretraining.py:  535]:	loss/mlm_loss, 6.793949127197266, 2593
[INFO] 2021-07-12 19:24:28,054 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5920000553014688e-05, 2593
[INFO] 2021-07-12 19:24:28,054 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2593
[INFO] 2021-07-12 19:24:28,055 [run_pretraining.py:  558]:	worker_index: 7, step: 2593, cost: 6.793949, mlm loss: 6.793949, speed: 0.950435 steps/s, speed: 7.603484 samples/s, speed: 3892.983644 tokens/s, learning rate: 2.592e-05, loss_scalings: 2814.750488, pp_loss: 6.972806
[INFO] 2021-07-12 19:24:28,055 [run_pretraining.py:  512]:	********exe.run_2593******* 
[INFO] 2021-07-12 19:24:29,112 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:29,112 [run_pretraining.py:  534]:	loss/total_loss, 6.680204391479492, 2594
[INFO] 2021-07-12 19:24:29,113 [run_pretraining.py:  535]:	loss/mlm_loss, 6.680204391479492, 2594
[INFO] 2021-07-12 19:24:29,113 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.592999953776598e-05, 2594
[INFO] 2021-07-12 19:24:29,113 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2594
[INFO] 2021-07-12 19:24:29,113 [run_pretraining.py:  558]:	worker_index: 7, step: 2594, cost: 6.680204, mlm loss: 6.680204, speed: 0.945577 steps/s, speed: 7.564615 samples/s, speed: 3873.083014 tokens/s, learning rate: 2.593e-05, loss_scalings: 2814.750488, pp_loss: 7.145838
[INFO] 2021-07-12 19:24:29,113 [run_pretraining.py:  512]:	********exe.run_2594******* 
[INFO] 2021-07-12 19:24:30,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:30,177 [run_pretraining.py:  534]:	loss/total_loss, 7.20022439956665, 2595
[INFO] 2021-07-12 19:24:30,178 [run_pretraining.py:  535]:	loss/mlm_loss, 7.20022439956665, 2595
[INFO] 2021-07-12 19:24:30,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5940000341506675e-05, 2595
[INFO] 2021-07-12 19:24:30,178 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2595
[INFO] 2021-07-12 19:24:30,178 [run_pretraining.py:  558]:	worker_index: 7, step: 2595, cost: 7.200224, mlm loss: 7.200224, speed: 0.939567 steps/s, speed: 7.516532 samples/s, speed: 3848.464586 tokens/s, learning rate: 2.594e-05, loss_scalings: 2814.750488, pp_loss: 7.337541
[INFO] 2021-07-12 19:24:30,178 [run_pretraining.py:  512]:	********exe.run_2595******* 
[INFO] 2021-07-12 19:24:31,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:31,228 [run_pretraining.py:  534]:	loss/total_loss, 6.915017127990723, 2596
[INFO] 2021-07-12 19:24:31,228 [run_pretraining.py:  535]:	loss/mlm_loss, 6.915017127990723, 2596
[INFO] 2021-07-12 19:24:31,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5949999326257966e-05, 2596
[INFO] 2021-07-12 19:24:31,228 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2596
[INFO] 2021-07-12 19:24:31,228 [run_pretraining.py:  558]:	worker_index: 7, step: 2596, cost: 6.915017, mlm loss: 6.915017, speed: 0.952580 steps/s, speed: 7.620640 samples/s, speed: 3901.767638 tokens/s, learning rate: 2.595e-05, loss_scalings: 2814.750488, pp_loss: 7.174411
[INFO] 2021-07-12 19:24:31,228 [run_pretraining.py:  512]:	********exe.run_2596******* 
[INFO] 2021-07-12 19:24:32,282 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:32,282 [run_pretraining.py:  534]:	loss/total_loss, 6.635942459106445, 2597
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  535]:	loss/mlm_loss, 6.635942459106445, 2597
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.596000012999866e-05, 2597
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2597
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  558]:	worker_index: 7, step: 2597, cost: 6.635942, mlm loss: 6.635942, speed: 0.948783 steps/s, speed: 7.590267 samples/s, speed: 3886.216941 tokens/s, learning rate: 2.596e-05, loss_scalings: 2814.750488, pp_loss: 7.235274
[INFO] 2021-07-12 19:24:32,283 [run_pretraining.py:  512]:	********exe.run_2597******* 
[INFO] 2021-07-12 19:24:33,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  534]:	loss/total_loss, 6.741115093231201, 2598
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  535]:	loss/mlm_loss, 6.741115093231201, 2598
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5969999114749953e-05, 2598
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2598
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  558]:	worker_index: 7, step: 2598, cost: 6.741115, mlm loss: 6.741115, speed: 0.938286 steps/s, speed: 7.506290 samples/s, speed: 3843.220720 tokens/s, learning rate: 2.597e-05, loss_scalings: 2814.750488, pp_loss: 6.079190
[INFO] 2021-07-12 19:24:33,349 [run_pretraining.py:  512]:	********exe.run_2598******* 
[INFO] 2021-07-12 19:24:34,413 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  534]:	loss/total_loss, 6.747370719909668, 2599
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  535]:	loss/mlm_loss, 6.747370719909668, 2599
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.5979998099501245e-05, 2599
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2599
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  558]:	worker_index: 7, step: 2599, cost: 6.747371, mlm loss: 6.747371, speed: 0.939836 steps/s, speed: 7.518687 samples/s, speed: 3849.567522 tokens/s, learning rate: 2.598e-05, loss_scalings: 2814.750488, pp_loss: 6.930083
[INFO] 2021-07-12 19:24:34,414 [run_pretraining.py:  512]:	********exe.run_2599******* 
[INFO] 2021-07-12 19:24:59,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:24:59,808 [run_pretraining.py:  534]:	loss/total_loss, 7.204855918884277, 2600
[INFO] 2021-07-12 19:24:59,808 [run_pretraining.py:  535]:	loss/mlm_loss, 7.204855918884277, 2600
[INFO] 2021-07-12 19:24:59,808 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.598999890324194e-05, 2600
[INFO] 2021-07-12 19:24:59,808 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2600
[INFO] 2021-07-12 19:24:59,809 [run_pretraining.py:  558]:	worker_index: 7, step: 2600, cost: 7.204856, mlm loss: 7.204856, speed: 0.039379 steps/s, speed: 0.315035 samples/s, speed: 161.297687 tokens/s, learning rate: 2.599e-05, loss_scalings: 2814.750488, pp_loss: 7.641613
[INFO] 2021-07-12 19:24:59,809 [run_pretraining.py:  512]:	********exe.run_2600******* 
[INFO] 2021-07-12 19:25:00,868 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:00,868 [run_pretraining.py:  534]:	loss/total_loss, 9.523931503295898, 2601
[INFO] 2021-07-12 19:25:00,868 [run_pretraining.py:  535]:	loss/mlm_loss, 9.523931503295898, 2601
[INFO] 2021-07-12 19:25:00,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.599999788799323e-05, 2601
[INFO] 2021-07-12 19:25:00,868 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2601
[INFO] 2021-07-12 19:25:00,868 [run_pretraining.py:  558]:	worker_index: 7, step: 2601, cost: 9.523932, mlm loss: 9.523932, speed: 0.944080 steps/s, speed: 7.552639 samples/s, speed: 3866.950932 tokens/s, learning rate: 2.600e-05, loss_scalings: 2814.750488, pp_loss: 7.656708
[INFO] 2021-07-12 19:25:00,869 [run_pretraining.py:  512]:	********exe.run_2601******* 
[INFO] 2021-07-12 19:25:01,930 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:01,930 [run_pretraining.py:  534]:	loss/total_loss, 6.79008674621582, 2602
[INFO] 2021-07-12 19:25:01,930 [run_pretraining.py:  535]:	loss/mlm_loss, 6.79008674621582, 2602
[INFO] 2021-07-12 19:25:01,930 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.601000051072333e-05, 2602
[INFO] 2021-07-12 19:25:01,930 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2602
[INFO] 2021-07-12 19:25:01,930 [run_pretraining.py:  558]:	worker_index: 7, step: 2602, cost: 6.790087, mlm loss: 6.790087, speed: 0.942195 steps/s, speed: 7.537559 samples/s, speed: 3859.230288 tokens/s, learning rate: 2.601e-05, loss_scalings: 2814.750488, pp_loss: 7.463476
[INFO] 2021-07-12 19:25:01,931 [run_pretraining.py:  512]:	********exe.run_2602******* 
[INFO] 2021-07-12 19:25:02,991 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:02,991 [run_pretraining.py:  534]:	loss/total_loss, 6.461338043212891, 2603
[INFO] 2021-07-12 19:25:02,991 [run_pretraining.py:  535]:	loss/mlm_loss, 6.461338043212891, 2603
[INFO] 2021-07-12 19:25:02,992 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.601999949547462e-05, 2603
[INFO] 2021-07-12 19:25:02,992 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2603
[INFO] 2021-07-12 19:25:02,992 [run_pretraining.py:  558]:	worker_index: 7, step: 2603, cost: 6.461338, mlm loss: 6.461338, speed: 0.942864 steps/s, speed: 7.542912 samples/s, speed: 3861.970848 tokens/s, learning rate: 2.602e-05, loss_scalings: 2814.750488, pp_loss: 7.094202
[INFO] 2021-07-12 19:25:02,992 [run_pretraining.py:  512]:	********exe.run_2603******* 
[INFO] 2021-07-12 19:25:04,052 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:04,052 [run_pretraining.py:  534]:	loss/total_loss, 7.790879249572754, 2604
[INFO] 2021-07-12 19:25:04,052 [run_pretraining.py:  535]:	loss/mlm_loss, 7.790879249572754, 2604
[INFO] 2021-07-12 19:25:04,052 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6030000299215317e-05, 2604
[INFO] 2021-07-12 19:25:04,052 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2604
[INFO] 2021-07-12 19:25:04,052 [run_pretraining.py:  558]:	worker_index: 7, step: 2604, cost: 7.790879, mlm loss: 7.790879, speed: 0.943394 steps/s, speed: 7.547153 samples/s, speed: 3864.142461 tokens/s, learning rate: 2.603e-05, loss_scalings: 2814.750488, pp_loss: 7.251195
[INFO] 2021-07-12 19:25:04,052 [run_pretraining.py:  512]:	********exe.run_2604******* 
[INFO] 2021-07-12 19:25:05,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:05,110 [run_pretraining.py:  534]:	loss/total_loss, 8.136881828308105, 2605
[INFO] 2021-07-12 19:25:05,110 [run_pretraining.py:  535]:	loss/mlm_loss, 8.136881828308105, 2605
[INFO] 2021-07-12 19:25:05,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.603999928396661e-05, 2605
[INFO] 2021-07-12 19:25:05,110 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2605
[INFO] 2021-07-12 19:25:05,110 [run_pretraining.py:  558]:	worker_index: 7, step: 2605, cost: 8.136882, mlm loss: 8.136882, speed: 0.945778 steps/s, speed: 7.566222 samples/s, speed: 3873.905706 tokens/s, learning rate: 2.604e-05, loss_scalings: 2814.750488, pp_loss: 7.375760
[INFO] 2021-07-12 19:25:05,110 [run_pretraining.py:  512]:	********exe.run_2605******* 
[INFO] 2021-07-12 19:25:06,166 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:06,166 [run_pretraining.py:  534]:	loss/total_loss, 7.5732574462890625, 2606
[INFO] 2021-07-12 19:25:06,166 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5732574462890625, 2606
[INFO] 2021-07-12 19:25:06,166 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6050000087707303e-05, 2606
[INFO] 2021-07-12 19:25:06,166 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2606
[INFO] 2021-07-12 19:25:06,166 [run_pretraining.py:  558]:	worker_index: 7, step: 2606, cost: 7.573257, mlm loss: 7.573257, speed: 0.947533 steps/s, speed: 7.580266 samples/s, speed: 3881.095956 tokens/s, learning rate: 2.605e-05, loss_scalings: 2814.750488, pp_loss: 7.564286
[INFO] 2021-07-12 19:25:06,166 [run_pretraining.py:  512]:	********exe.run_2606******* 
[INFO] 2021-07-12 19:25:07,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:07,231 [run_pretraining.py:  534]:	loss/total_loss, 7.324667930603027, 2607
[INFO] 2021-07-12 19:25:07,231 [run_pretraining.py:  535]:	loss/mlm_loss, 7.324667930603027, 2607
[INFO] 2021-07-12 19:25:07,231 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6059999072458595e-05, 2607
[INFO] 2021-07-12 19:25:07,231 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2607
[INFO] 2021-07-12 19:25:07,232 [run_pretraining.py:  558]:	worker_index: 7, step: 2607, cost: 7.324668, mlm loss: 7.324668, speed: 0.939397 steps/s, speed: 7.515172 samples/s, speed: 3847.768140 tokens/s, learning rate: 2.606e-05, loss_scalings: 2814.750488, pp_loss: 7.584050
[INFO] 2021-07-12 19:25:07,232 [run_pretraining.py:  512]:	********exe.run_2607******* 
[INFO] 2021-07-12 19:25:08,288 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:08,288 [run_pretraining.py:  534]:	loss/total_loss, 7.5277838706970215, 2608
[INFO] 2021-07-12 19:25:08,288 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5277838706970215, 2608
[INFO] 2021-07-12 19:25:08,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6069998057209887e-05, 2608
[INFO] 2021-07-12 19:25:08,288 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2608
[INFO] 2021-07-12 19:25:08,288 [run_pretraining.py:  558]:	worker_index: 7, step: 2608, cost: 7.527784, mlm loss: 7.527784, speed: 0.946725 steps/s, speed: 7.573803 samples/s, speed: 3877.787194 tokens/s, learning rate: 2.607e-05, loss_scalings: 2814.750488, pp_loss: 6.741109
[INFO] 2021-07-12 19:25:08,289 [run_pretraining.py:  512]:	********exe.run_2608******* 
[INFO] 2021-07-12 19:25:09,345 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:09,346 [run_pretraining.py:  534]:	loss/total_loss, 7.327234745025635, 2609
[INFO] 2021-07-12 19:25:09,346 [run_pretraining.py:  535]:	loss/mlm_loss, 7.327234745025635, 2609
[INFO] 2021-07-12 19:25:09,346 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6079998860950582e-05, 2609
[INFO] 2021-07-12 19:25:09,346 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2609
[INFO] 2021-07-12 19:25:09,346 [run_pretraining.py:  558]:	worker_index: 7, step: 2609, cost: 7.327235, mlm loss: 7.327235, speed: 0.945927 steps/s, speed: 7.567413 samples/s, speed: 3874.515526 tokens/s, learning rate: 2.608e-05, loss_scalings: 2814.750488, pp_loss: 7.594063
[INFO] 2021-07-12 19:25:09,346 [run_pretraining.py:  512]:	********exe.run_2609******* 
[INFO] 2021-07-12 19:25:10,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:10,284 [run_pretraining.py:  534]:	loss/total_loss, 7.657442092895508, 2610
[INFO] 2021-07-12 19:25:10,284 [run_pretraining.py:  535]:	loss/mlm_loss, 7.657442092895508, 2610
[INFO] 2021-07-12 19:25:10,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6089997845701873e-05, 2610
[INFO] 2021-07-12 19:25:10,284 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2610
[INFO] 2021-07-12 19:25:10,284 [run_pretraining.py:  558]:	worker_index: 7, step: 2610, cost: 7.657442, mlm loss: 7.657442, speed: 1.067243 steps/s, speed: 8.537947 samples/s, speed: 4371.429054 tokens/s, learning rate: 2.609e-05, loss_scalings: 2814.750488, pp_loss: 7.196828
[INFO] 2021-07-12 19:25:10,284 [run_pretraining.py:  512]:	********exe.run_2610******* 
[INFO] 2021-07-12 19:25:11,197 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:11,198 [run_pretraining.py:  534]:	loss/total_loss, 6.615099906921387, 2611
[INFO] 2021-07-12 19:25:11,198 [run_pretraining.py:  535]:	loss/mlm_loss, 6.615099906921387, 2611
[INFO] 2021-07-12 19:25:11,198 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6100000468431972e-05, 2611
[INFO] 2021-07-12 19:25:11,198 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2611
[INFO] 2021-07-12 19:25:11,198 [run_pretraining.py:  558]:	worker_index: 7, step: 2611, cost: 6.615100, mlm loss: 6.615100, speed: 1.094431 steps/s, speed: 8.755446 samples/s, speed: 4482.788280 tokens/s, learning rate: 2.610e-05, loss_scalings: 2814.750488, pp_loss: 7.196035
[INFO] 2021-07-12 19:25:11,198 [run_pretraining.py:  512]:	********exe.run_2611******* 
[INFO] 2021-07-12 19:25:12,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:12,104 [run_pretraining.py:  534]:	loss/total_loss, 6.89785099029541, 2612
[INFO] 2021-07-12 19:25:12,104 [run_pretraining.py:  535]:	loss/mlm_loss, 6.89785099029541, 2612
[INFO] 2021-07-12 19:25:12,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6109999453183264e-05, 2612
[INFO] 2021-07-12 19:25:12,104 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2612
[INFO] 2021-07-12 19:25:12,104 [run_pretraining.py:  558]:	worker_index: 7, step: 2612, cost: 6.897851, mlm loss: 6.897851, speed: 1.104711 steps/s, speed: 8.837686 samples/s, speed: 4524.895327 tokens/s, learning rate: 2.611e-05, loss_scalings: 2814.750488, pp_loss: 7.091404
[INFO] 2021-07-12 19:25:12,104 [run_pretraining.py:  512]:	********exe.run_2612******* 
[INFO] 2021-07-12 19:25:13,013 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:13,014 [run_pretraining.py:  534]:	loss/total_loss, 7.241695404052734, 2613
[INFO] 2021-07-12 19:25:13,014 [run_pretraining.py:  535]:	loss/mlm_loss, 7.241695404052734, 2613
[INFO] 2021-07-12 19:25:13,014 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.612000025692396e-05, 2613
[INFO] 2021-07-12 19:25:13,014 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2613
[INFO] 2021-07-12 19:25:13,014 [run_pretraining.py:  558]:	worker_index: 7, step: 2613, cost: 7.241695, mlm loss: 7.241695, speed: 1.099903 steps/s, speed: 8.799221 samples/s, speed: 4505.201393 tokens/s, learning rate: 2.612e-05, loss_scalings: 2814.750488, pp_loss: 7.280637
[INFO] 2021-07-12 19:25:13,014 [run_pretraining.py:  512]:	********exe.run_2613******* 
[INFO] 2021-07-12 19:25:13,923 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:13,923 [run_pretraining.py:  534]:	loss/total_loss, 7.453412055969238, 2614
[INFO] 2021-07-12 19:25:13,924 [run_pretraining.py:  535]:	loss/mlm_loss, 7.453412055969238, 2614
[INFO] 2021-07-12 19:25:13,924 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.612999924167525e-05, 2614
[INFO] 2021-07-12 19:25:13,924 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2614
[INFO] 2021-07-12 19:25:13,924 [run_pretraining.py:  558]:	worker_index: 7, step: 2614, cost: 7.453412, mlm loss: 7.453412, speed: 1.099977 steps/s, speed: 8.799819 samples/s, speed: 4505.507404 tokens/s, learning rate: 2.613e-05, loss_scalings: 2814.750488, pp_loss: 7.746634
[INFO] 2021-07-12 19:25:13,924 [run_pretraining.py:  512]:	********exe.run_2614******* 
[INFO] 2021-07-12 19:25:14,839 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:14,840 [run_pretraining.py:  534]:	loss/total_loss, 7.077244281768799, 2615
[INFO] 2021-07-12 19:25:14,840 [run_pretraining.py:  535]:	loss/mlm_loss, 7.077244281768799, 2615
[INFO] 2021-07-12 19:25:14,840 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6140000045415945e-05, 2615
[INFO] 2021-07-12 19:25:14,840 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2615
[INFO] 2021-07-12 19:25:14,840 [run_pretraining.py:  558]:	worker_index: 7, step: 2615, cost: 7.077244, mlm loss: 7.077244, speed: 1.091816 steps/s, speed: 8.734530 samples/s, speed: 4472.079534 tokens/s, learning rate: 2.614e-05, loss_scalings: 2814.750488, pp_loss: 7.187593
[INFO] 2021-07-12 19:25:14,840 [run_pretraining.py:  512]:	********exe.run_2615******* 
[INFO] 2021-07-12 19:25:15,749 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:15,749 [run_pretraining.py:  534]:	loss/total_loss, 7.551431179046631, 2616
[INFO] 2021-07-12 19:25:15,749 [run_pretraining.py:  535]:	loss/mlm_loss, 7.551431179046631, 2616
[INFO] 2021-07-12 19:25:15,749 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6149999030167237e-05, 2616
[INFO] 2021-07-12 19:25:15,749 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2616
[INFO] 2021-07-12 19:25:15,750 [run_pretraining.py:  558]:	worker_index: 7, step: 2616, cost: 7.551431, mlm loss: 7.551431, speed: 1.100586 steps/s, speed: 8.804691 samples/s, speed: 4508.001944 tokens/s, learning rate: 2.615e-05, loss_scalings: 2814.750488, pp_loss: 7.332591
[INFO] 2021-07-12 19:25:15,750 [run_pretraining.py:  512]:	********exe.run_2616******* 
[INFO] 2021-07-12 19:25:16,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:16,659 [run_pretraining.py:  534]:	loss/total_loss, 7.8327836990356445, 2617
[INFO] 2021-07-12 19:25:16,659 [run_pretraining.py:  535]:	loss/mlm_loss, 7.8327836990356445, 2617
[INFO] 2021-07-12 19:25:16,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.615999801491853e-05, 2617
[INFO] 2021-07-12 19:25:16,659 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2617
[INFO] 2021-07-12 19:25:16,659 [run_pretraining.py:  558]:	worker_index: 7, step: 2617, cost: 7.832784, mlm loss: 7.832784, speed: 1.100199 steps/s, speed: 8.801592 samples/s, speed: 4506.415050 tokens/s, learning rate: 2.616e-05, loss_scalings: 2814.750488, pp_loss: 7.322095
[INFO] 2021-07-12 19:25:16,659 [run_pretraining.py:  512]:	********exe.run_2617******* 
[INFO] 2021-07-12 19:25:17,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:17,569 [run_pretraining.py:  534]:	loss/total_loss, 6.787883281707764, 2618
[INFO] 2021-07-12 19:25:17,569 [run_pretraining.py:  535]:	loss/mlm_loss, 6.787883281707764, 2618
[INFO] 2021-07-12 19:25:17,569 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6170000637648627e-05, 2618
[INFO] 2021-07-12 19:25:17,569 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2618
[INFO] 2021-07-12 19:25:17,569 [run_pretraining.py:  558]:	worker_index: 7, step: 2618, cost: 6.787883, mlm loss: 6.787883, speed: 1.099935 steps/s, speed: 8.799482 samples/s, speed: 4505.334898 tokens/s, learning rate: 2.617e-05, loss_scalings: 2814.750488, pp_loss: 7.450877
[INFO] 2021-07-12 19:25:17,569 [run_pretraining.py:  512]:	********exe.run_2618******* 
[INFO] 2021-07-12 19:25:18,481 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:18,482 [run_pretraining.py:  534]:	loss/total_loss, 7.787768840789795, 2619
[INFO] 2021-07-12 19:25:18,482 [run_pretraining.py:  535]:	loss/mlm_loss, 7.787768840789795, 2619
[INFO] 2021-07-12 19:25:18,482 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6179997803410515e-05, 2619
[INFO] 2021-07-12 19:25:18,482 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2619
[INFO] 2021-07-12 19:25:18,482 [run_pretraining.py:  558]:	worker_index: 7, step: 2619, cost: 7.787769, mlm loss: 7.787769, speed: 1.096100 steps/s, speed: 8.768801 samples/s, speed: 4489.626267 tokens/s, learning rate: 2.618e-05, loss_scalings: 2814.750488, pp_loss: 7.480970
[INFO] 2021-07-12 19:25:18,482 [run_pretraining.py:  512]:	********exe.run_2619******* 
[INFO] 2021-07-12 19:25:19,405 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:19,407 [run_pretraining.py:  534]:	loss/total_loss, 7.699389457702637, 2620
[INFO] 2021-07-12 19:25:19,410 [run_pretraining.py:  535]:	loss/mlm_loss, 7.699389457702637, 2620
[INFO] 2021-07-12 19:25:19,411 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6190000426140614e-05, 2620
[INFO] 2021-07-12 19:25:19,412 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2620
[INFO] 2021-07-12 19:25:19,413 [run_pretraining.py:  558]:	worker_index: 7, step: 2620, cost: 7.699389, mlm loss: 7.699389, speed: 1.081489 steps/s, speed: 8.651912 samples/s, speed: 4429.778753 tokens/s, learning rate: 2.619e-05, loss_scalings: 2814.750488, pp_loss: 7.123786
[INFO] 2021-07-12 19:25:19,414 [run_pretraining.py:  512]:	********exe.run_2620******* 
[INFO] 2021-07-12 19:25:20,319 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:20,319 [run_pretraining.py:  534]:	loss/total_loss, 7.330975532531738, 2621
[INFO] 2021-07-12 19:25:20,319 [run_pretraining.py:  535]:	loss/mlm_loss, 7.330975532531738, 2621
[INFO] 2021-07-12 19:25:20,319 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6199999410891905e-05, 2621
[INFO] 2021-07-12 19:25:20,319 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2621
[INFO] 2021-07-12 19:25:20,319 [run_pretraining.py:  558]:	worker_index: 7, step: 2621, cost: 7.330976, mlm loss: 7.330976, speed: 1.104808 steps/s, speed: 8.838461 samples/s, speed: 4525.292226 tokens/s, learning rate: 2.620e-05, loss_scalings: 2814.750488, pp_loss: 6.941025
[INFO] 2021-07-12 19:25:20,320 [run_pretraining.py:  512]:	********exe.run_2621******* 
[INFO] 2021-07-12 19:25:21,233 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:21,234 [run_pretraining.py:  534]:	loss/total_loss, 7.402724266052246, 2622
[INFO] 2021-07-12 19:25:21,234 [run_pretraining.py:  535]:	loss/mlm_loss, 7.402724266052246, 2622
[INFO] 2021-07-12 19:25:21,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.62100002146326e-05, 2622
[INFO] 2021-07-12 19:25:21,234 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2622
[INFO] 2021-07-12 19:25:21,234 [run_pretraining.py:  558]:	worker_index: 7, step: 2622, cost: 7.402724, mlm loss: 7.402724, speed: 1.093863 steps/s, speed: 8.750906 samples/s, speed: 4480.464111 tokens/s, learning rate: 2.621e-05, loss_scalings: 2814.750488, pp_loss: 7.521790
[INFO] 2021-07-12 19:25:21,234 [run_pretraining.py:  512]:	********exe.run_2622******* 
[INFO] 2021-07-12 19:25:22,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:22,147 [run_pretraining.py:  534]:	loss/total_loss, 7.765745162963867, 2623
[INFO] 2021-07-12 19:25:22,147 [run_pretraining.py:  535]:	loss/mlm_loss, 7.765745162963867, 2623
[INFO] 2021-07-12 19:25:22,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6219999199383892e-05, 2623
[INFO] 2021-07-12 19:25:22,147 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2623
[INFO] 2021-07-12 19:25:22,147 [run_pretraining.py:  558]:	worker_index: 7, step: 2623, cost: 7.765745, mlm loss: 7.765745, speed: 1.095911 steps/s, speed: 8.767285 samples/s, speed: 4488.849692 tokens/s, learning rate: 2.622e-05, loss_scalings: 2814.750488, pp_loss: 7.513900
[INFO] 2021-07-12 19:25:22,148 [run_pretraining.py:  512]:	********exe.run_2623******* 
[INFO] 2021-07-12 19:25:23,068 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:23,068 [run_pretraining.py:  534]:	loss/total_loss, 7.6071624755859375, 2624
[INFO] 2021-07-12 19:25:23,068 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6071624755859375, 2624
[INFO] 2021-07-12 19:25:23,069 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6230000003124587e-05, 2624
[INFO] 2021-07-12 19:25:23,069 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2624
[INFO] 2021-07-12 19:25:23,069 [run_pretraining.py:  558]:	worker_index: 7, step: 2624, cost: 7.607162, mlm loss: 7.607162, speed: 1.086239 steps/s, speed: 8.689909 samples/s, speed: 4449.233339 tokens/s, learning rate: 2.623e-05, loss_scalings: 2814.750488, pp_loss: 7.557281
[INFO] 2021-07-12 19:25:23,069 [run_pretraining.py:  512]:	********exe.run_2624******* 
[INFO] 2021-07-12 19:25:23,999 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:24,000 [run_pretraining.py:  534]:	loss/total_loss, 7.227347373962402, 2625
[INFO] 2021-07-12 19:25:24,000 [run_pretraining.py:  535]:	loss/mlm_loss, 7.227347373962402, 2625
[INFO] 2021-07-12 19:25:24,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.623999898787588e-05, 2625
[INFO] 2021-07-12 19:25:24,000 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2625
[INFO] 2021-07-12 19:25:24,000 [run_pretraining.py:  558]:	worker_index: 7, step: 2625, cost: 7.227347, mlm loss: 7.227347, speed: 1.074336 steps/s, speed: 8.594687 samples/s, speed: 4400.479800 tokens/s, learning rate: 2.624e-05, loss_scalings: 2814.750488, pp_loss: 7.086852
[INFO] 2021-07-12 19:25:24,000 [run_pretraining.py:  512]:	********exe.run_2625******* 
[INFO] 2021-07-12 19:25:24,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:24,915 [run_pretraining.py:  534]:	loss/total_loss, 8.17263126373291, 2626
[INFO] 2021-07-12 19:25:24,915 [run_pretraining.py:  535]:	loss/mlm_loss, 8.17263126373291, 2626
[INFO] 2021-07-12 19:25:24,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.624999797262717e-05, 2626
[INFO] 2021-07-12 19:25:24,915 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2626
[INFO] 2021-07-12 19:25:24,915 [run_pretraining.py:  558]:	worker_index: 7, step: 2626, cost: 8.172631, mlm loss: 8.172631, speed: 1.093958 steps/s, speed: 8.751662 samples/s, speed: 4480.850915 tokens/s, learning rate: 2.625e-05, loss_scalings: 2814.750488, pp_loss: 7.354134
[INFO] 2021-07-12 19:25:24,915 [run_pretraining.py:  512]:	********exe.run_2626******* 
[INFO] 2021-07-12 19:25:25,827 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:25,827 [run_pretraining.py:  534]:	loss/total_loss, 6.721494674682617, 2627
[INFO] 2021-07-12 19:25:25,827 [run_pretraining.py:  535]:	loss/mlm_loss, 6.721494674682617, 2627
[INFO] 2021-07-12 19:25:25,827 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.626000059535727e-05, 2627
[INFO] 2021-07-12 19:25:25,827 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2627
[INFO] 2021-07-12 19:25:25,828 [run_pretraining.py:  558]:	worker_index: 7, step: 2627, cost: 6.721495, mlm loss: 6.721495, speed: 1.096537 steps/s, speed: 8.772300 samples/s, speed: 4491.417402 tokens/s, learning rate: 2.626e-05, loss_scalings: 2814.750488, pp_loss: 7.314640
[INFO] 2021-07-12 19:25:25,828 [run_pretraining.py:  512]:	********exe.run_2627******* 
[INFO] 2021-07-12 19:25:26,757 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:26,757 [run_pretraining.py:  534]:	loss/total_loss, 7.407176971435547, 2628
[INFO] 2021-07-12 19:25:26,757 [run_pretraining.py:  535]:	loss/mlm_loss, 7.407176971435547, 2628
[INFO] 2021-07-12 19:25:26,758 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6269997761119157e-05, 2628
[INFO] 2021-07-12 19:25:26,758 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2628
[INFO] 2021-07-12 19:25:26,758 [run_pretraining.py:  558]:	worker_index: 7, step: 2628, cost: 7.407177, mlm loss: 7.407177, speed: 1.075868 steps/s, speed: 8.606947 samples/s, speed: 4406.756801 tokens/s, learning rate: 2.627e-05, loss_scalings: 2814.750488, pp_loss: 7.299161
[INFO] 2021-07-12 19:25:26,758 [run_pretraining.py:  512]:	********exe.run_2628******* 
[INFO] 2021-07-12 19:25:27,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:27,686 [run_pretraining.py:  534]:	loss/total_loss, 7.126749038696289, 2629
[INFO] 2021-07-12 19:25:27,686 [run_pretraining.py:  535]:	loss/mlm_loss, 7.126749038696289, 2629
[INFO] 2021-07-12 19:25:27,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6280000383849256e-05, 2629
[INFO] 2021-07-12 19:25:27,686 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2629
[INFO] 2021-07-12 19:25:27,686 [run_pretraining.py:  558]:	worker_index: 7, step: 2629, cost: 7.126749, mlm loss: 7.126749, speed: 1.077948 steps/s, speed: 8.623583 samples/s, speed: 4415.274701 tokens/s, learning rate: 2.628e-05, loss_scalings: 2814.750488, pp_loss: 7.179326
[INFO] 2021-07-12 19:25:27,686 [run_pretraining.py:  512]:	********exe.run_2629******* 
[INFO] 2021-07-12 19:25:28,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:28,600 [run_pretraining.py:  534]:	loss/total_loss, 7.424941062927246, 2630
[INFO] 2021-07-12 19:25:28,600 [run_pretraining.py:  535]:	loss/mlm_loss, 7.424941062927246, 2630
[INFO] 2021-07-12 19:25:28,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6289999368600547e-05, 2630
[INFO] 2021-07-12 19:25:28,601 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2630
[INFO] 2021-07-12 19:25:28,601 [run_pretraining.py:  558]:	worker_index: 7, step: 2630, cost: 7.424941, mlm loss: 7.424941, speed: 1.093999 steps/s, speed: 8.751995 samples/s, speed: 4481.021551 tokens/s, learning rate: 2.629e-05, loss_scalings: 2814.750488, pp_loss: 6.629808
[INFO] 2021-07-12 19:25:28,601 [run_pretraining.py:  512]:	********exe.run_2630******* 
[INFO] 2021-07-12 19:25:29,509 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:29,509 [run_pretraining.py:  534]:	loss/total_loss, 7.021185874938965, 2631
[INFO] 2021-07-12 19:25:29,509 [run_pretraining.py:  535]:	loss/mlm_loss, 7.021185874938965, 2631
[INFO] 2021-07-12 19:25:29,509 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6300000172341242e-05, 2631
[INFO] 2021-07-12 19:25:29,510 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2631
[INFO] 2021-07-12 19:25:29,510 [run_pretraining.py:  558]:	worker_index: 7, step: 2631, cost: 7.021186, mlm loss: 7.021186, speed: 1.100961 steps/s, speed: 8.807689 samples/s, speed: 4509.536689 tokens/s, learning rate: 2.630e-05, loss_scalings: 2814.750488, pp_loss: 7.119188
[INFO] 2021-07-12 19:25:29,510 [run_pretraining.py:  512]:	********exe.run_2631******* 
[INFO] 2021-07-12 19:25:30,437 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:30,438 [run_pretraining.py:  534]:	loss/total_loss, 7.267294883728027, 2632
[INFO] 2021-07-12 19:25:30,438 [run_pretraining.py:  535]:	loss/mlm_loss, 7.267294883728027, 2632
[INFO] 2021-07-12 19:25:30,438 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6309999157092534e-05, 2632
[INFO] 2021-07-12 19:25:30,438 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2632
[INFO] 2021-07-12 19:25:30,438 [run_pretraining.py:  558]:	worker_index: 7, step: 2632, cost: 7.267295, mlm loss: 7.267295, speed: 1.077763 steps/s, speed: 8.622105 samples/s, speed: 4414.517961 tokens/s, learning rate: 2.631e-05, loss_scalings: 2814.750488, pp_loss: 6.859558
[INFO] 2021-07-12 19:25:30,438 [run_pretraining.py:  512]:	********exe.run_2632******* 
[INFO] 2021-07-12 19:25:31,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:31,350 [run_pretraining.py:  534]:	loss/total_loss, 6.978103160858154, 2633
[INFO] 2021-07-12 19:25:31,350 [run_pretraining.py:  535]:	loss/mlm_loss, 6.978103160858154, 2633
[INFO] 2021-07-12 19:25:31,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.631999996083323e-05, 2633
[INFO] 2021-07-12 19:25:31,350 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2633
[INFO] 2021-07-12 19:25:31,350 [run_pretraining.py:  558]:	worker_index: 7, step: 2633, cost: 6.978103, mlm loss: 6.978103, speed: 1.097312 steps/s, speed: 8.778494 samples/s, speed: 4494.588841 tokens/s, learning rate: 2.632e-05, loss_scalings: 2814.750488, pp_loss: 6.767951
[INFO] 2021-07-12 19:25:31,350 [run_pretraining.py:  512]:	********exe.run_2633******* 
[INFO] 2021-07-12 19:25:32,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:32,276 [run_pretraining.py:  534]:	loss/total_loss, 7.849459648132324, 2634
[INFO] 2021-07-12 19:25:32,276 [run_pretraining.py:  535]:	loss/mlm_loss, 7.849459648132324, 2634
[INFO] 2021-07-12 19:25:32,276 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.632999894558452e-05, 2634
[INFO] 2021-07-12 19:25:32,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2634
[INFO] 2021-07-12 19:25:32,277 [run_pretraining.py:  558]:	worker_index: 7, step: 2634, cost: 7.849460, mlm loss: 7.849460, speed: 1.080061 steps/s, speed: 8.640489 samples/s, speed: 4423.930397 tokens/s, learning rate: 2.633e-05, loss_scalings: 2814.750488, pp_loss: 7.651262
[INFO] 2021-07-12 19:25:32,277 [run_pretraining.py:  512]:	********exe.run_2634******* 
[INFO] 2021-07-12 19:25:33,183 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:33,184 [run_pretraining.py:  534]:	loss/total_loss, 8.089822769165039, 2635
[INFO] 2021-07-12 19:25:33,184 [run_pretraining.py:  535]:	loss/mlm_loss, 8.089822769165039, 2635
[INFO] 2021-07-12 19:25:33,184 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6339997930335812e-05, 2635
[INFO] 2021-07-12 19:25:33,184 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2635
[INFO] 2021-07-12 19:25:33,184 [run_pretraining.py:  558]:	worker_index: 7, step: 2635, cost: 8.089823, mlm loss: 8.089823, speed: 1.102800 steps/s, speed: 8.822403 samples/s, speed: 4517.070524 tokens/s, learning rate: 2.634e-05, loss_scalings: 2814.750488, pp_loss: 7.985636
[INFO] 2021-07-12 19:25:33,184 [run_pretraining.py:  512]:	********exe.run_2635******* 
[INFO] 2021-07-12 19:25:34,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:34,106 [run_pretraining.py:  534]:	loss/total_loss, 6.9644365310668945, 2636
[INFO] 2021-07-12 19:25:34,107 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9644365310668945, 2636
[INFO] 2021-07-12 19:25:34,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.635000055306591e-05, 2636
[INFO] 2021-07-12 19:25:34,107 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2636
[INFO] 2021-07-12 19:25:34,107 [run_pretraining.py:  558]:	worker_index: 7, step: 2636, cost: 6.964437, mlm loss: 6.964437, speed: 1.084466 steps/s, speed: 8.675731 samples/s, speed: 4441.974440 tokens/s, learning rate: 2.635e-05, loss_scalings: 2814.750488, pp_loss: 7.449137
[INFO] 2021-07-12 19:25:34,107 [run_pretraining.py:  512]:	********exe.run_2636******* 
[INFO] 2021-07-12 19:25:35,032 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:35,033 [run_pretraining.py:  534]:	loss/total_loss, 7.1991705894470215, 2637
[INFO] 2021-07-12 19:25:35,033 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1991705894470215, 2637
[INFO] 2021-07-12 19:25:35,033 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.63599977188278e-05, 2637
[INFO] 2021-07-12 19:25:35,033 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2637
[INFO] 2021-07-12 19:25:35,033 [run_pretraining.py:  558]:	worker_index: 7, step: 2637, cost: 7.199171, mlm loss: 7.199171, speed: 1.080054 steps/s, speed: 8.640436 samples/s, speed: 4423.903057 tokens/s, learning rate: 2.636e-05, loss_scalings: 2814.750488, pp_loss: 7.271664
[INFO] 2021-07-12 19:25:35,033 [run_pretraining.py:  512]:	********exe.run_2637******* 
[INFO] 2021-07-12 19:25:35,955 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:35,956 [run_pretraining.py:  534]:	loss/total_loss, 8.0877103805542, 2638
[INFO] 2021-07-12 19:25:35,956 [run_pretraining.py:  535]:	loss/mlm_loss, 8.0877103805542, 2638
[INFO] 2021-07-12 19:25:35,956 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6370000341557898e-05, 2638
[INFO] 2021-07-12 19:25:35,956 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2638
[INFO] 2021-07-12 19:25:35,956 [run_pretraining.py:  558]:	worker_index: 7, step: 2638, cost: 8.087710, mlm loss: 8.087710, speed: 1.084663 steps/s, speed: 8.677306 samples/s, speed: 4442.780836 tokens/s, learning rate: 2.637e-05, loss_scalings: 2814.750488, pp_loss: 6.664599
[INFO] 2021-07-12 19:25:35,956 [run_pretraining.py:  512]:	********exe.run_2638******* 
[INFO] 2021-07-12 19:25:36,873 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:36,873 [run_pretraining.py:  534]:	loss/total_loss, 7.60677433013916, 2639
[INFO] 2021-07-12 19:25:36,873 [run_pretraining.py:  535]:	loss/mlm_loss, 7.60677433013916, 2639
[INFO] 2021-07-12 19:25:36,873 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.637999932630919e-05, 2639
[INFO] 2021-07-12 19:25:36,873 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2639
[INFO] 2021-07-12 19:25:36,873 [run_pretraining.py:  558]:	worker_index: 7, step: 2639, cost: 7.606774, mlm loss: 7.606774, speed: 1.090763 steps/s, speed: 8.726103 samples/s, speed: 4467.764801 tokens/s, learning rate: 2.638e-05, loss_scalings: 2814.750488, pp_loss: 7.290819
[INFO] 2021-07-12 19:25:36,873 [run_pretraining.py:  512]:	********exe.run_2639******* 
[INFO] 2021-07-12 19:25:37,789 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:25:37,790 [run_pretraining.py:  534]:	loss/total_loss, 6.99322509765625, 2640
[INFO] 2021-07-12 19:25:37,790 [run_pretraining.py:  535]:	loss/mlm_loss, 6.99322509765625, 2640
[INFO] 2021-07-12 19:25:37,790 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6390000130049884e-05, 2640
[INFO] 2021-07-12 19:25:37,790 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2640
[INFO] 2021-07-12 19:25:37,790 [run_pretraining.py:  558]:	worker_index: 7, step: 2640, cost: 6.993225, mlm loss: 6.993225, speed: 1.091615 steps/s, speed: 8.732921 samples/s, speed: 4471.255486 tokens/s, learning rate: 2.639e-05, loss_scalings: 2814.750488, pp_loss: 7.162419
[INFO] 2021-07-12 19:25:37,790 [run_pretraining.py:  512]:	********exe.run_2640******* 
[INFO] 2021-07-12 19:26:03,409 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:03,410 [run_pretraining.py:  534]:	loss/total_loss, 6.895618915557861, 2641
[INFO] 2021-07-12 19:26:03,410 [run_pretraining.py:  535]:	loss/mlm_loss, 6.895618915557861, 2641
[INFO] 2021-07-12 19:26:03,410 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6399999114801176e-05, 2641
[INFO] 2021-07-12 19:26:03,410 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2641
[INFO] 2021-07-12 19:26:03,410 [run_pretraining.py:  558]:	worker_index: 7, step: 2641, cost: 6.895619, mlm loss: 6.895619, speed: 0.039033 steps/s, speed: 0.312266 samples/s, speed: 159.880008 tokens/s, learning rate: 2.640e-05, loss_scalings: 2814.750488, pp_loss: 7.272080
[INFO] 2021-07-12 19:26:03,410 [run_pretraining.py:  512]:	********exe.run_2641******* 
[INFO] 2021-07-12 19:26:04,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:04,329 [run_pretraining.py:  534]:	loss/total_loss, 7.407166957855225, 2642
[INFO] 2021-07-12 19:26:04,329 [run_pretraining.py:  535]:	loss/mlm_loss, 7.407166957855225, 2642
[INFO] 2021-07-12 19:26:04,329 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6409998099552467e-05, 2642
[INFO] 2021-07-12 19:26:04,329 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2642
[INFO] 2021-07-12 19:26:04,329 [run_pretraining.py:  558]:	worker_index: 7, step: 2642, cost: 7.407167, mlm loss: 7.407167, speed: 1.088355 steps/s, speed: 8.706841 samples/s, speed: 4457.902519 tokens/s, learning rate: 2.641e-05, loss_scalings: 2814.750488, pp_loss: 7.454746
[INFO] 2021-07-12 19:26:04,329 [run_pretraining.py:  512]:	********exe.run_2642******* 
[INFO] 2021-07-12 19:26:05,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:05,245 [run_pretraining.py:  534]:	loss/total_loss, 6.924051284790039, 2643
[INFO] 2021-07-12 19:26:05,245 [run_pretraining.py:  535]:	loss/mlm_loss, 6.924051284790039, 2643
[INFO] 2021-07-12 19:26:05,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6419998903293163e-05, 2643
[INFO] 2021-07-12 19:26:05,246 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2643
[INFO] 2021-07-12 19:26:05,246 [run_pretraining.py:  558]:	worker_index: 7, step: 2643, cost: 6.924051, mlm loss: 6.924051, speed: 1.092244 steps/s, speed: 8.737949 samples/s, speed: 4473.829897 tokens/s, learning rate: 2.642e-05, loss_scalings: 2814.750488, pp_loss: 6.703316
[INFO] 2021-07-12 19:26:05,246 [run_pretraining.py:  512]:	********exe.run_2643******* 
[INFO] 2021-07-12 19:26:06,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:06,157 [run_pretraining.py:  534]:	loss/total_loss, 7.570961952209473, 2644
[INFO] 2021-07-12 19:26:06,157 [run_pretraining.py:  535]:	loss/mlm_loss, 7.570961952209473, 2644
[INFO] 2021-07-12 19:26:06,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6429997888044454e-05, 2644
[INFO] 2021-07-12 19:26:06,157 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2644
[INFO] 2021-07-12 19:26:06,157 [run_pretraining.py:  558]:	worker_index: 7, step: 2644, cost: 7.570962, mlm loss: 7.570962, speed: 1.097851 steps/s, speed: 8.782809 samples/s, speed: 4496.798214 tokens/s, learning rate: 2.643e-05, loss_scalings: 2814.750488, pp_loss: 7.437231
[INFO] 2021-07-12 19:26:06,157 [run_pretraining.py:  512]:	********exe.run_2644******* 
[INFO] 2021-07-12 19:26:07,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:07,074 [run_pretraining.py:  534]:	loss/total_loss, 7.612371921539307, 2645
[INFO] 2021-07-12 19:26:07,074 [run_pretraining.py:  535]:	loss/mlm_loss, 7.612371921539307, 2645
[INFO] 2021-07-12 19:26:07,074 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6440000510774553e-05, 2645
[INFO] 2021-07-12 19:26:07,074 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2645
[INFO] 2021-07-12 19:26:07,074 [run_pretraining.py:  558]:	worker_index: 7, step: 2645, cost: 7.612372, mlm loss: 7.612372, speed: 1.091231 steps/s, speed: 8.729845 samples/s, speed: 4469.680398 tokens/s, learning rate: 2.644e-05, loss_scalings: 2814.750488, pp_loss: 7.397944
[INFO] 2021-07-12 19:26:07,074 [run_pretraining.py:  512]:	********exe.run_2645******* 
[INFO] 2021-07-12 19:26:07,988 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:07,988 [run_pretraining.py:  534]:	loss/total_loss, 7.2062201499938965, 2646
[INFO] 2021-07-12 19:26:07,988 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2062201499938965, 2646
[INFO] 2021-07-12 19:26:07,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.644999767653644e-05, 2646
[INFO] 2021-07-12 19:26:07,988 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2646
[INFO] 2021-07-12 19:26:07,988 [run_pretraining.py:  558]:	worker_index: 7, step: 2646, cost: 7.206220, mlm loss: 7.206220, speed: 1.094597 steps/s, speed: 8.756773 samples/s, speed: 4483.467982 tokens/s, learning rate: 2.645e-05, loss_scalings: 2814.750488, pp_loss: 7.284374
[INFO] 2021-07-12 19:26:07,988 [run_pretraining.py:  512]:	********exe.run_2646******* 
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  534]:	loss/total_loss, 7.499126434326172, 2647
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  535]:	loss/mlm_loss, 7.499126434326172, 2647
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.646000029926654e-05, 2647
[INFO] 2021-07-12 19:26:08,905 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2647
[INFO] 2021-07-12 19:26:08,906 [run_pretraining.py:  558]:	worker_index: 7, step: 2647, cost: 7.499126, mlm loss: 7.499126, speed: 1.091059 steps/s, speed: 8.728473 samples/s, speed: 4468.978132 tokens/s, learning rate: 2.646e-05, loss_scalings: 2814.750488, pp_loss: 7.353885
[INFO] 2021-07-12 19:26:08,906 [run_pretraining.py:  512]:	********exe.run_2647******* 
[INFO] 2021-07-12 19:26:09,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:09,821 [run_pretraining.py:  534]:	loss/total_loss, 7.31654691696167, 2648
[INFO] 2021-07-12 19:26:09,821 [run_pretraining.py:  535]:	loss/mlm_loss, 7.31654691696167, 2648
[INFO] 2021-07-12 19:26:09,821 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.646999928401783e-05, 2648
[INFO] 2021-07-12 19:26:09,822 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2648
[INFO] 2021-07-12 19:26:09,822 [run_pretraining.py:  558]:	worker_index: 7, step: 2648, cost: 7.316547, mlm loss: 7.316547, speed: 1.092446 steps/s, speed: 8.739567 samples/s, speed: 4474.658390 tokens/s, learning rate: 2.647e-05, loss_scalings: 2814.750488, pp_loss: 7.466157
[INFO] 2021-07-12 19:26:09,822 [run_pretraining.py:  512]:	********exe.run_2648******* 
[INFO] 2021-07-12 19:26:10,737 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:10,738 [run_pretraining.py:  534]:	loss/total_loss, 7.246152400970459, 2649
[INFO] 2021-07-12 19:26:10,738 [run_pretraining.py:  535]:	loss/mlm_loss, 7.246152400970459, 2649
[INFO] 2021-07-12 19:26:10,738 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6480000087758526e-05, 2649
[INFO] 2021-07-12 19:26:10,738 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2649
[INFO] 2021-07-12 19:26:10,738 [run_pretraining.py:  558]:	worker_index: 7, step: 2649, cost: 7.246152, mlm loss: 7.246152, speed: 1.092032 steps/s, speed: 8.736254 samples/s, speed: 4472.962114 tokens/s, learning rate: 2.648e-05, loss_scalings: 2814.750488, pp_loss: 6.997962
[INFO] 2021-07-12 19:26:10,738 [run_pretraining.py:  512]:	********exe.run_2649******* 
[INFO] 2021-07-12 19:26:11,654 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:11,655 [run_pretraining.py:  534]:	loss/total_loss, 6.59910774230957, 2650
[INFO] 2021-07-12 19:26:11,655 [run_pretraining.py:  535]:	loss/mlm_loss, 6.59910774230957, 2650
[INFO] 2021-07-12 19:26:11,655 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6489999072509818e-05, 2650
[INFO] 2021-07-12 19:26:11,655 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2650
[INFO] 2021-07-12 19:26:11,655 [run_pretraining.py:  558]:	worker_index: 7, step: 2650, cost: 6.599108, mlm loss: 6.599108, speed: 1.091310 steps/s, speed: 8.730478 samples/s, speed: 4470.004864 tokens/s, learning rate: 2.649e-05, loss_scalings: 2814.750488, pp_loss: 7.097662
[INFO] 2021-07-12 19:26:11,655 [run_pretraining.py:  512]:	********exe.run_2650******* 
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  534]:	loss/total_loss, 7.059459686279297, 2651
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  535]:	loss/mlm_loss, 7.059459686279297, 2651
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.649999805726111e-05, 2651
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2651
[INFO] 2021-07-12 19:26:12,568 [run_pretraining.py:  558]:	worker_index: 7, step: 2651, cost: 7.059460, mlm loss: 7.059460, speed: 1.095536 steps/s, speed: 8.764285 samples/s, speed: 4487.313757 tokens/s, learning rate: 2.650e-05, loss_scalings: 2814.750488, pp_loss: 7.312999
[INFO] 2021-07-12 19:26:12,569 [run_pretraining.py:  512]:	********exe.run_2651******* 
[INFO] 2021-07-12 19:26:13,479 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:13,479 [run_pretraining.py:  534]:	loss/total_loss, 7.183329105377197, 2652
[INFO] 2021-07-12 19:26:13,479 [run_pretraining.py:  535]:	loss/mlm_loss, 7.183329105377197, 2652
[INFO] 2021-07-12 19:26:13,480 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6509998861001804e-05, 2652
[INFO] 2021-07-12 19:26:13,480 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2652
[INFO] 2021-07-12 19:26:13,480 [run_pretraining.py:  558]:	worker_index: 7, step: 2652, cost: 7.183329, mlm loss: 7.183329, speed: 1.098157 steps/s, speed: 8.785256 samples/s, speed: 4498.050922 tokens/s, learning rate: 2.651e-05, loss_scalings: 2814.750488, pp_loss: 7.142927
[INFO] 2021-07-12 19:26:13,480 [run_pretraining.py:  512]:	********exe.run_2652******* 
[INFO] 2021-07-12 19:26:14,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:14,390 [run_pretraining.py:  534]:	loss/total_loss, 6.80230188369751, 2653
[INFO] 2021-07-12 19:26:14,390 [run_pretraining.py:  535]:	loss/mlm_loss, 6.80230188369751, 2653
[INFO] 2021-07-12 19:26:14,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6519997845753096e-05, 2653
[INFO] 2021-07-12 19:26:14,390 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2653
[INFO] 2021-07-12 19:26:14,390 [run_pretraining.py:  558]:	worker_index: 7, step: 2653, cost: 6.802302, mlm loss: 6.802302, speed: 1.099497 steps/s, speed: 8.795974 samples/s, speed: 4503.538551 tokens/s, learning rate: 2.652e-05, loss_scalings: 2814.750488, pp_loss: 6.896044
[INFO] 2021-07-12 19:26:14,390 [run_pretraining.py:  512]:	********exe.run_2653******* 
[INFO] 2021-07-12 19:26:15,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  534]:	loss/total_loss, 8.316963195800781, 2654
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  535]:	loss/mlm_loss, 8.316963195800781, 2654
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6530000468483195e-05, 2654
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2654
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  558]:	worker_index: 7, step: 2654, cost: 8.316963, mlm loss: 8.316963, speed: 1.090044 steps/s, speed: 8.720354 samples/s, speed: 4464.821380 tokens/s, learning rate: 2.653e-05, loss_scalings: 2814.750488, pp_loss: 7.759007
[INFO] 2021-07-12 19:26:15,308 [run_pretraining.py:  512]:	********exe.run_2654******* 
[INFO] 2021-07-12 19:26:16,227 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:16,228 [run_pretraining.py:  534]:	loss/total_loss, 7.125495910644531, 2655
[INFO] 2021-07-12 19:26:16,228 [run_pretraining.py:  535]:	loss/mlm_loss, 7.125495910644531, 2655
[INFO] 2021-07-12 19:26:16,228 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6539999453234486e-05, 2655
[INFO] 2021-07-12 19:26:16,228 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2655
[INFO] 2021-07-12 19:26:16,228 [run_pretraining.py:  558]:	worker_index: 7, step: 2655, cost: 7.125496, mlm loss: 7.125496, speed: 1.087406 steps/s, speed: 8.699247 samples/s, speed: 4454.014589 tokens/s, learning rate: 2.654e-05, loss_scalings: 2814.750488, pp_loss: 7.371752
[INFO] 2021-07-12 19:26:16,228 [run_pretraining.py:  512]:	********exe.run_2655******* 
[INFO] 2021-07-12 19:26:17,139 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:17,140 [run_pretraining.py:  534]:	loss/total_loss, 7.540227890014648, 2656
[INFO] 2021-07-12 19:26:17,140 [run_pretraining.py:  535]:	loss/mlm_loss, 7.540227890014648, 2656
[INFO] 2021-07-12 19:26:17,140 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.655000025697518e-05, 2656
[INFO] 2021-07-12 19:26:17,140 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2656
[INFO] 2021-07-12 19:26:17,140 [run_pretraining.py:  558]:	worker_index: 7, step: 2656, cost: 7.540228, mlm loss: 7.540228, speed: 1.097178 steps/s, speed: 8.777426 samples/s, speed: 4494.042127 tokens/s, learning rate: 2.655e-05, loss_scalings: 2814.750488, pp_loss: 7.188518
[INFO] 2021-07-12 19:26:17,140 [run_pretraining.py:  512]:	********exe.run_2656******* 
[INFO] 2021-07-12 19:26:18,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:18,058 [run_pretraining.py:  534]:	loss/total_loss, 7.118690490722656, 2657
[INFO] 2021-07-12 19:26:18,058 [run_pretraining.py:  535]:	loss/mlm_loss, 7.118690490722656, 2657
[INFO] 2021-07-12 19:26:18,058 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6559999241726473e-05, 2657
[INFO] 2021-07-12 19:26:18,058 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2657
[INFO] 2021-07-12 19:26:18,059 [run_pretraining.py:  558]:	worker_index: 7, step: 2657, cost: 7.118690, mlm loss: 7.118690, speed: 1.089817 steps/s, speed: 8.718539 samples/s, speed: 4463.892134 tokens/s, learning rate: 2.656e-05, loss_scalings: 2814.750488, pp_loss: 7.035606
[INFO] 2021-07-12 19:26:18,059 [run_pretraining.py:  512]:	********exe.run_2657******* 
[INFO] 2021-07-12 19:26:18,974 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:18,974 [run_pretraining.py:  534]:	loss/total_loss, 7.199390411376953, 2658
[INFO] 2021-07-12 19:26:18,974 [run_pretraining.py:  535]:	loss/mlm_loss, 7.199390411376953, 2658
[INFO] 2021-07-12 19:26:18,975 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6570000045467168e-05, 2658
[INFO] 2021-07-12 19:26:18,975 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2658
[INFO] 2021-07-12 19:26:18,975 [run_pretraining.py:  558]:	worker_index: 7, step: 2658, cost: 7.199390, mlm loss: 7.199390, speed: 1.092323 steps/s, speed: 8.738584 samples/s, speed: 4474.154965 tokens/s, learning rate: 2.657e-05, loss_scalings: 2814.750488, pp_loss: 6.564641
[INFO] 2021-07-12 19:26:18,975 [run_pretraining.py:  512]:	********exe.run_2658******* 
[INFO] 2021-07-12 19:26:19,889 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:19,889 [run_pretraining.py:  534]:	loss/total_loss, 7.104473114013672, 2659
[INFO] 2021-07-12 19:26:19,889 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104473114013672, 2659
[INFO] 2021-07-12 19:26:19,890 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.657999903021846e-05, 2659
[INFO] 2021-07-12 19:26:19,890 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2659
[INFO] 2021-07-12 19:26:19,890 [run_pretraining.py:  558]:	worker_index: 7, step: 2659, cost: 7.104473, mlm loss: 7.104473, speed: 1.093676 steps/s, speed: 8.749405 samples/s, speed: 4479.695374 tokens/s, learning rate: 2.658e-05, loss_scalings: 2814.750488, pp_loss: 7.311553
[INFO] 2021-07-12 19:26:19,890 [run_pretraining.py:  512]:	********exe.run_2659******* 
[INFO] 2021-07-12 19:26:20,814 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:20,815 [run_pretraining.py:  534]:	loss/total_loss, 6.481877326965332, 2660
[INFO] 2021-07-12 19:26:20,815 [run_pretraining.py:  535]:	loss/mlm_loss, 6.481877326965332, 2660
[INFO] 2021-07-12 19:26:20,815 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.658999801496975e-05, 2660
[INFO] 2021-07-12 19:26:20,815 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2660
[INFO] 2021-07-12 19:26:20,815 [run_pretraining.py:  558]:	worker_index: 7, step: 2660, cost: 6.481877, mlm loss: 6.481877, speed: 1.081081 steps/s, speed: 8.648649 samples/s, speed: 4428.108336 tokens/s, learning rate: 2.659e-05, loss_scalings: 2814.750488, pp_loss: 7.227024
[INFO] 2021-07-12 19:26:20,815 [run_pretraining.py:  512]:	********exe.run_2660******* 
[INFO] 2021-07-12 19:26:21,734 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:21,734 [run_pretraining.py:  534]:	loss/total_loss, 6.905287265777588, 2661
[INFO] 2021-07-12 19:26:21,734 [run_pretraining.py:  535]:	loss/mlm_loss, 6.905287265777588, 2661
[INFO] 2021-07-12 19:26:21,734 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6599998818710446e-05, 2661
[INFO] 2021-07-12 19:26:21,734 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2661
[INFO] 2021-07-12 19:26:21,735 [run_pretraining.py:  558]:	worker_index: 7, step: 2661, cost: 6.905287, mlm loss: 6.905287, speed: 1.088671 steps/s, speed: 8.709372 samples/s, speed: 4459.198461 tokens/s, learning rate: 2.660e-05, loss_scalings: 2814.750488, pp_loss: 7.393999
[INFO] 2021-07-12 19:26:21,735 [run_pretraining.py:  512]:	********exe.run_2661******* 
[INFO] 2021-07-12 19:26:22,656 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:22,657 [run_pretraining.py:  534]:	loss/total_loss, 7.533769130706787, 2662
[INFO] 2021-07-12 19:26:22,657 [run_pretraining.py:  535]:	loss/mlm_loss, 7.533769130706787, 2662
[INFO] 2021-07-12 19:26:22,657 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6609997803461738e-05, 2662
[INFO] 2021-07-12 19:26:22,657 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2662
[INFO] 2021-07-12 19:26:22,657 [run_pretraining.py:  558]:	worker_index: 7, step: 2662, cost: 7.533769, mlm loss: 7.533769, speed: 1.084743 steps/s, speed: 8.677944 samples/s, speed: 4443.107153 tokens/s, learning rate: 2.661e-05, loss_scalings: 2814.750488, pp_loss: 7.593998
[INFO] 2021-07-12 19:26:22,657 [run_pretraining.py:  512]:	********exe.run_2662******* 
[INFO] 2021-07-12 19:26:23,576 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:23,577 [run_pretraining.py:  534]:	loss/total_loss, 7.237215042114258, 2663
[INFO] 2021-07-12 19:26:23,577 [run_pretraining.py:  535]:	loss/mlm_loss, 7.237215042114258, 2663
[INFO] 2021-07-12 19:26:23,577 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6620000426191837e-05, 2663
[INFO] 2021-07-12 19:26:23,577 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2663
[INFO] 2021-07-12 19:26:23,577 [run_pretraining.py:  558]:	worker_index: 7, step: 2663, cost: 7.237215, mlm loss: 7.237215, speed: 1.087697 steps/s, speed: 8.701575 samples/s, speed: 4455.206598 tokens/s, learning rate: 2.662e-05, loss_scalings: 2814.750488, pp_loss: 7.275935
[INFO] 2021-07-12 19:26:23,577 [run_pretraining.py:  512]:	********exe.run_2663******* 
[INFO] 2021-07-12 19:26:24,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:24,487 [run_pretraining.py:  534]:	loss/total_loss, 7.620356559753418, 2664
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  535]:	loss/mlm_loss, 7.620356559753418, 2664
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6629999410943128e-05, 2664
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2664
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  558]:	worker_index: 7, step: 2664, cost: 7.620357, mlm loss: 7.620357, speed: 1.098940 steps/s, speed: 8.791524 samples/s, speed: 4501.260044 tokens/s, learning rate: 2.663e-05, loss_scalings: 2814.750488, pp_loss: 7.286255
[INFO] 2021-07-12 19:26:24,488 [run_pretraining.py:  512]:	********exe.run_2664******* 
[INFO] 2021-07-12 19:26:25,398 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:25,398 [run_pretraining.py:  534]:	loss/total_loss, 7.290635108947754, 2665
[INFO] 2021-07-12 19:26:25,398 [run_pretraining.py:  535]:	loss/mlm_loss, 7.290635108947754, 2665
[INFO] 2021-07-12 19:26:25,398 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6640000214683823e-05, 2665
[INFO] 2021-07-12 19:26:25,398 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2665
[INFO] 2021-07-12 19:26:25,398 [run_pretraining.py:  558]:	worker_index: 7, step: 2665, cost: 7.290635, mlm loss: 7.290635, speed: 1.098886 steps/s, speed: 8.791086 samples/s, speed: 4501.035976 tokens/s, learning rate: 2.664e-05, loss_scalings: 2814.750488, pp_loss: 7.483469
[INFO] 2021-07-12 19:26:25,398 [run_pretraining.py:  512]:	********exe.run_2665******* 
[INFO] 2021-07-12 19:26:26,323 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:26,324 [run_pretraining.py:  534]:	loss/total_loss, 7.280559539794922, 2666
[INFO] 2021-07-12 19:26:26,324 [run_pretraining.py:  535]:	loss/mlm_loss, 7.280559539794922, 2666
[INFO] 2021-07-12 19:26:26,324 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6649999199435115e-05, 2666
[INFO] 2021-07-12 19:26:26,324 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2666
[INFO] 2021-07-12 19:26:26,324 [run_pretraining.py:  558]:	worker_index: 7, step: 2666, cost: 7.280560, mlm loss: 7.280560, speed: 1.081272 steps/s, speed: 8.650176 samples/s, speed: 4428.890295 tokens/s, learning rate: 2.665e-05, loss_scalings: 2814.750488, pp_loss: 7.153046
[INFO] 2021-07-12 19:26:26,324 [run_pretraining.py:  512]:	********exe.run_2666******* 
[INFO] 2021-07-12 19:26:27,243 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  534]:	loss/total_loss, 7.21784782409668, 2667
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  535]:	loss/mlm_loss, 7.21784782409668, 2667
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.666000000317581e-05, 2667
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2667
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  558]:	worker_index: 7, step: 2667, cost: 7.217848, mlm loss: 7.217848, speed: 1.087362 steps/s, speed: 8.698900 samples/s, speed: 4453.836767 tokens/s, learning rate: 2.666e-05, loss_scalings: 2814.750488, pp_loss: 7.299759
[INFO] 2021-07-12 19:26:27,244 [run_pretraining.py:  512]:	********exe.run_2667******* 
[INFO] 2021-07-12 19:26:28,161 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:28,162 [run_pretraining.py:  534]:	loss/total_loss, 6.908623218536377, 2668
[INFO] 2021-07-12 19:26:28,162 [run_pretraining.py:  535]:	loss/mlm_loss, 6.908623218536377, 2668
[INFO] 2021-07-12 19:26:28,162 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.66699989879271e-05, 2668
[INFO] 2021-07-12 19:26:28,162 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2668
[INFO] 2021-07-12 19:26:28,162 [run_pretraining.py:  558]:	worker_index: 7, step: 2668, cost: 6.908623, mlm loss: 6.908623, speed: 1.090049 steps/s, speed: 8.720393 samples/s, speed: 4464.841106 tokens/s, learning rate: 2.667e-05, loss_scalings: 2814.750488, pp_loss: 6.967199
[INFO] 2021-07-12 19:26:28,162 [run_pretraining.py:  512]:	********exe.run_2668******* 
[INFO] 2021-07-12 19:26:29,085 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:29,085 [run_pretraining.py:  534]:	loss/total_loss, 6.642364501953125, 2669
[INFO] 2021-07-12 19:26:29,085 [run_pretraining.py:  535]:	loss/mlm_loss, 6.642364501953125, 2669
[INFO] 2021-07-12 19:26:29,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6679997972678393e-05, 2669
[INFO] 2021-07-12 19:26:29,086 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2669
[INFO] 2021-07-12 19:26:29,086 [run_pretraining.py:  558]:	worker_index: 7, step: 2669, cost: 6.642365, mlm loss: 6.642365, speed: 1.083804 steps/s, speed: 8.670429 samples/s, speed: 4439.259890 tokens/s, learning rate: 2.668e-05, loss_scalings: 2814.750488, pp_loss: 7.352979
[INFO] 2021-07-12 19:26:29,086 [run_pretraining.py:  512]:	********exe.run_2669******* 
[INFO] 2021-07-12 19:26:30,000 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:30,000 [run_pretraining.py:  534]:	loss/total_loss, 7.155673980712891, 2670
[INFO] 2021-07-12 19:26:30,000 [run_pretraining.py:  535]:	loss/mlm_loss, 7.155673980712891, 2670
[INFO] 2021-07-12 19:26:30,000 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6689998776419088e-05, 2670
[INFO] 2021-07-12 19:26:30,001 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2670
[INFO] 2021-07-12 19:26:30,001 [run_pretraining.py:  558]:	worker_index: 7, step: 2670, cost: 7.155674, mlm loss: 7.155674, speed: 1.093642 steps/s, speed: 8.749138 samples/s, speed: 4479.558712 tokens/s, learning rate: 2.669e-05, loss_scalings: 2814.750488, pp_loss: 7.516183
[INFO] 2021-07-12 19:26:30,001 [run_pretraining.py:  512]:	********exe.run_2670******* 
[INFO] 2021-07-12 19:26:31,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:31,037 [run_pretraining.py:  534]:	loss/total_loss, 7.531004905700684, 2671
[INFO] 2021-07-12 19:26:31,037 [run_pretraining.py:  535]:	loss/mlm_loss, 7.531004905700684, 2671
[INFO] 2021-07-12 19:26:31,037 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.669999776117038e-05, 2671
[INFO] 2021-07-12 19:26:31,037 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2671
[INFO] 2021-07-12 19:26:31,037 [run_pretraining.py:  558]:	worker_index: 7, step: 2671, cost: 7.531005, mlm loss: 7.531005, speed: 0.965255 steps/s, speed: 7.722038 samples/s, speed: 3953.683371 tokens/s, learning rate: 2.670e-05, loss_scalings: 2814.750488, pp_loss: 7.419716
[INFO] 2021-07-12 19:26:31,037 [run_pretraining.py:  512]:	********exe.run_2671******* 
[INFO] 2021-07-12 19:26:32,130 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:32,130 [run_pretraining.py:  534]:	loss/total_loss, 6.602089881896973, 2672
[INFO] 2021-07-12 19:26:32,130 [run_pretraining.py:  535]:	loss/mlm_loss, 6.602089881896973, 2672
[INFO] 2021-07-12 19:26:32,131 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.671000038390048e-05, 2672
[INFO] 2021-07-12 19:26:32,131 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2672
[INFO] 2021-07-12 19:26:32,131 [run_pretraining.py:  558]:	worker_index: 7, step: 2672, cost: 6.602090, mlm loss: 6.602090, speed: 0.915046 steps/s, speed: 7.320370 samples/s, speed: 3748.029528 tokens/s, learning rate: 2.671e-05, loss_scalings: 2814.750488, pp_loss: 6.262363
[INFO] 2021-07-12 19:26:32,131 [run_pretraining.py:  512]:	********exe.run_2672******* 
[INFO] 2021-07-12 19:26:33,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:33,229 [run_pretraining.py:  534]:	loss/total_loss, 6.521693229675293, 2673
[INFO] 2021-07-12 19:26:33,229 [run_pretraining.py:  535]:	loss/mlm_loss, 6.521693229675293, 2673
[INFO] 2021-07-12 19:26:33,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.671999936865177e-05, 2673
[INFO] 2021-07-12 19:26:33,230 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2673
[INFO] 2021-07-12 19:26:33,230 [run_pretraining.py:  558]:	worker_index: 7, step: 2673, cost: 6.521693, mlm loss: 6.521693, speed: 0.910473 steps/s, speed: 7.283785 samples/s, speed: 3729.298045 tokens/s, learning rate: 2.672e-05, loss_scalings: 2814.750488, pp_loss: 7.011800
[INFO] 2021-07-12 19:26:33,230 [run_pretraining.py:  512]:	********exe.run_2673******* 
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  534]:	loss/total_loss, 7.023566246032715, 2674
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  535]:	loss/mlm_loss, 7.023566246032715, 2674
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6730000172392465e-05, 2674
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2674
[INFO] 2021-07-12 19:26:34,320 [run_pretraining.py:  558]:	worker_index: 7, step: 2674, cost: 7.023566, mlm loss: 7.023566, speed: 0.917345 steps/s, speed: 7.338760 samples/s, speed: 3757.445054 tokens/s, learning rate: 2.673e-05, loss_scalings: 2814.750488, pp_loss: 7.271373
[INFO] 2021-07-12 19:26:34,321 [run_pretraining.py:  512]:	********exe.run_2674******* 
[INFO] 2021-07-12 19:26:35,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:35,418 [run_pretraining.py:  534]:	loss/total_loss, 6.961280822753906, 2675
[INFO] 2021-07-12 19:26:35,418 [run_pretraining.py:  535]:	loss/mlm_loss, 6.961280822753906, 2675
[INFO] 2021-07-12 19:26:35,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6739999157143757e-05, 2675
[INFO] 2021-07-12 19:26:35,418 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2675
[INFO] 2021-07-12 19:26:35,418 [run_pretraining.py:  558]:	worker_index: 7, step: 2675, cost: 6.961281, mlm loss: 6.961281, speed: 0.911433 steps/s, speed: 7.291462 samples/s, speed: 3733.228416 tokens/s, learning rate: 2.674e-05, loss_scalings: 2814.750488, pp_loss: 7.013637
[INFO] 2021-07-12 19:26:35,418 [run_pretraining.py:  512]:	********exe.run_2675******* 
[INFO] 2021-07-12 19:26:36,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:36,515 [run_pretraining.py:  534]:	loss/total_loss, 7.068077087402344, 2676
[INFO] 2021-07-12 19:26:36,515 [run_pretraining.py:  535]:	loss/mlm_loss, 7.068077087402344, 2676
[INFO] 2021-07-12 19:26:36,515 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6749999960884452e-05, 2676
[INFO] 2021-07-12 19:26:36,515 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2676
[INFO] 2021-07-12 19:26:36,516 [run_pretraining.py:  558]:	worker_index: 7, step: 2676, cost: 7.068077, mlm loss: 7.068077, speed: 0.911923 steps/s, speed: 7.295384 samples/s, speed: 3735.236503 tokens/s, learning rate: 2.675e-05, loss_scalings: 2814.750488, pp_loss: 6.960854
[INFO] 2021-07-12 19:26:36,516 [run_pretraining.py:  512]:	********exe.run_2676******* 
[INFO] 2021-07-12 19:26:37,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:37,606 [run_pretraining.py:  534]:	loss/total_loss, 7.651067733764648, 2677
[INFO] 2021-07-12 19:26:37,606 [run_pretraining.py:  535]:	loss/mlm_loss, 7.651067733764648, 2677
[INFO] 2021-07-12 19:26:37,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6759998945635743e-05, 2677
[INFO] 2021-07-12 19:26:37,607 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2677
[INFO] 2021-07-12 19:26:37,607 [run_pretraining.py:  558]:	worker_index: 7, step: 2677, cost: 7.651068, mlm loss: 7.651068, speed: 0.917028 steps/s, speed: 7.336222 samples/s, speed: 3756.145419 tokens/s, learning rate: 2.676e-05, loss_scalings: 2814.750488, pp_loss: 7.375845
[INFO] 2021-07-12 19:26:37,607 [run_pretraining.py:  512]:	********exe.run_2677******* 
[INFO] 2021-07-12 19:26:38,702 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:38,703 [run_pretraining.py:  534]:	loss/total_loss, 7.4773268699646, 2678
[INFO] 2021-07-12 19:26:38,703 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4773268699646, 2678
[INFO] 2021-07-12 19:26:38,703 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6769997930387035e-05, 2678
[INFO] 2021-07-12 19:26:38,703 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2678
[INFO] 2021-07-12 19:26:38,703 [run_pretraining.py:  558]:	worker_index: 7, step: 2678, cost: 7.477327, mlm loss: 7.477327, speed: 0.912551 steps/s, speed: 7.300406 samples/s, speed: 3737.807797 tokens/s, learning rate: 2.677e-05, loss_scalings: 2814.750488, pp_loss: 7.710598
[INFO] 2021-07-12 19:26:38,703 [run_pretraining.py:  512]:	********exe.run_2678******* 
[INFO] 2021-07-12 19:26:39,802 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:39,803 [run_pretraining.py:  534]:	loss/total_loss, 7.437892913818359, 2679
[INFO] 2021-07-12 19:26:39,803 [run_pretraining.py:  535]:	loss/mlm_loss, 7.437892913818359, 2679
[INFO] 2021-07-12 19:26:39,803 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6780000553117134e-05, 2679
[INFO] 2021-07-12 19:26:39,803 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2679
[INFO] 2021-07-12 19:26:39,803 [run_pretraining.py:  558]:	worker_index: 7, step: 2679, cost: 7.437893, mlm loss: 7.437893, speed: 0.909750 steps/s, speed: 7.277997 samples/s, speed: 3726.334275 tokens/s, learning rate: 2.678e-05, loss_scalings: 2814.750488, pp_loss: 7.256748
[INFO] 2021-07-12 19:26:39,803 [run_pretraining.py:  512]:	********exe.run_2679******* 
[INFO] 2021-07-12 19:26:40,888 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:40,889 [run_pretraining.py:  534]:	loss/total_loss, 7.71858549118042, 2680
[INFO] 2021-07-12 19:26:40,889 [run_pretraining.py:  535]:	loss/mlm_loss, 7.71858549118042, 2680
[INFO] 2021-07-12 19:26:40,889 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6789997718879022e-05, 2680
[INFO] 2021-07-12 19:26:40,889 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2680
[INFO] 2021-07-12 19:26:40,889 [run_pretraining.py:  558]:	worker_index: 7, step: 2680, cost: 7.718585, mlm loss: 7.718585, speed: 0.921191 steps/s, speed: 7.369531 samples/s, speed: 3773.199795 tokens/s, learning rate: 2.679e-05, loss_scalings: 2814.750488, pp_loss: 7.468338
[INFO] 2021-07-12 19:26:40,889 [run_pretraining.py:  512]:	********exe.run_2680******* 
[INFO] 2021-07-12 19:26:41,984 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  534]:	loss/total_loss, 7.793068885803223, 2681
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  535]:	loss/mlm_loss, 7.793068885803223, 2681
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.680000034160912e-05, 2681
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2681
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  558]:	worker_index: 7, step: 2681, cost: 7.793069, mlm loss: 7.793069, speed: 0.913232 steps/s, speed: 7.305858 samples/s, speed: 3740.599263 tokens/s, learning rate: 2.680e-05, loss_scalings: 2814.750488, pp_loss: 7.672755
[INFO] 2021-07-12 19:26:41,985 [run_pretraining.py:  512]:	********exe.run_2681******* 
[INFO] 2021-07-12 19:26:43,083 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:43,084 [run_pretraining.py:  534]:	loss/total_loss, 7.663766860961914, 2682
[INFO] 2021-07-12 19:26:43,084 [run_pretraining.py:  535]:	loss/mlm_loss, 7.663766860961914, 2682
[INFO] 2021-07-12 19:26:43,084 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6809999326360412e-05, 2682
[INFO] 2021-07-12 19:26:43,084 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2682
[INFO] 2021-07-12 19:26:43,084 [run_pretraining.py:  558]:	worker_index: 7, step: 2682, cost: 7.663767, mlm loss: 7.663767, speed: 0.910284 steps/s, speed: 7.282269 samples/s, speed: 3728.521865 tokens/s, learning rate: 2.681e-05, loss_scalings: 2814.750488, pp_loss: 7.363341
[INFO] 2021-07-12 19:26:43,084 [run_pretraining.py:  512]:	********exe.run_2682******* 
[INFO] 2021-07-12 19:26:44,176 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:44,176 [run_pretraining.py:  534]:	loss/total_loss, 7.068842887878418, 2683
[INFO] 2021-07-12 19:26:44,176 [run_pretraining.py:  535]:	loss/mlm_loss, 7.068842887878418, 2683
[INFO] 2021-07-12 19:26:44,177 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6820000130101107e-05, 2683
[INFO] 2021-07-12 19:26:44,177 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2683
[INFO] 2021-07-12 19:26:44,177 [run_pretraining.py:  558]:	worker_index: 7, step: 2683, cost: 7.068843, mlm loss: 7.068843, speed: 0.915822 steps/s, speed: 7.326574 samples/s, speed: 3751.205654 tokens/s, learning rate: 2.682e-05, loss_scalings: 2814.750488, pp_loss: 7.154472
[INFO] 2021-07-12 19:26:44,177 [run_pretraining.py:  512]:	********exe.run_2683******* 
[INFO] 2021-07-12 19:26:45,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:45,270 [run_pretraining.py:  534]:	loss/total_loss, 7.786571025848389, 2684
[INFO] 2021-07-12 19:26:45,270 [run_pretraining.py:  535]:	loss/mlm_loss, 7.786571025848389, 2684
[INFO] 2021-07-12 19:26:45,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.68299991148524e-05, 2684
[INFO] 2021-07-12 19:26:45,270 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2684
[INFO] 2021-07-12 19:26:45,270 [run_pretraining.py:  558]:	worker_index: 7, step: 2684, cost: 7.786571, mlm loss: 7.786571, speed: 0.914869 steps/s, speed: 7.318954 samples/s, speed: 3747.304382 tokens/s, learning rate: 2.683e-05, loss_scalings: 2814.750488, pp_loss: 7.643920
[INFO] 2021-07-12 19:26:45,270 [run_pretraining.py:  512]:	********exe.run_2684******* 
[INFO] 2021-07-12 19:26:46,402 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:46,402 [run_pretraining.py:  534]:	loss/total_loss, 6.9276885986328125, 2685
[INFO] 2021-07-12 19:26:46,403 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9276885986328125, 2685
[INFO] 2021-07-12 19:26:46,403 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6839999918593094e-05, 2685
[INFO] 2021-07-12 19:26:46,403 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2685
[INFO] 2021-07-12 19:26:46,403 [run_pretraining.py:  558]:	worker_index: 7, step: 2685, cost: 6.927689, mlm loss: 6.927689, speed: 0.883637 steps/s, speed: 7.069096 samples/s, speed: 3619.377084 tokens/s, learning rate: 2.684e-05, loss_scalings: 2814.750488, pp_loss: 7.080136
[INFO] 2021-07-12 19:26:46,403 [run_pretraining.py:  512]:	********exe.run_2685******* 
[INFO] 2021-07-12 19:26:47,497 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:47,498 [run_pretraining.py:  534]:	loss/total_loss, 7.512644290924072, 2686
[INFO] 2021-07-12 19:26:47,498 [run_pretraining.py:  535]:	loss/mlm_loss, 7.512644290924072, 2686
[INFO] 2021-07-12 19:26:47,498 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6849998903344385e-05, 2686
[INFO] 2021-07-12 19:26:47,498 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2686
[INFO] 2021-07-12 19:26:47,498 [run_pretraining.py:  558]:	worker_index: 7, step: 2686, cost: 7.512644, mlm loss: 7.512644, speed: 0.913334 steps/s, speed: 7.306674 samples/s, speed: 3741.017121 tokens/s, learning rate: 2.685e-05, loss_scalings: 2814.750488, pp_loss: 7.389838
[INFO] 2021-07-12 19:26:47,498 [run_pretraining.py:  512]:	********exe.run_2686******* 
[INFO] 2021-07-12 19:26:48,593 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:48,594 [run_pretraining.py:  534]:	loss/total_loss, 6.787253379821777, 2687
[INFO] 2021-07-12 19:26:48,594 [run_pretraining.py:  535]:	loss/mlm_loss, 6.787253379821777, 2687
[INFO] 2021-07-12 19:26:48,594 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6859997888095677e-05, 2687
[INFO] 2021-07-12 19:26:48,594 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2687
[INFO] 2021-07-12 19:26:48,594 [run_pretraining.py:  558]:	worker_index: 7, step: 2687, cost: 6.787253, mlm loss: 6.787253, speed: 0.913271 steps/s, speed: 7.306171 samples/s, speed: 3740.759716 tokens/s, learning rate: 2.686e-05, loss_scalings: 2814.750488, pp_loss: 7.084820
[INFO] 2021-07-12 19:26:48,594 [run_pretraining.py:  512]:	********exe.run_2687******* 
[INFO] 2021-07-12 19:26:49,679 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:49,680 [run_pretraining.py:  534]:	loss/total_loss, 6.811239242553711, 2688
[INFO] 2021-07-12 19:26:49,680 [run_pretraining.py:  535]:	loss/mlm_loss, 6.811239242553711, 2688
[INFO] 2021-07-12 19:26:49,680 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6870000510825776e-05, 2688
[INFO] 2021-07-12 19:26:49,680 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2688
[INFO] 2021-07-12 19:26:49,680 [run_pretraining.py:  558]:	worker_index: 7, step: 2688, cost: 6.811239, mlm loss: 6.811239, speed: 0.921333 steps/s, speed: 7.370666 samples/s, speed: 3773.780807 tokens/s, learning rate: 2.687e-05, loss_scalings: 2814.750488, pp_loss: 7.113194
[INFO] 2021-07-12 19:26:49,680 [run_pretraining.py:  512]:	********exe.run_2688******* 
[INFO] 2021-07-12 19:26:50,772 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:50,773 [run_pretraining.py:  534]:	loss/total_loss, 7.364350318908691, 2689
[INFO] 2021-07-12 19:26:50,773 [run_pretraining.py:  535]:	loss/mlm_loss, 7.364350318908691, 2689
[INFO] 2021-07-12 19:26:50,773 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6879997676587664e-05, 2689
[INFO] 2021-07-12 19:26:50,773 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2689
[INFO] 2021-07-12 19:26:50,773 [run_pretraining.py:  558]:	worker_index: 7, step: 2689, cost: 7.364350, mlm loss: 7.364350, speed: 0.915255 steps/s, speed: 7.322038 samples/s, speed: 3748.883386 tokens/s, learning rate: 2.688e-05, loss_scalings: 2814.750488, pp_loss: 6.896719
[INFO] 2021-07-12 19:26:50,773 [run_pretraining.py:  512]:	********exe.run_2689******* 
[INFO] 2021-07-12 19:26:51,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:51,868 [run_pretraining.py:  534]:	loss/total_loss, 7.232235908508301, 2690
[INFO] 2021-07-12 19:26:51,868 [run_pretraining.py:  535]:	loss/mlm_loss, 7.232235908508301, 2690
[INFO] 2021-07-12 19:26:51,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6890000299317762e-05, 2690
[INFO] 2021-07-12 19:26:51,868 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2690
[INFO] 2021-07-12 19:26:51,868 [run_pretraining.py:  558]:	worker_index: 7, step: 2690, cost: 7.232236, mlm loss: 7.232236, speed: 0.913661 steps/s, speed: 7.309286 samples/s, speed: 3742.354404 tokens/s, learning rate: 2.689e-05, loss_scalings: 2814.750488, pp_loss: 7.310601
[INFO] 2021-07-12 19:26:51,868 [run_pretraining.py:  512]:	********exe.run_2690******* 
[INFO] 2021-07-12 19:26:52,965 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:52,965 [run_pretraining.py:  534]:	loss/total_loss, 7.269426345825195, 2691
[INFO] 2021-07-12 19:26:52,966 [run_pretraining.py:  535]:	loss/mlm_loss, 7.269426345825195, 2691
[INFO] 2021-07-12 19:26:52,966 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6899999284069054e-05, 2691
[INFO] 2021-07-12 19:26:52,966 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2691
[INFO] 2021-07-12 19:26:52,966 [run_pretraining.py:  558]:	worker_index: 7, step: 2691, cost: 7.269426, mlm loss: 7.269426, speed: 0.911729 steps/s, speed: 7.293831 samples/s, speed: 3734.441614 tokens/s, learning rate: 2.690e-05, loss_scalings: 2814.750488, pp_loss: 6.898814
[INFO] 2021-07-12 19:26:52,966 [run_pretraining.py:  512]:	********exe.run_2691******* 
[INFO] 2021-07-12 19:26:54,058 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:54,058 [run_pretraining.py:  534]:	loss/total_loss, 7.308276653289795, 2692
[INFO] 2021-07-12 19:26:54,059 [run_pretraining.py:  535]:	loss/mlm_loss, 7.308276653289795, 2692
[INFO] 2021-07-12 19:26:54,059 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.691000008780975e-05, 2692
[INFO] 2021-07-12 19:26:54,059 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2692
[INFO] 2021-07-12 19:26:54,059 [run_pretraining.py:  558]:	worker_index: 7, step: 2692, cost: 7.308277, mlm loss: 7.308277, speed: 0.915500 steps/s, speed: 7.323999 samples/s, speed: 3749.887412 tokens/s, learning rate: 2.691e-05, loss_scalings: 2814.750488, pp_loss: 7.421002
[INFO] 2021-07-12 19:26:54,059 [run_pretraining.py:  512]:	********exe.run_2692******* 
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  534]:	loss/total_loss, 7.029964447021484, 2693
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  535]:	loss/mlm_loss, 7.029964447021484, 2693
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.691999907256104e-05, 2693
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2693
[INFO] 2021-07-12 19:26:55,164 [run_pretraining.py:  558]:	worker_index: 7, step: 2693, cost: 7.029964, mlm loss: 7.029964, speed: 0.904931 steps/s, speed: 7.239449 samples/s, speed: 3706.597726 tokens/s, learning rate: 2.692e-05, loss_scalings: 2814.750488, pp_loss: 7.333797
[INFO] 2021-07-12 19:26:55,165 [run_pretraining.py:  512]:	********exe.run_2693******* 
[INFO] 2021-07-12 19:26:56,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:56,254 [run_pretraining.py:  534]:	loss/total_loss, 7.128944396972656, 2694
[INFO] 2021-07-12 19:26:56,254 [run_pretraining.py:  535]:	loss/mlm_loss, 7.128944396972656, 2694
[INFO] 2021-07-12 19:26:56,254 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6929999876301736e-05, 2694
[INFO] 2021-07-12 19:26:56,254 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2694
[INFO] 2021-07-12 19:26:56,254 [run_pretraining.py:  558]:	worker_index: 7, step: 2694, cost: 7.128944, mlm loss: 7.128944, speed: 0.918279 steps/s, speed: 7.346229 samples/s, speed: 3761.269485 tokens/s, learning rate: 2.693e-05, loss_scalings: 2814.750488, pp_loss: 7.267104
[INFO] 2021-07-12 19:26:56,254 [run_pretraining.py:  512]:	********exe.run_2694******* 
[INFO] 2021-07-12 19:26:57,349 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:57,349 [run_pretraining.py:  534]:	loss/total_loss, 7.1618804931640625, 2695
[INFO] 2021-07-12 19:26:57,349 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1618804931640625, 2695
[INFO] 2021-07-12 19:26:57,350 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6939998861053027e-05, 2695
[INFO] 2021-07-12 19:26:57,350 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2695
[INFO] 2021-07-12 19:26:57,350 [run_pretraining.py:  558]:	worker_index: 7, step: 2695, cost: 7.161880, mlm loss: 7.161880, speed: 0.913274 steps/s, speed: 7.306192 samples/s, speed: 3740.770305 tokens/s, learning rate: 2.694e-05, loss_scalings: 2814.750488, pp_loss: 6.991030
[INFO] 2021-07-12 19:26:57,350 [run_pretraining.py:  512]:	********exe.run_2695******* 
[INFO] 2021-07-12 19:26:58,446 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:58,447 [run_pretraining.py:  534]:	loss/total_loss, 7.008488655090332, 2696
[INFO] 2021-07-12 19:26:58,447 [run_pretraining.py:  535]:	loss/mlm_loss, 7.008488655090332, 2696
[INFO] 2021-07-12 19:26:58,447 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.694999784580432e-05, 2696
[INFO] 2021-07-12 19:26:58,447 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2696
[INFO] 2021-07-12 19:26:58,447 [run_pretraining.py:  558]:	worker_index: 7, step: 2696, cost: 7.008489, mlm loss: 7.008489, speed: 0.911665 steps/s, speed: 7.293316 samples/s, speed: 3734.177808 tokens/s, learning rate: 2.695e-05, loss_scalings: 2814.750488, pp_loss: 7.043722
[INFO] 2021-07-12 19:26:58,447 [run_pretraining.py:  512]:	********exe.run_2696******* 
[INFO] 2021-07-12 19:26:59,532 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:26:59,533 [run_pretraining.py:  534]:	loss/total_loss, 7.248259544372559, 2697
[INFO] 2021-07-12 19:26:59,533 [run_pretraining.py:  535]:	loss/mlm_loss, 7.248259544372559, 2697
[INFO] 2021-07-12 19:26:59,533 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6960000468534417e-05, 2697
[INFO] 2021-07-12 19:26:59,533 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2697
[INFO] 2021-07-12 19:26:59,533 [run_pretraining.py:  558]:	worker_index: 7, step: 2697, cost: 7.248260, mlm loss: 7.248260, speed: 0.921390 steps/s, speed: 7.371124 samples/s, speed: 3774.015417 tokens/s, learning rate: 2.696e-05, loss_scalings: 2814.750488, pp_loss: 7.015070
[INFO] 2021-07-12 19:26:59,533 [run_pretraining.py:  512]:	********exe.run_2697******* 
[INFO] 2021-07-12 19:27:00,623 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:00,623 [run_pretraining.py:  534]:	loss/total_loss, 6.8758320808410645, 2698
[INFO] 2021-07-12 19:27:00,623 [run_pretraining.py:  535]:	loss/mlm_loss, 6.8758320808410645, 2698
[INFO] 2021-07-12 19:27:00,623 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6969997634296305e-05, 2698
[INFO] 2021-07-12 19:27:00,623 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2698
[INFO] 2021-07-12 19:27:00,624 [run_pretraining.py:  558]:	worker_index: 7, step: 2698, cost: 6.875832, mlm loss: 6.875832, speed: 0.917706 steps/s, speed: 7.341647 samples/s, speed: 3758.923230 tokens/s, learning rate: 2.697e-05, loss_scalings: 2814.750488, pp_loss: 6.262680
[INFO] 2021-07-12 19:27:00,624 [run_pretraining.py:  512]:	********exe.run_2698******* 
[INFO] 2021-07-12 19:27:01,724 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:01,725 [run_pretraining.py:  534]:	loss/total_loss, 7.457332611083984, 2699
[INFO] 2021-07-12 19:27:01,725 [run_pretraining.py:  535]:	loss/mlm_loss, 7.457332611083984, 2699
[INFO] 2021-07-12 19:27:01,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6980000257026404e-05, 2699
[INFO] 2021-07-12 19:27:01,725 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2699
[INFO] 2021-07-12 19:27:01,725 [run_pretraining.py:  558]:	worker_index: 7, step: 2699, cost: 7.457333, mlm loss: 7.457333, speed: 0.908548 steps/s, speed: 7.268383 samples/s, speed: 3721.412099 tokens/s, learning rate: 2.698e-05, loss_scalings: 2814.750488, pp_loss: 7.596285
[INFO] 2021-07-12 19:27:01,725 [run_pretraining.py:  512]:	********exe.run_2699******* 
[INFO] 2021-07-12 19:27:02,825 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:02,825 [run_pretraining.py:  534]:	loss/total_loss, 7.359745979309082, 2700
[INFO] 2021-07-12 19:27:02,825 [run_pretraining.py:  535]:	loss/mlm_loss, 7.359745979309082, 2700
[INFO] 2021-07-12 19:27:02,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.6989999241777696e-05, 2700
[INFO] 2021-07-12 19:27:02,826 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2700
[INFO] 2021-07-12 19:27:02,826 [run_pretraining.py:  558]:	worker_index: 7, step: 2700, cost: 7.359746, mlm loss: 7.359746, speed: 0.909001 steps/s, speed: 7.272011 samples/s, speed: 3723.269503 tokens/s, learning rate: 2.699e-05, loss_scalings: 2814.750488, pp_loss: 7.306067
[INFO] 2021-07-12 19:27:02,826 [run_pretraining.py:  512]:	********exe.run_2700******* 
[INFO] 2021-07-12 19:27:03,933 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:03,933 [run_pretraining.py:  534]:	loss/total_loss, 7.161818027496338, 2701
[INFO] 2021-07-12 19:27:03,933 [run_pretraining.py:  535]:	loss/mlm_loss, 7.161818027496338, 2701
[INFO] 2021-07-12 19:27:03,933 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.700000004551839e-05, 2701
[INFO] 2021-07-12 19:27:03,933 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2701
[INFO] 2021-07-12 19:27:03,933 [run_pretraining.py:  558]:	worker_index: 7, step: 2701, cost: 7.161818, mlm loss: 7.161818, speed: 0.903174 steps/s, speed: 7.225389 samples/s, speed: 3699.399173 tokens/s, learning rate: 2.700e-05, loss_scalings: 2814.750488, pp_loss: 6.218561
[INFO] 2021-07-12 19:27:03,934 [run_pretraining.py:  512]:	********exe.run_2701******* 
[INFO] 2021-07-12 19:27:05,027 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:05,027 [run_pretraining.py:  534]:	loss/total_loss, 7.342153549194336, 2702
[INFO] 2021-07-12 19:27:05,027 [run_pretraining.py:  535]:	loss/mlm_loss, 7.342153549194336, 2702
[INFO] 2021-07-12 19:27:05,027 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7009999030269682e-05, 2702
[INFO] 2021-07-12 19:27:05,027 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2702
[INFO] 2021-07-12 19:27:05,028 [run_pretraining.py:  558]:	worker_index: 7, step: 2702, cost: 7.342154, mlm loss: 7.342154, speed: 0.914564 steps/s, speed: 7.316511 samples/s, speed: 3746.053408 tokens/s, learning rate: 2.701e-05, loss_scalings: 2814.750488, pp_loss: 7.074777
[INFO] 2021-07-12 19:27:05,028 [run_pretraining.py:  512]:	********exe.run_2702******* 
[INFO] 2021-07-12 19:27:06,129 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:06,129 [run_pretraining.py:  534]:	loss/total_loss, 7.396385669708252, 2703
[INFO] 2021-07-12 19:27:06,130 [run_pretraining.py:  535]:	loss/mlm_loss, 7.396385669708252, 2703
[INFO] 2021-07-12 19:27:06,130 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7019999834010378e-05, 2703
[INFO] 2021-07-12 19:27:06,130 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2703
[INFO] 2021-07-12 19:27:06,130 [run_pretraining.py:  558]:	worker_index: 7, step: 2703, cost: 7.396386, mlm loss: 7.396386, speed: 0.907793 steps/s, speed: 7.262341 samples/s, speed: 3718.318395 tokens/s, learning rate: 2.702e-05, loss_scalings: 2814.750488, pp_loss: 7.522293
[INFO] 2021-07-12 19:27:06,130 [run_pretraining.py:  512]:	********exe.run_2703******* 
[INFO] 2021-07-12 19:27:07,228 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:07,228 [run_pretraining.py:  534]:	loss/total_loss, 6.937062740325928, 2704
[INFO] 2021-07-12 19:27:07,229 [run_pretraining.py:  535]:	loss/mlm_loss, 6.937062740325928, 2704
[INFO] 2021-07-12 19:27:07,229 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.702999881876167e-05, 2704
[INFO] 2021-07-12 19:27:07,229 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2704
[INFO] 2021-07-12 19:27:07,229 [run_pretraining.py:  558]:	worker_index: 7, step: 2704, cost: 6.937063, mlm loss: 6.937063, speed: 0.910436 steps/s, speed: 7.283488 samples/s, speed: 3729.145859 tokens/s, learning rate: 2.703e-05, loss_scalings: 2814.750488, pp_loss: 6.974451
[INFO] 2021-07-12 19:27:07,229 [run_pretraining.py:  512]:	********exe.run_2704******* 
[INFO] 2021-07-12 19:27:08,327 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:08,328 [run_pretraining.py:  534]:	loss/total_loss, 7.102629661560059, 2705
[INFO] 2021-07-12 19:27:08,328 [run_pretraining.py:  535]:	loss/mlm_loss, 7.102629661560059, 2705
[INFO] 2021-07-12 19:27:08,328 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.703999780351296e-05, 2705
[INFO] 2021-07-12 19:27:08,328 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2705
[INFO] 2021-07-12 19:27:08,328 [run_pretraining.py:  558]:	worker_index: 7, step: 2705, cost: 7.102630, mlm loss: 7.102630, speed: 0.910126 steps/s, speed: 7.281005 samples/s, speed: 3727.874621 tokens/s, learning rate: 2.704e-05, loss_scalings: 2814.750488, pp_loss: 7.123674
[INFO] 2021-07-12 19:27:08,328 [run_pretraining.py:  512]:	********exe.run_2705******* 
[INFO] 2021-07-12 19:27:09,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:09,428 [run_pretraining.py:  534]:	loss/total_loss, 7.544952392578125, 2706
[INFO] 2021-07-12 19:27:09,428 [run_pretraining.py:  535]:	loss/mlm_loss, 7.544952392578125, 2706
[INFO] 2021-07-12 19:27:09,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.705000042624306e-05, 2706
[INFO] 2021-07-12 19:27:09,428 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2706
[INFO] 2021-07-12 19:27:09,428 [run_pretraining.py:  558]:	worker_index: 7, step: 2706, cost: 7.544952, mlm loss: 7.544952, speed: 0.909652 steps/s, speed: 7.277214 samples/s, speed: 3725.933428 tokens/s, learning rate: 2.705e-05, loss_scalings: 2814.750488, pp_loss: 6.197361
[INFO] 2021-07-12 19:27:09,428 [run_pretraining.py:  512]:	********exe.run_2706******* 
[INFO] 2021-07-12 19:27:10,528 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:10,529 [run_pretraining.py:  534]:	loss/total_loss, 7.3271164894104, 2707
[INFO] 2021-07-12 19:27:10,529 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3271164894104, 2707
[INFO] 2021-07-12 19:27:10,529 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7059997592004947e-05, 2707
[INFO] 2021-07-12 19:27:10,529 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2707
[INFO] 2021-07-12 19:27:10,529 [run_pretraining.py:  558]:	worker_index: 7, step: 2707, cost: 7.327116, mlm loss: 7.327116, speed: 0.909008 steps/s, speed: 7.272064 samples/s, speed: 3723.296938 tokens/s, learning rate: 2.706e-05, loss_scalings: 2814.750488, pp_loss: 6.750172
[INFO] 2021-07-12 19:27:10,529 [run_pretraining.py:  512]:	********exe.run_2707******* 
[INFO] 2021-07-12 19:27:11,619 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:11,620 [run_pretraining.py:  534]:	loss/total_loss, 7.243415355682373, 2708
[INFO] 2021-07-12 19:27:11,620 [run_pretraining.py:  535]:	loss/mlm_loss, 7.243415355682373, 2708
[INFO] 2021-07-12 19:27:11,620 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7070000214735046e-05, 2708
[INFO] 2021-07-12 19:27:11,620 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2708
[INFO] 2021-07-12 19:27:11,620 [run_pretraining.py:  558]:	worker_index: 7, step: 2708, cost: 7.243415, mlm loss: 7.243415, speed: 0.916777 steps/s, speed: 7.334217 samples/s, speed: 3755.119161 tokens/s, learning rate: 2.707e-05, loss_scalings: 2814.750488, pp_loss: 7.442102
[INFO] 2021-07-12 19:27:11,620 [run_pretraining.py:  512]:	********exe.run_2708******* 
[INFO] 2021-07-12 19:27:12,710 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:12,710 [run_pretraining.py:  534]:	loss/total_loss, 6.767544269561768, 2709
[INFO] 2021-07-12 19:27:12,710 [run_pretraining.py:  535]:	loss/mlm_loss, 6.767544269561768, 2709
[INFO] 2021-07-12 19:27:12,711 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7079999199486338e-05, 2709
[INFO] 2021-07-12 19:27:12,711 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2709
[INFO] 2021-07-12 19:27:12,711 [run_pretraining.py:  558]:	worker_index: 7, step: 2709, cost: 6.767544, mlm loss: 6.767544, speed: 0.917661 steps/s, speed: 7.341292 samples/s, speed: 3758.741478 tokens/s, learning rate: 2.708e-05, loss_scalings: 2814.750488, pp_loss: 7.262610
[INFO] 2021-07-12 19:27:12,711 [run_pretraining.py:  512]:	********exe.run_2709******* 
[INFO] 2021-07-12 19:27:13,808 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:13,809 [run_pretraining.py:  534]:	loss/total_loss, 7.450419902801514, 2710
[INFO] 2021-07-12 19:27:13,809 [run_pretraining.py:  535]:	loss/mlm_loss, 7.450419902801514, 2710
[INFO] 2021-07-12 19:27:13,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7090000003227033e-05, 2710
[INFO] 2021-07-12 19:27:13,809 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2710
[INFO] 2021-07-12 19:27:13,809 [run_pretraining.py:  558]:	worker_index: 7, step: 2710, cost: 7.450420, mlm loss: 7.450420, speed: 0.910726 steps/s, speed: 7.285810 samples/s, speed: 3730.334535 tokens/s, learning rate: 2.709e-05, loss_scalings: 2814.750488, pp_loss: 7.308257
[INFO] 2021-07-12 19:27:13,809 [run_pretraining.py:  512]:	********exe.run_2710******* 
[INFO] 2021-07-12 19:27:14,775 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:14,776 [run_pretraining.py:  534]:	loss/total_loss, 7.537879943847656, 2711
[INFO] 2021-07-12 19:27:14,776 [run_pretraining.py:  535]:	loss/mlm_loss, 7.537879943847656, 2711
[INFO] 2021-07-12 19:27:14,776 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7099998987978324e-05, 2711
[INFO] 2021-07-12 19:27:14,776 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2711
[INFO] 2021-07-12 19:27:14,776 [run_pretraining.py:  558]:	worker_index: 7, step: 2711, cost: 7.537880, mlm loss: 7.537880, speed: 1.035130 steps/s, speed: 8.281039 samples/s, speed: 4239.892157 tokens/s, learning rate: 2.710e-05, loss_scalings: 2814.750488, pp_loss: 7.546921
[INFO] 2021-07-12 19:27:14,776 [run_pretraining.py:  512]:	********exe.run_2711******* 
[INFO] 2021-07-12 19:27:15,701 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:15,701 [run_pretraining.py:  534]:	loss/total_loss, 9.086073875427246, 2712
[INFO] 2021-07-12 19:27:15,701 [run_pretraining.py:  535]:	loss/mlm_loss, 9.086073875427246, 2712
[INFO] 2021-07-12 19:27:15,701 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7110001610708423e-05, 2712
[INFO] 2021-07-12 19:27:15,701 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2712
[INFO] 2021-07-12 19:27:15,701 [run_pretraining.py:  558]:	worker_index: 7, step: 2712, cost: 9.086074, mlm loss: 9.086074, speed: 1.081322 steps/s, speed: 8.650578 samples/s, speed: 4429.095819 tokens/s, learning rate: 2.711e-05, loss_scalings: 2814.750488, pp_loss: 7.850461
[INFO] 2021-07-12 19:27:15,702 [run_pretraining.py:  512]:	********exe.run_2712******* 
[INFO] 2021-07-12 19:27:16,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:16,622 [run_pretraining.py:  534]:	loss/total_loss, 8.110895156860352, 2713
[INFO] 2021-07-12 19:27:16,622 [run_pretraining.py:  535]:	loss/mlm_loss, 8.110895156860352, 2713
[INFO] 2021-07-12 19:27:16,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.711999877647031e-05, 2713
[INFO] 2021-07-12 19:27:16,622 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2713
[INFO] 2021-07-12 19:27:16,622 [run_pretraining.py:  558]:	worker_index: 7, step: 2713, cost: 8.110895, mlm loss: 8.110895, speed: 1.087192 steps/s, speed: 8.697538 samples/s, speed: 4453.139470 tokens/s, learning rate: 2.712e-05, loss_scalings: 2814.750488, pp_loss: 7.823365
[INFO] 2021-07-12 19:27:16,622 [run_pretraining.py:  512]:	********exe.run_2713******* 
[INFO] 2021-07-12 19:27:17,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:17,539 [run_pretraining.py:  534]:	loss/total_loss, 7.152693748474121, 2714
[INFO] 2021-07-12 19:27:17,539 [run_pretraining.py:  535]:	loss/mlm_loss, 7.152693748474121, 2714
[INFO] 2021-07-12 19:27:17,539 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7129997761221603e-05, 2714
[INFO] 2021-07-12 19:27:17,539 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2714
[INFO] 2021-07-12 19:27:17,540 [run_pretraining.py:  558]:	worker_index: 7, step: 2714, cost: 7.152694, mlm loss: 7.152694, speed: 1.090627 steps/s, speed: 8.725016 samples/s, speed: 4467.208331 tokens/s, learning rate: 2.713e-05, loss_scalings: 2814.750488, pp_loss: 7.460598
[INFO] 2021-07-12 19:27:17,540 [run_pretraining.py:  512]:	********exe.run_2714******* 
[INFO] 2021-07-12 19:27:18,458 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:18,458 [run_pretraining.py:  534]:	loss/total_loss, 7.017653942108154, 2715
[INFO] 2021-07-12 19:27:18,458 [run_pretraining.py:  535]:	loss/mlm_loss, 7.017653942108154, 2715
[INFO] 2021-07-12 19:27:18,458 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.71400003839517e-05, 2715
[INFO] 2021-07-12 19:27:18,458 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2715
[INFO] 2021-07-12 19:27:18,458 [run_pretraining.py:  558]:	worker_index: 7, step: 2715, cost: 7.017654, mlm loss: 7.017654, speed: 1.089045 steps/s, speed: 8.712362 samples/s, speed: 4460.729105 tokens/s, learning rate: 2.714e-05, loss_scalings: 2814.750488, pp_loss: 7.226578
[INFO] 2021-07-12 19:27:18,458 [run_pretraining.py:  512]:	********exe.run_2715******* 
[INFO] 2021-07-12 19:27:19,378 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:19,378 [run_pretraining.py:  534]:	loss/total_loss, 7.258957862854004, 2716
[INFO] 2021-07-12 19:27:19,378 [run_pretraining.py:  535]:	loss/mlm_loss, 7.258957862854004, 2716
[INFO] 2021-07-12 19:27:19,378 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.714999754971359e-05, 2716
[INFO] 2021-07-12 19:27:19,379 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2716
[INFO] 2021-07-12 19:27:19,379 [run_pretraining.py:  558]:	worker_index: 7, step: 2716, cost: 7.258958, mlm loss: 7.258958, speed: 1.087485 steps/s, speed: 8.699881 samples/s, speed: 4454.339094 tokens/s, learning rate: 2.715e-05, loss_scalings: 2814.750488, pp_loss: 7.237613
[INFO] 2021-07-12 19:27:19,379 [run_pretraining.py:  512]:	********exe.run_2716******* 
[INFO] 2021-07-12 19:27:20,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:20,303 [run_pretraining.py:  534]:	loss/total_loss, 7.504915237426758, 2717
[INFO] 2021-07-12 19:27:20,303 [run_pretraining.py:  535]:	loss/mlm_loss, 7.504915237426758, 2717
[INFO] 2021-07-12 19:27:20,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7160000172443688e-05, 2717
[INFO] 2021-07-12 19:27:20,303 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2717
[INFO] 2021-07-12 19:27:20,303 [run_pretraining.py:  558]:	worker_index: 7, step: 2717, cost: 7.504915, mlm loss: 7.504915, speed: 1.082671 steps/s, speed: 8.661370 samples/s, speed: 4434.621281 tokens/s, learning rate: 2.716e-05, loss_scalings: 2814.750488, pp_loss: 7.310147
[INFO] 2021-07-12 19:27:20,303 [run_pretraining.py:  512]:	********exe.run_2717******* 
[INFO] 2021-07-12 19:27:21,244 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:21,245 [run_pretraining.py:  534]:	loss/total_loss, 7.370748043060303, 2718
[INFO] 2021-07-12 19:27:21,245 [run_pretraining.py:  535]:	loss/mlm_loss, 7.370748043060303, 2718
[INFO] 2021-07-12 19:27:21,245 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.716999915719498e-05, 2718
[INFO] 2021-07-12 19:27:21,245 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2718
[INFO] 2021-07-12 19:27:21,245 [run_pretraining.py:  558]:	worker_index: 7, step: 2718, cost: 7.370748, mlm loss: 7.370748, speed: 1.061886 steps/s, speed: 8.495088 samples/s, speed: 4349.484826 tokens/s, learning rate: 2.717e-05, loss_scalings: 2814.750488, pp_loss: 7.474884
[INFO] 2021-07-12 19:27:21,245 [run_pretraining.py:  512]:	********exe.run_2718******* 
[INFO] 2021-07-12 19:27:22,169 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:22,169 [run_pretraining.py:  534]:	loss/total_loss, 6.81367301940918, 2719
[INFO] 2021-07-12 19:27:22,169 [run_pretraining.py:  535]:	loss/mlm_loss, 6.81367301940918, 2719
[INFO] 2021-07-12 19:27:22,169 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7179999960935675e-05, 2719
[INFO] 2021-07-12 19:27:22,169 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2719
[INFO] 2021-07-12 19:27:22,169 [run_pretraining.py:  558]:	worker_index: 7, step: 2719, cost: 6.813673, mlm loss: 6.813673, speed: 1.082720 steps/s, speed: 8.661756 samples/s, speed: 4434.819323 tokens/s, learning rate: 2.718e-05, loss_scalings: 2814.750488, pp_loss: 7.340430
[INFO] 2021-07-12 19:27:22,170 [run_pretraining.py:  512]:	********exe.run_2719******* 
[INFO] 2021-07-12 19:27:23,096 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:23,097 [run_pretraining.py:  534]:	loss/total_loss, 7.737448692321777, 2720
[INFO] 2021-07-12 19:27:23,097 [run_pretraining.py:  535]:	loss/mlm_loss, 7.737448692321777, 2720
[INFO] 2021-07-12 19:27:23,097 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7189998945686966e-05, 2720
[INFO] 2021-07-12 19:27:23,097 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2720
[INFO] 2021-07-12 19:27:23,097 [run_pretraining.py:  558]:	worker_index: 7, step: 2720, cost: 7.737449, mlm loss: 7.737449, speed: 1.079080 steps/s, speed: 8.632638 samples/s, speed: 4419.910429 tokens/s, learning rate: 2.719e-05, loss_scalings: 2814.750488, pp_loss: 7.046006
[INFO] 2021-07-12 19:27:23,097 [run_pretraining.py:  512]:	********exe.run_2720******* 
[INFO] 2021-07-12 19:27:24,018 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:24,019 [run_pretraining.py:  534]:	loss/total_loss, 7.197227954864502, 2721
[INFO] 2021-07-12 19:27:24,019 [run_pretraining.py:  535]:	loss/mlm_loss, 7.197227954864502, 2721
[INFO] 2021-07-12 19:27:24,019 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7200001568417065e-05, 2721
[INFO] 2021-07-12 19:27:24,019 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2721
[INFO] 2021-07-12 19:27:24,019 [run_pretraining.py:  558]:	worker_index: 7, step: 2721, cost: 7.197228, mlm loss: 7.197228, speed: 1.084901 steps/s, speed: 8.679210 samples/s, speed: 4443.755334 tokens/s, learning rate: 2.720e-05, loss_scalings: 2814.750488, pp_loss: 6.834140
[INFO] 2021-07-12 19:27:24,019 [run_pretraining.py:  512]:	********exe.run_2721******* 
[INFO] 2021-07-12 19:27:24,941 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:24,941 [run_pretraining.py:  534]:	loss/total_loss, 7.37662935256958, 2722
[INFO] 2021-07-12 19:27:24,941 [run_pretraining.py:  535]:	loss/mlm_loss, 7.37662935256958, 2722
[INFO] 2021-07-12 19:27:24,941 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7209998734178953e-05, 2722
[INFO] 2021-07-12 19:27:24,941 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2722
[INFO] 2021-07-12 19:27:24,941 [run_pretraining.py:  558]:	worker_index: 7, step: 2722, cost: 7.376629, mlm loss: 7.376629, speed: 1.085035 steps/s, speed: 8.680276 samples/s, speed: 4444.301378 tokens/s, learning rate: 2.721e-05, loss_scalings: 2814.750488, pp_loss: 7.234817
[INFO] 2021-07-12 19:27:24,942 [run_pretraining.py:  512]:	********exe.run_2722******* 
[INFO] 2021-07-12 19:27:25,870 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:25,870 [run_pretraining.py:  534]:	loss/total_loss, 7.457665920257568, 2723
[INFO] 2021-07-12 19:27:25,870 [run_pretraining.py:  535]:	loss/mlm_loss, 7.457665920257568, 2723
[INFO] 2021-07-12 19:27:25,870 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7219997718930244e-05, 2723
[INFO] 2021-07-12 19:27:25,870 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2723
[INFO] 2021-07-12 19:27:25,870 [run_pretraining.py:  558]:	worker_index: 7, step: 2723, cost: 7.457666, mlm loss: 7.457666, speed: 1.077238 steps/s, speed: 8.617905 samples/s, speed: 4412.367149 tokens/s, learning rate: 2.722e-05, loss_scalings: 2814.750488, pp_loss: 7.148685
[INFO] 2021-07-12 19:27:25,871 [run_pretraining.py:  512]:	********exe.run_2723******* 
[INFO] 2021-07-12 19:27:26,796 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:26,797 [run_pretraining.py:  534]:	loss/total_loss, 6.993648529052734, 2724
[INFO] 2021-07-12 19:27:26,797 [run_pretraining.py:  535]:	loss/mlm_loss, 6.993648529052734, 2724
[INFO] 2021-07-12 19:27:26,797 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7230000341660343e-05, 2724
[INFO] 2021-07-12 19:27:26,797 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2724
[INFO] 2021-07-12 19:27:26,797 [run_pretraining.py:  558]:	worker_index: 7, step: 2724, cost: 6.993649, mlm loss: 6.993649, speed: 1.079794 steps/s, speed: 8.638354 samples/s, speed: 4422.837043 tokens/s, learning rate: 2.723e-05, loss_scalings: 2814.750488, pp_loss: 7.242324
[INFO] 2021-07-12 19:27:26,797 [run_pretraining.py:  512]:	********exe.run_2724******* 
[INFO] 2021-07-12 19:27:27,720 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:27,721 [run_pretraining.py:  534]:	loss/total_loss, 7.2222490310668945, 2725
[INFO] 2021-07-12 19:27:27,721 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2222490310668945, 2725
[INFO] 2021-07-12 19:27:27,721 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7239999326411635e-05, 2725
[INFO] 2021-07-12 19:27:27,721 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2725
[INFO] 2021-07-12 19:27:27,721 [run_pretraining.py:  558]:	worker_index: 7, step: 2725, cost: 7.222249, mlm loss: 7.222249, speed: 1.082874 steps/s, speed: 8.662989 samples/s, speed: 4435.450201 tokens/s, learning rate: 2.724e-05, loss_scalings: 2814.750488, pp_loss: 7.237061
[INFO] 2021-07-12 19:27:27,721 [run_pretraining.py:  512]:	********exe.run_2725******* 
[INFO] 2021-07-12 19:27:28,658 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:28,659 [run_pretraining.py:  534]:	loss/total_loss, 7.819652557373047, 2726
[INFO] 2021-07-12 19:27:28,659 [run_pretraining.py:  535]:	loss/mlm_loss, 7.819652557373047, 2726
[INFO] 2021-07-12 19:27:28,659 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.725000013015233e-05, 2726
[INFO] 2021-07-12 19:27:28,659 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2726
[INFO] 2021-07-12 19:27:28,659 [run_pretraining.py:  558]:	worker_index: 7, step: 2726, cost: 7.819653, mlm loss: 7.819653, speed: 1.067271 steps/s, speed: 8.538171 samples/s, speed: 4371.543626 tokens/s, learning rate: 2.725e-05, loss_scalings: 2814.750488, pp_loss: 7.357886
[INFO] 2021-07-12 19:27:28,659 [run_pretraining.py:  512]:	********exe.run_2726******* 
[INFO] 2021-07-12 19:27:29,587 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:29,588 [run_pretraining.py:  534]:	loss/total_loss, 7.534602165222168, 2727
[INFO] 2021-07-12 19:27:29,588 [run_pretraining.py:  535]:	loss/mlm_loss, 7.534602165222168, 2727
[INFO] 2021-07-12 19:27:29,588 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.725999911490362e-05, 2727
[INFO] 2021-07-12 19:27:29,588 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2727
[INFO] 2021-07-12 19:27:29,588 [run_pretraining.py:  558]:	worker_index: 7, step: 2727, cost: 7.534602, mlm loss: 7.534602, speed: 1.076964 steps/s, speed: 8.615712 samples/s, speed: 4411.244390 tokens/s, learning rate: 2.726e-05, loss_scalings: 2814.750488, pp_loss: 7.379807
[INFO] 2021-07-12 19:27:29,588 [run_pretraining.py:  512]:	********exe.run_2727******* 
[INFO] 2021-07-12 19:27:30,515 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:30,516 [run_pretraining.py:  534]:	loss/total_loss, 7.249724388122559, 2728
[INFO] 2021-07-12 19:27:30,516 [run_pretraining.py:  535]:	loss/mlm_loss, 7.249724388122559, 2728
[INFO] 2021-07-12 19:27:30,516 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7269999918644316e-05, 2728
[INFO] 2021-07-12 19:27:30,516 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2728
[INFO] 2021-07-12 19:27:30,516 [run_pretraining.py:  558]:	worker_index: 7, step: 2728, cost: 7.249724, mlm loss: 7.249724, speed: 1.078416 steps/s, speed: 8.627328 samples/s, speed: 4417.192106 tokens/s, learning rate: 2.727e-05, loss_scalings: 2814.750488, pp_loss: 7.232115
[INFO] 2021-07-12 19:27:30,516 [run_pretraining.py:  512]:	********exe.run_2728******* 
[INFO] 2021-07-12 19:27:31,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:31,449 [run_pretraining.py:  534]:	loss/total_loss, 7.197571277618408, 2729
[INFO] 2021-07-12 19:27:31,449 [run_pretraining.py:  535]:	loss/mlm_loss, 7.197571277618408, 2729
[INFO] 2021-07-12 19:27:31,449 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7279998903395608e-05, 2729
[INFO] 2021-07-12 19:27:31,449 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2729
[INFO] 2021-07-12 19:27:31,449 [run_pretraining.py:  558]:	worker_index: 7, step: 2729, cost: 7.197571, mlm loss: 7.197571, speed: 1.072498 steps/s, speed: 8.579980 samples/s, speed: 4392.949846 tokens/s, learning rate: 2.728e-05, loss_scalings: 2814.750488, pp_loss: 7.131348
[INFO] 2021-07-12 19:27:31,449 [run_pretraining.py:  512]:	********exe.run_2729******* 
[INFO] 2021-07-12 19:27:32,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:32,387 [run_pretraining.py:  534]:	loss/total_loss, 7.373823165893555, 2730
[INFO] 2021-07-12 19:27:32,387 [run_pretraining.py:  535]:	loss/mlm_loss, 7.373823165893555, 2730
[INFO] 2021-07-12 19:27:32,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.72899978881469e-05, 2730
[INFO] 2021-07-12 19:27:32,387 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2730
[INFO] 2021-07-12 19:27:32,387 [run_pretraining.py:  558]:	worker_index: 7, step: 2730, cost: 7.373823, mlm loss: 7.373823, speed: 1.066476 steps/s, speed: 8.531808 samples/s, speed: 4368.285695 tokens/s, learning rate: 2.729e-05, loss_scalings: 2814.750488, pp_loss: 6.966177
[INFO] 2021-07-12 19:27:32,387 [run_pretraining.py:  512]:	********exe.run_2730******* 
[INFO] 2021-07-12 19:27:33,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:33,326 [run_pretraining.py:  534]:	loss/total_loss, 7.720490455627441, 2731
[INFO] 2021-07-12 19:27:33,326 [run_pretraining.py:  535]:	loss/mlm_loss, 7.720490455627441, 2731
[INFO] 2021-07-12 19:27:33,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7299998691887595e-05, 2731
[INFO] 2021-07-12 19:27:33,326 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2731
[INFO] 2021-07-12 19:27:33,326 [run_pretraining.py:  558]:	worker_index: 7, step: 2731, cost: 7.720490, mlm loss: 7.720490, speed: 1.066051 steps/s, speed: 8.528406 samples/s, speed: 4366.543680 tokens/s, learning rate: 2.730e-05, loss_scalings: 2814.750488, pp_loss: 7.223186
[INFO] 2021-07-12 19:27:33,326 [run_pretraining.py:  512]:	********exe.run_2731******* 
[INFO] 2021-07-12 19:27:34,268 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:34,269 [run_pretraining.py:  534]:	loss/total_loss, 7.119339942932129, 2732
[INFO] 2021-07-12 19:27:34,269 [run_pretraining.py:  535]:	loss/mlm_loss, 7.119339942932129, 2732
[INFO] 2021-07-12 19:27:34,269 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7309997676638886e-05, 2732
[INFO] 2021-07-12 19:27:34,269 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2732
[INFO] 2021-07-12 19:27:34,269 [run_pretraining.py:  558]:	worker_index: 7, step: 2732, cost: 7.119340, mlm loss: 7.119340, speed: 1.061100 steps/s, speed: 8.488797 samples/s, speed: 4346.264078 tokens/s, learning rate: 2.731e-05, loss_scalings: 2814.750488, pp_loss: 7.225474
[INFO] 2021-07-12 19:27:34,269 [run_pretraining.py:  512]:	********exe.run_2732******* 
[INFO] 2021-07-12 19:27:35,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:35,206 [run_pretraining.py:  534]:	loss/total_loss, 6.467912673950195, 2733
[INFO] 2021-07-12 19:27:35,206 [run_pretraining.py:  535]:	loss/mlm_loss, 6.467912673950195, 2733
[INFO] 2021-07-12 19:27:35,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7320000299368985e-05, 2733
[INFO] 2021-07-12 19:27:35,206 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2733
[INFO] 2021-07-12 19:27:35,207 [run_pretraining.py:  558]:	worker_index: 7, step: 2733, cost: 6.467913, mlm loss: 6.467913, speed: 1.067451 steps/s, speed: 8.539612 samples/s, speed: 4372.281252 tokens/s, learning rate: 2.732e-05, loss_scalings: 2814.750488, pp_loss: 6.859089
[INFO] 2021-07-12 19:27:35,207 [run_pretraining.py:  512]:	********exe.run_2733******* 
[INFO] 2021-07-12 19:27:36,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:36,138 [run_pretraining.py:  534]:	loss/total_loss, 7.285945415496826, 2734
[INFO] 2021-07-12 19:27:36,138 [run_pretraining.py:  535]:	loss/mlm_loss, 7.285945415496826, 2734
[INFO] 2021-07-12 19:27:36,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7329999284120277e-05, 2734
[INFO] 2021-07-12 19:27:36,138 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2734
[INFO] 2021-07-12 19:27:36,138 [run_pretraining.py:  558]:	worker_index: 7, step: 2734, cost: 7.285945, mlm loss: 7.285945, speed: 1.074067 steps/s, speed: 8.592535 samples/s, speed: 4399.377728 tokens/s, learning rate: 2.733e-05, loss_scalings: 2814.750488, pp_loss: 7.203150
[INFO] 2021-07-12 19:27:36,138 [run_pretraining.py:  512]:	********exe.run_2734******* 
[INFO] 2021-07-12 19:27:37,071 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:37,072 [run_pretraining.py:  534]:	loss/total_loss, 7.256394386291504, 2735
[INFO] 2021-07-12 19:27:37,072 [run_pretraining.py:  535]:	loss/mlm_loss, 7.256394386291504, 2735
[INFO] 2021-07-12 19:27:37,072 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.734000008786097e-05, 2735
[INFO] 2021-07-12 19:27:37,072 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2735
[INFO] 2021-07-12 19:27:37,072 [run_pretraining.py:  558]:	worker_index: 7, step: 2735, cost: 7.256394, mlm loss: 7.256394, speed: 1.071370 steps/s, speed: 8.570959 samples/s, speed: 4388.331237 tokens/s, learning rate: 2.734e-05, loss_scalings: 2814.750488, pp_loss: 7.155124
[INFO] 2021-07-12 19:27:37,072 [run_pretraining.py:  512]:	********exe.run_2735******* 
[INFO] 2021-07-12 19:27:37,986 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:37,987 [run_pretraining.py:  534]:	loss/total_loss, 7.710787773132324, 2736
[INFO] 2021-07-12 19:27:37,987 [run_pretraining.py:  535]:	loss/mlm_loss, 7.710787773132324, 2736
[INFO] 2021-07-12 19:27:37,987 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7349999072612263e-05, 2736
[INFO] 2021-07-12 19:27:37,987 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2736
[INFO] 2021-07-12 19:27:37,987 [run_pretraining.py:  558]:	worker_index: 7, step: 2736, cost: 7.710788, mlm loss: 7.710788, speed: 1.094110 steps/s, speed: 8.752883 samples/s, speed: 4481.476254 tokens/s, learning rate: 2.735e-05, loss_scalings: 2814.750488, pp_loss: 7.209651
[INFO] 2021-07-12 19:27:37,987 [run_pretraining.py:  512]:	********exe.run_2736******* 
[INFO] 2021-07-12 19:27:38,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:38,910 [run_pretraining.py:  534]:	loss/total_loss, 7.25860595703125, 2737
[INFO] 2021-07-12 19:27:38,910 [run_pretraining.py:  535]:	loss/mlm_loss, 7.25860595703125, 2737
[INFO] 2021-07-12 19:27:38,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.735999987635296e-05, 2737
[INFO] 2021-07-12 19:27:38,910 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2737
[INFO] 2021-07-12 19:27:38,910 [run_pretraining.py:  558]:	worker_index: 7, step: 2737, cost: 7.258606, mlm loss: 7.258606, speed: 1.083760 steps/s, speed: 8.670082 samples/s, speed: 4439.082096 tokens/s, learning rate: 2.736e-05, loss_scalings: 2814.750488, pp_loss: 7.388178
[INFO] 2021-07-12 19:27:38,910 [run_pretraining.py:  512]:	********exe.run_2737******* 
[INFO] 2021-07-12 19:27:39,829 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  534]:	loss/total_loss, 7.104778289794922, 2738
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  535]:	loss/mlm_loss, 7.104778289794922, 2738
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.736999886110425e-05, 2738
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2738
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  558]:	worker_index: 7, step: 2738, cost: 7.104778, mlm loss: 7.104778, speed: 1.087939 steps/s, speed: 8.703510 samples/s, speed: 4456.196958 tokens/s, learning rate: 2.737e-05, loss_scalings: 2814.750488, pp_loss: 7.370679
[INFO] 2021-07-12 19:27:39,830 [run_pretraining.py:  512]:	********exe.run_2738******* 
[INFO] 2021-07-12 19:27:40,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:40,757 [run_pretraining.py:  534]:	loss/total_loss, 7.322351455688477, 2739
[INFO] 2021-07-12 19:27:40,757 [run_pretraining.py:  535]:	loss/mlm_loss, 7.322351455688477, 2739
[INFO] 2021-07-12 19:27:40,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.737999784585554e-05, 2739
[INFO] 2021-07-12 19:27:40,757 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2739
[INFO] 2021-07-12 19:27:40,757 [run_pretraining.py:  558]:	worker_index: 7, step: 2739, cost: 7.322351, mlm loss: 7.322351, speed: 1.079703 steps/s, speed: 8.637622 samples/s, speed: 4422.462466 tokens/s, learning rate: 2.738e-05, loss_scalings: 2814.750488, pp_loss: 7.322126
[INFO] 2021-07-12 19:27:40,757 [run_pretraining.py:  512]:	********exe.run_2739******* 
[INFO] 2021-07-12 19:27:41,683 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:41,683 [run_pretraining.py:  534]:	loss/total_loss, 6.98978328704834, 2740
[INFO] 2021-07-12 19:27:41,683 [run_pretraining.py:  535]:	loss/mlm_loss, 6.98978328704834, 2740
[INFO] 2021-07-12 19:27:41,683 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7389998649596237e-05, 2740
[INFO] 2021-07-12 19:27:41,683 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2740
[INFO] 2021-07-12 19:27:41,683 [run_pretraining.py:  558]:	worker_index: 7, step: 2740, cost: 6.989783, mlm loss: 6.989783, speed: 1.080120 steps/s, speed: 8.640963 samples/s, speed: 4424.173058 tokens/s, learning rate: 2.739e-05, loss_scalings: 2814.750488, pp_loss: 7.373720
[INFO] 2021-07-12 19:27:41,683 [run_pretraining.py:  512]:	********exe.run_2740******* 
[INFO] 2021-07-12 19:27:42,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:42,622 [run_pretraining.py:  534]:	loss/total_loss, 6.694673538208008, 2741
[INFO] 2021-07-12 19:27:42,622 [run_pretraining.py:  535]:	loss/mlm_loss, 6.694673538208008, 2741
[INFO] 2021-07-12 19:27:42,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7399997634347528e-05, 2741
[INFO] 2021-07-12 19:27:42,622 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2741
[INFO] 2021-07-12 19:27:42,622 [run_pretraining.py:  558]:	worker_index: 7, step: 2741, cost: 6.694674, mlm loss: 6.694674, speed: 1.065764 steps/s, speed: 8.526111 samples/s, speed: 4365.368688 tokens/s, learning rate: 2.740e-05, loss_scalings: 2814.750488, pp_loss: 6.985677
[INFO] 2021-07-12 19:27:42,622 [run_pretraining.py:  512]:	********exe.run_2741******* 
[INFO] 2021-07-12 19:27:43,527 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:43,527 [run_pretraining.py:  534]:	loss/total_loss, 5.8123016357421875, 2742
[INFO] 2021-07-12 19:27:43,527 [run_pretraining.py:  535]:	loss/mlm_loss, 5.8123016357421875, 2742
[INFO] 2021-07-12 19:27:43,527 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7410000257077627e-05, 2742
[INFO] 2021-07-12 19:27:43,527 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2742
[INFO] 2021-07-12 19:27:43,528 [run_pretraining.py:  558]:	worker_index: 7, step: 2742, cost: 5.812302, mlm loss: 5.812302, speed: 1.105495 steps/s, speed: 8.843957 samples/s, speed: 4528.105884 tokens/s, learning rate: 2.741e-05, loss_scalings: 2814.750488, pp_loss: 6.505661
[INFO] 2021-07-12 19:27:43,528 [run_pretraining.py:  512]:	********exe.run_2742******* 
[INFO] 2021-07-12 19:27:44,456 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:44,456 [run_pretraining.py:  534]:	loss/total_loss, 7.688876628875732, 2743
[INFO] 2021-07-12 19:27:44,456 [run_pretraining.py:  535]:	loss/mlm_loss, 7.688876628875732, 2743
[INFO] 2021-07-12 19:27:44,456 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.741999924182892e-05, 2743
[INFO] 2021-07-12 19:27:44,456 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2743
[INFO] 2021-07-12 19:27:44,456 [run_pretraining.py:  558]:	worker_index: 7, step: 2743, cost: 7.688877, mlm loss: 7.688877, speed: 1.077369 steps/s, speed: 8.618952 samples/s, speed: 4412.903238 tokens/s, learning rate: 2.742e-05, loss_scalings: 2814.750488, pp_loss: 7.215787
[INFO] 2021-07-12 19:27:44,456 [run_pretraining.py:  512]:	********exe.run_2743******* 
[INFO] 2021-07-12 19:27:45,379 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:45,379 [run_pretraining.py:  534]:	loss/total_loss, 7.479376316070557, 2744
[INFO] 2021-07-12 19:27:45,379 [run_pretraining.py:  535]:	loss/mlm_loss, 7.479376316070557, 2744
[INFO] 2021-07-12 19:27:45,379 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7430000045569614e-05, 2744
[INFO] 2021-07-12 19:27:45,380 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2744
[INFO] 2021-07-12 19:27:45,380 [run_pretraining.py:  558]:	worker_index: 7, step: 2744, cost: 7.479376, mlm loss: 7.479376, speed: 1.083958 steps/s, speed: 8.671664 samples/s, speed: 4439.892032 tokens/s, learning rate: 2.743e-05, loss_scalings: 2814.750488, pp_loss: 7.366025
[INFO] 2021-07-12 19:27:45,380 [run_pretraining.py:  512]:	********exe.run_2744******* 
[INFO] 2021-07-12 19:27:46,302 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:46,302 [run_pretraining.py:  534]:	loss/total_loss, 6.960006237030029, 2745
[INFO] 2021-07-12 19:27:46,302 [run_pretraining.py:  535]:	loss/mlm_loss, 6.960006237030029, 2745
[INFO] 2021-07-12 19:27:46,303 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7439999030320905e-05, 2745
[INFO] 2021-07-12 19:27:46,303 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2745
[INFO] 2021-07-12 19:27:46,303 [run_pretraining.py:  558]:	worker_index: 7, step: 2745, cost: 6.960006, mlm loss: 6.960006, speed: 1.084070 steps/s, speed: 8.672558 samples/s, speed: 4440.349902 tokens/s, learning rate: 2.744e-05, loss_scalings: 2814.750488, pp_loss: 7.091054
[INFO] 2021-07-12 19:27:46,303 [run_pretraining.py:  512]:	********exe.run_2745******* 
[INFO] 2021-07-12 19:27:47,224 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:47,224 [run_pretraining.py:  534]:	loss/total_loss, 6.637324333190918, 2746
[INFO] 2021-07-12 19:27:47,224 [run_pretraining.py:  535]:	loss/mlm_loss, 6.637324333190918, 2746
[INFO] 2021-07-12 19:27:47,224 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.74499998340616e-05, 2746
[INFO] 2021-07-12 19:27:47,224 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2746
[INFO] 2021-07-12 19:27:47,225 [run_pretraining.py:  558]:	worker_index: 7, step: 2746, cost: 6.637324, mlm loss: 6.637324, speed: 1.085481 steps/s, speed: 8.683848 samples/s, speed: 4446.130164 tokens/s, learning rate: 2.745e-05, loss_scalings: 2814.750488, pp_loss: 6.935413
[INFO] 2021-07-12 19:27:47,225 [run_pretraining.py:  512]:	********exe.run_2746******* 
[INFO] 2021-07-12 19:27:48,144 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:48,145 [run_pretraining.py:  534]:	loss/total_loss, 6.862056255340576, 2747
[INFO] 2021-07-12 19:27:48,145 [run_pretraining.py:  535]:	loss/mlm_loss, 6.862056255340576, 2747
[INFO] 2021-07-12 19:27:48,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7459998818812892e-05, 2747
[INFO] 2021-07-12 19:27:48,145 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2747
[INFO] 2021-07-12 19:27:48,145 [run_pretraining.py:  558]:	worker_index: 7, step: 2747, cost: 6.862056, mlm loss: 6.862056, speed: 1.087323 steps/s, speed: 8.698582 samples/s, speed: 4453.673968 tokens/s, learning rate: 2.746e-05, loss_scalings: 2814.750488, pp_loss: 7.265931
[INFO] 2021-07-12 19:27:48,145 [run_pretraining.py:  512]:	********exe.run_2747******* 
[INFO] 2021-07-12 19:27:49,077 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:49,078 [run_pretraining.py:  534]:	loss/total_loss, 6.952659606933594, 2748
[INFO] 2021-07-12 19:27:49,078 [run_pretraining.py:  535]:	loss/mlm_loss, 6.952659606933594, 2748
[INFO] 2021-07-12 19:27:49,078 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7469997803564183e-05, 2748
[INFO] 2021-07-12 19:27:49,078 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2748
[INFO] 2021-07-12 19:27:49,078 [run_pretraining.py:  558]:	worker_index: 7, step: 2748, cost: 6.952660, mlm loss: 6.952660, speed: 1.072291 steps/s, speed: 8.578331 samples/s, speed: 4392.105293 tokens/s, learning rate: 2.747e-05, loss_scalings: 2814.750488, pp_loss: 6.620347
[INFO] 2021-07-12 19:27:49,078 [run_pretraining.py:  512]:	********exe.run_2748******* 
[INFO] 2021-07-12 19:27:49,997 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:49,998 [run_pretraining.py:  534]:	loss/total_loss, 7.069431781768799, 2749
[INFO] 2021-07-12 19:27:49,998 [run_pretraining.py:  535]:	loss/mlm_loss, 7.069431781768799, 2749
[INFO] 2021-07-12 19:27:49,998 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7480000426294282e-05, 2749
[INFO] 2021-07-12 19:27:49,998 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2749
[INFO] 2021-07-12 19:27:49,998 [run_pretraining.py:  558]:	worker_index: 7, step: 2749, cost: 7.069432, mlm loss: 7.069432, speed: 1.088002 steps/s, speed: 8.704015 samples/s, speed: 4456.455888 tokens/s, learning rate: 2.748e-05, loss_scalings: 2814.750488, pp_loss: 7.127962
[INFO] 2021-07-12 19:27:49,998 [run_pretraining.py:  512]:	********exe.run_2749******* 
[INFO] 2021-07-12 19:27:50,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:50,927 [run_pretraining.py:  534]:	loss/total_loss, 6.249130725860596, 2750
[INFO] 2021-07-12 19:27:50,927 [run_pretraining.py:  535]:	loss/mlm_loss, 6.249130725860596, 2750
[INFO] 2021-07-12 19:27:50,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.748999759205617e-05, 2750
[INFO] 2021-07-12 19:27:50,927 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2750
[INFO] 2021-07-12 19:27:50,927 [run_pretraining.py:  558]:	worker_index: 7, step: 2750, cost: 6.249131, mlm loss: 6.249131, speed: 1.076844 steps/s, speed: 8.614754 samples/s, speed: 4410.753999 tokens/s, learning rate: 2.749e-05, loss_scalings: 2814.750488, pp_loss: 6.834527
[INFO] 2021-07-12 19:27:50,927 [run_pretraining.py:  512]:	********exe.run_2750******* 
[INFO] 2021-07-12 19:27:51,847 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:51,847 [run_pretraining.py:  534]:	loss/total_loss, 7.91444206237793, 2751
[INFO] 2021-07-12 19:27:51,848 [run_pretraining.py:  535]:	loss/mlm_loss, 7.91444206237793, 2751
[INFO] 2021-07-12 19:27:51,848 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750000021478627e-05, 2751
[INFO] 2021-07-12 19:27:51,848 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2751
[INFO] 2021-07-12 19:27:51,848 [run_pretraining.py:  558]:	worker_index: 7, step: 2751, cost: 7.914442, mlm loss: 7.914442, speed: 1.086976 steps/s, speed: 8.695811 samples/s, speed: 4452.255464 tokens/s, learning rate: 2.750e-05, loss_scalings: 2814.750488, pp_loss: 7.792458
[INFO] 2021-07-12 19:27:51,848 [run_pretraining.py:  512]:	********exe.run_2751******* 
[INFO] 2021-07-12 19:27:52,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:52,767 [run_pretraining.py:  534]:	loss/total_loss, 7.767895698547363, 2752
[INFO] 2021-07-12 19:27:52,767 [run_pretraining.py:  535]:	loss/mlm_loss, 7.767895698547363, 2752
[INFO] 2021-07-12 19:27:52,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.750999919953756e-05, 2752
[INFO] 2021-07-12 19:27:52,768 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2752
[INFO] 2021-07-12 19:27:52,768 [run_pretraining.py:  558]:	worker_index: 7, step: 2752, cost: 7.767896, mlm loss: 7.767896, speed: 1.087955 steps/s, speed: 8.703636 samples/s, speed: 4456.261688 tokens/s, learning rate: 2.751e-05, loss_scalings: 2814.750488, pp_loss: 7.304786
[INFO] 2021-07-12 19:27:52,768 [run_pretraining.py:  512]:	********exe.run_2752******* 
[INFO] 2021-07-12 19:27:53,686 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:53,686 [run_pretraining.py:  534]:	loss/total_loss, 7.507734298706055, 2753
[INFO] 2021-07-12 19:27:53,687 [run_pretraining.py:  535]:	loss/mlm_loss, 7.507734298706055, 2753
[INFO] 2021-07-12 19:27:53,687 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7520000003278255e-05, 2753
[INFO] 2021-07-12 19:27:53,687 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2753
[INFO] 2021-07-12 19:27:53,687 [run_pretraining.py:  558]:	worker_index: 7, step: 2753, cost: 7.507734, mlm loss: 7.507734, speed: 1.088701 steps/s, speed: 8.709612 samples/s, speed: 4459.321151 tokens/s, learning rate: 2.752e-05, loss_scalings: 2814.750488, pp_loss: 7.816629
[INFO] 2021-07-12 19:27:53,687 [run_pretraining.py:  512]:	********exe.run_2753******* 
[INFO] 2021-07-12 19:27:54,607 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:54,608 [run_pretraining.py:  534]:	loss/total_loss, 7.934403419494629, 2754
[INFO] 2021-07-12 19:27:54,608 [run_pretraining.py:  535]:	loss/mlm_loss, 7.934403419494629, 2754
[INFO] 2021-07-12 19:27:54,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7529998988029547e-05, 2754
[INFO] 2021-07-12 19:27:54,608 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2754
[INFO] 2021-07-12 19:27:54,608 [run_pretraining.py:  558]:	worker_index: 7, step: 2754, cost: 7.934403, mlm loss: 7.934403, speed: 1.086458 steps/s, speed: 8.691667 samples/s, speed: 4450.133436 tokens/s, learning rate: 2.753e-05, loss_scalings: 2814.750488, pp_loss: 7.521283
[INFO] 2021-07-12 19:27:54,608 [run_pretraining.py:  512]:	********exe.run_2754******* 
[INFO] 2021-07-12 19:27:55,535 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:55,536 [run_pretraining.py:  534]:	loss/total_loss, 7.783783435821533, 2755
[INFO] 2021-07-12 19:27:55,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.783783435821533, 2755
[INFO] 2021-07-12 19:27:55,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7539999791770242e-05, 2755
[INFO] 2021-07-12 19:27:55,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2755
[INFO] 2021-07-12 19:27:55,536 [run_pretraining.py:  558]:	worker_index: 7, step: 2755, cost: 7.783783, mlm loss: 7.783783, speed: 1.077945 steps/s, speed: 8.623557 samples/s, speed: 4415.261084 tokens/s, learning rate: 2.754e-05, loss_scalings: 2814.750488, pp_loss: 7.718563
[INFO] 2021-07-12 19:27:55,536 [run_pretraining.py:  512]:	********exe.run_2755******* 
[INFO] 2021-07-12 19:27:56,463 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:56,464 [run_pretraining.py:  534]:	loss/total_loss, 7.1743059158325195, 2756
[INFO] 2021-07-12 19:27:56,464 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1743059158325195, 2756
[INFO] 2021-07-12 19:27:56,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7549998776521534e-05, 2756
[INFO] 2021-07-12 19:27:56,464 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2756
[INFO] 2021-07-12 19:27:56,464 [run_pretraining.py:  558]:	worker_index: 7, step: 2756, cost: 7.174306, mlm loss: 7.174306, speed: 1.078769 steps/s, speed: 8.630151 samples/s, speed: 4418.637219 tokens/s, learning rate: 2.755e-05, loss_scalings: 2814.750488, pp_loss: 7.231966
[INFO] 2021-07-12 19:27:56,464 [run_pretraining.py:  512]:	********exe.run_2756******* 
[INFO] 2021-07-12 19:27:57,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:57,386 [run_pretraining.py:  534]:	loss/total_loss, 7.539749622344971, 2757
[INFO] 2021-07-12 19:27:57,386 [run_pretraining.py:  535]:	loss/mlm_loss, 7.539749622344971, 2757
[INFO] 2021-07-12 19:27:57,386 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7559997761272825e-05, 2757
[INFO] 2021-07-12 19:27:57,386 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2757
[INFO] 2021-07-12 19:27:57,386 [run_pretraining.py:  558]:	worker_index: 7, step: 2757, cost: 7.539750, mlm loss: 7.539750, speed: 1.085320 steps/s, speed: 8.682563 samples/s, speed: 4445.472088 tokens/s, learning rate: 2.756e-05, loss_scalings: 2814.750488, pp_loss: 7.192734
[INFO] 2021-07-12 19:27:57,386 [run_pretraining.py:  512]:	********exe.run_2757******* 
[INFO] 2021-07-12 19:27:58,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:58,400 [run_pretraining.py:  534]:	loss/total_loss, 7.090641975402832, 2758
[INFO] 2021-07-12 19:27:58,400 [run_pretraining.py:  535]:	loss/mlm_loss, 7.090641975402832, 2758
[INFO] 2021-07-12 19:27:58,400 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7570000384002924e-05, 2758
[INFO] 2021-07-12 19:27:58,400 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2758
[INFO] 2021-07-12 19:27:58,400 [run_pretraining.py:  558]:	worker_index: 7, step: 2758, cost: 7.090642, mlm loss: 7.090642, speed: 0.986751 steps/s, speed: 7.894009 samples/s, speed: 4041.732543 tokens/s, learning rate: 2.757e-05, loss_scalings: 2814.750488, pp_loss: 7.277455
[INFO] 2021-07-12 19:27:58,400 [run_pretraining.py:  512]:	********exe.run_2758******* 
[INFO] 2021-07-12 19:27:59,465 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:27:59,466 [run_pretraining.py:  534]:	loss/total_loss, 7.19968318939209, 2759
[INFO] 2021-07-12 19:27:59,466 [run_pretraining.py:  535]:	loss/mlm_loss, 7.19968318939209, 2759
[INFO] 2021-07-12 19:27:59,466 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7579997549764812e-05, 2759
[INFO] 2021-07-12 19:27:59,466 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2759
[INFO] 2021-07-12 19:27:59,466 [run_pretraining.py:  558]:	worker_index: 7, step: 2759, cost: 7.199683, mlm loss: 7.199683, speed: 0.938707 steps/s, speed: 7.509655 samples/s, speed: 3844.943566 tokens/s, learning rate: 2.758e-05, loss_scalings: 2814.750488, pp_loss: 7.322978
[INFO] 2021-07-12 19:27:59,466 [run_pretraining.py:  512]:	********exe.run_2759******* 
[INFO] 2021-07-12 19:28:00,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:00,536 [run_pretraining.py:  534]:	loss/total_loss, 7.760851860046387, 2760
[INFO] 2021-07-12 19:28:00,536 [run_pretraining.py:  535]:	loss/mlm_loss, 7.760851860046387, 2760
[INFO] 2021-07-12 19:28:00,536 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.759000017249491e-05, 2760
[INFO] 2021-07-12 19:28:00,536 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2760
[INFO] 2021-07-12 19:28:00,536 [run_pretraining.py:  558]:	worker_index: 7, step: 2760, cost: 7.760852, mlm loss: 7.760852, speed: 0.934619 steps/s, speed: 7.476949 samples/s, speed: 3828.197987 tokens/s, learning rate: 2.759e-05, loss_scalings: 2814.750488, pp_loss: 7.340133
[INFO] 2021-07-12 19:28:00,537 [run_pretraining.py:  512]:	********exe.run_2760******* 
[INFO] 2021-07-12 19:28:01,600 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:01,601 [run_pretraining.py:  534]:	loss/total_loss, 6.950334548950195, 2761
[INFO] 2021-07-12 19:28:01,601 [run_pretraining.py:  535]:	loss/mlm_loss, 6.950334548950195, 2761
[INFO] 2021-07-12 19:28:01,601 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7599999157246202e-05, 2761
[INFO] 2021-07-12 19:28:01,601 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2761
[INFO] 2021-07-12 19:28:01,601 [run_pretraining.py:  558]:	worker_index: 7, step: 2761, cost: 6.950335, mlm loss: 6.950335, speed: 0.940000 steps/s, speed: 7.520003 samples/s, speed: 3850.241322 tokens/s, learning rate: 2.760e-05, loss_scalings: 2814.750488, pp_loss: 7.308469
[INFO] 2021-07-12 19:28:01,601 [run_pretraining.py:  512]:	********exe.run_2761******* 
[INFO] 2021-07-12 19:28:02,701 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:02,702 [run_pretraining.py:  534]:	loss/total_loss, 6.972787380218506, 2762
[INFO] 2021-07-12 19:28:02,702 [run_pretraining.py:  535]:	loss/mlm_loss, 6.972787380218506, 2762
[INFO] 2021-07-12 19:28:02,702 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7609999960986897e-05, 2762
[INFO] 2021-07-12 19:28:02,702 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2762
[INFO] 2021-07-12 19:28:02,702 [run_pretraining.py:  558]:	worker_index: 7, step: 2762, cost: 6.972787, mlm loss: 6.972787, speed: 0.908600 steps/s, speed: 7.268797 samples/s, speed: 3721.624119 tokens/s, learning rate: 2.761e-05, loss_scalings: 2814.750488, pp_loss: 7.172921
[INFO] 2021-07-12 19:28:02,702 [run_pretraining.py:  512]:	********exe.run_2762******* 
[INFO] 2021-07-12 19:28:03,767 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:03,767 [run_pretraining.py:  534]:	loss/total_loss, 7.03548526763916, 2763
[INFO] 2021-07-12 19:28:03,767 [run_pretraining.py:  535]:	loss/mlm_loss, 7.03548526763916, 2763
[INFO] 2021-07-12 19:28:03,767 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.761999894573819e-05, 2763
[INFO] 2021-07-12 19:28:03,767 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2763
[INFO] 2021-07-12 19:28:03,768 [run_pretraining.py:  558]:	worker_index: 7, step: 2763, cost: 7.035485, mlm loss: 7.035485, speed: 0.939304 steps/s, speed: 7.514433 samples/s, speed: 3847.389854 tokens/s, learning rate: 2.762e-05, loss_scalings: 2814.750488, pp_loss: 7.361584
[INFO] 2021-07-12 19:28:03,768 [run_pretraining.py:  512]:	********exe.run_2763******* 
[INFO] 2021-07-12 19:28:04,843 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:04,843 [run_pretraining.py:  534]:	loss/total_loss, 6.78801965713501, 2764
[INFO] 2021-07-12 19:28:04,843 [run_pretraining.py:  535]:	loss/mlm_loss, 6.78801965713501, 2764
[INFO] 2021-07-12 19:28:04,843 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7629999749478884e-05, 2764
[INFO] 2021-07-12 19:28:04,843 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2764
[INFO] 2021-07-12 19:28:04,843 [run_pretraining.py:  558]:	worker_index: 7, step: 2764, cost: 6.788020, mlm loss: 6.788020, speed: 0.929959 steps/s, speed: 7.439676 samples/s, speed: 3809.113870 tokens/s, learning rate: 2.763e-05, loss_scalings: 2814.750488, pp_loss: 7.101103
[INFO] 2021-07-12 19:28:04,844 [run_pretraining.py:  512]:	********exe.run_2764******* 
[INFO] 2021-07-12 19:28:05,909 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:05,909 [run_pretraining.py:  534]:	loss/total_loss, 7.19789981842041, 2765
[INFO] 2021-07-12 19:28:05,909 [run_pretraining.py:  535]:	loss/mlm_loss, 7.19789981842041, 2765
[INFO] 2021-07-12 19:28:05,910 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7639998734230176e-05, 2765
[INFO] 2021-07-12 19:28:05,910 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2765
[INFO] 2021-07-12 19:28:05,910 [run_pretraining.py:  558]:	worker_index: 7, step: 2765, cost: 7.197900, mlm loss: 7.197900, speed: 0.938543 steps/s, speed: 7.508345 samples/s, speed: 3844.272479 tokens/s, learning rate: 2.764e-05, loss_scalings: 2814.750488, pp_loss: 7.128175
[INFO] 2021-07-12 19:28:05,910 [run_pretraining.py:  512]:	********exe.run_2765******* 
[INFO] 2021-07-12 19:28:06,968 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:06,968 [run_pretraining.py:  534]:	loss/total_loss, 6.950808525085449, 2766
[INFO] 2021-07-12 19:28:06,968 [run_pretraining.py:  535]:	loss/mlm_loss, 6.950808525085449, 2766
[INFO] 2021-07-12 19:28:06,968 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7649997718981467e-05, 2766
[INFO] 2021-07-12 19:28:06,968 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2766
[INFO] 2021-07-12 19:28:06,969 [run_pretraining.py:  558]:	worker_index: 7, step: 2766, cost: 6.950809, mlm loss: 6.950809, speed: 0.944974 steps/s, speed: 7.559792 samples/s, speed: 3870.613547 tokens/s, learning rate: 2.765e-05, loss_scalings: 2814.750488, pp_loss: 6.004559
[INFO] 2021-07-12 19:28:06,969 [run_pretraining.py:  512]:	********exe.run_2766******* 
[INFO] 2021-07-12 19:28:08,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:08,028 [run_pretraining.py:  534]:	loss/total_loss, 7.419572830200195, 2767
[INFO] 2021-07-12 19:28:08,028 [run_pretraining.py:  535]:	loss/mlm_loss, 7.419572830200195, 2767
[INFO] 2021-07-12 19:28:08,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7660000341711566e-05, 2767
[INFO] 2021-07-12 19:28:08,029 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2767
[INFO] 2021-07-12 19:28:08,029 [run_pretraining.py:  558]:	worker_index: 7, step: 2767, cost: 7.419573, mlm loss: 7.419573, speed: 0.943814 steps/s, speed: 7.550511 samples/s, speed: 3865.861502 tokens/s, learning rate: 2.766e-05, loss_scalings: 2814.750488, pp_loss: 7.110720
[INFO] 2021-07-12 19:28:08,029 [run_pretraining.py:  512]:	********exe.run_2767******* 
[INFO] 2021-07-12 19:28:09,097 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:09,098 [run_pretraining.py:  534]:	loss/total_loss, 7.830301761627197, 2768
[INFO] 2021-07-12 19:28:09,098 [run_pretraining.py:  535]:	loss/mlm_loss, 7.830301761627197, 2768
[INFO] 2021-07-12 19:28:09,098 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7669997507473454e-05, 2768
[INFO] 2021-07-12 19:28:09,098 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2768
[INFO] 2021-07-12 19:28:09,098 [run_pretraining.py:  558]:	worker_index: 7, step: 2768, cost: 7.830302, mlm loss: 7.830302, speed: 0.935812 steps/s, speed: 7.486498 samples/s, speed: 3833.087018 tokens/s, learning rate: 2.767e-05, loss_scalings: 2814.750488, pp_loss: 7.199721
[INFO] 2021-07-12 19:28:09,098 [run_pretraining.py:  512]:	********exe.run_2768******* 
[INFO] 2021-07-12 19:28:10,174 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:10,175 [run_pretraining.py:  534]:	loss/total_loss, 7.123898506164551, 2769
[INFO] 2021-07-12 19:28:10,175 [run_pretraining.py:  535]:	loss/mlm_loss, 7.123898506164551, 2769
[INFO] 2021-07-12 19:28:10,175 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7680000130203553e-05, 2769
[INFO] 2021-07-12 19:28:10,175 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2769
[INFO] 2021-07-12 19:28:10,175 [run_pretraining.py:  558]:	worker_index: 7, step: 2769, cost: 7.123899, mlm loss: 7.123899, speed: 0.929034 steps/s, speed: 7.432272 samples/s, speed: 3805.323059 tokens/s, learning rate: 2.768e-05, loss_scalings: 2814.750488, pp_loss: 7.071526
[INFO] 2021-07-12 19:28:10,175 [run_pretraining.py:  512]:	********exe.run_2769******* 
[INFO] 2021-07-12 19:28:11,234 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:11,234 [run_pretraining.py:  534]:	loss/total_loss, 7.451436996459961, 2770
[INFO] 2021-07-12 19:28:11,234 [run_pretraining.py:  535]:	loss/mlm_loss, 7.451436996459961, 2770
[INFO] 2021-07-12 19:28:11,234 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7689999114954844e-05, 2770
[INFO] 2021-07-12 19:28:11,234 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2770
[INFO] 2021-07-12 19:28:11,235 [run_pretraining.py:  558]:	worker_index: 7, step: 2770, cost: 7.451437, mlm loss: 7.451437, speed: 0.944398 steps/s, speed: 7.555184 samples/s, speed: 3868.254356 tokens/s, learning rate: 2.769e-05, loss_scalings: 2814.750488, pp_loss: 7.238173
[INFO] 2021-07-12 19:28:11,235 [run_pretraining.py:  512]:	********exe.run_2770******* 
[INFO] 2021-07-12 19:28:12,300 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:12,301 [run_pretraining.py:  534]:	loss/total_loss, 7.1139373779296875, 2771
[INFO] 2021-07-12 19:28:12,301 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1139373779296875, 2771
[INFO] 2021-07-12 19:28:12,301 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.769999991869554e-05, 2771
[INFO] 2021-07-12 19:28:12,301 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2771
[INFO] 2021-07-12 19:28:12,301 [run_pretraining.py:  558]:	worker_index: 7, step: 2771, cost: 7.113937, mlm loss: 7.113937, speed: 0.938264 steps/s, speed: 7.506112 samples/s, speed: 3843.129589 tokens/s, learning rate: 2.770e-05, loss_scalings: 2814.750488, pp_loss: 6.939994
[INFO] 2021-07-12 19:28:12,301 [run_pretraining.py:  512]:	********exe.run_2771******* 
[INFO] 2021-07-12 19:28:13,368 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:13,369 [run_pretraining.py:  534]:	loss/total_loss, 7.002490997314453, 2772
[INFO] 2021-07-12 19:28:13,369 [run_pretraining.py:  535]:	loss/mlm_loss, 7.002490997314453, 2772
[INFO] 2021-07-12 19:28:13,369 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.770999890344683e-05, 2772
[INFO] 2021-07-12 19:28:13,369 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2772
[INFO] 2021-07-12 19:28:13,369 [run_pretraining.py:  558]:	worker_index: 7, step: 2772, cost: 7.002491, mlm loss: 7.002491, speed: 0.936810 steps/s, speed: 7.494479 samples/s, speed: 3837.173332 tokens/s, learning rate: 2.771e-05, loss_scalings: 2814.750488, pp_loss: 6.989351
[INFO] 2021-07-12 19:28:13,369 [run_pretraining.py:  512]:	********exe.run_2772******* 
[INFO] 2021-07-12 19:28:14,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:14,427 [run_pretraining.py:  534]:	loss/total_loss, 7.226284027099609, 2773
[INFO] 2021-07-12 19:28:14,427 [run_pretraining.py:  535]:	loss/mlm_loss, 7.226284027099609, 2773
[INFO] 2021-07-12 19:28:14,427 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.772000152617693e-05, 2773
[INFO] 2021-07-12 19:28:14,427 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2773
[INFO] 2021-07-12 19:28:14,427 [run_pretraining.py:  558]:	worker_index: 7, step: 2773, cost: 7.226284, mlm loss: 7.226284, speed: 0.945603 steps/s, speed: 7.564825 samples/s, speed: 3873.190416 tokens/s, learning rate: 2.772e-05, loss_scalings: 2814.750488, pp_loss: 6.981383
[INFO] 2021-07-12 19:28:14,427 [run_pretraining.py:  512]:	********exe.run_2773******* 
[INFO] 2021-07-12 19:28:15,484 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:15,484 [run_pretraining.py:  534]:	loss/total_loss, 7.348319053649902, 2774
[INFO] 2021-07-12 19:28:15,484 [run_pretraining.py:  535]:	loss/mlm_loss, 7.348319053649902, 2774
[INFO] 2021-07-12 19:28:15,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7729998691938818e-05, 2774
[INFO] 2021-07-12 19:28:15,484 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2774
[INFO] 2021-07-12 19:28:15,484 [run_pretraining.py:  558]:	worker_index: 7, step: 2774, cost: 7.348319, mlm loss: 7.348319, speed: 0.946488 steps/s, speed: 7.571906 samples/s, speed: 3876.815874 tokens/s, learning rate: 2.773e-05, loss_scalings: 2814.750488, pp_loss: 7.263663
[INFO] 2021-07-12 19:28:15,485 [run_pretraining.py:  512]:	********exe.run_2774******* 
[INFO] 2021-07-12 19:28:16,426 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:16,426 [run_pretraining.py:  534]:	loss/total_loss, 6.361069679260254, 2775
[INFO] 2021-07-12 19:28:16,426 [run_pretraining.py:  535]:	loss/mlm_loss, 6.361069679260254, 2775
[INFO] 2021-07-12 19:28:16,426 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.773999767669011e-05, 2775
[INFO] 2021-07-12 19:28:16,426 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2775
[INFO] 2021-07-12 19:28:16,426 [run_pretraining.py:  558]:	worker_index: 7, step: 2775, cost: 6.361070, mlm loss: 6.361070, speed: 1.062229 steps/s, speed: 8.497835 samples/s, speed: 4350.891480 tokens/s, learning rate: 2.774e-05, loss_scalings: 2814.750488, pp_loss: 6.841990
[INFO] 2021-07-12 19:28:16,427 [run_pretraining.py:  512]:	********exe.run_2775******* 
[INFO] 2021-07-12 19:28:17,351 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:17,352 [run_pretraining.py:  534]:	loss/total_loss, 6.538449287414551, 2776
[INFO] 2021-07-12 19:28:17,352 [run_pretraining.py:  535]:	loss/mlm_loss, 6.538449287414551, 2776
[INFO] 2021-07-12 19:28:17,352 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7750000299420208e-05, 2776
[INFO] 2021-07-12 19:28:17,352 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2776
[INFO] 2021-07-12 19:28:17,352 [run_pretraining.py:  558]:	worker_index: 7, step: 2776, cost: 6.538449, mlm loss: 6.538449, speed: 1.081336 steps/s, speed: 8.650692 samples/s, speed: 4429.154055 tokens/s, learning rate: 2.775e-05, loss_scalings: 2814.750488, pp_loss: 7.041807
[INFO] 2021-07-12 19:28:17,352 [run_pretraining.py:  512]:	********exe.run_2776******* 
[INFO] 2021-07-12 19:28:18,273 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:18,273 [run_pretraining.py:  534]:	loss/total_loss, 6.948891639709473, 2777
[INFO] 2021-07-12 19:28:18,273 [run_pretraining.py:  535]:	loss/mlm_loss, 6.948891639709473, 2777
[INFO] 2021-07-12 19:28:18,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7759997465182096e-05, 2777
[INFO] 2021-07-12 19:28:18,274 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2777
[INFO] 2021-07-12 19:28:18,274 [run_pretraining.py:  558]:	worker_index: 7, step: 2777, cost: 6.948892, mlm loss: 6.948892, speed: 1.085732 steps/s, speed: 8.685855 samples/s, speed: 4447.157935 tokens/s, learning rate: 2.776e-05, loss_scalings: 2814.750488, pp_loss: 7.031377
[INFO] 2021-07-12 19:28:18,274 [run_pretraining.py:  512]:	********exe.run_2777******* 
[INFO] 2021-07-12 19:28:19,196 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:19,196 [run_pretraining.py:  534]:	loss/total_loss, 7.167692184448242, 2778
[INFO] 2021-07-12 19:28:19,197 [run_pretraining.py:  535]:	loss/mlm_loss, 7.167692184448242, 2778
[INFO] 2021-07-12 19:28:19,197 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7770000087912194e-05, 2778
[INFO] 2021-07-12 19:28:19,197 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2778
[INFO] 2021-07-12 19:28:19,197 [run_pretraining.py:  558]:	worker_index: 7, step: 2778, cost: 7.167692, mlm loss: 7.167692, speed: 1.083979 steps/s, speed: 8.671832 samples/s, speed: 4439.978090 tokens/s, learning rate: 2.777e-05, loss_scalings: 2814.750488, pp_loss: 7.145989
[INFO] 2021-07-12 19:28:19,197 [run_pretraining.py:  512]:	********exe.run_2778******* 
[INFO] 2021-07-12 19:28:20,116 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:20,116 [run_pretraining.py:  534]:	loss/total_loss, 7.32429313659668, 2779
[INFO] 2021-07-12 19:28:20,116 [run_pretraining.py:  535]:	loss/mlm_loss, 7.32429313659668, 2779
[INFO] 2021-07-12 19:28:20,117 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7779999072663486e-05, 2779
[INFO] 2021-07-12 19:28:20,117 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2779
[INFO] 2021-07-12 19:28:20,117 [run_pretraining.py:  558]:	worker_index: 7, step: 2779, cost: 7.324293, mlm loss: 7.324293, speed: 1.087817 steps/s, speed: 8.702535 samples/s, speed: 4455.697678 tokens/s, learning rate: 2.778e-05, loss_scalings: 2814.750488, pp_loss: 6.958727
[INFO] 2021-07-12 19:28:20,117 [run_pretraining.py:  512]:	********exe.run_2779******* 
[INFO] 2021-07-12 19:28:21,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:21,041 [run_pretraining.py:  534]:	loss/total_loss, 7.239699363708496, 2780
[INFO] 2021-07-12 19:28:21,041 [run_pretraining.py:  535]:	loss/mlm_loss, 7.239699363708496, 2780
[INFO] 2021-07-12 19:28:21,042 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.778999987640418e-05, 2780
[INFO] 2021-07-12 19:28:21,042 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2780
[INFO] 2021-07-12 19:28:21,042 [run_pretraining.py:  558]:	worker_index: 7, step: 2780, cost: 7.239699, mlm loss: 7.239699, speed: 1.081839 steps/s, speed: 8.654712 samples/s, speed: 4431.212685 tokens/s, learning rate: 2.779e-05, loss_scalings: 2814.750488, pp_loss: 7.355183
[INFO] 2021-07-12 19:28:21,042 [run_pretraining.py:  512]:	********exe.run_2780******* 
[INFO] 2021-07-12 19:28:21,958 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:21,958 [run_pretraining.py:  534]:	loss/total_loss, 7.108348846435547, 2781
[INFO] 2021-07-12 19:28:21,958 [run_pretraining.py:  535]:	loss/mlm_loss, 7.108348846435547, 2781
[INFO] 2021-07-12 19:28:21,958 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7799998861155473e-05, 2781
[INFO] 2021-07-12 19:28:21,958 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2781
[INFO] 2021-07-12 19:28:21,959 [run_pretraining.py:  558]:	worker_index: 7, step: 2781, cost: 7.108349, mlm loss: 7.108349, speed: 1.091547 steps/s, speed: 8.732380 samples/s, speed: 4470.978544 tokens/s, learning rate: 2.780e-05, loss_scalings: 2814.750488, pp_loss: 7.231768
[INFO] 2021-07-12 19:28:21,959 [run_pretraining.py:  512]:	********exe.run_2781******* 
[INFO] 2021-07-12 19:28:22,880 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:22,880 [run_pretraining.py:  534]:	loss/total_loss, 7.141574859619141, 2782
[INFO] 2021-07-12 19:28:22,880 [run_pretraining.py:  535]:	loss/mlm_loss, 7.141574859619141, 2782
[INFO] 2021-07-12 19:28:22,880 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.781000148388557e-05, 2782
[INFO] 2021-07-12 19:28:22,880 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2782
[INFO] 2021-07-12 19:28:22,881 [run_pretraining.py:  558]:	worker_index: 7, step: 2782, cost: 7.141575, mlm loss: 7.141575, speed: 1.085314 steps/s, speed: 8.682511 samples/s, speed: 4445.445631 tokens/s, learning rate: 2.781e-05, loss_scalings: 2814.750488, pp_loss: 7.337347
[INFO] 2021-07-12 19:28:22,881 [run_pretraining.py:  512]:	********exe.run_2782******* 
[INFO] 2021-07-12 19:28:23,803 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:23,804 [run_pretraining.py:  534]:	loss/total_loss, 7.367213249206543, 2783
[INFO] 2021-07-12 19:28:23,804 [run_pretraining.py:  535]:	loss/mlm_loss, 7.367213249206543, 2783
[INFO] 2021-07-12 19:28:23,804 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.781999864964746e-05, 2783
[INFO] 2021-07-12 19:28:23,804 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2783
[INFO] 2021-07-12 19:28:23,804 [run_pretraining.py:  558]:	worker_index: 7, step: 2783, cost: 7.367213, mlm loss: 7.367213, speed: 1.083718 steps/s, speed: 8.669744 samples/s, speed: 4438.908905 tokens/s, learning rate: 2.782e-05, loss_scalings: 2814.750488, pp_loss: 7.404876
[INFO] 2021-07-12 19:28:23,804 [run_pretraining.py:  512]:	********exe.run_2783******* 
[INFO] 2021-07-12 19:28:24,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:24,728 [run_pretraining.py:  534]:	loss/total_loss, 7.505293369293213, 2784
[INFO] 2021-07-12 19:28:24,728 [run_pretraining.py:  535]:	loss/mlm_loss, 7.505293369293213, 2784
[INFO] 2021-07-12 19:28:24,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.782999763439875e-05, 2784
[INFO] 2021-07-12 19:28:24,729 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2784
[INFO] 2021-07-12 19:28:24,729 [run_pretraining.py:  558]:	worker_index: 7, step: 2784, cost: 7.505293, mlm loss: 7.505293, speed: 1.082254 steps/s, speed: 8.658031 samples/s, speed: 4432.911752 tokens/s, learning rate: 2.783e-05, loss_scalings: 2814.750488, pp_loss: 6.525690
[INFO] 2021-07-12 19:28:24,729 [run_pretraining.py:  512]:	********exe.run_2784******* 
[INFO] 2021-07-12 19:28:25,644 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:25,644 [run_pretraining.py:  534]:	loss/total_loss, 7.198541641235352, 2785
[INFO] 2021-07-12 19:28:25,644 [run_pretraining.py:  535]:	loss/mlm_loss, 7.198541641235352, 2785
[INFO] 2021-07-12 19:28:25,644 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.784000025712885e-05, 2785
[INFO] 2021-07-12 19:28:25,644 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2785
[INFO] 2021-07-12 19:28:25,645 [run_pretraining.py:  558]:	worker_index: 7, step: 2785, cost: 7.198542, mlm loss: 7.198542, speed: 1.092485 steps/s, speed: 8.739877 samples/s, speed: 4474.816899 tokens/s, learning rate: 2.784e-05, loss_scalings: 2814.750488, pp_loss: 7.321814
[INFO] 2021-07-12 19:28:25,645 [run_pretraining.py:  512]:	********exe.run_2785******* 
[INFO] 2021-07-12 19:28:26,571 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:26,572 [run_pretraining.py:  534]:	loss/total_loss, 7.9264984130859375, 2786
[INFO] 2021-07-12 19:28:26,572 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9264984130859375, 2786
[INFO] 2021-07-12 19:28:26,572 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.784999924188014e-05, 2786
[INFO] 2021-07-12 19:28:26,572 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2786
[INFO] 2021-07-12 19:28:26,572 [run_pretraining.py:  558]:	worker_index: 7, step: 2786, cost: 7.926498, mlm loss: 7.926498, speed: 1.078835 steps/s, speed: 8.630679 samples/s, speed: 4418.907715 tokens/s, learning rate: 2.785e-05, loss_scalings: 2814.750488, pp_loss: 7.182762
[INFO] 2021-07-12 19:28:26,572 [run_pretraining.py:  512]:	********exe.run_2786******* 
[INFO] 2021-07-12 19:28:27,485 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:27,485 [run_pretraining.py:  534]:	loss/total_loss, 7.607919216156006, 2787
[INFO] 2021-07-12 19:28:27,485 [run_pretraining.py:  535]:	loss/mlm_loss, 7.607919216156006, 2787
[INFO] 2021-07-12 19:28:27,485 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7860000045620836e-05, 2787
[INFO] 2021-07-12 19:28:27,486 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2787
[INFO] 2021-07-12 19:28:27,486 [run_pretraining.py:  558]:	worker_index: 7, step: 2787, cost: 7.607919, mlm loss: 7.607919, speed: 1.095521 steps/s, speed: 8.764166 samples/s, speed: 4487.252810 tokens/s, learning rate: 2.786e-05, loss_scalings: 2814.750488, pp_loss: 7.266988
[INFO] 2021-07-12 19:28:27,486 [run_pretraining.py:  512]:	********exe.run_2787******* 
[INFO] 2021-07-12 19:28:28,400 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:28,400 [run_pretraining.py:  534]:	loss/total_loss, 7.873781204223633, 2788
[INFO] 2021-07-12 19:28:28,401 [run_pretraining.py:  535]:	loss/mlm_loss, 7.873781204223633, 2788
[INFO] 2021-07-12 19:28:28,401 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7869999030372128e-05, 2788
[INFO] 2021-07-12 19:28:28,401 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2788
[INFO] 2021-07-12 19:28:28,401 [run_pretraining.py:  558]:	worker_index: 7, step: 2788, cost: 7.873781, mlm loss: 7.873781, speed: 1.093517 steps/s, speed: 8.748137 samples/s, speed: 4479.046009 tokens/s, learning rate: 2.787e-05, loss_scalings: 2814.750488, pp_loss: 7.529682
[INFO] 2021-07-12 19:28:28,401 [run_pretraining.py:  512]:	********exe.run_2788******* 
[INFO] 2021-07-12 19:28:29,315 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:29,316 [run_pretraining.py:  534]:	loss/total_loss, 8.276006698608398, 2789
[INFO] 2021-07-12 19:28:29,316 [run_pretraining.py:  535]:	loss/mlm_loss, 8.276006698608398, 2789
[INFO] 2021-07-12 19:28:29,316 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7879999834112823e-05, 2789
[INFO] 2021-07-12 19:28:29,316 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2789
[INFO] 2021-07-12 19:28:29,316 [run_pretraining.py:  558]:	worker_index: 7, step: 2789, cost: 8.276007, mlm loss: 8.276007, speed: 1.093265 steps/s, speed: 8.746116 samples/s, speed: 4478.011618 tokens/s, learning rate: 2.788e-05, loss_scalings: 2814.750488, pp_loss: 7.787358
[INFO] 2021-07-12 19:28:29,316 [run_pretraining.py:  512]:	********exe.run_2789******* 
[INFO] 2021-07-12 19:28:30,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  534]:	loss/total_loss, 7.520438194274902, 2790
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.520438194274902, 2790
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7889998818864115e-05, 2790
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2790
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  558]:	worker_index: 7, step: 2790, cost: 7.520438, mlm loss: 7.520438, speed: 1.092829 steps/s, speed: 8.742634 samples/s, speed: 4476.228825 tokens/s, learning rate: 2.789e-05, loss_scalings: 2814.750488, pp_loss: 6.985813
[INFO] 2021-07-12 19:28:30,232 [run_pretraining.py:  512]:	********exe.run_2790******* 
[INFO] 2021-07-12 19:28:31,187 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:31,187 [run_pretraining.py:  534]:	loss/total_loss, 8.083290100097656, 2791
[INFO] 2021-07-12 19:28:31,187 [run_pretraining.py:  535]:	loss/mlm_loss, 8.083290100097656, 2791
[INFO] 2021-07-12 19:28:31,188 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7900001441594213e-05, 2791
[INFO] 2021-07-12 19:28:31,188 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2791
[INFO] 2021-07-12 19:28:31,188 [run_pretraining.py:  558]:	worker_index: 7, step: 2791, cost: 8.083290, mlm loss: 8.083290, speed: 1.046982 steps/s, speed: 8.375858 samples/s, speed: 4288.439219 tokens/s, learning rate: 2.790e-05, loss_scalings: 2814.750488, pp_loss: 7.507562
[INFO] 2021-07-12 19:28:31,188 [run_pretraining.py:  512]:	********exe.run_2791******* 
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  534]:	loss/total_loss, 7.246446132659912, 2792
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  535]:	loss/mlm_loss, 7.246446132659912, 2792
[INFO] 2021-07-12 19:28:32,150 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.79099986073561e-05, 2792
[INFO] 2021-07-12 19:28:32,151 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2792
[INFO] 2021-07-12 19:28:32,151 [run_pretraining.py:  558]:	worker_index: 7, step: 2792, cost: 7.246446, mlm loss: 7.246446, speed: 1.039201 steps/s, speed: 8.313609 samples/s, speed: 4256.567734 tokens/s, learning rate: 2.791e-05, loss_scalings: 2814.750488, pp_loss: 7.575447
[INFO] 2021-07-12 19:28:32,151 [run_pretraining.py:  512]:	********exe.run_2792******* 
[INFO] 2021-07-12 19:28:33,073 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:33,073 [run_pretraining.py:  534]:	loss/total_loss, 7.445301532745361, 2793
[INFO] 2021-07-12 19:28:33,073 [run_pretraining.py:  535]:	loss/mlm_loss, 7.445301532745361, 2793
[INFO] 2021-07-12 19:28:33,073 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7919997592107393e-05, 2793
[INFO] 2021-07-12 19:28:33,073 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2793
[INFO] 2021-07-12 19:28:33,073 [run_pretraining.py:  558]:	worker_index: 7, step: 2793, cost: 7.445302, mlm loss: 7.445302, speed: 1.084340 steps/s, speed: 8.674718 samples/s, speed: 4441.455377 tokens/s, learning rate: 2.792e-05, loss_scalings: 2814.750488, pp_loss: 7.501867
[INFO] 2021-07-12 19:28:33,074 [run_pretraining.py:  512]:	********exe.run_2793******* 
[INFO] 2021-07-12 19:28:33,983 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:33,983 [run_pretraining.py:  534]:	loss/total_loss, 6.724567890167236, 2794
[INFO] 2021-07-12 19:28:33,983 [run_pretraining.py:  535]:	loss/mlm_loss, 6.724567890167236, 2794
[INFO] 2021-07-12 19:28:33,984 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.793000021483749e-05, 2794
[INFO] 2021-07-12 19:28:33,984 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2794
[INFO] 2021-07-12 19:28:33,984 [run_pretraining.py:  558]:	worker_index: 7, step: 2794, cost: 6.724568, mlm loss: 6.724568, speed: 1.099459 steps/s, speed: 8.795669 samples/s, speed: 4503.382723 tokens/s, learning rate: 2.793e-05, loss_scalings: 2814.750488, pp_loss: 6.897858
[INFO] 2021-07-12 19:28:33,984 [run_pretraining.py:  512]:	********exe.run_2794******* 
[INFO] 2021-07-12 19:28:34,908 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:34,908 [run_pretraining.py:  534]:	loss/total_loss, 7.764174461364746, 2795
[INFO] 2021-07-12 19:28:34,908 [run_pretraining.py:  535]:	loss/mlm_loss, 7.764174461364746, 2795
[INFO] 2021-07-12 19:28:34,908 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7939999199588783e-05, 2795
[INFO] 2021-07-12 19:28:34,908 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2795
[INFO] 2021-07-12 19:28:34,908 [run_pretraining.py:  558]:	worker_index: 7, step: 2795, cost: 7.764174, mlm loss: 7.764174, speed: 1.082071 steps/s, speed: 8.656568 samples/s, speed: 4432.162676 tokens/s, learning rate: 2.794e-05, loss_scalings: 2814.750488, pp_loss: 7.210481
[INFO] 2021-07-12 19:28:34,909 [run_pretraining.py:  512]:	********exe.run_2795******* 
[INFO] 2021-07-12 19:28:35,836 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:35,836 [run_pretraining.py:  534]:	loss/total_loss, 8.414947509765625, 2796
[INFO] 2021-07-12 19:28:35,836 [run_pretraining.py:  535]:	loss/mlm_loss, 8.414947509765625, 2796
[INFO] 2021-07-12 19:28:35,836 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7950000003329478e-05, 2796
[INFO] 2021-07-12 19:28:35,836 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2796
[INFO] 2021-07-12 19:28:35,836 [run_pretraining.py:  558]:	worker_index: 7, step: 2796, cost: 8.414948, mlm loss: 8.414948, speed: 1.078377 steps/s, speed: 8.627018 samples/s, speed: 4417.033110 tokens/s, learning rate: 2.795e-05, loss_scalings: 2814.750488, pp_loss: 7.635546
[INFO] 2021-07-12 19:28:35,837 [run_pretraining.py:  512]:	********exe.run_2796******* 
[INFO] 2021-07-12 19:28:36,756 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:36,757 [run_pretraining.py:  534]:	loss/total_loss, 7.393407344818115, 2797
[INFO] 2021-07-12 19:28:36,757 [run_pretraining.py:  535]:	loss/mlm_loss, 7.393407344818115, 2797
[INFO] 2021-07-12 19:28:36,757 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.795999898808077e-05, 2797
[INFO] 2021-07-12 19:28:36,757 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2797
[INFO] 2021-07-12 19:28:36,757 [run_pretraining.py:  558]:	worker_index: 7, step: 2797, cost: 7.393407, mlm loss: 7.393407, speed: 1.087165 steps/s, speed: 8.697319 samples/s, speed: 4453.027507 tokens/s, learning rate: 2.796e-05, loss_scalings: 2814.750488, pp_loss: 7.531181
[INFO] 2021-07-12 19:28:36,757 [run_pretraining.py:  512]:	********exe.run_2797******* 
[INFO] 2021-07-12 19:28:37,685 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:37,686 [run_pretraining.py:  534]:	loss/total_loss, 7.407467842102051, 2798
[INFO] 2021-07-12 19:28:37,686 [run_pretraining.py:  535]:	loss/mlm_loss, 7.407467842102051, 2798
[INFO] 2021-07-12 19:28:37,686 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7969999791821465e-05, 2798
[INFO] 2021-07-12 19:28:37,686 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2798
[INFO] 2021-07-12 19:28:37,686 [run_pretraining.py:  558]:	worker_index: 7, step: 2798, cost: 7.407468, mlm loss: 7.407468, speed: 1.077166 steps/s, speed: 8.617327 samples/s, speed: 4412.071392 tokens/s, learning rate: 2.797e-05, loss_scalings: 2814.750488, pp_loss: 7.486545
[INFO] 2021-07-12 19:28:37,686 [run_pretraining.py:  512]:	********exe.run_2798******* 
[INFO] 2021-07-12 19:28:38,608 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:38,608 [run_pretraining.py:  534]:	loss/total_loss, 7.040780544281006, 2799
[INFO] 2021-07-12 19:28:38,608 [run_pretraining.py:  535]:	loss/mlm_loss, 7.040780544281006, 2799
[INFO] 2021-07-12 19:28:38,608 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7979998776572756e-05, 2799
[INFO] 2021-07-12 19:28:38,608 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2799
[INFO] 2021-07-12 19:28:38,608 [run_pretraining.py:  558]:	worker_index: 7, step: 2799, cost: 7.040781, mlm loss: 7.040781, speed: 1.084734 steps/s, speed: 8.677874 samples/s, speed: 4443.071532 tokens/s, learning rate: 2.798e-05, loss_scalings: 2814.750488, pp_loss: 7.526445
[INFO] 2021-07-12 19:28:38,609 [run_pretraining.py:  512]:	********exe.run_2799******* 
[INFO] 2021-07-12 19:28:39,541 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:39,541 [run_pretraining.py:  534]:	loss/total_loss, 7.6276702880859375, 2800
[INFO] 2021-07-12 19:28:39,541 [run_pretraining.py:  535]:	loss/mlm_loss, 7.6276702880859375, 2800
[INFO] 2021-07-12 19:28:39,541 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7990001399302855e-05, 2800
[INFO] 2021-07-12 19:28:39,542 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2800
[INFO] 2021-07-12 19:28:39,542 [run_pretraining.py:  558]:	worker_index: 7, step: 2800, cost: 7.627670, mlm loss: 7.627670, speed: 1.072355 steps/s, speed: 8.578844 samples/s, speed: 4392.368058 tokens/s, learning rate: 2.799e-05, loss_scalings: 2814.750488, pp_loss: 7.496068
[INFO] 2021-07-12 19:28:39,542 [run_pretraining.py:  512]:	********exe.run_2800******* 
[INFO] 2021-07-12 19:28:40,461 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:40,461 [run_pretraining.py:  534]:	loss/total_loss, 7.524728775024414, 2801
[INFO] 2021-07-12 19:28:40,461 [run_pretraining.py:  535]:	loss/mlm_loss, 7.524728775024414, 2801
[INFO] 2021-07-12 19:28:40,462 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.7999998565064743e-05, 2801
[INFO] 2021-07-12 19:28:40,462 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2801
[INFO] 2021-07-12 19:28:40,462 [run_pretraining.py:  558]:	worker_index: 7, step: 2801, cost: 7.524729, mlm loss: 7.524729, speed: 1.087688 steps/s, speed: 8.701508 samples/s, speed: 4455.171937 tokens/s, learning rate: 2.800e-05, loss_scalings: 2814.750488, pp_loss: 7.127744
[INFO] 2021-07-12 19:28:40,462 [run_pretraining.py:  512]:	********exe.run_2801******* 
[INFO] 2021-07-12 19:28:41,389 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:41,389 [run_pretraining.py:  534]:	loss/total_loss, 7.002756118774414, 2802
[INFO] 2021-07-12 19:28:41,389 [run_pretraining.py:  535]:	loss/mlm_loss, 7.002756118774414, 2802
[INFO] 2021-07-12 19:28:41,390 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8009997549816035e-05, 2802
[INFO] 2021-07-12 19:28:41,390 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2802
[INFO] 2021-07-12 19:28:41,390 [run_pretraining.py:  558]:	worker_index: 7, step: 2802, cost: 7.002756, mlm loss: 7.002756, speed: 1.078296 steps/s, speed: 8.626368 samples/s, speed: 4416.700392 tokens/s, learning rate: 2.801e-05, loss_scalings: 2814.750488, pp_loss: 7.424776
[INFO] 2021-07-12 19:28:41,390 [run_pretraining.py:  512]:	********exe.run_2802******* 
[INFO] 2021-07-12 19:28:42,304 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:42,304 [run_pretraining.py:  534]:	loss/total_loss, 7.1349358558654785, 2803
[INFO] 2021-07-12 19:28:42,304 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1349358558654785, 2803
[INFO] 2021-07-12 19:28:42,305 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8020000172546133e-05, 2803
[INFO] 2021-07-12 19:28:42,305 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2803
[INFO] 2021-07-12 19:28:42,305 [run_pretraining.py:  558]:	worker_index: 7, step: 2803, cost: 7.134936, mlm loss: 7.134936, speed: 1.093665 steps/s, speed: 8.749318 samples/s, speed: 4479.650987 tokens/s, learning rate: 2.802e-05, loss_scalings: 2814.750488, pp_loss: 7.423555
[INFO] 2021-07-12 19:28:42,305 [run_pretraining.py:  512]:	********exe.run_2803******* 
[INFO] 2021-07-12 19:28:43,231 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:43,231 [run_pretraining.py:  534]:	loss/total_loss, 7.058960914611816, 2804
[INFO] 2021-07-12 19:28:43,232 [run_pretraining.py:  535]:	loss/mlm_loss, 7.058960914611816, 2804
[INFO] 2021-07-12 19:28:43,232 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8029999157297425e-05, 2804
[INFO] 2021-07-12 19:28:43,232 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2804
[INFO] 2021-07-12 19:28:43,232 [run_pretraining.py:  558]:	worker_index: 7, step: 2804, cost: 7.058961, mlm loss: 7.058961, speed: 1.079479 steps/s, speed: 8.635828 samples/s, speed: 4421.543940 tokens/s, learning rate: 2.803e-05, loss_scalings: 2814.750488, pp_loss: 7.119487
[INFO] 2021-07-12 19:28:43,232 [run_pretraining.py:  512]:	********exe.run_2804******* 
[INFO] 2021-07-12 19:28:44,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:44,157 [run_pretraining.py:  534]:	loss/total_loss, 7.034228324890137, 2805
[INFO] 2021-07-12 19:28:44,157 [run_pretraining.py:  535]:	loss/mlm_loss, 7.034228324890137, 2805
[INFO] 2021-07-12 19:28:44,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.803999996103812e-05, 2805
[INFO] 2021-07-12 19:28:44,157 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2805
[INFO] 2021-07-12 19:28:44,157 [run_pretraining.py:  558]:	worker_index: 7, step: 2805, cost: 7.034228, mlm loss: 7.034228, speed: 1.081286 steps/s, speed: 8.650288 samples/s, speed: 4428.947383 tokens/s, learning rate: 2.804e-05, loss_scalings: 2814.750488, pp_loss: 7.269279
[INFO] 2021-07-12 19:28:44,157 [run_pretraining.py:  512]:	********exe.run_2805******* 
[INFO] 2021-07-12 19:28:45,076 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:45,076 [run_pretraining.py:  534]:	loss/total_loss, 7.746537208557129, 2806
[INFO] 2021-07-12 19:28:45,076 [run_pretraining.py:  535]:	loss/mlm_loss, 7.746537208557129, 2806
[INFO] 2021-07-12 19:28:45,076 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.804999894578941e-05, 2806
[INFO] 2021-07-12 19:28:45,077 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2806
[INFO] 2021-07-12 19:28:45,077 [run_pretraining.py:  558]:	worker_index: 7, step: 2806, cost: 7.746537, mlm loss: 7.746537, speed: 1.088536 steps/s, speed: 8.708292 samples/s, speed: 4458.645279 tokens/s, learning rate: 2.805e-05, loss_scalings: 2814.750488, pp_loss: 7.193931
[INFO] 2021-07-12 19:28:45,077 [run_pretraining.py:  512]:	********exe.run_2806******* 
[INFO] 2021-07-12 19:28:45,990 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:45,991 [run_pretraining.py:  534]:	loss/total_loss, 7.054373264312744, 2807
[INFO] 2021-07-12 19:28:45,991 [run_pretraining.py:  535]:	loss/mlm_loss, 7.054373264312744, 2807
[INFO] 2021-07-12 19:28:45,991 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8059999749530107e-05, 2807
[INFO] 2021-07-12 19:28:45,991 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2807
[INFO] 2021-07-12 19:28:45,991 [run_pretraining.py:  558]:	worker_index: 7, step: 2807, cost: 7.054373, mlm loss: 7.054373, speed: 1.094007 steps/s, speed: 8.752055 samples/s, speed: 4481.051940 tokens/s, learning rate: 2.806e-05, loss_scalings: 2814.750488, pp_loss: 7.158179
[INFO] 2021-07-12 19:28:45,991 [run_pretraining.py:  512]:	********exe.run_2807******* 
[INFO] 2021-07-12 19:28:46,913 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:46,914 [run_pretraining.py:  534]:	loss/total_loss, 6.809345722198486, 2808
[INFO] 2021-07-12 19:28:46,914 [run_pretraining.py:  535]:	loss/mlm_loss, 6.809345722198486, 2808
[INFO] 2021-07-12 19:28:46,914 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.80699987342814e-05, 2808
[INFO] 2021-07-12 19:28:46,914 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2808
[INFO] 2021-07-12 19:28:46,914 [run_pretraining.py:  558]:	worker_index: 7, step: 2808, cost: 6.809346, mlm loss: 6.809346, speed: 1.084741 steps/s, speed: 8.677926 samples/s, speed: 4443.097960 tokens/s, learning rate: 2.807e-05, loss_scalings: 2814.750488, pp_loss: 7.060098
[INFO] 2021-07-12 19:28:46,914 [run_pretraining.py:  512]:	********exe.run_2808******* 
[INFO] 2021-07-12 19:28:47,821 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:47,822 [run_pretraining.py:  534]:	loss/total_loss, 6.870028495788574, 2809
[INFO] 2021-07-12 19:28:47,822 [run_pretraining.py:  535]:	loss/mlm_loss, 6.870028495788574, 2809
[INFO] 2021-07-12 19:28:47,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8080001357011497e-05, 2809
[INFO] 2021-07-12 19:28:47,822 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2809
[INFO] 2021-07-12 19:28:47,822 [run_pretraining.py:  558]:	worker_index: 7, step: 2809, cost: 6.870028, mlm loss: 6.870028, speed: 1.101509 steps/s, speed: 8.812070 samples/s, speed: 4511.779744 tokens/s, learning rate: 2.808e-05, loss_scalings: 2814.750488, pp_loss: 7.201306
[INFO] 2021-07-12 19:28:47,822 [run_pretraining.py:  512]:	********exe.run_2809******* 
[INFO] 2021-07-12 19:28:48,738 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:48,739 [run_pretraining.py:  534]:	loss/total_loss, 7.505178928375244, 2810
[INFO] 2021-07-12 19:28:48,739 [run_pretraining.py:  535]:	loss/mlm_loss, 7.505178928375244, 2810
[INFO] 2021-07-12 19:28:48,739 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.809000034176279e-05, 2810
[INFO] 2021-07-12 19:28:48,739 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2810
[INFO] 2021-07-12 19:28:48,739 [run_pretraining.py:  558]:	worker_index: 7, step: 2810, cost: 7.505179, mlm loss: 7.505179, speed: 1.091457 steps/s, speed: 8.731657 samples/s, speed: 4470.608565 tokens/s, learning rate: 2.809e-05, loss_scalings: 2814.750488, pp_loss: 6.674008
[INFO] 2021-07-12 19:28:48,739 [run_pretraining.py:  512]:	********exe.run_2810******* 
[INFO] 2021-07-12 19:28:49,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:49,671 [run_pretraining.py:  534]:	loss/total_loss, 7.261900901794434, 2811
[INFO] 2021-07-12 19:28:49,671 [run_pretraining.py:  535]:	loss/mlm_loss, 7.261900901794434, 2811
[INFO] 2021-07-12 19:28:49,671 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8099997507524677e-05, 2811
[INFO] 2021-07-12 19:28:49,671 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2811
[INFO] 2021-07-12 19:28:49,672 [run_pretraining.py:  558]:	worker_index: 7, step: 2811, cost: 7.261901, mlm loss: 7.261901, speed: 1.073362 steps/s, speed: 8.586892 samples/s, speed: 4396.488818 tokens/s, learning rate: 2.810e-05, loss_scalings: 2814.750488, pp_loss: 7.931892
[INFO] 2021-07-12 19:28:49,672 [run_pretraining.py:  512]:	********exe.run_2811******* 
[INFO] 2021-07-12 19:28:50,588 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  534]:	loss/total_loss, 7.487313747406006, 2812
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  535]:	loss/mlm_loss, 7.487313747406006, 2812
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8110000130254775e-05, 2812
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2812
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  558]:	worker_index: 7, step: 2812, cost: 7.487314, mlm loss: 7.487314, speed: 1.090756 steps/s, speed: 8.726049 samples/s, speed: 4467.736916 tokens/s, learning rate: 2.811e-05, loss_scalings: 2814.750488, pp_loss: 7.917300
[INFO] 2021-07-12 19:28:50,589 [run_pretraining.py:  512]:	********exe.run_2812******* 
[INFO] 2021-07-12 19:28:51,507 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:51,508 [run_pretraining.py:  534]:	loss/total_loss, 6.747440338134766, 2813
[INFO] 2021-07-12 19:28:51,508 [run_pretraining.py:  535]:	loss/mlm_loss, 6.747440338134766, 2813
[INFO] 2021-07-12 19:28:51,508 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8119999115006067e-05, 2813
[INFO] 2021-07-12 19:28:51,508 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2813
[INFO] 2021-07-12 19:28:51,508 [run_pretraining.py:  558]:	worker_index: 7, step: 2813, cost: 6.747440, mlm loss: 6.747440, speed: 1.089043 steps/s, speed: 8.712341 samples/s, speed: 4460.718681 tokens/s, learning rate: 2.812e-05, loss_scalings: 2814.750488, pp_loss: 7.115995
[INFO] 2021-07-12 19:28:51,508 [run_pretraining.py:  512]:	********exe.run_2813******* 
[INFO] 2021-07-12 19:28:52,427 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  534]:	loss/total_loss, 7.738064765930176, 2814
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  535]:	loss/mlm_loss, 7.738064765930176, 2814
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8129999918746762e-05, 2814
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2814
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  558]:	worker_index: 7, step: 2814, cost: 7.738065, mlm loss: 7.738065, speed: 1.087576 steps/s, speed: 8.700607 samples/s, speed: 4454.711005 tokens/s, learning rate: 2.813e-05, loss_scalings: 2814.750488, pp_loss: 7.395340
[INFO] 2021-07-12 19:28:52,428 [run_pretraining.py:  512]:	********exe.run_2814******* 
[INFO] 2021-07-12 19:28:53,354 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:53,354 [run_pretraining.py:  534]:	loss/total_loss, 7.708216667175293, 2815
[INFO] 2021-07-12 19:28:53,354 [run_pretraining.py:  535]:	loss/mlm_loss, 7.708216667175293, 2815
[INFO] 2021-07-12 19:28:53,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8139998903498054e-05, 2815
[INFO] 2021-07-12 19:28:53,355 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2815
[INFO] 2021-07-12 19:28:53,355 [run_pretraining.py:  558]:	worker_index: 7, step: 2815, cost: 7.708217, mlm loss: 7.708217, speed: 1.079931 steps/s, speed: 8.639450 samples/s, speed: 4423.398459 tokens/s, learning rate: 2.814e-05, loss_scalings: 2814.750488, pp_loss: 7.117124
[INFO] 2021-07-12 19:28:53,355 [run_pretraining.py:  512]:	********exe.run_2815******* 
[INFO] 2021-07-12 19:28:54,276 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  534]:	loss/total_loss, 6.920558929443359, 2816
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  535]:	loss/mlm_loss, 6.920558929443359, 2816
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.814999970723875e-05, 2816
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2816
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  558]:	worker_index: 7, step: 2816, cost: 6.920559, mlm loss: 6.920559, speed: 1.084608 steps/s, speed: 8.676862 samples/s, speed: 4442.553361 tokens/s, learning rate: 2.815e-05, loss_scalings: 2814.750488, pp_loss: 7.246270
[INFO] 2021-07-12 19:28:54,277 [run_pretraining.py:  512]:	********exe.run_2816******* 
[INFO] 2021-07-12 19:28:55,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:55,193 [run_pretraining.py:  534]:	loss/total_loss, 6.724095344543457, 2817
[INFO] 2021-07-12 19:28:55,193 [run_pretraining.py:  535]:	loss/mlm_loss, 6.724095344543457, 2817
[INFO] 2021-07-12 19:28:55,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.815999869199004e-05, 2817
[INFO] 2021-07-12 19:28:55,193 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2817
[INFO] 2021-07-12 19:28:55,193 [run_pretraining.py:  558]:	worker_index: 7, step: 2817, cost: 6.724095, mlm loss: 6.724095, speed: 1.092437 steps/s, speed: 8.739499 samples/s, speed: 4474.623427 tokens/s, learning rate: 2.816e-05, loss_scalings: 2814.750488, pp_loss: 7.076108
[INFO] 2021-07-12 19:28:55,193 [run_pretraining.py:  512]:	********exe.run_2817******* 
[INFO] 2021-07-12 19:28:56,103 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:56,104 [run_pretraining.py:  534]:	loss/total_loss, 7.493616580963135, 2818
[INFO] 2021-07-12 19:28:56,104 [run_pretraining.py:  535]:	loss/mlm_loss, 7.493616580963135, 2818
[INFO] 2021-07-12 19:28:56,104 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8169997676741332e-05, 2818
[INFO] 2021-07-12 19:28:56,104 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2818
[INFO] 2021-07-12 19:28:56,104 [run_pretraining.py:  558]:	worker_index: 7, step: 2818, cost: 7.493617, mlm loss: 7.493617, speed: 1.098682 steps/s, speed: 8.789458 samples/s, speed: 4500.202402 tokens/s, learning rate: 2.817e-05, loss_scalings: 2814.750488, pp_loss: 7.359605
[INFO] 2021-07-12 19:28:56,104 [run_pretraining.py:  512]:	********exe.run_2818******* 
[INFO] 2021-07-12 19:28:57,022 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:57,023 [run_pretraining.py:  534]:	loss/total_loss, 7.522783279418945, 2819
[INFO] 2021-07-12 19:28:57,023 [run_pretraining.py:  535]:	loss/mlm_loss, 7.522783279418945, 2819
[INFO] 2021-07-12 19:28:57,023 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.818000029947143e-05, 2819
[INFO] 2021-07-12 19:28:57,023 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2819
[INFO] 2021-07-12 19:28:57,023 [run_pretraining.py:  558]:	worker_index: 7, step: 2819, cost: 7.522783, mlm loss: 7.522783, speed: 1.089109 steps/s, speed: 8.712871 samples/s, speed: 4460.989720 tokens/s, learning rate: 2.818e-05, loss_scalings: 2814.750488, pp_loss: 7.351267
[INFO] 2021-07-12 19:28:57,023 [run_pretraining.py:  512]:	********exe.run_2819******* 
[INFO] 2021-07-12 19:28:57,948 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:57,949 [run_pretraining.py:  534]:	loss/total_loss, 7.266070365905762, 2820
[INFO] 2021-07-12 19:28:57,949 [run_pretraining.py:  535]:	loss/mlm_loss, 7.266070365905762, 2820
[INFO] 2021-07-12 19:28:57,949 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.818999746523332e-05, 2820
[INFO] 2021-07-12 19:28:57,949 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2820
[INFO] 2021-07-12 19:28:57,949 [run_pretraining.py:  558]:	worker_index: 7, step: 2820, cost: 7.266070, mlm loss: 7.266070, speed: 1.080910 steps/s, speed: 8.647276 samples/s, speed: 4427.405380 tokens/s, learning rate: 2.819e-05, loss_scalings: 2814.750488, pp_loss: 7.656878
[INFO] 2021-07-12 19:28:57,949 [run_pretraining.py:  512]:	********exe.run_2820******* 
[INFO] 2021-07-12 19:28:58,867 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:58,867 [run_pretraining.py:  534]:	loss/total_loss, 6.825217247009277, 2821
[INFO] 2021-07-12 19:28:58,868 [run_pretraining.py:  535]:	loss/mlm_loss, 6.825217247009277, 2821
[INFO] 2021-07-12 19:28:58,868 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8200000087963417e-05, 2821
[INFO] 2021-07-12 19:28:58,868 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2821
[INFO] 2021-07-12 19:28:58,868 [run_pretraining.py:  558]:	worker_index: 7, step: 2821, cost: 6.825217, mlm loss: 6.825217, speed: 1.089004 steps/s, speed: 8.712031 samples/s, speed: 4460.560011 tokens/s, learning rate: 2.820e-05, loss_scalings: 2814.750488, pp_loss: 7.135273
[INFO] 2021-07-12 19:28:58,868 [run_pretraining.py:  512]:	********exe.run_2821******* 
[INFO] 2021-07-12 19:28:59,780 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:28:59,780 [run_pretraining.py:  534]:	loss/total_loss, 7.171876907348633, 2822
[INFO] 2021-07-12 19:28:59,780 [run_pretraining.py:  535]:	loss/mlm_loss, 7.171876907348633, 2822
[INFO] 2021-07-12 19:28:59,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.820999907271471e-05, 2822
[INFO] 2021-07-12 19:28:59,780 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2822
[INFO] 2021-07-12 19:28:59,780 [run_pretraining.py:  558]:	worker_index: 7, step: 2822, cost: 7.171877, mlm loss: 7.171877, speed: 1.096692 steps/s, speed: 8.773538 samples/s, speed: 4492.051566 tokens/s, learning rate: 2.821e-05, loss_scalings: 2814.750488, pp_loss: 7.309838
[INFO] 2021-07-12 19:28:59,780 [run_pretraining.py:  512]:	********exe.run_2822******* 
[INFO] 2021-07-12 19:29:00,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:00,694 [run_pretraining.py:  534]:	loss/total_loss, 6.863425254821777, 2823
[INFO] 2021-07-12 19:29:00,694 [run_pretraining.py:  535]:	loss/mlm_loss, 6.863425254821777, 2823
[INFO] 2021-07-12 19:29:00,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8219999876455404e-05, 2823
[INFO] 2021-07-12 19:29:00,694 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2823
[INFO] 2021-07-12 19:29:00,695 [run_pretraining.py:  558]:	worker_index: 7, step: 2823, cost: 6.863425, mlm loss: 6.863425, speed: 1.094706 steps/s, speed: 8.757646 samples/s, speed: 4483.914990 tokens/s, learning rate: 2.822e-05, loss_scalings: 2814.750488, pp_loss: 6.936414
[INFO] 2021-07-12 19:29:00,695 [run_pretraining.py:  512]:	********exe.run_2823******* 
[INFO] 2021-07-12 19:29:01,605 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:01,606 [run_pretraining.py:  534]:	loss/total_loss, 6.944799423217773, 2824
[INFO] 2021-07-12 19:29:01,606 [run_pretraining.py:  535]:	loss/mlm_loss, 6.944799423217773, 2824
[INFO] 2021-07-12 19:29:01,606 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8229998861206695e-05, 2824
[INFO] 2021-07-12 19:29:01,606 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2824
[INFO] 2021-07-12 19:29:01,606 [run_pretraining.py:  558]:	worker_index: 7, step: 2824, cost: 6.944799, mlm loss: 6.944799, speed: 1.097475 steps/s, speed: 8.779801 samples/s, speed: 4495.258012 tokens/s, learning rate: 2.823e-05, loss_scalings: 2814.750488, pp_loss: 7.268400
[INFO] 2021-07-12 19:29:01,606 [run_pretraining.py:  512]:	********exe.run_2824******* 
[INFO] 2021-07-12 19:29:02,517 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:02,517 [run_pretraining.py:  534]:	loss/total_loss, 7.679975509643555, 2825
[INFO] 2021-07-12 19:29:02,518 [run_pretraining.py:  535]:	loss/mlm_loss, 7.679975509643555, 2825
[INFO] 2021-07-12 19:29:02,518 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.823999966494739e-05, 2825
[INFO] 2021-07-12 19:29:02,518 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2825
[INFO] 2021-07-12 19:29:02,518 [run_pretraining.py:  558]:	worker_index: 7, step: 2825, cost: 7.679976, mlm loss: 7.679976, speed: 1.097974 steps/s, speed: 8.783795 samples/s, speed: 4497.303216 tokens/s, learning rate: 2.824e-05, loss_scalings: 2814.750488, pp_loss: 7.508617
[INFO] 2021-07-12 19:29:02,518 [run_pretraining.py:  512]:	********exe.run_2825******* 
[INFO] 2021-07-12 19:29:03,428 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:03,429 [run_pretraining.py:  534]:	loss/total_loss, 7.117480278015137, 2826
[INFO] 2021-07-12 19:29:03,429 [run_pretraining.py:  535]:	loss/mlm_loss, 7.117480278015137, 2826
[INFO] 2021-07-12 19:29:03,429 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8249998649698682e-05, 2826
[INFO] 2021-07-12 19:29:03,429 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2826
[INFO] 2021-07-12 19:29:03,429 [run_pretraining.py:  558]:	worker_index: 7, step: 2826, cost: 7.117480, mlm loss: 7.117480, speed: 1.097893 steps/s, speed: 8.783142 samples/s, speed: 4496.968890 tokens/s, learning rate: 2.825e-05, loss_scalings: 2814.750488, pp_loss: 6.703761
[INFO] 2021-07-12 19:29:03,429 [run_pretraining.py:  512]:	********exe.run_2826******* 
[INFO] 2021-07-12 19:29:04,338 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:04,338 [run_pretraining.py:  534]:	loss/total_loss, 7.132709503173828, 2827
[INFO] 2021-07-12 19:29:04,338 [run_pretraining.py:  535]:	loss/mlm_loss, 7.132709503173828, 2827
[INFO] 2021-07-12 19:29:04,338 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8259997634449974e-05, 2827
[INFO] 2021-07-12 19:29:04,338 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2827
[INFO] 2021-07-12 19:29:04,338 [run_pretraining.py:  558]:	worker_index: 7, step: 2827, cost: 7.132710, mlm loss: 7.132710, speed: 1.100735 steps/s, speed: 8.805877 samples/s, speed: 4508.608854 tokens/s, learning rate: 2.826e-05, loss_scalings: 2814.750488, pp_loss: 7.154366
[INFO] 2021-07-12 19:29:04,339 [run_pretraining.py:  512]:	********exe.run_2827******* 
[INFO] 2021-07-12 19:29:05,253 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:05,253 [run_pretraining.py:  534]:	loss/total_loss, 7.191618919372559, 2828
[INFO] 2021-07-12 19:29:05,253 [run_pretraining.py:  535]:	loss/mlm_loss, 7.191618919372559, 2828
[INFO] 2021-07-12 19:29:05,253 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8270000257180072e-05, 2828
[INFO] 2021-07-12 19:29:05,253 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2828
[INFO] 2021-07-12 19:29:05,253 [run_pretraining.py:  558]:	worker_index: 7, step: 2828, cost: 7.191619, mlm loss: 7.191619, speed: 1.093661 steps/s, speed: 8.749286 samples/s, speed: 4479.634634 tokens/s, learning rate: 2.827e-05, loss_scalings: 2814.750488, pp_loss: 7.104547
[INFO] 2021-07-12 19:29:05,254 [run_pretraining.py:  512]:	********exe.run_2828******* 
[INFO] 2021-07-12 19:29:06,172 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:06,173 [run_pretraining.py:  534]:	loss/total_loss, 7.735923767089844, 2829
[INFO] 2021-07-12 19:29:06,173 [run_pretraining.py:  535]:	loss/mlm_loss, 7.735923767089844, 2829
[INFO] 2021-07-12 19:29:06,173 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.827999742294196e-05, 2829
[INFO] 2021-07-12 19:29:06,173 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2829
[INFO] 2021-07-12 19:29:06,173 [run_pretraining.py:  558]:	worker_index: 7, step: 2829, cost: 7.735924, mlm loss: 7.735924, speed: 1.088331 steps/s, speed: 8.706644 samples/s, speed: 4457.801883 tokens/s, learning rate: 2.828e-05, loss_scalings: 2814.750488, pp_loss: 7.398897
[INFO] 2021-07-12 19:29:06,173 [run_pretraining.py:  512]:	********exe.run_2829******* 
[INFO] 2021-07-12 19:29:07,090 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:07,091 [run_pretraining.py:  534]:	loss/total_loss, 7.137372016906738, 2830
[INFO] 2021-07-12 19:29:07,091 [run_pretraining.py:  535]:	loss/mlm_loss, 7.137372016906738, 2830
[INFO] 2021-07-12 19:29:07,091 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.829000004567206e-05, 2830
[INFO] 2021-07-12 19:29:07,091 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2830
[INFO] 2021-07-12 19:29:07,091 [run_pretraining.py:  558]:	worker_index: 7, step: 2830, cost: 7.137372, mlm loss: 7.137372, speed: 1.089764 steps/s, speed: 8.718113 samples/s, speed: 4463.674090 tokens/s, learning rate: 2.829e-05, loss_scalings: 2814.750488, pp_loss: 7.124333
[INFO] 2021-07-12 19:29:07,091 [run_pretraining.py:  512]:	********exe.run_2830******* 
[INFO] 2021-07-12 19:29:08,030 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:08,030 [run_pretraining.py:  534]:	loss/total_loss, 7.364949703216553, 2831
[INFO] 2021-07-12 19:29:08,031 [run_pretraining.py:  535]:	loss/mlm_loss, 7.364949703216553, 2831
[INFO] 2021-07-12 19:29:08,031 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.829999903042335e-05, 2831
[INFO] 2021-07-12 19:29:08,031 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2831
[INFO] 2021-07-12 19:29:08,031 [run_pretraining.py:  558]:	worker_index: 7, step: 2831, cost: 7.364950, mlm loss: 7.364950, speed: 1.065031 steps/s, speed: 8.520248 samples/s, speed: 4362.366956 tokens/s, learning rate: 2.830e-05, loss_scalings: 2814.750488, pp_loss: 7.196907
[INFO] 2021-07-12 19:29:08,031 [run_pretraining.py:  512]:	********exe.run_2831******* 
[INFO] 2021-07-12 19:29:09,095 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:09,096 [run_pretraining.py:  534]:	loss/total_loss, 7.652613162994385, 2832
[INFO] 2021-07-12 19:29:09,096 [run_pretraining.py:  535]:	loss/mlm_loss, 7.652613162994385, 2832
[INFO] 2021-07-12 19:29:09,096 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8309999834164046e-05, 2832
[INFO] 2021-07-12 19:29:09,096 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2832
[INFO] 2021-07-12 19:29:09,096 [run_pretraining.py:  558]:	worker_index: 7, step: 2832, cost: 7.652613, mlm loss: 7.652613, speed: 0.939346 steps/s, speed: 7.514765 samples/s, speed: 3847.559599 tokens/s, learning rate: 2.831e-05, loss_scalings: 2814.750488, pp_loss: 7.880384
[INFO] 2021-07-12 19:29:09,096 [run_pretraining.py:  512]:	********exe.run_2832******* 
[INFO] 2021-07-12 19:29:10,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:10,153 [run_pretraining.py:  534]:	loss/total_loss, 6.459970474243164, 2833
[INFO] 2021-07-12 19:29:10,153 [run_pretraining.py:  535]:	loss/mlm_loss, 6.459970474243164, 2833
[INFO] 2021-07-12 19:29:10,153 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8319998818915337e-05, 2833
[INFO] 2021-07-12 19:29:10,153 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2833
[INFO] 2021-07-12 19:29:10,153 [run_pretraining.py:  558]:	worker_index: 7, step: 2833, cost: 6.459970, mlm loss: 6.459970, speed: 0.946271 steps/s, speed: 7.570169 samples/s, speed: 3875.926362 tokens/s, learning rate: 2.832e-05, loss_scalings: 2814.750488, pp_loss: 7.230627
[INFO] 2021-07-12 19:29:10,154 [run_pretraining.py:  512]:	********exe.run_2833******* 
[INFO] 2021-07-12 19:29:11,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:11,216 [run_pretraining.py:  534]:	loss/total_loss, 7.384782791137695, 2834
[INFO] 2021-07-12 19:29:11,216 [run_pretraining.py:  535]:	loss/mlm_loss, 7.384782791137695, 2834
[INFO] 2021-07-12 19:29:11,216 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8329999622656032e-05, 2834
[INFO] 2021-07-12 19:29:11,216 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2834
[INFO] 2021-07-12 19:29:11,216 [run_pretraining.py:  558]:	worker_index: 7, step: 2834, cost: 7.384783, mlm loss: 7.384783, speed: 0.941718 steps/s, speed: 7.533746 samples/s, speed: 3857.278093 tokens/s, learning rate: 2.833e-05, loss_scalings: 2814.750488, pp_loss: 7.374567
[INFO] 2021-07-12 19:29:11,216 [run_pretraining.py:  512]:	********exe.run_2834******* 
[INFO] 2021-07-12 19:29:12,278 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:12,278 [run_pretraining.py:  534]:	loss/total_loss, 6.708568572998047, 2835
[INFO] 2021-07-12 19:29:12,278 [run_pretraining.py:  535]:	loss/mlm_loss, 6.708568572998047, 2835
[INFO] 2021-07-12 19:29:12,278 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8339998607407324e-05, 2835
[INFO] 2021-07-12 19:29:12,278 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2835
[INFO] 2021-07-12 19:29:12,279 [run_pretraining.py:  558]:	worker_index: 7, step: 2835, cost: 6.708569, mlm loss: 6.708569, speed: 0.941752 steps/s, speed: 7.534014 samples/s, speed: 3857.414934 tokens/s, learning rate: 2.834e-05, loss_scalings: 2814.750488, pp_loss: 7.123356
[INFO] 2021-07-12 19:29:12,279 [run_pretraining.py:  512]:	********exe.run_2835******* 
[INFO] 2021-07-12 19:29:13,325 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:13,325 [run_pretraining.py:  534]:	loss/total_loss, 7.775940895080566, 2836
[INFO] 2021-07-12 19:29:13,325 [run_pretraining.py:  535]:	loss/mlm_loss, 7.775940895080566, 2836
[INFO] 2021-07-12 19:29:13,326 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8349997592158616e-05, 2836
[INFO] 2021-07-12 19:29:13,326 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2836
[INFO] 2021-07-12 19:29:13,326 [run_pretraining.py:  558]:	worker_index: 7, step: 2836, cost: 7.775941, mlm loss: 7.775941, speed: 0.955532 steps/s, speed: 7.644256 samples/s, speed: 3913.859173 tokens/s, learning rate: 2.835e-05, loss_scalings: 2814.750488, pp_loss: 6.096574
[INFO] 2021-07-12 19:29:13,326 [run_pretraining.py:  512]:	********exe.run_2836******* 
[INFO] 2021-07-12 19:29:14,381 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:14,381 [run_pretraining.py:  534]:	loss/total_loss, 6.535828590393066, 2837
[INFO] 2021-07-12 19:29:14,381 [run_pretraining.py:  535]:	loss/mlm_loss, 6.535828590393066, 2837
[INFO] 2021-07-12 19:29:14,382 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8360000214888714e-05, 2837
[INFO] 2021-07-12 19:29:14,382 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2837
[INFO] 2021-07-12 19:29:14,382 [run_pretraining.py:  558]:	worker_index: 7, step: 2837, cost: 6.535829, mlm loss: 6.535829, speed: 0.947571 steps/s, speed: 7.580565 samples/s, speed: 3881.249398 tokens/s, learning rate: 2.836e-05, loss_scalings: 2814.750488, pp_loss: 6.989493
[INFO] 2021-07-12 19:29:14,382 [run_pretraining.py:  512]:	********exe.run_2837******* 
[INFO] 2021-07-12 19:29:15,445 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:15,445 [run_pretraining.py:  534]:	loss/total_loss, 7.068477630615234, 2838
[INFO] 2021-07-12 19:29:15,445 [run_pretraining.py:  535]:	loss/mlm_loss, 7.068477630615234, 2838
[INFO] 2021-07-12 19:29:15,446 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8369997380650602e-05, 2838
[INFO] 2021-07-12 19:29:15,446 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2838
[INFO] 2021-07-12 19:29:15,446 [run_pretraining.py:  558]:	worker_index: 7, step: 2838, cost: 7.068478, mlm loss: 7.068478, speed: 0.940396 steps/s, speed: 7.523167 samples/s, speed: 3851.861650 tokens/s, learning rate: 2.837e-05, loss_scalings: 2814.750488, pp_loss: 7.198241
[INFO] 2021-07-12 19:29:15,446 [run_pretraining.py:  512]:	********exe.run_2838******* 
[INFO] 2021-07-12 19:29:16,514 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:16,514 [run_pretraining.py:  534]:	loss/total_loss, 7.208082675933838, 2839
[INFO] 2021-07-12 19:29:16,514 [run_pretraining.py:  535]:	loss/mlm_loss, 7.208082675933838, 2839
[INFO] 2021-07-12 19:29:16,514 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.83800000033807e-05, 2839
[INFO] 2021-07-12 19:29:16,514 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2839
[INFO] 2021-07-12 19:29:16,514 [run_pretraining.py:  558]:	worker_index: 7, step: 2839, cost: 7.208083, mlm loss: 7.208083, speed: 0.936229 steps/s, speed: 7.489832 samples/s, speed: 3834.793941 tokens/s, learning rate: 2.838e-05, loss_scalings: 2814.750488, pp_loss: 6.159425
[INFO] 2021-07-12 19:29:16,515 [run_pretraining.py:  512]:	********exe.run_2839******* 
[INFO] 2021-07-12 19:29:17,580 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:17,580 [run_pretraining.py:  534]:	loss/total_loss, 5.845029830932617, 2840
[INFO] 2021-07-12 19:29:17,580 [run_pretraining.py:  535]:	loss/mlm_loss, 5.845029830932617, 2840
[INFO] 2021-07-12 19:29:17,581 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8389998988131993e-05, 2840
[INFO] 2021-07-12 19:29:17,581 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2840
[INFO] 2021-07-12 19:29:17,581 [run_pretraining.py:  558]:	worker_index: 7, step: 2840, cost: 5.845030, mlm loss: 5.845030, speed: 0.938472 steps/s, speed: 7.507775 samples/s, speed: 3843.980887 tokens/s, learning rate: 2.839e-05, loss_scalings: 2814.750488, pp_loss: 6.876665
[INFO] 2021-07-12 19:29:17,581 [run_pretraining.py:  512]:	********exe.run_2840******* 
[INFO] 2021-07-12 19:29:18,641 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  534]:	loss/total_loss, 7.557217597961426, 2841
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  535]:	loss/mlm_loss, 7.557217597961426, 2841
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8399999791872688e-05, 2841
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2841
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  558]:	worker_index: 7, step: 2841, cost: 7.557218, mlm loss: 7.557218, speed: 0.942626 steps/s, speed: 7.541008 samples/s, speed: 3860.996154 tokens/s, learning rate: 2.840e-05, loss_scalings: 2814.750488, pp_loss: 7.328887
[INFO] 2021-07-12 19:29:18,642 [run_pretraining.py:  512]:	********exe.run_2841******* 
[INFO] 2021-07-12 19:29:19,718 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:19,719 [run_pretraining.py:  534]:	loss/total_loss, 7.228533744812012, 2842
[INFO] 2021-07-12 19:29:19,719 [run_pretraining.py:  535]:	loss/mlm_loss, 7.228533744812012, 2842
[INFO] 2021-07-12 19:29:19,719 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.840999877662398e-05, 2842
[INFO] 2021-07-12 19:29:19,719 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2842
[INFO] 2021-07-12 19:29:19,719 [run_pretraining.py:  558]:	worker_index: 7, step: 2842, cost: 7.228534, mlm loss: 7.228534, speed: 0.929084 steps/s, speed: 7.432675 samples/s, speed: 3805.529575 tokens/s, learning rate: 2.841e-05, loss_scalings: 2814.750488, pp_loss: 7.262969
[INFO] 2021-07-12 19:29:19,719 [run_pretraining.py:  512]:	********exe.run_2842******* 
[INFO] 2021-07-12 19:29:20,639 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:20,639 [run_pretraining.py:  534]:	loss/total_loss, 7.700684070587158, 2843
[INFO] 2021-07-12 19:29:20,639 [run_pretraining.py:  535]:	loss/mlm_loss, 7.700684070587158, 2843
[INFO] 2021-07-12 19:29:20,639 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8420001399354078e-05, 2843
[INFO] 2021-07-12 19:29:20,639 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2843
[INFO] 2021-07-12 19:29:20,639 [run_pretraining.py:  558]:	worker_index: 7, step: 2843, cost: 7.700684, mlm loss: 7.700684, speed: 1.087384 steps/s, speed: 8.699071 samples/s, speed: 4453.924522 tokens/s, learning rate: 2.842e-05, loss_scalings: 2814.750488, pp_loss: 7.540305
[INFO] 2021-07-12 19:29:20,640 [run_pretraining.py:  512]:	********exe.run_2843******* 
[INFO] 2021-07-12 19:29:21,565 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  534]:	loss/total_loss, 6.9157490730285645, 2844
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9157490730285645, 2844
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8429998565115966e-05, 2844
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2844
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  558]:	worker_index: 7, step: 2844, cost: 6.915749, mlm loss: 6.915749, speed: 1.079891 steps/s, speed: 8.639128 samples/s, speed: 4423.233322 tokens/s, learning rate: 2.843e-05, loss_scalings: 2814.750488, pp_loss: 7.076130
[INFO] 2021-07-12 19:29:21,566 [run_pretraining.py:  512]:	********exe.run_2844******* 
[INFO] 2021-07-12 19:29:22,487 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:22,488 [run_pretraining.py:  534]:	loss/total_loss, 6.786570072174072, 2845
[INFO] 2021-07-12 19:29:22,488 [run_pretraining.py:  535]:	loss/mlm_loss, 6.786570072174072, 2845
[INFO] 2021-07-12 19:29:22,488 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8439997549867257e-05, 2845
[INFO] 2021-07-12 19:29:22,488 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2845
[INFO] 2021-07-12 19:29:22,488 [run_pretraining.py:  558]:	worker_index: 7, step: 2845, cost: 6.786570, mlm loss: 6.786570, speed: 1.085520 steps/s, speed: 8.684163 samples/s, speed: 4446.291261 tokens/s, learning rate: 2.844e-05, loss_scalings: 2814.750488, pp_loss: 6.903871
[INFO] 2021-07-12 19:29:22,488 [run_pretraining.py:  512]:	********exe.run_2845******* 
[INFO] 2021-07-12 19:29:23,418 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:23,419 [run_pretraining.py:  534]:	loss/total_loss, 7.204080581665039, 2846
[INFO] 2021-07-12 19:29:23,419 [run_pretraining.py:  535]:	loss/mlm_loss, 7.204080581665039, 2846
[INFO] 2021-07-12 19:29:23,419 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8450000172597356e-05, 2846
[INFO] 2021-07-12 19:29:23,419 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2846
[INFO] 2021-07-12 19:29:23,419 [run_pretraining.py:  558]:	worker_index: 7, step: 2846, cost: 7.204081, mlm loss: 7.204081, speed: 1.075006 steps/s, speed: 8.600047 samples/s, speed: 4403.223857 tokens/s, learning rate: 2.845e-05, loss_scalings: 2814.750488, pp_loss: 7.494411
[INFO] 2021-07-12 19:29:23,419 [run_pretraining.py:  512]:	********exe.run_2846******* 
[INFO] 2021-07-12 19:29:24,329 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:24,330 [run_pretraining.py:  534]:	loss/total_loss, 5.283878326416016, 2847
[INFO] 2021-07-12 19:29:24,330 [run_pretraining.py:  535]:	loss/mlm_loss, 5.283878326416016, 2847
[INFO] 2021-07-12 19:29:24,330 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8459997338359244e-05, 2847
[INFO] 2021-07-12 19:29:24,330 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2847
[INFO] 2021-07-12 19:29:24,330 [run_pretraining.py:  558]:	worker_index: 7, step: 2847, cost: 5.283878, mlm loss: 5.283878, speed: 1.097945 steps/s, speed: 8.783563 samples/s, speed: 4497.184313 tokens/s, learning rate: 2.846e-05, loss_scalings: 2814.750488, pp_loss: 6.503543
[INFO] 2021-07-12 19:29:24,330 [run_pretraining.py:  512]:	********exe.run_2847******* 
[INFO] 2021-07-12 19:29:25,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:25,385 [run_pretraining.py:  534]:	loss/total_loss, 4.521462917327881, 2848
[INFO] 2021-07-12 19:29:25,385 [run_pretraining.py:  535]:	loss/mlm_loss, 4.521462917327881, 2848
[INFO] 2021-07-12 19:29:25,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8469999961089343e-05, 2848
[INFO] 2021-07-12 19:29:25,385 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2848
[INFO] 2021-07-12 19:29:25,385 [run_pretraining.py:  558]:	worker_index: 7, step: 2848, cost: 4.521463, mlm loss: 4.521463, speed: 0.948656 steps/s, speed: 7.589251 samples/s, speed: 3885.696589 tokens/s, learning rate: 2.847e-05, loss_scalings: 2814.750488, pp_loss: 6.764778
[INFO] 2021-07-12 19:29:25,385 [run_pretraining.py:  512]:	********exe.run_2848******* 
[INFO] 2021-07-12 19:29:26,298 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:26,298 [run_pretraining.py:  534]:	loss/total_loss, 7.4250030517578125, 2849
[INFO] 2021-07-12 19:29:26,299 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4250030517578125, 2849
[INFO] 2021-07-12 19:29:26,299 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8479998945840634e-05, 2849
[INFO] 2021-07-12 19:29:26,299 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2849
[INFO] 2021-07-12 19:29:26,299 [run_pretraining.py:  558]:	worker_index: 7, step: 2849, cost: 7.425003, mlm loss: 7.425003, speed: 1.095273 steps/s, speed: 8.762184 samples/s, speed: 4486.238055 tokens/s, learning rate: 2.848e-05, loss_scalings: 2814.750488, pp_loss: 7.311161
[INFO] 2021-07-12 19:29:26,299 [run_pretraining.py:  512]:	********exe.run_2849******* 
[INFO] 2021-07-12 19:29:27,218 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:27,218 [run_pretraining.py:  534]:	loss/total_loss, 6.914200305938721, 2850
[INFO] 2021-07-12 19:29:27,218 [run_pretraining.py:  535]:	loss/mlm_loss, 6.914200305938721, 2850
[INFO] 2021-07-12 19:29:27,218 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.848999974958133e-05, 2850
[INFO] 2021-07-12 19:29:27,218 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2850
[INFO] 2021-07-12 19:29:27,219 [run_pretraining.py:  558]:	worker_index: 7, step: 2850, cost: 6.914200, mlm loss: 6.914200, speed: 1.088047 steps/s, speed: 8.704372 samples/s, speed: 4456.638544 tokens/s, learning rate: 2.849e-05, loss_scalings: 2814.750488, pp_loss: 7.082461
[INFO] 2021-07-12 19:29:27,219 [run_pretraining.py:  512]:	********exe.run_2850******* 
[INFO] 2021-07-12 19:29:28,137 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:28,138 [run_pretraining.py:  534]:	loss/total_loss, 7.320713520050049, 2851
[INFO] 2021-07-12 19:29:28,138 [run_pretraining.py:  535]:	loss/mlm_loss, 7.320713520050049, 2851
[INFO] 2021-07-12 19:29:28,138 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.849999873433262e-05, 2851
[INFO] 2021-07-12 19:29:28,138 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2851
[INFO] 2021-07-12 19:29:28,138 [run_pretraining.py:  558]:	worker_index: 7, step: 2851, cost: 7.320714, mlm loss: 7.320714, speed: 1.088305 steps/s, speed: 8.706439 samples/s, speed: 4457.696626 tokens/s, learning rate: 2.850e-05, loss_scalings: 2814.750488, pp_loss: 7.196868
[INFO] 2021-07-12 19:29:28,138 [run_pretraining.py:  512]:	********exe.run_2851******* 
[INFO] 2021-07-12 19:29:29,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:29,062 [run_pretraining.py:  534]:	loss/total_loss, 4.490199565887451, 2852
[INFO] 2021-07-12 19:29:29,062 [run_pretraining.py:  535]:	loss/mlm_loss, 4.490199565887451, 2852
[INFO] 2021-07-12 19:29:29,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.851000135706272e-05, 2852
[INFO] 2021-07-12 19:29:29,062 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2852
[INFO] 2021-07-12 19:29:29,062 [run_pretraining.py:  558]:	worker_index: 7, step: 2852, cost: 4.490200, mlm loss: 4.490200, speed: 1.083121 steps/s, speed: 8.664966 samples/s, speed: 4436.462729 tokens/s, learning rate: 2.851e-05, loss_scalings: 2814.750488, pp_loss: 6.569596
[INFO] 2021-07-12 19:29:29,062 [run_pretraining.py:  512]:	********exe.run_2852******* 
[INFO] 2021-07-12 19:29:30,089 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:30,090 [run_pretraining.py:  534]:	loss/total_loss, 7.239863395690918, 2853
[INFO] 2021-07-12 19:29:30,090 [run_pretraining.py:  535]:	loss/mlm_loss, 7.239863395690918, 2853
[INFO] 2021-07-12 19:29:30,090 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8519998522824608e-05, 2853
[INFO] 2021-07-12 19:29:30,090 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2853
[INFO] 2021-07-12 19:29:30,090 [run_pretraining.py:  558]:	worker_index: 7, step: 2853, cost: 7.239863, mlm loss: 7.239863, speed: 0.973370 steps/s, speed: 7.786964 samples/s, speed: 3986.925473 tokens/s, learning rate: 2.852e-05, loss_scalings: 2814.750488, pp_loss: 7.514749
[INFO] 2021-07-12 19:29:30,090 [run_pretraining.py:  512]:	********exe.run_2853******* 
[INFO] 2021-07-12 19:29:31,144 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:31,145 [run_pretraining.py:  534]:	loss/total_loss, 4.335680961608887, 2854
[INFO] 2021-07-12 19:29:31,145 [run_pretraining.py:  535]:	loss/mlm_loss, 4.335680961608887, 2854
[INFO] 2021-07-12 19:29:31,145 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.85299975075759e-05, 2854
[INFO] 2021-07-12 19:29:31,145 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2854
[INFO] 2021-07-12 19:29:31,145 [run_pretraining.py:  558]:	worker_index: 7, step: 2854, cost: 4.335681, mlm loss: 4.335681, speed: 0.948229 steps/s, speed: 7.585832 samples/s, speed: 3883.945817 tokens/s, learning rate: 2.853e-05, loss_scalings: 2814.750488, pp_loss: 6.814543
[INFO] 2021-07-12 19:29:31,145 [run_pretraining.py:  512]:	********exe.run_2854******* 
[INFO] 2021-07-12 19:29:32,204 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:32,205 [run_pretraining.py:  534]:	loss/total_loss, 7.41215181350708, 2855
[INFO] 2021-07-12 19:29:32,205 [run_pretraining.py:  535]:	loss/mlm_loss, 7.41215181350708, 2855
[INFO] 2021-07-12 19:29:32,205 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8540000130305998e-05, 2855
[INFO] 2021-07-12 19:29:32,205 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2855
[INFO] 2021-07-12 19:29:32,205 [run_pretraining.py:  558]:	worker_index: 7, step: 2855, cost: 7.412152, mlm loss: 7.412152, speed: 0.943863 steps/s, speed: 7.550902 samples/s, speed: 3866.061591 tokens/s, learning rate: 2.854e-05, loss_scalings: 2814.750488, pp_loss: 7.232153
[INFO] 2021-07-12 19:29:32,205 [run_pretraining.py:  512]:	********exe.run_2855******* 
[INFO] 2021-07-12 19:29:33,283 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:33,284 [run_pretraining.py:  534]:	loss/total_loss, 6.3759684562683105, 2856
[INFO] 2021-07-12 19:29:33,284 [run_pretraining.py:  535]:	loss/mlm_loss, 6.3759684562683105, 2856
[INFO] 2021-07-12 19:29:33,284 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.854999911505729e-05, 2856
[INFO] 2021-07-12 19:29:33,284 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2856
[INFO] 2021-07-12 19:29:33,284 [run_pretraining.py:  558]:	worker_index: 7, step: 2856, cost: 6.375968, mlm loss: 6.375968, speed: 0.927547 steps/s, speed: 7.420375 samples/s, speed: 3799.232095 tokens/s, learning rate: 2.855e-05, loss_scalings: 2814.750488, pp_loss: 7.013860
[INFO] 2021-07-12 19:29:33,284 [run_pretraining.py:  512]:	********exe.run_2856******* 
[INFO] 2021-07-12 19:29:34,355 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:34,355 [run_pretraining.py:  534]:	loss/total_loss, 6.873053073883057, 2857
[INFO] 2021-07-12 19:29:34,355 [run_pretraining.py:  535]:	loss/mlm_loss, 6.873053073883057, 2857
[INFO] 2021-07-12 19:29:34,355 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8559999918797985e-05, 2857
[INFO] 2021-07-12 19:29:34,356 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2857
[INFO] 2021-07-12 19:29:34,356 [run_pretraining.py:  558]:	worker_index: 7, step: 2857, cost: 6.873053, mlm loss: 6.873053, speed: 0.933884 steps/s, speed: 7.471073 samples/s, speed: 3825.189125 tokens/s, learning rate: 2.856e-05, loss_scalings: 2814.750488, pp_loss: 7.030214
[INFO] 2021-07-12 19:29:34,356 [run_pretraining.py:  512]:	********exe.run_2857******* 
[INFO] 2021-07-12 19:29:35,417 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  534]:	loss/total_loss, 6.08198881149292, 2858
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  535]:	loss/mlm_loss, 6.08198881149292, 2858
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8569998903549276e-05, 2858
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2858
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  558]:	worker_index: 7, step: 2858, cost: 6.081989, mlm loss: 6.081989, speed: 0.941789 steps/s, speed: 7.534311 samples/s, speed: 3857.567375 tokens/s, learning rate: 2.857e-05, loss_scalings: 2814.750488, pp_loss: 6.178137
[INFO] 2021-07-12 19:29:35,418 [run_pretraining.py:  512]:	********exe.run_2858******* 
[INFO] 2021-07-12 19:29:36,483 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:36,484 [run_pretraining.py:  534]:	loss/total_loss, 6.995432376861572, 2859
[INFO] 2021-07-12 19:29:36,484 [run_pretraining.py:  535]:	loss/mlm_loss, 6.995432376861572, 2859
[INFO] 2021-07-12 19:29:36,484 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.857999970728997e-05, 2859
[INFO] 2021-07-12 19:29:36,484 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2859
[INFO] 2021-07-12 19:29:36,484 [run_pretraining.py:  558]:	worker_index: 7, step: 2859, cost: 6.995432, mlm loss: 6.995432, speed: 0.938676 steps/s, speed: 7.509407 samples/s, speed: 3844.816214 tokens/s, learning rate: 2.858e-05, loss_scalings: 2814.750488, pp_loss: 7.176691
[INFO] 2021-07-12 19:29:36,484 [run_pretraining.py:  512]:	********exe.run_2859******* 
[INFO] 2021-07-12 19:29:37,543 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:37,544 [run_pretraining.py:  534]:	loss/total_loss, 6.064479827880859, 2860
[INFO] 2021-07-12 19:29:37,544 [run_pretraining.py:  535]:	loss/mlm_loss, 6.064479827880859, 2860
[INFO] 2021-07-12 19:29:37,544 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8589998692041263e-05, 2860
[INFO] 2021-07-12 19:29:37,544 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2860
[INFO] 2021-07-12 19:29:37,544 [run_pretraining.py:  558]:	worker_index: 7, step: 2860, cost: 6.064480, mlm loss: 6.064480, speed: 0.943698 steps/s, speed: 7.549581 samples/s, speed: 3865.385721 tokens/s, learning rate: 2.859e-05, loss_scalings: 2814.750488, pp_loss: 7.414332
[INFO] 2021-07-12 19:29:37,544 [run_pretraining.py:  512]:	********exe.run_2860******* 
[INFO] 2021-07-12 19:29:38,599 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:38,600 [run_pretraining.py:  534]:	loss/total_loss, 7.214972496032715, 2861
[INFO] 2021-07-12 19:29:38,600 [run_pretraining.py:  535]:	loss/mlm_loss, 7.214972496032715, 2861
[INFO] 2021-07-12 19:29:38,600 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.860000131477136e-05, 2861
[INFO] 2021-07-12 19:29:38,600 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2861
[INFO] 2021-07-12 19:29:38,600 [run_pretraining.py:  558]:	worker_index: 7, step: 2861, cost: 7.214972, mlm loss: 7.214972, speed: 0.947713 steps/s, speed: 7.581701 samples/s, speed: 3881.830834 tokens/s, learning rate: 2.860e-05, loss_scalings: 2814.750488, pp_loss: 7.256178
[INFO] 2021-07-12 19:29:38,600 [run_pretraining.py:  512]:	********exe.run_2861******* 
[INFO] 2021-07-12 19:29:39,530 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:39,531 [run_pretraining.py:  534]:	loss/total_loss, 6.984353542327881, 2862
[INFO] 2021-07-12 19:29:39,531 [run_pretraining.py:  535]:	loss/mlm_loss, 6.984353542327881, 2862
[INFO] 2021-07-12 19:29:39,531 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.860999848053325e-05, 2862
[INFO] 2021-07-12 19:29:39,531 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2862
[INFO] 2021-07-12 19:29:39,531 [run_pretraining.py:  558]:	worker_index: 7, step: 2862, cost: 6.984354, mlm loss: 6.984354, speed: 1.074764 steps/s, speed: 8.598110 samples/s, speed: 4402.232083 tokens/s, learning rate: 2.861e-05, loss_scalings: 2814.750488, pp_loss: 7.260798
[INFO] 2021-07-12 19:29:39,531 [run_pretraining.py:  512]:	********exe.run_2862******* 
[INFO] 2021-07-12 19:29:40,442 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:40,443 [run_pretraining.py:  534]:	loss/total_loss, 7.3583855628967285, 2863
[INFO] 2021-07-12 19:29:40,443 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3583855628967285, 2863
[INFO] 2021-07-12 19:29:40,443 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.861999746528454e-05, 2863
[INFO] 2021-07-12 19:29:40,443 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2863
[INFO] 2021-07-12 19:29:40,443 [run_pretraining.py:  558]:	worker_index: 7, step: 2863, cost: 7.358386, mlm loss: 7.358386, speed: 1.097487 steps/s, speed: 8.779900 samples/s, speed: 4495.308590 tokens/s, learning rate: 2.862e-05, loss_scalings: 2814.750488, pp_loss: 7.255412
[INFO] 2021-07-12 19:29:40,443 [run_pretraining.py:  512]:	********exe.run_2863******* 
[INFO] 2021-07-12 19:29:41,356 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:41,356 [run_pretraining.py:  534]:	loss/total_loss, 7.094267845153809, 2864
[INFO] 2021-07-12 19:29:41,356 [run_pretraining.py:  535]:	loss/mlm_loss, 7.094267845153809, 2864
[INFO] 2021-07-12 19:29:41,356 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.863000008801464e-05, 2864
[INFO] 2021-07-12 19:29:41,356 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2864
[INFO] 2021-07-12 19:29:41,357 [run_pretraining.py:  558]:	worker_index: 7, step: 2864, cost: 7.094268, mlm loss: 7.094268, speed: 1.095477 steps/s, speed: 8.763813 samples/s, speed: 4487.072323 tokens/s, learning rate: 2.863e-05, loss_scalings: 2814.750488, pp_loss: 6.427834
[INFO] 2021-07-12 19:29:41,357 [run_pretraining.py:  512]:	********exe.run_2864******* 
[INFO] 2021-07-12 19:29:42,285 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:42,285 [run_pretraining.py:  534]:	loss/total_loss, 8.175833702087402, 2865
[INFO] 2021-07-12 19:29:42,286 [run_pretraining.py:  535]:	loss/mlm_loss, 8.175833702087402, 2865
[INFO] 2021-07-12 19:29:42,286 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.863999907276593e-05, 2865
[INFO] 2021-07-12 19:29:42,286 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2865
[INFO] 2021-07-12 19:29:42,286 [run_pretraining.py:  558]:	worker_index: 7, step: 2865, cost: 8.175834, mlm loss: 8.175834, speed: 1.076870 steps/s, speed: 8.614962 samples/s, speed: 4410.860449 tokens/s, learning rate: 2.864e-05, loss_scalings: 2814.750488, pp_loss: 7.348809
[INFO] 2021-07-12 19:29:42,286 [run_pretraining.py:  512]:	********exe.run_2865******* 
[INFO] 2021-07-12 19:29:43,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:43,192 [run_pretraining.py:  534]:	loss/total_loss, 7.398731231689453, 2866
[INFO] 2021-07-12 19:29:43,192 [run_pretraining.py:  535]:	loss/mlm_loss, 7.398731231689453, 2866
[INFO] 2021-07-12 19:29:43,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8649999876506627e-05, 2866
[INFO] 2021-07-12 19:29:43,193 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2866
[INFO] 2021-07-12 19:29:43,193 [run_pretraining.py:  558]:	worker_index: 7, step: 2866, cost: 7.398731, mlm loss: 7.398731, speed: 1.103491 steps/s, speed: 8.827925 samples/s, speed: 4519.897747 tokens/s, learning rate: 2.865e-05, loss_scalings: 2814.750488, pp_loss: 7.698432
[INFO] 2021-07-12 19:29:43,193 [run_pretraining.py:  512]:	********exe.run_2866******* 
[INFO] 2021-07-12 19:29:44,118 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:44,118 [run_pretraining.py:  534]:	loss/total_loss, 6.750030517578125, 2867
[INFO] 2021-07-12 19:29:44,118 [run_pretraining.py:  535]:	loss/mlm_loss, 6.750030517578125, 2867
[INFO] 2021-07-12 19:29:44,118 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8659998861257918e-05, 2867
[INFO] 2021-07-12 19:29:44,119 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2867
[INFO] 2021-07-12 19:29:44,119 [run_pretraining.py:  558]:	worker_index: 7, step: 2867, cost: 6.750031, mlm loss: 6.750031, speed: 1.080767 steps/s, speed: 8.646135 samples/s, speed: 4426.821274 tokens/s, learning rate: 2.866e-05, loss_scalings: 2814.750488, pp_loss: 7.110102
[INFO] 2021-07-12 19:29:44,119 [run_pretraining.py:  512]:	********exe.run_2867******* 
[INFO] 2021-07-12 19:29:45,036 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  534]:	loss/total_loss, 7.535219192504883, 2868
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  535]:	loss/mlm_loss, 7.535219192504883, 2868
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8669999664998613e-05, 2868
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2868
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  558]:	worker_index: 7, step: 2868, cost: 7.535219, mlm loss: 7.535219, speed: 1.089802 steps/s, speed: 8.718419 samples/s, speed: 4463.830662 tokens/s, learning rate: 2.867e-05, loss_scalings: 2814.750488, pp_loss: 6.226784
[INFO] 2021-07-12 19:29:45,037 [run_pretraining.py:  512]:	********exe.run_2868******* 
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  534]:	loss/total_loss, 6.418957233428955, 2869
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  535]:	loss/mlm_loss, 6.418957233428955, 2869
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8679998649749905e-05, 2869
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2869
[INFO] 2021-07-12 19:29:45,952 [run_pretraining.py:  558]:	worker_index: 7, step: 2869, cost: 6.418957, mlm loss: 6.418957, speed: 1.092973 steps/s, speed: 8.743783 samples/s, speed: 4476.816710 tokens/s, learning rate: 2.868e-05, loss_scalings: 2814.750488, pp_loss: 6.950079
[INFO] 2021-07-12 19:29:45,953 [run_pretraining.py:  512]:	********exe.run_2869******* 
[INFO] 2021-07-12 19:29:46,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:46,919 [run_pretraining.py:  534]:	loss/total_loss, 7.060555458068848, 2870
[INFO] 2021-07-12 19:29:46,919 [run_pretraining.py:  535]:	loss/mlm_loss, 7.060555458068848, 2870
[INFO] 2021-07-12 19:29:46,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8690001272480004e-05, 2870
[INFO] 2021-07-12 19:29:46,919 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2870
[INFO] 2021-07-12 19:29:46,919 [run_pretraining.py:  558]:	worker_index: 7, step: 2870, cost: 7.060555, mlm loss: 7.060555, speed: 1.035083 steps/s, speed: 8.280665 samples/s, speed: 4239.700678 tokens/s, learning rate: 2.869e-05, loss_scalings: 2814.750488, pp_loss: 6.994619
[INFO] 2021-07-12 19:29:46,919 [run_pretraining.py:  512]:	********exe.run_2870******* 
[INFO] 2021-07-12 19:29:47,935 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:47,935 [run_pretraining.py:  534]:	loss/total_loss, 7.123363018035889, 2871
[INFO] 2021-07-12 19:29:47,935 [run_pretraining.py:  535]:	loss/mlm_loss, 7.123363018035889, 2871
[INFO] 2021-07-12 19:29:47,935 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.869999843824189e-05, 2871
[INFO] 2021-07-12 19:29:47,935 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2871
[INFO] 2021-07-12 19:29:47,936 [run_pretraining.py:  558]:	worker_index: 7, step: 2871, cost: 7.123363, mlm loss: 7.123363, speed: 0.984558 steps/s, speed: 7.876466 samples/s, speed: 4032.750783 tokens/s, learning rate: 2.870e-05, loss_scalings: 2814.750488, pp_loss: 7.056666
[INFO] 2021-07-12 19:29:47,936 [run_pretraining.py:  512]:	********exe.run_2871******* 
[INFO] 2021-07-12 19:29:48,914 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:48,915 [run_pretraining.py:  534]:	loss/total_loss, 7.296119213104248, 2872
[INFO] 2021-07-12 19:29:48,915 [run_pretraining.py:  535]:	loss/mlm_loss, 7.296119213104248, 2872
[INFO] 2021-07-12 19:29:48,915 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8709997422993183e-05, 2872
[INFO] 2021-07-12 19:29:48,915 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2872
[INFO] 2021-07-12 19:29:48,915 [run_pretraining.py:  558]:	worker_index: 7, step: 2872, cost: 7.296119, mlm loss: 7.296119, speed: 1.021634 steps/s, speed: 8.173070 samples/s, speed: 4184.611761 tokens/s, learning rate: 2.871e-05, loss_scalings: 2814.750488, pp_loss: 7.584092
[INFO] 2021-07-12 19:29:48,915 [run_pretraining.py:  512]:	********exe.run_2872******* 
[INFO] 2021-07-12 19:29:49,895 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:49,895 [run_pretraining.py:  534]:	loss/total_loss, 6.951737403869629, 2873
[INFO] 2021-07-12 19:29:49,895 [run_pretraining.py:  535]:	loss/mlm_loss, 6.951737403869629, 2873
[INFO] 2021-07-12 19:29:49,896 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8720000045723282e-05, 2873
[INFO] 2021-07-12 19:29:49,896 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2873
[INFO] 2021-07-12 19:29:49,896 [run_pretraining.py:  558]:	worker_index: 7, step: 2873, cost: 6.951737, mlm loss: 6.951737, speed: 1.020431 steps/s, speed: 8.163446 samples/s, speed: 4179.684289 tokens/s, learning rate: 2.872e-05, loss_scalings: 2814.750488, pp_loss: 7.094347
[INFO] 2021-07-12 19:29:49,896 [run_pretraining.py:  512]:	********exe.run_2873******* 
[INFO] 2021-07-12 19:29:50,874 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:50,874 [run_pretraining.py:  534]:	loss/total_loss, 7.290340423583984, 2874
[INFO] 2021-07-12 19:29:50,874 [run_pretraining.py:  535]:	loss/mlm_loss, 7.290340423583984, 2874
[INFO] 2021-07-12 19:29:50,875 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8729999030474573e-05, 2874
[INFO] 2021-07-12 19:29:50,875 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2874
[INFO] 2021-07-12 19:29:50,875 [run_pretraining.py:  558]:	worker_index: 7, step: 2874, cost: 7.290340, mlm loss: 7.290340, speed: 1.022116 steps/s, speed: 8.176930 samples/s, speed: 4186.588045 tokens/s, learning rate: 2.873e-05, loss_scalings: 2814.750488, pp_loss: 7.017512
[INFO] 2021-07-12 19:29:50,875 [run_pretraining.py:  512]:	********exe.run_2874******* 
[INFO] 2021-07-12 19:29:51,862 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:51,863 [run_pretraining.py:  534]:	loss/total_loss, 7.223657608032227, 2875
[INFO] 2021-07-12 19:29:51,863 [run_pretraining.py:  535]:	loss/mlm_loss, 7.223657608032227, 2875
[INFO] 2021-07-12 19:29:51,863 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.873999983421527e-05, 2875
[INFO] 2021-07-12 19:29:51,863 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2875
[INFO] 2021-07-12 19:29:51,863 [run_pretraining.py:  558]:	worker_index: 7, step: 2875, cost: 7.223658, mlm loss: 7.223658, speed: 1.012398 steps/s, speed: 8.099188 samples/s, speed: 4146.784042 tokens/s, learning rate: 2.874e-05, loss_scalings: 2814.750488, pp_loss: 6.948805
[INFO] 2021-07-12 19:29:51,863 [run_pretraining.py:  512]:	********exe.run_2875******* 
[INFO] 2021-07-12 19:29:52,856 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:52,856 [run_pretraining.py:  534]:	loss/total_loss, 7.041333198547363, 2876
[INFO] 2021-07-12 19:29:52,856 [run_pretraining.py:  535]:	loss/mlm_loss, 7.041333198547363, 2876
[INFO] 2021-07-12 19:29:52,856 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.874999881896656e-05, 2876
[INFO] 2021-07-12 19:29:52,857 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2876
[INFO] 2021-07-12 19:29:52,857 [run_pretraining.py:  558]:	worker_index: 7, step: 2876, cost: 7.041333, mlm loss: 7.041333, speed: 1.007173 steps/s, speed: 8.057381 samples/s, speed: 4125.379147 tokens/s, learning rate: 2.875e-05, loss_scalings: 2814.750488, pp_loss: 6.765073
[INFO] 2021-07-12 19:29:52,857 [run_pretraining.py:  512]:	********exe.run_2876******* 
[INFO] 2021-07-12 19:29:53,866 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:53,867 [run_pretraining.py:  534]:	loss/total_loss, 6.415881633758545, 2877
[INFO] 2021-07-12 19:29:53,867 [run_pretraining.py:  535]:	loss/mlm_loss, 6.415881633758545, 2877
[INFO] 2021-07-12 19:29:53,867 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8759999622707255e-05, 2877
[INFO] 2021-07-12 19:29:53,867 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2877
[INFO] 2021-07-12 19:29:53,867 [run_pretraining.py:  558]:	worker_index: 7, step: 2877, cost: 6.415882, mlm loss: 6.415882, speed: 0.990232 steps/s, speed: 7.921858 samples/s, speed: 4055.991329 tokens/s, learning rate: 2.876e-05, loss_scalings: 2814.750488, pp_loss: 7.078012
[INFO] 2021-07-12 19:29:53,867 [run_pretraining.py:  512]:	********exe.run_2877******* 
[INFO] 2021-07-12 19:29:54,779 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:54,780 [run_pretraining.py:  534]:	loss/total_loss, 7.758051872253418, 2878
[INFO] 2021-07-12 19:29:54,780 [run_pretraining.py:  535]:	loss/mlm_loss, 7.758051872253418, 2878
[INFO] 2021-07-12 19:29:54,780 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8769998607458547e-05, 2878
[INFO] 2021-07-12 19:29:54,780 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2878
[INFO] 2021-07-12 19:29:54,780 [run_pretraining.py:  558]:	worker_index: 7, step: 2878, cost: 7.758052, mlm loss: 7.758052, speed: 1.096186 steps/s, speed: 8.769487 samples/s, speed: 4489.977104 tokens/s, learning rate: 2.877e-05, loss_scalings: 2814.750488, pp_loss: 7.449161
[INFO] 2021-07-12 19:29:54,780 [run_pretraining.py:  512]:	********exe.run_2878******* 
[INFO] 2021-07-12 19:29:55,694 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:55,694 [run_pretraining.py:  534]:	loss/total_loss, 7.445889472961426, 2879
[INFO] 2021-07-12 19:29:55,694 [run_pretraining.py:  535]:	loss/mlm_loss, 7.445889472961426, 2879
[INFO] 2021-07-12 19:29:55,694 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8780001230188645e-05, 2879
[INFO] 2021-07-12 19:29:55,694 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2879
[INFO] 2021-07-12 19:29:55,694 [run_pretraining.py:  558]:	worker_index: 7, step: 2879, cost: 7.445889, mlm loss: 7.445889, speed: 1.094424 steps/s, speed: 8.755393 samples/s, speed: 4482.761377 tokens/s, learning rate: 2.878e-05, loss_scalings: 2814.750488, pp_loss: 7.457051
[INFO] 2021-07-12 19:29:55,694 [run_pretraining.py:  512]:	********exe.run_2879******* 
[INFO] 2021-07-12 19:29:56,606 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:56,607 [run_pretraining.py:  534]:	loss/total_loss, 7.796020984649658, 2880
[INFO] 2021-07-12 19:29:56,607 [run_pretraining.py:  535]:	loss/mlm_loss, 7.796020984649658, 2880
[INFO] 2021-07-12 19:29:56,607 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8790000214939937e-05, 2880
[INFO] 2021-07-12 19:29:56,607 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2880
[INFO] 2021-07-12 19:29:56,607 [run_pretraining.py:  558]:	worker_index: 7, step: 2880, cost: 7.796021, mlm loss: 7.796021, speed: 1.096555 steps/s, speed: 8.772442 samples/s, speed: 4491.490204 tokens/s, learning rate: 2.879e-05, loss_scalings: 2814.750488, pp_loss: 7.464869
[INFO] 2021-07-12 19:29:56,607 [run_pretraining.py:  512]:	********exe.run_2880******* 
[INFO] 2021-07-12 19:29:57,519 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:57,519 [run_pretraining.py:  534]:	loss/total_loss, 7.267045974731445, 2881
[INFO] 2021-07-12 19:29:57,519 [run_pretraining.py:  535]:	loss/mlm_loss, 7.267045974731445, 2881
[INFO] 2021-07-12 19:29:57,520 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8799997380701825e-05, 2881
[INFO] 2021-07-12 19:29:57,520 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2881
[INFO] 2021-07-12 19:29:57,520 [run_pretraining.py:  558]:	worker_index: 7, step: 2881, cost: 7.267046, mlm loss: 7.267046, speed: 1.096441 steps/s, speed: 8.771529 samples/s, speed: 4491.022901 tokens/s, learning rate: 2.880e-05, loss_scalings: 2814.750488, pp_loss: 7.217050
[INFO] 2021-07-12 19:29:57,520 [run_pretraining.py:  512]:	********exe.run_2881******* 
[INFO] 2021-07-12 19:29:58,430 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:58,431 [run_pretraining.py:  534]:	loss/total_loss, 7.0934062004089355, 2882
[INFO] 2021-07-12 19:29:58,431 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0934062004089355, 2882
[INFO] 2021-07-12 19:29:58,431 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8810000003431924e-05, 2882
[INFO] 2021-07-12 19:29:58,431 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2882
[INFO] 2021-07-12 19:29:58,431 [run_pretraining.py:  558]:	worker_index: 7, step: 2882, cost: 7.093406, mlm loss: 7.093406, speed: 1.097770 steps/s, speed: 8.782158 samples/s, speed: 4496.465140 tokens/s, learning rate: 2.881e-05, loss_scalings: 2814.750488, pp_loss: 7.317306
[INFO] 2021-07-12 19:29:58,431 [run_pretraining.py:  512]:	********exe.run_2882******* 
[INFO] 2021-07-12 19:29:59,348 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:29:59,349 [run_pretraining.py:  534]:	loss/total_loss, 4.379462718963623, 2883
[INFO] 2021-07-12 19:29:59,349 [run_pretraining.py:  535]:	loss/mlm_loss, 4.379462718963623, 2883
[INFO] 2021-07-12 19:29:59,349 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8819998988183215e-05, 2883
[INFO] 2021-07-12 19:29:59,349 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2883
[INFO] 2021-07-12 19:29:59,349 [run_pretraining.py:  558]:	worker_index: 7, step: 2883, cost: 4.379463, mlm loss: 4.379463, speed: 1.090096 steps/s, speed: 8.720771 samples/s, speed: 4465.034894 tokens/s, learning rate: 2.882e-05, loss_scalings: 2814.750488, pp_loss: 6.406601
[INFO] 2021-07-12 19:29:59,349 [run_pretraining.py:  512]:	********exe.run_2883******* 
[INFO] 2021-07-12 19:30:00,265 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:00,266 [run_pretraining.py:  534]:	loss/total_loss, 6.694619655609131, 2884
[INFO] 2021-07-12 19:30:00,266 [run_pretraining.py:  535]:	loss/mlm_loss, 6.694619655609131, 2884
[INFO] 2021-07-12 19:30:00,266 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.882999979192391e-05, 2884
[INFO] 2021-07-12 19:30:00,266 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2884
[INFO] 2021-07-12 19:30:00,266 [run_pretraining.py:  558]:	worker_index: 7, step: 2884, cost: 6.694620, mlm loss: 6.694620, speed: 1.091762 steps/s, speed: 8.734094 samples/s, speed: 4471.856033 tokens/s, learning rate: 2.883e-05, loss_scalings: 2814.750488, pp_loss: 7.044640
[INFO] 2021-07-12 19:30:00,266 [run_pretraining.py:  512]:	********exe.run_2884******* 
[INFO] 2021-07-12 19:30:01,195 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:01,196 [run_pretraining.py:  534]:	loss/total_loss, 7.0221662521362305, 2885
[INFO] 2021-07-12 19:30:01,196 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0221662521362305, 2885
[INFO] 2021-07-12 19:30:01,196 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8839998776675202e-05, 2885
[INFO] 2021-07-12 19:30:01,196 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2885
[INFO] 2021-07-12 19:30:01,196 [run_pretraining.py:  558]:	worker_index: 7, step: 2885, cost: 7.022166, mlm loss: 7.022166, speed: 1.076073 steps/s, speed: 8.608583 samples/s, speed: 4407.594560 tokens/s, learning rate: 2.884e-05, loss_scalings: 2814.750488, pp_loss: 6.953478
[INFO] 2021-07-12 19:30:01,196 [run_pretraining.py:  512]:	********exe.run_2885******* 
[INFO] 2021-07-12 19:30:02,106 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:02,107 [run_pretraining.py:  534]:	loss/total_loss, 7.110633850097656, 2886
[INFO] 2021-07-12 19:30:02,107 [run_pretraining.py:  535]:	loss/mlm_loss, 7.110633850097656, 2886
[INFO] 2021-07-12 19:30:02,107 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8849999580415897e-05, 2886
[INFO] 2021-07-12 19:30:02,107 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2886
[INFO] 2021-07-12 19:30:02,107 [run_pretraining.py:  558]:	worker_index: 7, step: 2886, cost: 7.110634, mlm loss: 7.110634, speed: 1.098316 steps/s, speed: 8.786530 samples/s, speed: 4498.703453 tokens/s, learning rate: 2.885e-05, loss_scalings: 2814.750488, pp_loss: 7.436327
[INFO] 2021-07-12 19:30:02,107 [run_pretraining.py:  512]:	********exe.run_2886******* 
[INFO] 2021-07-12 19:30:03,023 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:03,024 [run_pretraining.py:  534]:	loss/total_loss, 7.239938735961914, 2887
[INFO] 2021-07-12 19:30:03,024 [run_pretraining.py:  535]:	loss/mlm_loss, 7.239938735961914, 2887
[INFO] 2021-07-12 19:30:03,024 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.885999856516719e-05, 2887
[INFO] 2021-07-12 19:30:03,024 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2887
[INFO] 2021-07-12 19:30:03,024 [run_pretraining.py:  558]:	worker_index: 7, step: 2887, cost: 7.239939, mlm loss: 7.239939, speed: 1.091306 steps/s, speed: 8.730444 samples/s, speed: 4469.987418 tokens/s, learning rate: 2.886e-05, loss_scalings: 2814.750488, pp_loss: 7.314906
[INFO] 2021-07-12 19:30:03,024 [run_pretraining.py:  512]:	********exe.run_2887******* 
[INFO] 2021-07-12 19:30:03,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:03,939 [run_pretraining.py:  534]:	loss/total_loss, 8.424880981445312, 2888
[INFO] 2021-07-12 19:30:03,939 [run_pretraining.py:  535]:	loss/mlm_loss, 8.424880981445312, 2888
[INFO] 2021-07-12 19:30:03,939 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8870001187897287e-05, 2888
[INFO] 2021-07-12 19:30:03,939 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2888
[INFO] 2021-07-12 19:30:03,939 [run_pretraining.py:  558]:	worker_index: 7, step: 2888, cost: 8.424881, mlm loss: 8.424881, speed: 1.093686 steps/s, speed: 8.749485 samples/s, speed: 4479.736258 tokens/s, learning rate: 2.887e-05, loss_scalings: 2814.750488, pp_loss: 7.340569
[INFO] 2021-07-12 19:30:03,939 [run_pretraining.py:  512]:	********exe.run_2888******* 
[INFO] 2021-07-12 19:30:04,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:04,852 [run_pretraining.py:  534]:	loss/total_loss, 6.851698875427246, 2889
[INFO] 2021-07-12 19:30:04,852 [run_pretraining.py:  535]:	loss/mlm_loss, 6.851698875427246, 2889
[INFO] 2021-07-12 19:30:04,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.888000017264858e-05, 2889
[INFO] 2021-07-12 19:30:04,852 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2889
[INFO] 2021-07-12 19:30:04,852 [run_pretraining.py:  558]:	worker_index: 7, step: 2889, cost: 6.851699, mlm loss: 6.851699, speed: 1.095950 steps/s, speed: 8.767603 samples/s, speed: 4489.012727 tokens/s, learning rate: 2.888e-05, loss_scalings: 2814.750488, pp_loss: 6.833744
[INFO] 2021-07-12 19:30:04,852 [run_pretraining.py:  512]:	********exe.run_2889******* 
[INFO] 2021-07-12 19:30:05,769 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:05,770 [run_pretraining.py:  534]:	loss/total_loss, 6.813107967376709, 2890
[INFO] 2021-07-12 19:30:05,770 [run_pretraining.py:  535]:	loss/mlm_loss, 6.813107967376709, 2890
[INFO] 2021-07-12 19:30:05,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8889997338410467e-05, 2890
[INFO] 2021-07-12 19:30:05,770 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2890
[INFO] 2021-07-12 19:30:05,770 [run_pretraining.py:  558]:	worker_index: 7, step: 2890, cost: 6.813108, mlm loss: 6.813108, speed: 1.089809 steps/s, speed: 8.718474 samples/s, speed: 4463.858498 tokens/s, learning rate: 2.889e-05, loss_scalings: 2814.750488, pp_loss: 6.535674
[INFO] 2021-07-12 19:30:05,770 [run_pretraining.py:  512]:	********exe.run_2890******* 
[INFO] 2021-07-12 19:30:06,681 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:06,682 [run_pretraining.py:  534]:	loss/total_loss, 7.5966925621032715, 2891
[INFO] 2021-07-12 19:30:06,682 [run_pretraining.py:  535]:	loss/mlm_loss, 7.5966925621032715, 2891
[INFO] 2021-07-12 19:30:06,682 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8899999961140566e-05, 2891
[INFO] 2021-07-12 19:30:06,682 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2891
[INFO] 2021-07-12 19:30:06,682 [run_pretraining.py:  558]:	worker_index: 7, step: 2891, cost: 7.596693, mlm loss: 7.596693, speed: 1.097160 steps/s, speed: 8.777284 samples/s, speed: 4493.969242 tokens/s, learning rate: 2.890e-05, loss_scalings: 2814.750488, pp_loss: 7.354631
[INFO] 2021-07-12 19:30:06,682 [run_pretraining.py:  512]:	********exe.run_2891******* 
[INFO] 2021-07-12 19:30:07,597 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:07,598 [run_pretraining.py:  534]:	loss/total_loss, 7.231605529785156, 2892
[INFO] 2021-07-12 19:30:07,598 [run_pretraining.py:  535]:	loss/mlm_loss, 7.231605529785156, 2892
[INFO] 2021-07-12 19:30:07,598 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8909998945891857e-05, 2892
[INFO] 2021-07-12 19:30:07,598 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2892
[INFO] 2021-07-12 19:30:07,598 [run_pretraining.py:  558]:	worker_index: 7, step: 2892, cost: 7.231606, mlm loss: 7.231606, speed: 1.092505 steps/s, speed: 8.740041 samples/s, speed: 4474.900821 tokens/s, learning rate: 2.891e-05, loss_scalings: 2814.750488, pp_loss: 6.392461
[INFO] 2021-07-12 19:30:07,598 [run_pretraining.py:  512]:	********exe.run_2892******* 
[INFO] 2021-07-12 19:30:08,505 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:08,505 [run_pretraining.py:  534]:	loss/total_loss, 7.3854827880859375, 2893
[INFO] 2021-07-12 19:30:08,506 [run_pretraining.py:  535]:	loss/mlm_loss, 7.3854827880859375, 2893
[INFO] 2021-07-12 19:30:08,506 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8919999749632552e-05, 2893
[INFO] 2021-07-12 19:30:08,506 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2893
[INFO] 2021-07-12 19:30:08,506 [run_pretraining.py:  558]:	worker_index: 7, step: 2893, cost: 7.385483, mlm loss: 7.385483, speed: 1.102864 steps/s, speed: 8.822911 samples/s, speed: 4517.330638 tokens/s, learning rate: 2.892e-05, loss_scalings: 2814.750488, pp_loss: 7.469387
[INFO] 2021-07-12 19:30:08,506 [run_pretraining.py:  512]:	********exe.run_2893******* 
[INFO] 2021-07-12 19:30:09,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  534]:	loss/total_loss, 7.788882732391357, 2894
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  535]:	loss/mlm_loss, 7.788882732391357, 2894
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8929998734383844e-05, 2894
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2894
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  558]:	worker_index: 7, step: 2894, cost: 7.788883, mlm loss: 7.788883, speed: 1.082686 steps/s, speed: 8.661488 samples/s, speed: 4434.681951 tokens/s, learning rate: 2.893e-05, loss_scalings: 2814.750488, pp_loss: 7.405039
[INFO] 2021-07-12 19:30:09,430 [run_pretraining.py:  512]:	********exe.run_2894******* 
[INFO] 2021-07-12 19:30:10,357 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:10,357 [run_pretraining.py:  534]:	loss/total_loss, 7.7850446701049805, 2895
[INFO] 2021-07-12 19:30:10,358 [run_pretraining.py:  535]:	loss/mlm_loss, 7.7850446701049805, 2895
[INFO] 2021-07-12 19:30:10,358 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.893999953812454e-05, 2895
[INFO] 2021-07-12 19:30:10,358 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2895
[INFO] 2021-07-12 19:30:10,358 [run_pretraining.py:  558]:	worker_index: 7, step: 2895, cost: 7.785045, mlm loss: 7.785045, speed: 1.078566 steps/s, speed: 8.628529 samples/s, speed: 4417.806618 tokens/s, learning rate: 2.894e-05, loss_scalings: 2814.750488, pp_loss: 7.360697
[INFO] 2021-07-12 19:30:10,358 [run_pretraining.py:  512]:	********exe.run_2895******* 
[INFO] 2021-07-12 19:30:11,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:11,270 [run_pretraining.py:  534]:	loss/total_loss, 7.883493423461914, 2896
[INFO] 2021-07-12 19:30:11,270 [run_pretraining.py:  535]:	loss/mlm_loss, 7.883493423461914, 2896
[INFO] 2021-07-12 19:30:11,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.894999852287583e-05, 2896
[INFO] 2021-07-12 19:30:11,270 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2896
[INFO] 2021-07-12 19:30:11,271 [run_pretraining.py:  558]:	worker_index: 7, step: 2896, cost: 7.883493, mlm loss: 7.883493, speed: 1.096413 steps/s, speed: 8.771304 samples/s, speed: 4490.907851 tokens/s, learning rate: 2.895e-05, loss_scalings: 2814.750488, pp_loss: 7.486657
[INFO] 2021-07-12 19:30:11,271 [run_pretraining.py:  512]:	********exe.run_2896******* 
[INFO] 2021-07-12 19:30:12,189 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:12,189 [run_pretraining.py:  534]:	loss/total_loss, 7.731319904327393, 2897
[INFO] 2021-07-12 19:30:12,189 [run_pretraining.py:  535]:	loss/mlm_loss, 7.731319904327393, 2897
[INFO] 2021-07-12 19:30:12,189 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.896000114560593e-05, 2897
[INFO] 2021-07-12 19:30:12,189 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2897
[INFO] 2021-07-12 19:30:12,189 [run_pretraining.py:  558]:	worker_index: 7, step: 2897, cost: 7.731320, mlm loss: 7.731320, speed: 1.089006 steps/s, speed: 8.712045 samples/s, speed: 4460.566960 tokens/s, learning rate: 2.896e-05, loss_scalings: 2814.750488, pp_loss: 7.261123
[INFO] 2021-07-12 19:30:12,190 [run_pretraining.py:  512]:	********exe.run_2897******* 
[INFO] 2021-07-12 19:30:13,100 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:13,101 [run_pretraining.py:  534]:	loss/total_loss, 7.2277750968933105, 2898
[INFO] 2021-07-12 19:30:13,101 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2277750968933105, 2898
[INFO] 2021-07-12 19:30:13,101 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.897000013035722e-05, 2898
[INFO] 2021-07-12 19:30:13,101 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2898
[INFO] 2021-07-12 19:30:13,101 [run_pretraining.py:  558]:	worker_index: 7, step: 2898, cost: 7.227775, mlm loss: 7.227775, speed: 1.097787 steps/s, speed: 8.782296 samples/s, speed: 4496.535752 tokens/s, learning rate: 2.897e-05, loss_scalings: 2814.750488, pp_loss: 7.156110
[INFO] 2021-07-12 19:30:13,101 [run_pretraining.py:  512]:	********exe.run_2898******* 
[INFO] 2021-07-12 19:30:14,011 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  534]:	loss/total_loss, 7.488994121551514, 2899
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  535]:	loss/mlm_loss, 7.488994121551514, 2899
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.897999729611911e-05, 2899
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2899
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  558]:	worker_index: 7, step: 2899, cost: 7.488994, mlm loss: 7.488994, speed: 1.098249 steps/s, speed: 8.785994 samples/s, speed: 4498.428990 tokens/s, learning rate: 2.898e-05, loss_scalings: 2814.750488, pp_loss: 7.464627
[INFO] 2021-07-12 19:30:14,012 [run_pretraining.py:  512]:	********exe.run_2899******* 
[INFO] 2021-07-12 19:30:14,926 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:14,927 [run_pretraining.py:  534]:	loss/total_loss, 7.29799222946167, 2900
[INFO] 2021-07-12 19:30:14,927 [run_pretraining.py:  535]:	loss/mlm_loss, 7.29799222946167, 2900
[INFO] 2021-07-12 19:30:14,927 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.8989999918849207e-05, 2900
[INFO] 2021-07-12 19:30:14,927 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2900
[INFO] 2021-07-12 19:30:14,927 [run_pretraining.py:  558]:	worker_index: 7, step: 2900, cost: 7.297992, mlm loss: 7.297992, speed: 1.093873 steps/s, speed: 8.750984 samples/s, speed: 4480.503840 tokens/s, learning rate: 2.899e-05, loss_scalings: 2814.750488, pp_loss: 7.390605
[INFO] 2021-07-12 19:30:14,927 [run_pretraining.py:  512]:	********exe.run_2900******* 
[INFO] 2021-07-12 19:30:15,851 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:15,851 [run_pretraining.py:  534]:	loss/total_loss, 7.668605804443359, 2901
[INFO] 2021-07-12 19:30:15,851 [run_pretraining.py:  535]:	loss/mlm_loss, 7.668605804443359, 2901
[INFO] 2021-07-12 19:30:15,852 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.89999989036005e-05, 2901
[INFO] 2021-07-12 19:30:15,852 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2901
[INFO] 2021-07-12 19:30:15,852 [run_pretraining.py:  558]:	worker_index: 7, step: 2901, cost: 7.668606, mlm loss: 7.668606, speed: 1.082254 steps/s, speed: 8.658029 samples/s, speed: 4432.910608 tokens/s, learning rate: 2.900e-05, loss_scalings: 2814.750488, pp_loss: 8.103618
[INFO] 2021-07-12 19:30:15,852 [run_pretraining.py:  512]:	********exe.run_2901******* 
[INFO] 2021-07-12 19:30:16,761 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:16,762 [run_pretraining.py:  534]:	loss/total_loss, 6.729857921600342, 2902
[INFO] 2021-07-12 19:30:16,762 [run_pretraining.py:  535]:	loss/mlm_loss, 6.729857921600342, 2902
[INFO] 2021-07-12 19:30:16,762 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9009999707341194e-05, 2902
[INFO] 2021-07-12 19:30:16,762 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2902
[INFO] 2021-07-12 19:30:16,762 [run_pretraining.py:  558]:	worker_index: 7, step: 2902, cost: 6.729858, mlm loss: 6.729858, speed: 1.099092 steps/s, speed: 8.792733 samples/s, speed: 4501.879296 tokens/s, learning rate: 2.901e-05, loss_scalings: 2814.750488, pp_loss: 7.293262
[INFO] 2021-07-12 19:30:16,762 [run_pretraining.py:  512]:	********exe.run_2902******* 
[INFO] 2021-07-12 19:30:17,671 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:17,672 [run_pretraining.py:  534]:	loss/total_loss, 7.131285190582275, 2903
[INFO] 2021-07-12 19:30:17,672 [run_pretraining.py:  535]:	loss/mlm_loss, 7.131285190582275, 2903
[INFO] 2021-07-12 19:30:17,672 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9019998692092486e-05, 2903
[INFO] 2021-07-12 19:30:17,672 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2903
[INFO] 2021-07-12 19:30:17,672 [run_pretraining.py:  558]:	worker_index: 7, step: 2903, cost: 7.131285, mlm loss: 7.131285, speed: 1.099712 steps/s, speed: 8.797696 samples/s, speed: 4504.420602 tokens/s, learning rate: 2.902e-05, loss_scalings: 2814.750488, pp_loss: 7.182576
[INFO] 2021-07-12 19:30:17,672 [run_pretraining.py:  512]:	********exe.run_2903******* 
[INFO] 2021-07-12 19:30:18,621 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:18,621 [run_pretraining.py:  534]:	loss/total_loss, 6.631381511688232, 2904
[INFO] 2021-07-12 19:30:18,622 [run_pretraining.py:  535]:	loss/mlm_loss, 6.631381511688232, 2904
[INFO] 2021-07-12 19:30:18,622 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9030001314822584e-05, 2904
[INFO] 2021-07-12 19:30:18,622 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2904
[INFO] 2021-07-12 19:30:18,622 [run_pretraining.py:  558]:	worker_index: 7, step: 2904, cost: 6.631382, mlm loss: 6.631382, speed: 1.053876 steps/s, speed: 8.431008 samples/s, speed: 4316.675859 tokens/s, learning rate: 2.903e-05, loss_scalings: 2814.750488, pp_loss: 7.314692
[INFO] 2021-07-12 19:30:18,622 [run_pretraining.py:  512]:	********exe.run_2904******* 
[INFO] 2021-07-12 19:30:19,539 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:19,540 [run_pretraining.py:  534]:	loss/total_loss, 7.065560817718506, 2905
[INFO] 2021-07-12 19:30:19,540 [run_pretraining.py:  535]:	loss/mlm_loss, 7.065560817718506, 2905
[INFO] 2021-07-12 19:30:19,540 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9039998480584472e-05, 2905
[INFO] 2021-07-12 19:30:19,540 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2905
[INFO] 2021-07-12 19:30:19,540 [run_pretraining.py:  558]:	worker_index: 7, step: 2905, cost: 7.065561, mlm loss: 7.065561, speed: 1.089638 steps/s, speed: 8.717108 samples/s, speed: 4463.159220 tokens/s, learning rate: 2.904e-05, loss_scalings: 2814.750488, pp_loss: 7.408896
[INFO] 2021-07-12 19:30:19,540 [run_pretraining.py:  512]:	********exe.run_2905******* 
[INFO] 2021-07-12 19:30:20,454 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:20,455 [run_pretraining.py:  534]:	loss/total_loss, 7.404515743255615, 2906
[INFO] 2021-07-12 19:30:20,455 [run_pretraining.py:  535]:	loss/mlm_loss, 7.404515743255615, 2906
[INFO] 2021-07-12 19:30:20,455 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9049997465335764e-05, 2906
[INFO] 2021-07-12 19:30:20,455 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2906
[INFO] 2021-07-12 19:30:20,455 [run_pretraining.py:  558]:	worker_index: 7, step: 2906, cost: 7.404516, mlm loss: 7.404516, speed: 1.093910 steps/s, speed: 8.751283 samples/s, speed: 4480.656920 tokens/s, learning rate: 2.905e-05, loss_scalings: 2814.750488, pp_loss: 6.340969
[INFO] 2021-07-12 19:30:20,455 [run_pretraining.py:  512]:	********exe.run_2906******* 
[INFO] 2021-07-12 19:30:21,380 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  534]:	loss/total_loss, 7.818043231964111, 2907
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  535]:	loss/mlm_loss, 7.818043231964111, 2907
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9060000088065863e-05, 2907
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2907
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  558]:	worker_index: 7, step: 2907, cost: 7.818043, mlm loss: 7.818043, speed: 1.080634 steps/s, speed: 8.645068 samples/s, speed: 4426.274956 tokens/s, learning rate: 2.906e-05, loss_scalings: 2814.750488, pp_loss: 7.274806
[INFO] 2021-07-12 19:30:21,381 [run_pretraining.py:  512]:	********exe.run_2907******* 
[INFO] 2021-07-12 19:30:22,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:22,288 [run_pretraining.py:  534]:	loss/total_loss, 7.315489768981934, 2908
[INFO] 2021-07-12 19:30:22,288 [run_pretraining.py:  535]:	loss/mlm_loss, 7.315489768981934, 2908
[INFO] 2021-07-12 19:30:22,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.906999725382775e-05, 2908
[INFO] 2021-07-12 19:30:22,288 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2908
[INFO] 2021-07-12 19:30:22,288 [run_pretraining.py:  558]:	worker_index: 7, step: 2908, cost: 7.315490, mlm loss: 7.315490, speed: 1.103372 steps/s, speed: 8.826973 samples/s, speed: 4519.410248 tokens/s, learning rate: 2.907e-05, loss_scalings: 2814.750488, pp_loss: 7.212414
[INFO] 2021-07-12 19:30:22,288 [run_pretraining.py:  512]:	********exe.run_2908******* 
[INFO] 2021-07-12 19:30:23,225 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:23,226 [run_pretraining.py:  534]:	loss/total_loss, 7.347654819488525, 2909
[INFO] 2021-07-12 19:30:23,226 [run_pretraining.py:  535]:	loss/mlm_loss, 7.347654819488525, 2909
[INFO] 2021-07-12 19:30:23,226 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.907999987655785e-05, 2909
[INFO] 2021-07-12 19:30:23,226 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2909
[INFO] 2021-07-12 19:30:23,226 [run_pretraining.py:  558]:	worker_index: 7, step: 2909, cost: 7.347655, mlm loss: 7.347655, speed: 1.066385 steps/s, speed: 8.531083 samples/s, speed: 4367.914748 tokens/s, learning rate: 2.908e-05, loss_scalings: 2814.750488, pp_loss: 7.138518
[INFO] 2021-07-12 19:30:23,226 [run_pretraining.py:  512]:	********exe.run_2909******* 
[INFO] 2021-07-12 19:30:24,133 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:24,133 [run_pretraining.py:  534]:	loss/total_loss, 7.670314311981201, 2910
[INFO] 2021-07-12 19:30:24,133 [run_pretraining.py:  535]:	loss/mlm_loss, 7.670314311981201, 2910
[INFO] 2021-07-12 19:30:24,133 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.908999886130914e-05, 2910
[INFO] 2021-07-12 19:30:24,133 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2910
[INFO] 2021-07-12 19:30:24,133 [run_pretraining.py:  558]:	worker_index: 7, step: 2910, cost: 7.670314, mlm loss: 7.670314, speed: 1.103136 steps/s, speed: 8.825088 samples/s, speed: 4518.445071 tokens/s, learning rate: 2.909e-05, loss_scalings: 2814.750488, pp_loss: 7.356276
[INFO] 2021-07-12 19:30:24,134 [run_pretraining.py:  512]:	********exe.run_2910******* 
[INFO] 2021-07-12 19:30:25,041 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:25,041 [run_pretraining.py:  534]:	loss/total_loss, 6.956710338592529, 2911
[INFO] 2021-07-12 19:30:25,041 [run_pretraining.py:  535]:	loss/mlm_loss, 6.956710338592529, 2911
[INFO] 2021-07-12 19:30:25,041 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9099999665049836e-05, 2911
[INFO] 2021-07-12 19:30:25,041 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2911
[INFO] 2021-07-12 19:30:25,041 [run_pretraining.py:  558]:	worker_index: 7, step: 2911, cost: 6.956710, mlm loss: 6.956710, speed: 1.102176 steps/s, speed: 8.817410 samples/s, speed: 4514.513742 tokens/s, learning rate: 2.910e-05, loss_scalings: 2814.750488, pp_loss: 6.997388
[INFO] 2021-07-12 19:30:25,041 [run_pretraining.py:  512]:	********exe.run_2911******* 
[INFO] 2021-07-12 19:30:25,952 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:25,953 [run_pretraining.py:  534]:	loss/total_loss, 7.186733722686768, 2912
[INFO] 2021-07-12 19:30:25,953 [run_pretraining.py:  535]:	loss/mlm_loss, 7.186733722686768, 2912
[INFO] 2021-07-12 19:30:25,953 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9109998649801128e-05, 2912
[INFO] 2021-07-12 19:30:25,953 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2912
[INFO] 2021-07-12 19:30:25,953 [run_pretraining.py:  558]:	worker_index: 7, step: 2912, cost: 7.186734, mlm loss: 7.186734, speed: 1.097666 steps/s, speed: 8.781329 samples/s, speed: 4496.040336 tokens/s, learning rate: 2.911e-05, loss_scalings: 2814.750488, pp_loss: 7.426254
[INFO] 2021-07-12 19:30:25,953 [run_pretraining.py:  512]:	********exe.run_2912******* 
[INFO] 2021-07-12 19:30:26,861 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:26,861 [run_pretraining.py:  534]:	loss/total_loss, 7.4823317527771, 2913
[INFO] 2021-07-12 19:30:26,862 [run_pretraining.py:  535]:	loss/mlm_loss, 7.4823317527771, 2913
[INFO] 2021-07-12 19:30:26,862 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9120001272531226e-05, 2913
[INFO] 2021-07-12 19:30:26,862 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2913
[INFO] 2021-07-12 19:30:26,862 [run_pretraining.py:  558]:	worker_index: 7, step: 2913, cost: 7.482332, mlm loss: 7.482332, speed: 1.101102 steps/s, speed: 8.808813 samples/s, speed: 4510.112043 tokens/s, learning rate: 2.912e-05, loss_scalings: 2814.750488, pp_loss: 7.262619
[INFO] 2021-07-12 19:30:26,862 [run_pretraining.py:  512]:	********exe.run_2913******* 
[INFO] 2021-07-12 19:30:27,769 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:27,770 [run_pretraining.py:  534]:	loss/total_loss, 7.49785041809082, 2914
[INFO] 2021-07-12 19:30:27,770 [run_pretraining.py:  535]:	loss/mlm_loss, 7.49785041809082, 2914
[INFO] 2021-07-12 19:30:27,770 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9129998438293114e-05, 2914
[INFO] 2021-07-12 19:30:27,770 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2914
[INFO] 2021-07-12 19:30:27,770 [run_pretraining.py:  558]:	worker_index: 7, step: 2914, cost: 7.497850, mlm loss: 7.497850, speed: 1.101676 steps/s, speed: 8.813408 samples/s, speed: 4512.464711 tokens/s, learning rate: 2.913e-05, loss_scalings: 2814.750488, pp_loss: 7.314929
[INFO] 2021-07-12 19:30:27,770 [run_pretraining.py:  512]:	********exe.run_2914******* 
[INFO] 2021-07-12 19:30:28,677 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:28,678 [run_pretraining.py:  534]:	loss/total_loss, 7.982420921325684, 2915
[INFO] 2021-07-12 19:30:28,678 [run_pretraining.py:  535]:	loss/mlm_loss, 7.982420921325684, 2915
[INFO] 2021-07-12 19:30:28,678 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9139997423044406e-05, 2915
[INFO] 2021-07-12 19:30:28,678 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2915
[INFO] 2021-07-12 19:30:28,678 [run_pretraining.py:  558]:	worker_index: 7, step: 2915, cost: 7.982421, mlm loss: 7.982421, speed: 1.102156 steps/s, speed: 8.817250 samples/s, speed: 4514.431888 tokens/s, learning rate: 2.914e-05, loss_scalings: 2814.750488, pp_loss: 7.326903
[INFO] 2021-07-12 19:30:28,678 [run_pretraining.py:  512]:	********exe.run_2915******* 
[INFO] 2021-07-12 19:30:29,586 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:29,587 [run_pretraining.py:  534]:	loss/total_loss, 7.133747577667236, 2916
[INFO] 2021-07-12 19:30:29,587 [run_pretraining.py:  535]:	loss/mlm_loss, 7.133747577667236, 2916
[INFO] 2021-07-12 19:30:29,587 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9150000045774505e-05, 2916
[INFO] 2021-07-12 19:30:29,587 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2916
[INFO] 2021-07-12 19:30:29,587 [run_pretraining.py:  558]:	worker_index: 7, step: 2916, cost: 7.133748, mlm loss: 7.133748, speed: 1.101183 steps/s, speed: 8.809467 samples/s, speed: 4510.447143 tokens/s, learning rate: 2.915e-05, loss_scalings: 2814.750488, pp_loss: 7.721286
[INFO] 2021-07-12 19:30:29,587 [run_pretraining.py:  512]:	********exe.run_2916******* 
[INFO] 2021-07-12 19:30:30,493 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:30,494 [run_pretraining.py:  534]:	loss/total_loss, 8.096181869506836, 2917
[INFO] 2021-07-12 19:30:30,494 [run_pretraining.py:  535]:	loss/mlm_loss, 8.096181869506836, 2917
[INFO] 2021-07-12 19:30:30,494 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9159999030525796e-05, 2917
[INFO] 2021-07-12 19:30:30,494 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2917
[INFO] 2021-07-12 19:30:30,494 [run_pretraining.py:  558]:	worker_index: 7, step: 2917, cost: 8.096182, mlm loss: 8.096182, speed: 1.103043 steps/s, speed: 8.824343 samples/s, speed: 4518.063630 tokens/s, learning rate: 2.916e-05, loss_scalings: 2814.750488, pp_loss: 7.471050
[INFO] 2021-07-12 19:30:30,494 [run_pretraining.py:  512]:	********exe.run_2917******* 
[INFO] 2021-07-12 19:30:31,399 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:31,399 [run_pretraining.py:  534]:	loss/total_loss, 6.646324157714844, 2918
[INFO] 2021-07-12 19:30:31,399 [run_pretraining.py:  535]:	loss/mlm_loss, 6.646324157714844, 2918
[INFO] 2021-07-12 19:30:31,399 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.916999983426649e-05, 2918
[INFO] 2021-07-12 19:30:31,400 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2918
[INFO] 2021-07-12 19:30:31,400 [run_pretraining.py:  558]:	worker_index: 7, step: 2918, cost: 6.646324, mlm loss: 6.646324, speed: 1.105218 steps/s, speed: 8.841748 samples/s, speed: 4526.974752 tokens/s, learning rate: 2.917e-05, loss_scalings: 2814.750488, pp_loss: 7.115202
[INFO] 2021-07-12 19:30:31,400 [run_pretraining.py:  512]:	********exe.run_2918******* 
[INFO] 2021-07-12 19:30:32,307 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:32,307 [run_pretraining.py:  534]:	loss/total_loss, 7.414464950561523, 2919
[INFO] 2021-07-12 19:30:32,308 [run_pretraining.py:  535]:	loss/mlm_loss, 7.414464950561523, 2919
[INFO] 2021-07-12 19:30:32,308 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9179998819017783e-05, 2919
[INFO] 2021-07-12 19:30:32,308 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2919
[INFO] 2021-07-12 19:30:32,308 [run_pretraining.py:  558]:	worker_index: 7, step: 2919, cost: 7.414465, mlm loss: 7.414465, speed: 1.101884 steps/s, speed: 8.815072 samples/s, speed: 4513.317062 tokens/s, learning rate: 2.918e-05, loss_scalings: 2814.750488, pp_loss: 7.560549
[INFO] 2021-07-12 19:30:32,308 [run_pretraining.py:  512]:	********exe.run_2919******* 
[INFO] 2021-07-12 19:30:33,214 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:33,214 [run_pretraining.py:  534]:	loss/total_loss, 7.201345443725586, 2920
[INFO] 2021-07-12 19:30:33,214 [run_pretraining.py:  535]:	loss/mlm_loss, 7.201345443725586, 2920
[INFO] 2021-07-12 19:30:33,214 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9189999622758478e-05, 2920
[INFO] 2021-07-12 19:30:33,215 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2920
[INFO] 2021-07-12 19:30:33,215 [run_pretraining.py:  558]:	worker_index: 7, step: 2920, cost: 7.201345, mlm loss: 7.201345, speed: 1.103554 steps/s, speed: 8.828434 samples/s, speed: 4520.158187 tokens/s, learning rate: 2.919e-05, loss_scalings: 2814.750488, pp_loss: 7.106775
[INFO] 2021-07-12 19:30:33,215 [run_pretraining.py:  512]:	********exe.run_2920******* 
[INFO] 2021-07-12 19:30:34,121 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:34,122 [run_pretraining.py:  534]:	loss/total_loss, 7.621527671813965, 2921
[INFO] 2021-07-12 19:30:34,122 [run_pretraining.py:  535]:	loss/mlm_loss, 7.621527671813965, 2921
[INFO] 2021-07-12 19:30:34,122 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.919999860750977e-05, 2921
[INFO] 2021-07-12 19:30:34,122 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2921
[INFO] 2021-07-12 19:30:34,122 [run_pretraining.py:  558]:	worker_index: 7, step: 2921, cost: 7.621528, mlm loss: 7.621528, speed: 1.103097 steps/s, speed: 8.824777 samples/s, speed: 4518.285832 tokens/s, learning rate: 2.920e-05, loss_scalings: 2814.750488, pp_loss: 7.730805
[INFO] 2021-07-12 19:30:34,122 [run_pretraining.py:  512]:	********exe.run_2921******* 
[INFO] 2021-07-12 19:30:35,028 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:35,029 [run_pretraining.py:  534]:	loss/total_loss, 7.219696998596191, 2922
[INFO] 2021-07-12 19:30:35,029 [run_pretraining.py:  535]:	loss/mlm_loss, 7.219696998596191, 2922
[INFO] 2021-07-12 19:30:35,029 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9210001230239868e-05, 2922
[INFO] 2021-07-12 19:30:35,029 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2922
[INFO] 2021-07-12 19:30:35,029 [run_pretraining.py:  558]:	worker_index: 7, step: 2922, cost: 7.219697, mlm loss: 7.219697, speed: 1.102899 steps/s, speed: 8.823190 samples/s, speed: 4517.473179 tokens/s, learning rate: 2.921e-05, loss_scalings: 2814.750488, pp_loss: 7.106165
[INFO] 2021-07-12 19:30:35,029 [run_pretraining.py:  512]:	********exe.run_2922******* 
[INFO] 2021-07-12 19:30:35,938 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:35,938 [run_pretraining.py:  534]:	loss/total_loss, 8.032838821411133, 2923
[INFO] 2021-07-12 19:30:35,938 [run_pretraining.py:  535]:	loss/mlm_loss, 8.032838821411133, 2923
[INFO] 2021-07-12 19:30:35,938 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9219998396001756e-05, 2923
[INFO] 2021-07-12 19:30:35,938 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2923
[INFO] 2021-07-12 19:30:35,938 [run_pretraining.py:  558]:	worker_index: 7, step: 2923, cost: 8.032839, mlm loss: 8.032839, speed: 1.100616 steps/s, speed: 8.804929 samples/s, speed: 4508.123786 tokens/s, learning rate: 2.922e-05, loss_scalings: 2814.750488, pp_loss: 7.353742
[INFO] 2021-07-12 19:30:35,938 [run_pretraining.py:  512]:	********exe.run_2923******* 
[INFO] 2021-07-12 19:30:36,884 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:36,885 [run_pretraining.py:  534]:	loss/total_loss, 7.164647102355957, 2924
[INFO] 2021-07-12 19:30:36,885 [run_pretraining.py:  535]:	loss/mlm_loss, 7.164647102355957, 2924
[INFO] 2021-07-12 19:30:36,885 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9229997380753048e-05, 2924
[INFO] 2021-07-12 19:30:36,885 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2924
[INFO] 2021-07-12 19:30:36,885 [run_pretraining.py:  558]:	worker_index: 7, step: 2924, cost: 7.164647, mlm loss: 7.164647, speed: 1.057145 steps/s, speed: 8.457162 samples/s, speed: 4330.066818 tokens/s, learning rate: 2.923e-05, loss_scalings: 2814.750488, pp_loss: 7.219542
[INFO] 2021-07-12 19:30:36,885 [run_pretraining.py:  512]:	********exe.run_2924******* 
[INFO] 2021-07-12 19:30:37,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:37,798 [run_pretraining.py:  534]:	loss/total_loss, 7.251293659210205, 2925
[INFO] 2021-07-12 19:30:37,798 [run_pretraining.py:  535]:	loss/mlm_loss, 7.251293659210205, 2925
[INFO] 2021-07-12 19:30:37,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9240000003483146e-05, 2925
[INFO] 2021-07-12 19:30:37,798 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2925
[INFO] 2021-07-12 19:30:37,798 [run_pretraining.py:  558]:	worker_index: 7, step: 2925, cost: 7.251294, mlm loss: 7.251294, speed: 1.096132 steps/s, speed: 8.769056 samples/s, speed: 4489.756504 tokens/s, learning rate: 2.924e-05, loss_scalings: 2814.750488, pp_loss: 6.536924
[INFO] 2021-07-12 19:30:37,798 [run_pretraining.py:  512]:	********exe.run_2925******* 
[INFO] 2021-07-12 19:30:38,704 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:38,704 [run_pretraining.py:  534]:	loss/total_loss, 6.417445182800293, 2926
[INFO] 2021-07-12 19:30:38,704 [run_pretraining.py:  535]:	loss/mlm_loss, 6.417445182800293, 2926
[INFO] 2021-07-12 19:30:38,704 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9249998988234438e-05, 2926
[INFO] 2021-07-12 19:30:38,704 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2926
[INFO] 2021-07-12 19:30:38,704 [run_pretraining.py:  558]:	worker_index: 7, step: 2926, cost: 6.417445, mlm loss: 6.417445, speed: 1.103937 steps/s, speed: 8.831499 samples/s, speed: 4521.727404 tokens/s, learning rate: 2.925e-05, loss_scalings: 2814.750488, pp_loss: 6.284228
[INFO] 2021-07-12 19:30:38,705 [run_pretraining.py:  512]:	********exe.run_2926******* 
[INFO] 2021-07-12 19:30:39,611 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:39,612 [run_pretraining.py:  534]:	loss/total_loss, 3.5918898582458496, 2927
[INFO] 2021-07-12 19:30:39,612 [run_pretraining.py:  535]:	loss/mlm_loss, 3.5918898582458496, 2927
[INFO] 2021-07-12 19:30:39,612 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9259999791975133e-05, 2927
[INFO] 2021-07-12 19:30:39,612 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2927
[INFO] 2021-07-12 19:30:39,612 [run_pretraining.py:  558]:	worker_index: 7, step: 2927, cost: 3.591890, mlm loss: 3.591890, speed: 1.102569 steps/s, speed: 8.820553 samples/s, speed: 4516.122967 tokens/s, learning rate: 2.926e-05, loss_scalings: 2814.750488, pp_loss: 6.638059
[INFO] 2021-07-12 19:30:39,612 [run_pretraining.py:  512]:	********exe.run_2927******* 
[INFO] 2021-07-12 19:30:40,520 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:40,520 [run_pretraining.py:  534]:	loss/total_loss, 7.164712429046631, 2928
[INFO] 2021-07-12 19:30:40,520 [run_pretraining.py:  535]:	loss/mlm_loss, 7.164712429046631, 2928
[INFO] 2021-07-12 19:30:40,521 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9269998776726425e-05, 2928
[INFO] 2021-07-12 19:30:40,521 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2928
[INFO] 2021-07-12 19:30:40,521 [run_pretraining.py:  558]:	worker_index: 7, step: 2928, cost: 7.164712, mlm loss: 7.164712, speed: 1.101310 steps/s, speed: 8.810480 samples/s, speed: 4510.965875 tokens/s, learning rate: 2.927e-05, loss_scalings: 2814.750488, pp_loss: 6.924307
[INFO] 2021-07-12 19:30:40,521 [run_pretraining.py:  512]:	********exe.run_2928******* 
[INFO] 2021-07-12 19:30:41,424 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:41,425 [run_pretraining.py:  534]:	loss/total_loss, 7.131152153015137, 2929
[INFO] 2021-07-12 19:30:41,425 [run_pretraining.py:  535]:	loss/mlm_loss, 7.131152153015137, 2929
[INFO] 2021-07-12 19:30:41,425 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.927999958046712e-05, 2929
[INFO] 2021-07-12 19:30:41,425 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2929
[INFO] 2021-07-12 19:30:41,425 [run_pretraining.py:  558]:	worker_index: 7, step: 2929, cost: 7.131152, mlm loss: 7.131152, speed: 1.106730 steps/s, speed: 8.853842 samples/s, speed: 4533.167094 tokens/s, learning rate: 2.928e-05, loss_scalings: 2814.750488, pp_loss: 7.514783
[INFO] 2021-07-12 19:30:41,425 [run_pretraining.py:  512]:	********exe.run_2929******* 
[INFO] 2021-07-12 19:30:42,332 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:42,333 [run_pretraining.py:  534]:	loss/total_loss, 7.318411827087402, 2930
[INFO] 2021-07-12 19:30:42,334 [run_pretraining.py:  535]:	loss/mlm_loss, 7.318411827087402, 2930
[INFO] 2021-07-12 19:30:42,334 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.928999856521841e-05, 2930
[INFO] 2021-07-12 19:30:42,334 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2930
[INFO] 2021-07-12 19:30:42,334 [run_pretraining.py:  558]:	worker_index: 7, step: 2930, cost: 7.318412, mlm loss: 7.318412, speed: 1.101389 steps/s, speed: 8.811114 samples/s, speed: 4511.290440 tokens/s, learning rate: 2.929e-05, loss_scalings: 2814.750488, pp_loss: 7.361769
[INFO] 2021-07-12 19:30:42,340 [run_pretraining.py:  512]:	********exe.run_2930******* 
[INFO] 2021-07-12 19:30:43,245 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:43,246 [run_pretraining.py:  534]:	loss/total_loss, 7.320023536682129, 2931
[INFO] 2021-07-12 19:30:43,246 [run_pretraining.py:  535]:	loss/mlm_loss, 7.320023536682129, 2931
[INFO] 2021-07-12 19:30:43,246 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.930000118794851e-05, 2931
[INFO] 2021-07-12 19:30:43,246 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2931
[INFO] 2021-07-12 19:30:43,246 [run_pretraining.py:  558]:	worker_index: 7, step: 2931, cost: 7.320024, mlm loss: 7.320024, speed: 1.103798 steps/s, speed: 8.830388 samples/s, speed: 4521.158600 tokens/s, learning rate: 2.930e-05, loss_scalings: 2814.750488, pp_loss: 7.158222
[INFO] 2021-07-12 19:30:43,246 [run_pretraining.py:  512]:	********exe.run_2931******* 
[INFO] 2021-07-12 19:30:44,153 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:44,154 [run_pretraining.py:  534]:	loss/total_loss, 6.405670166015625, 2932
[INFO] 2021-07-12 19:30:44,154 [run_pretraining.py:  535]:	loss/mlm_loss, 6.405670166015625, 2932
[INFO] 2021-07-12 19:30:44,154 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9309998353710398e-05, 2932
[INFO] 2021-07-12 19:30:44,154 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2932
[INFO] 2021-07-12 19:30:44,154 [run_pretraining.py:  558]:	worker_index: 7, step: 2932, cost: 6.405670, mlm loss: 6.405670, speed: 1.102125 steps/s, speed: 8.817000 samples/s, speed: 4514.303773 tokens/s, learning rate: 2.931e-05, loss_scalings: 2814.750488, pp_loss: 7.180338
[INFO] 2021-07-12 19:30:44,154 [run_pretraining.py:  512]:	********exe.run_2932******* 
[INFO] 2021-07-12 19:30:45,061 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:45,062 [run_pretraining.py:  534]:	loss/total_loss, 7.278624534606934, 2933
[INFO] 2021-07-12 19:30:45,062 [run_pretraining.py:  535]:	loss/mlm_loss, 7.278624534606934, 2933
[INFO] 2021-07-12 19:30:45,062 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.931999733846169e-05, 2933
[INFO] 2021-07-12 19:30:45,062 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2933
[INFO] 2021-07-12 19:30:45,062 [run_pretraining.py:  558]:	worker_index: 7, step: 2933, cost: 7.278625, mlm loss: 7.278625, speed: 1.102174 steps/s, speed: 8.817393 samples/s, speed: 4514.505438 tokens/s, learning rate: 2.932e-05, loss_scalings: 2814.750488, pp_loss: 7.356320
[INFO] 2021-07-12 19:30:45,062 [run_pretraining.py:  512]:	********exe.run_2933******* 
[INFO] 2021-07-12 19:30:45,964 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:45,965 [run_pretraining.py:  534]:	loss/total_loss, 6.671661376953125, 2934
[INFO] 2021-07-12 19:30:45,965 [run_pretraining.py:  535]:	loss/mlm_loss, 6.671661376953125, 2934
[INFO] 2021-07-12 19:30:45,965 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.932999996119179e-05, 2934
[INFO] 2021-07-12 19:30:45,965 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2934
[INFO] 2021-07-12 19:30:45,965 [run_pretraining.py:  558]:	worker_index: 7, step: 2934, cost: 6.671661, mlm loss: 6.671661, speed: 1.108434 steps/s, speed: 8.867469 samples/s, speed: 4540.144161 tokens/s, learning rate: 2.933e-05, loss_scalings: 2814.750488, pp_loss: 6.361236
[INFO] 2021-07-12 19:30:45,965 [run_pretraining.py:  512]:	********exe.run_2934******* 
[INFO] 2021-07-12 19:30:46,869 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:46,869 [run_pretraining.py:  534]:	loss/total_loss, 7.993478298187256, 2935
[INFO] 2021-07-12 19:30:46,869 [run_pretraining.py:  535]:	loss/mlm_loss, 7.993478298187256, 2935
[INFO] 2021-07-12 19:30:46,869 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.933999894594308e-05, 2935
[INFO] 2021-07-12 19:30:46,869 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2935
[INFO] 2021-07-12 19:30:46,870 [run_pretraining.py:  558]:	worker_index: 7, step: 2935, cost: 7.993478, mlm loss: 7.993478, speed: 1.106135 steps/s, speed: 8.849079 samples/s, speed: 4530.728272 tokens/s, learning rate: 2.934e-05, loss_scalings: 2814.750488, pp_loss: 7.432146
[INFO] 2021-07-12 19:30:46,870 [run_pretraining.py:  512]:	********exe.run_2935******* 
[INFO] 2021-07-12 19:30:47,774 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:47,775 [run_pretraining.py:  534]:	loss/total_loss, 7.096709728240967, 2936
[INFO] 2021-07-12 19:30:47,775 [run_pretraining.py:  535]:	loss/mlm_loss, 7.096709728240967, 2936
[INFO] 2021-07-12 19:30:47,775 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9349999749683775e-05, 2936
[INFO] 2021-07-12 19:30:47,775 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2936
[INFO] 2021-07-12 19:30:47,775 [run_pretraining.py:  558]:	worker_index: 7, step: 2936, cost: 7.096710, mlm loss: 7.096710, speed: 1.104999 steps/s, speed: 8.839991 samples/s, speed: 4526.075500 tokens/s, learning rate: 2.935e-05, loss_scalings: 2814.750488, pp_loss: 6.859724
[INFO] 2021-07-12 19:30:47,775 [run_pretraining.py:  512]:	********exe.run_2936******* 
[INFO] 2021-07-12 19:30:48,680 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:48,681 [run_pretraining.py:  534]:	loss/total_loss, 7.002837181091309, 2937
[INFO] 2021-07-12 19:30:48,681 [run_pretraining.py:  535]:	loss/mlm_loss, 7.002837181091309, 2937
[INFO] 2021-07-12 19:30:48,681 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9359998734435067e-05, 2937
[INFO] 2021-07-12 19:30:48,681 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2937
[INFO] 2021-07-12 19:30:48,681 [run_pretraining.py:  558]:	worker_index: 7, step: 2937, cost: 7.002837, mlm loss: 7.002837, speed: 1.104331 steps/s, speed: 8.834645 samples/s, speed: 4523.338203 tokens/s, learning rate: 2.936e-05, loss_scalings: 2814.750488, pp_loss: 7.012395
[INFO] 2021-07-12 19:30:48,681 [run_pretraining.py:  512]:	********exe.run_2937******* 
[INFO] 2021-07-12 19:30:49,579 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:49,579 [run_pretraining.py:  534]:	loss/total_loss, 7.737850666046143, 2938
[INFO] 2021-07-12 19:30:49,579 [run_pretraining.py:  535]:	loss/mlm_loss, 7.737850666046143, 2938
[INFO] 2021-07-12 19:30:49,579 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9369999538175762e-05, 2938
[INFO] 2021-07-12 19:30:49,579 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2938
[INFO] 2021-07-12 19:30:49,580 [run_pretraining.py:  558]:	worker_index: 7, step: 2938, cost: 7.737851, mlm loss: 7.737851, speed: 1.114180 steps/s, speed: 8.913440 samples/s, speed: 4563.681422 tokens/s, learning rate: 2.937e-05, loss_scalings: 2814.750488, pp_loss: 7.381534
[INFO] 2021-07-12 19:30:49,580 [run_pretraining.py:  512]:	********exe.run_2938******* 
[INFO] 2021-07-12 19:30:50,482 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:50,483 [run_pretraining.py:  534]:	loss/total_loss, 7.516397953033447, 2939
[INFO] 2021-07-12 19:30:50,483 [run_pretraining.py:  535]:	loss/mlm_loss, 7.516397953033447, 2939
[INFO] 2021-07-12 19:30:50,483 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9379998522927053e-05, 2939
[INFO] 2021-07-12 19:30:50,483 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2939
[INFO] 2021-07-12 19:30:50,483 [run_pretraining.py:  558]:	worker_index: 7, step: 2939, cost: 7.516398, mlm loss: 7.516398, speed: 1.107534 steps/s, speed: 8.860269 samples/s, speed: 4536.457682 tokens/s, learning rate: 2.938e-05, loss_scalings: 2814.750488, pp_loss: 7.399341
[INFO] 2021-07-12 19:30:50,483 [run_pretraining.py:  512]:	********exe.run_2939******* 
[INFO] 2021-07-12 19:30:51,386 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:51,387 [run_pretraining.py:  534]:	loss/total_loss, 7.28837776184082, 2940
[INFO] 2021-07-12 19:30:51,387 [run_pretraining.py:  535]:	loss/mlm_loss, 7.28837776184082, 2940
[INFO] 2021-07-12 19:30:51,387 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9390001145657152e-05, 2940
[INFO] 2021-07-12 19:30:51,387 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2940
[INFO] 2021-07-12 19:30:51,387 [run_pretraining.py:  558]:	worker_index: 7, step: 2940, cost: 7.288378, mlm loss: 7.288378, speed: 1.107204 steps/s, speed: 8.857633 samples/s, speed: 4535.108071 tokens/s, learning rate: 2.939e-05, loss_scalings: 2814.750488, pp_loss: 6.465677
[INFO] 2021-07-12 19:30:51,387 [run_pretraining.py:  512]:	********exe.run_2940******* 
[INFO] 2021-07-12 19:30:52,294 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:52,295 [run_pretraining.py:  534]:	loss/total_loss, 7.121529579162598, 2941
[INFO] 2021-07-12 19:30:52,295 [run_pretraining.py:  535]:	loss/mlm_loss, 7.121529579162598, 2941
[INFO] 2021-07-12 19:30:52,295 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9400000130408444e-05, 2941
[INFO] 2021-07-12 19:30:52,295 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2941
[INFO] 2021-07-12 19:30:52,295 [run_pretraining.py:  558]:	worker_index: 7, step: 2941, cost: 7.121530, mlm loss: 7.121530, speed: 1.102003 steps/s, speed: 8.816027 samples/s, speed: 4513.805620 tokens/s, learning rate: 2.940e-05, loss_scalings: 2814.750488, pp_loss: 7.345455
[INFO] 2021-07-12 19:30:52,295 [run_pretraining.py:  512]:	********exe.run_2941******* 
[INFO] 2021-07-12 19:30:53,206 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:53,206 [run_pretraining.py:  534]:	loss/total_loss, 7.1110944747924805, 2942
[INFO] 2021-07-12 19:30:53,206 [run_pretraining.py:  535]:	loss/mlm_loss, 7.1110944747924805, 2942
[INFO] 2021-07-12 19:30:53,206 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.940999729617033e-05, 2942
[INFO] 2021-07-12 19:30:53,206 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2942
[INFO] 2021-07-12 19:30:53,206 [run_pretraining.py:  558]:	worker_index: 7, step: 2942, cost: 7.111094, mlm loss: 7.111094, speed: 1.097943 steps/s, speed: 8.783545 samples/s, speed: 4497.174895 tokens/s, learning rate: 2.941e-05, loss_scalings: 2814.750488, pp_loss: 6.919207
[INFO] 2021-07-12 19:30:53,207 [run_pretraining.py:  512]:	********exe.run_2942******* 
[INFO] 2021-07-12 19:30:54,109 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  534]:	loss/total_loss, 6.982776641845703, 2943
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  535]:	loss/mlm_loss, 6.982776641845703, 2943
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.941999991890043e-05, 2943
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2943
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  558]:	worker_index: 7, step: 2943, cost: 6.982777, mlm loss: 6.982777, speed: 1.107443 steps/s, speed: 8.859546 samples/s, speed: 4536.087567 tokens/s, learning rate: 2.942e-05, loss_scalings: 2814.750488, pp_loss: 6.800041
[INFO] 2021-07-12 19:30:54,110 [run_pretraining.py:  512]:	********exe.run_2943******* 
[INFO] 2021-07-12 19:30:55,016 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:55,016 [run_pretraining.py:  534]:	loss/total_loss, 8.235097885131836, 2944
[INFO] 2021-07-12 19:30:55,016 [run_pretraining.py:  535]:	loss/mlm_loss, 8.235097885131836, 2944
[INFO] 2021-07-12 19:30:55,016 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9429998903651722e-05, 2944
[INFO] 2021-07-12 19:30:55,017 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2944
[INFO] 2021-07-12 19:30:55,017 [run_pretraining.py:  558]:	worker_index: 7, step: 2944, cost: 8.235098, mlm loss: 8.235098, speed: 1.103904 steps/s, speed: 8.831234 samples/s, speed: 4521.591735 tokens/s, learning rate: 2.943e-05, loss_scalings: 2814.750488, pp_loss: 7.383817
[INFO] 2021-07-12 19:30:55,017 [run_pretraining.py:  512]:	********exe.run_2944******* 
[INFO] 2021-07-12 19:30:55,918 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:55,919 [run_pretraining.py:  534]:	loss/total_loss, 5.095668315887451, 2945
[INFO] 2021-07-12 19:30:55,919 [run_pretraining.py:  535]:	loss/mlm_loss, 5.095668315887451, 2945
[INFO] 2021-07-12 19:30:55,919 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9439999707392417e-05, 2945
[INFO] 2021-07-12 19:30:55,919 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2945
[INFO] 2021-07-12 19:30:55,919 [run_pretraining.py:  558]:	worker_index: 7, step: 2945, cost: 5.095668, mlm loss: 5.095668, speed: 1.109056 steps/s, speed: 8.872447 samples/s, speed: 4542.692828 tokens/s, learning rate: 2.944e-05, loss_scalings: 2814.750488, pp_loss: 6.785978
[INFO] 2021-07-12 19:30:55,919 [run_pretraining.py:  512]:	********exe.run_2945******* 
[INFO] 2021-07-12 19:30:56,822 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:56,822 [run_pretraining.py:  534]:	loss/total_loss, 7.404425621032715, 2946
[INFO] 2021-07-12 19:30:56,822 [run_pretraining.py:  535]:	loss/mlm_loss, 7.404425621032715, 2946
[INFO] 2021-07-12 19:30:56,822 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.944999869214371e-05, 2946
[INFO] 2021-07-12 19:30:56,822 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2946
[INFO] 2021-07-12 19:30:56,823 [run_pretraining.py:  558]:	worker_index: 7, step: 2946, cost: 7.404426, mlm loss: 7.404426, speed: 1.107451 steps/s, speed: 8.859612 samples/s, speed: 4536.121102 tokens/s, learning rate: 2.945e-05, loss_scalings: 2814.750488, pp_loss: 7.304759
[INFO] 2021-07-12 19:30:56,823 [run_pretraining.py:  512]:	********exe.run_2946******* 
[INFO] 2021-07-12 19:30:57,728 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:57,728 [run_pretraining.py:  534]:	loss/total_loss, 7.135391712188721, 2947
[INFO] 2021-07-12 19:30:57,728 [run_pretraining.py:  535]:	loss/mlm_loss, 7.135391712188721, 2947
[INFO] 2021-07-12 19:30:57,728 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9459999495884404e-05, 2947
[INFO] 2021-07-12 19:30:57,729 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2947
[INFO] 2021-07-12 19:30:57,729 [run_pretraining.py:  558]:	worker_index: 7, step: 2947, cost: 7.135392, mlm loss: 7.135392, speed: 1.104573 steps/s, speed: 8.836581 samples/s, speed: 4524.329301 tokens/s, learning rate: 2.946e-05, loss_scalings: 2814.750488, pp_loss: 7.296518
[INFO] 2021-07-12 19:30:57,729 [run_pretraining.py:  512]:	********exe.run_2947******* 
[INFO] 2021-07-12 19:30:58,627 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:58,628 [run_pretraining.py:  534]:	loss/total_loss, 8.4053955078125, 2948
[INFO] 2021-07-12 19:30:58,628 [run_pretraining.py:  535]:	loss/mlm_loss, 8.4053955078125, 2948
[INFO] 2021-07-12 19:30:58,628 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9469998480635695e-05, 2948
[INFO] 2021-07-12 19:30:58,628 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2948
[INFO] 2021-07-12 19:30:58,628 [run_pretraining.py:  558]:	worker_index: 7, step: 2948, cost: 8.405396, mlm loss: 8.405396, speed: 1.112309 steps/s, speed: 8.898475 samples/s, speed: 4556.019225 tokens/s, learning rate: 2.947e-05, loss_scalings: 2814.750488, pp_loss: 7.304343
[INFO] 2021-07-12 19:30:58,628 [run_pretraining.py:  512]:	********exe.run_2948******* 
[INFO] 2021-07-12 19:30:59,533 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:30:59,534 [run_pretraining.py:  534]:	loss/total_loss, 7.2983479499816895, 2949
[INFO] 2021-07-12 19:30:59,534 [run_pretraining.py:  535]:	loss/mlm_loss, 7.2983479499816895, 2949
[INFO] 2021-07-12 19:30:59,534 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9480001103365794e-05, 2949
[INFO] 2021-07-12 19:30:59,534 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2949
[INFO] 2021-07-12 19:30:59,534 [run_pretraining.py:  558]:	worker_index: 7, step: 2949, cost: 7.298348, mlm loss: 7.298348, speed: 1.105032 steps/s, speed: 8.840254 samples/s, speed: 4526.210246 tokens/s, learning rate: 2.948e-05, loss_scalings: 2814.750488, pp_loss: 7.163468
[INFO] 2021-07-12 19:30:59,534 [run_pretraining.py:  512]:	********exe.run_2949******* 
[INFO] 2021-07-12 19:31:00,448 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:00,454 [run_pretraining.py:  534]:	loss/total_loss, 7.303704738616943, 2950
[INFO] 2021-07-12 19:31:00,459 [run_pretraining.py:  535]:	loss/mlm_loss, 7.303704738616943, 2950
[INFO] 2021-07-12 19:31:00,464 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9490000088117085e-05, 2950
[INFO] 2021-07-12 19:31:00,469 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2950
[INFO] 2021-07-12 19:31:00,474 [run_pretraining.py:  558]:	worker_index: 7, step: 2950, cost: 7.303705, mlm loss: 7.303705, speed: 1.087768 steps/s, speed: 8.702144 samples/s, speed: 4455.497767 tokens/s, learning rate: 2.949e-05, loss_scalings: 2814.750488, pp_loss: 7.678920
[INFO] 2021-07-12 19:31:00,479 [run_pretraining.py:  512]:	********exe.run_2950******* 
[INFO] 2021-07-12 19:31:01,384 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:01,385 [run_pretraining.py:  534]:	loss/total_loss, 6.766965389251709, 2951
[INFO] 2021-07-12 19:31:01,385 [run_pretraining.py:  535]:	loss/mlm_loss, 6.766965389251709, 2951
[INFO] 2021-07-12 19:31:01,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9499997253878973e-05, 2951
[INFO] 2021-07-12 19:31:01,385 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2951
[INFO] 2021-07-12 19:31:01,385 [run_pretraining.py:  558]:	worker_index: 7, step: 2951, cost: 6.766965, mlm loss: 6.766965, speed: 1.104543 steps/s, speed: 8.836341 samples/s, speed: 4524.206581 tokens/s, learning rate: 2.950e-05, loss_scalings: 2814.750488, pp_loss: 7.246017
[INFO] 2021-07-12 19:31:01,385 [run_pretraining.py:  512]:	********exe.run_2951******* 
[INFO] 2021-07-12 19:31:02,287 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:02,288 [run_pretraining.py:  534]:	loss/total_loss, 7.633389949798584, 2952
[INFO] 2021-07-12 19:31:02,288 [run_pretraining.py:  535]:	loss/mlm_loss, 7.633389949798584, 2952
[INFO] 2021-07-12 19:31:02,288 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9509999876609072e-05, 2952
[INFO] 2021-07-12 19:31:02,288 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2952
[INFO] 2021-07-12 19:31:02,288 [run_pretraining.py:  558]:	worker_index: 7, step: 2952, cost: 7.633390, mlm loss: 7.633390, speed: 1.108268 steps/s, speed: 8.866145 samples/s, speed: 4539.466359 tokens/s, learning rate: 2.951e-05, loss_scalings: 2814.750488, pp_loss: 7.236965
[INFO] 2021-07-12 19:31:02,288 [run_pretraining.py:  512]:	********exe.run_2952******* 
[INFO] 2021-07-12 19:31:03,192 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:03,192 [run_pretraining.py:  534]:	loss/total_loss, 7.265411853790283, 2953
[INFO] 2021-07-12 19:31:03,193 [run_pretraining.py:  535]:	loss/mlm_loss, 7.265411853790283, 2953
[INFO] 2021-07-12 19:31:03,193 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9519998861360364e-05, 2953
[INFO] 2021-07-12 19:31:03,193 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2953
[INFO] 2021-07-12 19:31:03,193 [run_pretraining.py:  558]:	worker_index: 7, step: 2953, cost: 7.265412, mlm loss: 7.265412, speed: 1.106332 steps/s, speed: 8.850654 samples/s, speed: 4531.534945 tokens/s, learning rate: 2.952e-05, loss_scalings: 2814.750488, pp_loss: 7.012055
[INFO] 2021-07-12 19:31:03,193 [run_pretraining.py:  512]:	********exe.run_2953******* 
[INFO] 2021-07-12 19:31:04,091 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:04,091 [run_pretraining.py:  534]:	loss/total_loss, 7.299051761627197, 2954
[INFO] 2021-07-12 19:31:04,091 [run_pretraining.py:  535]:	loss/mlm_loss, 7.299051761627197, 2954
[INFO] 2021-07-12 19:31:04,092 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.952999966510106e-05, 2954
[INFO] 2021-07-12 19:31:04,092 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2954
[INFO] 2021-07-12 19:31:04,092 [run_pretraining.py:  558]:	worker_index: 7, step: 2954, cost: 7.299052, mlm loss: 7.299052, speed: 1.113392 steps/s, speed: 8.907132 samples/s, speed: 4560.451712 tokens/s, learning rate: 2.953e-05, loss_scalings: 2814.750488, pp_loss: 6.974707
[INFO] 2021-07-12 19:31:04,092 [run_pretraining.py:  512]:	********exe.run_2954******* 
[INFO] 2021-07-12 19:31:04,986 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:04,987 [run_pretraining.py:  534]:	loss/total_loss, 7.105853080749512, 2955
[INFO] 2021-07-12 19:31:04,987 [run_pretraining.py:  535]:	loss/mlm_loss, 7.105853080749512, 2955
[INFO] 2021-07-12 19:31:04,987 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.953999864985235e-05, 2955
[INFO] 2021-07-12 19:31:04,987 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2955
[INFO] 2021-07-12 19:31:04,987 [run_pretraining.py:  558]:	worker_index: 7, step: 2955, cost: 7.105853, mlm loss: 7.105853, speed: 1.117431 steps/s, speed: 8.939445 samples/s, speed: 4576.996073 tokens/s, learning rate: 2.954e-05, loss_scalings: 2814.750488, pp_loss: 6.906319
[INFO] 2021-07-12 19:31:04,987 [run_pretraining.py:  512]:	********exe.run_2955******* 
[INFO] 2021-07-12 19:31:05,900 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:05,901 [run_pretraining.py:  534]:	loss/total_loss, 7.369564056396484, 2956
[INFO] 2021-07-12 19:31:05,901 [run_pretraining.py:  535]:	loss/mlm_loss, 7.369564056396484, 2956
[INFO] 2021-07-12 19:31:05,901 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9549999453593045e-05, 2956
[INFO] 2021-07-12 19:31:05,901 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2956
[INFO] 2021-07-12 19:31:05,901 [run_pretraining.py:  558]:	worker_index: 7, step: 2956, cost: 7.369564, mlm loss: 7.369564, speed: 1.094990 steps/s, speed: 8.759917 samples/s, speed: 4485.077393 tokens/s, learning rate: 2.955e-05, loss_scalings: 2814.750488, pp_loss: 7.312788
[INFO] 2021-07-12 19:31:05,901 [run_pretraining.py:  512]:	********exe.run_2956******* 
[INFO] 2021-07-12 19:31:06,809 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:06,809 [run_pretraining.py:  534]:	loss/total_loss, 6.840022087097168, 2957
[INFO] 2021-07-12 19:31:06,809 [run_pretraining.py:  535]:	loss/mlm_loss, 6.840022087097168, 2957
[INFO] 2021-07-12 19:31:06,809 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9559998438344337e-05, 2957
[INFO] 2021-07-12 19:31:06,809 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2957
[INFO] 2021-07-12 19:31:06,810 [run_pretraining.py:  558]:	worker_index: 7, step: 2957, cost: 6.840022, mlm loss: 6.840022, speed: 1.101528 steps/s, speed: 8.812223 samples/s, speed: 4511.857947 tokens/s, learning rate: 2.956e-05, loss_scalings: 2814.750488, pp_loss: 6.657348
[INFO] 2021-07-12 19:31:06,810 [run_pretraining.py:  512]:	********exe.run_2957******* 
[INFO] 2021-07-12 19:31:07,719 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:07,720 [run_pretraining.py:  534]:	loss/total_loss, 7.284626483917236, 2958
[INFO] 2021-07-12 19:31:07,720 [run_pretraining.py:  535]:	loss/mlm_loss, 7.284626483917236, 2958
[INFO] 2021-07-12 19:31:07,720 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9570001061074436e-05, 2958
[INFO] 2021-07-12 19:31:07,720 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2958
[INFO] 2021-07-12 19:31:07,720 [run_pretraining.py:  558]:	worker_index: 7, step: 2958, cost: 7.284626, mlm loss: 7.284626, speed: 1.099342 steps/s, speed: 8.794736 samples/s, speed: 4502.904680 tokens/s, learning rate: 2.957e-05, loss_scalings: 2814.750488, pp_loss: 7.158167
[INFO] 2021-07-12 19:31:07,720 [run_pretraining.py:  512]:	********exe.run_2958******* 
[INFO] 2021-07-12 19:31:08,625 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:08,626 [run_pretraining.py:  534]:	loss/total_loss, 6.929255485534668, 2959
[INFO] 2021-07-12 19:31:08,626 [run_pretraining.py:  535]:	loss/mlm_loss, 6.929255485534668, 2959
[INFO] 2021-07-12 19:31:08,626 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9580000045825727e-05, 2959
[INFO] 2021-07-12 19:31:08,626 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2959
[INFO] 2021-07-12 19:31:08,626 [run_pretraining.py:  558]:	worker_index: 7, step: 2959, cost: 6.929255, mlm loss: 6.929255, speed: 1.104154 steps/s, speed: 8.833233 samples/s, speed: 4522.615404 tokens/s, learning rate: 2.958e-05, loss_scalings: 2814.750488, pp_loss: 7.208144
[INFO] 2021-07-12 19:31:08,626 [run_pretraining.py:  512]:	********exe.run_2959******* 
[INFO] 2021-07-12 19:31:09,536 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:09,537 [run_pretraining.py:  534]:	loss/total_loss, 7.062174320220947, 2960
[INFO] 2021-07-12 19:31:09,537 [run_pretraining.py:  535]:	loss/mlm_loss, 7.062174320220947, 2960
[INFO] 2021-07-12 19:31:09,537 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9589997211587615e-05, 2960
[INFO] 2021-07-12 19:31:09,537 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2960
[INFO] 2021-07-12 19:31:09,537 [run_pretraining.py:  558]:	worker_index: 7, step: 2960, cost: 7.062174, mlm loss: 7.062174, speed: 1.098316 steps/s, speed: 8.786530 samples/s, speed: 4498.703453 tokens/s, learning rate: 2.959e-05, loss_scalings: 2814.750488, pp_loss: 6.698330
[INFO] 2021-07-12 19:31:09,537 [run_pretraining.py:  512]:	********exe.run_2960******* 
[INFO] 2021-07-12 19:31:10,447 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:10,448 [run_pretraining.py:  534]:	loss/total_loss, 7.136009216308594, 2961
[INFO] 2021-07-12 19:31:10,448 [run_pretraining.py:  535]:	loss/mlm_loss, 7.136009216308594, 2961
[INFO] 2021-07-12 19:31:10,448 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9599999834317714e-05, 2961
[INFO] 2021-07-12 19:31:10,448 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2961
[INFO] 2021-07-12 19:31:10,448 [run_pretraining.py:  558]:	worker_index: 7, step: 2961, cost: 7.136009, mlm loss: 7.136009, speed: 1.098424 steps/s, speed: 8.787393 samples/s, speed: 4499.145256 tokens/s, learning rate: 2.960e-05, loss_scalings: 2814.750488, pp_loss: 7.066006
[INFO] 2021-07-12 19:31:10,448 [run_pretraining.py:  512]:	********exe.run_2961******* 
[INFO] 2021-07-12 19:31:11,359 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:11,360 [run_pretraining.py:  534]:	loss/total_loss, 6.9990153312683105, 2962
[INFO] 2021-07-12 19:31:11,360 [run_pretraining.py:  535]:	loss/mlm_loss, 6.9990153312683105, 2962
[INFO] 2021-07-12 19:31:11,360 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9609998819069006e-05, 2962
[INFO] 2021-07-12 19:31:11,360 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2962
[INFO] 2021-07-12 19:31:11,360 [run_pretraining.py:  558]:	worker_index: 7, step: 2962, cost: 6.999015, mlm loss: 6.999015, speed: 1.097539 steps/s, speed: 8.780309 samples/s, speed: 4495.517972 tokens/s, learning rate: 2.961e-05, loss_scalings: 2814.750488, pp_loss: 6.560260
[INFO] 2021-07-12 19:31:11,360 [run_pretraining.py:  512]:	********exe.run_2962******* 
[INFO] 2021-07-12 19:31:12,270 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:12,270 [run_pretraining.py:  534]:	loss/total_loss, 7.479562759399414, 2963
[INFO] 2021-07-12 19:31:12,270 [run_pretraining.py:  535]:	loss/mlm_loss, 7.479562759399414, 2963
[INFO] 2021-07-12 19:31:12,270 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.96199996228097e-05, 2963
[INFO] 2021-07-12 19:31:12,270 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2963
[INFO] 2021-07-12 19:31:12,270 [run_pretraining.py:  558]:	worker_index: 7, step: 2963, cost: 7.479563, mlm loss: 7.479563, speed: 1.099314 steps/s, speed: 8.794514 samples/s, speed: 4502.791381 tokens/s, learning rate: 2.962e-05, loss_scalings: 2814.750488, pp_loss: 7.340414
[INFO] 2021-07-12 19:31:12,271 [run_pretraining.py:  512]:	********exe.run_2963******* 
[INFO] 2021-07-12 19:31:13,175 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:13,175 [run_pretraining.py:  534]:	loss/total_loss, 7.052762508392334, 2964
[INFO] 2021-07-12 19:31:13,176 [run_pretraining.py:  535]:	loss/mlm_loss, 7.052762508392334, 2964
[INFO] 2021-07-12 19:31:13,176 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9629998607560992e-05, 2964
[INFO] 2021-07-12 19:31:13,176 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2964
[INFO] 2021-07-12 19:31:13,176 [run_pretraining.py:  558]:	worker_index: 7, step: 2964, cost: 7.052763, mlm loss: 7.052763, speed: 1.105426 steps/s, speed: 8.843409 samples/s, speed: 4527.825434 tokens/s, learning rate: 2.963e-05, loss_scalings: 2814.750488, pp_loss: 7.076283
[INFO] 2021-07-12 19:31:13,176 [run_pretraining.py:  512]:	********exe.run_2964******* 
[INFO] 2021-07-12 19:31:14,081 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:14,081 [run_pretraining.py:  534]:	loss/total_loss, 7.522887229919434, 2965
[INFO] 2021-07-12 19:31:14,081 [run_pretraining.py:  535]:	loss/mlm_loss, 7.522887229919434, 2965
[INFO] 2021-07-12 19:31:14,081 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9639999411301687e-05, 2965
[INFO] 2021-07-12 19:31:14,082 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2965
[INFO] 2021-07-12 19:31:14,082 [run_pretraining.py:  558]:	worker_index: 7, step: 2965, cost: 7.522887, mlm loss: 7.522887, speed: 1.104707 steps/s, speed: 8.837656 samples/s, speed: 4524.879834 tokens/s, learning rate: 2.964e-05, loss_scalings: 2814.750488, pp_loss: 7.736059
[INFO] 2021-07-12 19:31:14,082 [run_pretraining.py:  512]:	********exe.run_2965******* 
[INFO] 2021-07-12 19:31:14,993 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:14,994 [run_pretraining.py:  534]:	loss/total_loss, 7.53641939163208, 2966
[INFO] 2021-07-12 19:31:14,994 [run_pretraining.py:  535]:	loss/mlm_loss, 7.53641939163208, 2966
[INFO] 2021-07-12 19:31:14,994 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.964999839605298e-05, 2966
[INFO] 2021-07-12 19:31:14,994 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2966
[INFO] 2021-07-12 19:31:14,994 [run_pretraining.py:  558]:	worker_index: 7, step: 2966, cost: 7.536419, mlm loss: 7.536419, speed: 1.096657 steps/s, speed: 8.773256 samples/s, speed: 4491.907102 tokens/s, learning rate: 2.965e-05, loss_scalings: 2814.750488, pp_loss: 7.336469
[INFO] 2021-07-12 19:31:14,994 [run_pretraining.py:  512]:	********exe.run_2966******* 
[INFO] 2021-07-12 19:31:15,894 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:15,895 [run_pretraining.py:  534]:	loss/total_loss, 7.298464775085449, 2967
[INFO] 2021-07-12 19:31:15,895 [run_pretraining.py:  535]:	loss/mlm_loss, 7.298464775085449, 2967
[INFO] 2021-07-12 19:31:15,895 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9660001018783078e-05, 2967
[INFO] 2021-07-12 19:31:15,895 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2967
[INFO] 2021-07-12 19:31:15,895 [run_pretraining.py:  558]:	worker_index: 7, step: 2967, cost: 7.298465, mlm loss: 7.298465, speed: 1.110385 steps/s, speed: 8.883083 samples/s, speed: 4548.138276 tokens/s, learning rate: 2.966e-05, loss_scalings: 2814.750488, pp_loss: 7.429559
[INFO] 2021-07-12 19:31:15,895 [run_pretraining.py:  512]:	********exe.run_2967******* 
[INFO] 2021-07-12 19:31:16,824 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:16,825 [run_pretraining.py:  534]:	loss/total_loss, 7.353325843811035, 2968
[INFO] 2021-07-12 19:31:16,825 [run_pretraining.py:  535]:	loss/mlm_loss, 7.353325843811035, 2968
[INFO] 2021-07-12 19:31:16,825 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.967000000353437e-05, 2968
[INFO] 2021-07-12 19:31:16,825 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2968
[INFO] 2021-07-12 19:31:16,825 [run_pretraining.py:  558]:	worker_index: 7, step: 2968, cost: 7.353326, mlm loss: 7.353326, speed: 1.076267 steps/s, speed: 8.610136 samples/s, speed: 4408.389651 tokens/s, learning rate: 2.967e-05, loss_scalings: 2814.750488, pp_loss: 7.197938
[INFO] 2021-07-12 19:31:16,825 [run_pretraining.py:  512]:	********exe.run_2968******* 
[INFO] 2021-07-12 19:31:17,883 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:17,884 [run_pretraining.py:  534]:	loss/total_loss, 6.933229446411133, 2969
[INFO] 2021-07-12 19:31:17,884 [run_pretraining.py:  535]:	loss/mlm_loss, 6.933229446411133, 2969
[INFO] 2021-07-12 19:31:17,884 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9679997169296257e-05, 2969
[INFO] 2021-07-12 19:31:17,884 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2969
[INFO] 2021-07-12 19:31:17,884 [run_pretraining.py:  558]:	worker_index: 7, step: 2969, cost: 6.933229, mlm loss: 6.933229, speed: 0.944818 steps/s, speed: 7.558547 samples/s, speed: 3869.976186 tokens/s, learning rate: 2.968e-05, loss_scalings: 2814.750488, pp_loss: 6.903030
[INFO] 2021-07-12 19:31:17,884 [run_pretraining.py:  512]:	********exe.run_2969******* 
[INFO] 2021-07-12 19:31:18,949 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:18,950 [run_pretraining.py:  534]:	loss/total_loss, 7.670283794403076, 2970
[INFO] 2021-07-12 19:31:18,950 [run_pretraining.py:  535]:	loss/mlm_loss, 7.670283794403076, 2970
[INFO] 2021-07-12 19:31:18,950 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9689999792026356e-05, 2970
[INFO] 2021-07-12 19:31:18,950 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2970
[INFO] 2021-07-12 19:31:18,950 [run_pretraining.py:  558]:	worker_index: 7, step: 2970, cost: 7.670284, mlm loss: 7.670284, speed: 0.938667 steps/s, speed: 7.509336 samples/s, speed: 3844.780075 tokens/s, learning rate: 2.969e-05, loss_scalings: 2814.750488, pp_loss: 7.147511
[INFO] 2021-07-12 19:31:18,950 [run_pretraining.py:  512]:	********exe.run_2970******* 
[INFO] 2021-07-12 19:31:20,002 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:20,003 [run_pretraining.py:  534]:	loss/total_loss, 7.199329853057861, 2971
[INFO] 2021-07-12 19:31:20,003 [run_pretraining.py:  535]:	loss/mlm_loss, 7.199329853057861, 2971
[INFO] 2021-07-12 19:31:20,003 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9699998776777647e-05, 2971
[INFO] 2021-07-12 19:31:20,003 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2971
[INFO] 2021-07-12 19:31:20,003 [run_pretraining.py:  558]:	worker_index: 7, step: 2971, cost: 7.199330, mlm loss: 7.199330, speed: 0.950430 steps/s, speed: 7.603437 samples/s, speed: 3892.959826 tokens/s, learning rate: 2.970e-05, loss_scalings: 2814.750488, pp_loss: 7.369750
[INFO] 2021-07-12 19:31:20,003 [run_pretraining.py:  512]:	********exe.run_2971******* 
[INFO] 2021-07-12 19:31:21,048 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:21,048 [run_pretraining.py:  534]:	loss/total_loss, 7.387360572814941, 2972
[INFO] 2021-07-12 19:31:21,048 [run_pretraining.py:  535]:	loss/mlm_loss, 7.387360572814941, 2972
[INFO] 2021-07-12 19:31:21,048 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9709999580518343e-05, 2972
[INFO] 2021-07-12 19:31:21,048 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2972
[INFO] 2021-07-12 19:31:21,048 [run_pretraining.py:  558]:	worker_index: 7, step: 2972, cost: 7.387361, mlm loss: 7.387361, speed: 0.957061 steps/s, speed: 7.656491 samples/s, speed: 3920.123159 tokens/s, learning rate: 2.971e-05, loss_scalings: 2814.750488, pp_loss: 7.367828
[INFO] 2021-07-12 19:31:21,049 [run_pretraining.py:  512]:	********exe.run_2972******* 
[INFO] 2021-07-12 19:31:22,102 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:22,102 [run_pretraining.py:  534]:	loss/total_loss, 7.348964691162109, 2973
[INFO] 2021-07-12 19:31:22,102 [run_pretraining.py:  535]:	loss/mlm_loss, 7.348964691162109, 2973
[INFO] 2021-07-12 19:31:22,102 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9719998565269634e-05, 2973
[INFO] 2021-07-12 19:31:22,103 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2973
[INFO] 2021-07-12 19:31:22,103 [run_pretraining.py:  558]:	worker_index: 7, step: 2973, cost: 7.348965, mlm loss: 7.348965, speed: 0.949278 steps/s, speed: 7.594222 samples/s, speed: 3888.241665 tokens/s, learning rate: 2.972e-05, loss_scalings: 2814.750488, pp_loss: 7.113059
[INFO] 2021-07-12 19:31:22,103 [run_pretraining.py:  512]:	********exe.run_2973******* 
[INFO] 2021-07-12 19:31:23,156 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:23,157 [run_pretraining.py:  534]:	loss/total_loss, 7.330711841583252, 2974
[INFO] 2021-07-12 19:31:23,157 [run_pretraining.py:  535]:	loss/mlm_loss, 7.330711841583252, 2974
[INFO] 2021-07-12 19:31:23,157 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9730001187999733e-05, 2974
[INFO] 2021-07-12 19:31:23,157 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2974
[INFO] 2021-07-12 19:31:23,157 [run_pretraining.py:  558]:	worker_index: 7, step: 2974, cost: 7.330712, mlm loss: 7.330712, speed: 0.948864 steps/s, speed: 7.590915 samples/s, speed: 3886.548387 tokens/s, learning rate: 2.973e-05, loss_scalings: 2814.750488, pp_loss: 7.283815
[INFO] 2021-07-12 19:31:23,157 [run_pretraining.py:  512]:	********exe.run_2974******* 
[INFO] 2021-07-12 19:31:24,215 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:24,215 [run_pretraining.py:  534]:	loss/total_loss, 6.927453517913818, 2975
[INFO] 2021-07-12 19:31:24,215 [run_pretraining.py:  535]:	loss/mlm_loss, 6.927453517913818, 2975
[INFO] 2021-07-12 19:31:24,215 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.973999835376162e-05, 2975
[INFO] 2021-07-12 19:31:24,216 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2975
[INFO] 2021-07-12 19:31:24,216 [run_pretraining.py:  558]:	worker_index: 7, step: 2975, cost: 6.927454, mlm loss: 6.927454, speed: 0.945372 steps/s, speed: 7.562978 samples/s, speed: 3872.244962 tokens/s, learning rate: 2.974e-05, loss_scalings: 2814.750488, pp_loss: 7.011565
[INFO] 2021-07-12 19:31:24,216 [run_pretraining.py:  512]:	********exe.run_2975******* 
[INFO] 2021-07-12 19:31:25,272 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:25,273 [run_pretraining.py:  534]:	loss/total_loss, 7.529411315917969, 2976
[INFO] 2021-07-12 19:31:25,273 [run_pretraining.py:  535]:	loss/mlm_loss, 7.529411315917969, 2976
[INFO] 2021-07-12 19:31:25,273 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.975000097649172e-05, 2976
[INFO] 2021-07-12 19:31:25,273 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2976
[INFO] 2021-07-12 19:31:25,273 [run_pretraining.py:  558]:	worker_index: 7, step: 2976, cost: 7.529411, mlm loss: 7.529411, speed: 0.946323 steps/s, speed: 7.570582 samples/s, speed: 3876.137989 tokens/s, learning rate: 2.975e-05, loss_scalings: 2814.750488, pp_loss: 7.369224
[INFO] 2021-07-12 19:31:25,273 [run_pretraining.py:  512]:	********exe.run_2976******* 
[INFO] 2021-07-12 19:31:26,330 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:26,331 [run_pretraining.py:  534]:	loss/total_loss, 7.301225185394287, 2977
[INFO] 2021-07-12 19:31:26,331 [run_pretraining.py:  535]:	loss/mlm_loss, 7.301225185394287, 2977
[INFO] 2021-07-12 19:31:26,331 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.975999996124301e-05, 2977
[INFO] 2021-07-12 19:31:26,331 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2977
[INFO] 2021-07-12 19:31:26,331 [run_pretraining.py:  558]:	worker_index: 7, step: 2977, cost: 7.301225, mlm loss: 7.301225, speed: 0.945757 steps/s, speed: 7.566057 samples/s, speed: 3873.820975 tokens/s, learning rate: 2.976e-05, loss_scalings: 2814.750488, pp_loss: 6.464524
[INFO] 2021-07-12 19:31:26,331 [run_pretraining.py:  512]:	********exe.run_2977******* 
[INFO] 2021-07-12 19:31:27,385 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:27,385 [run_pretraining.py:  534]:	loss/total_loss, 7.184358596801758, 2978
[INFO] 2021-07-12 19:31:27,385 [run_pretraining.py:  535]:	loss/mlm_loss, 7.184358596801758, 2978
[INFO] 2021-07-12 19:31:27,385 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9769998945994303e-05, 2978
[INFO] 2021-07-12 19:31:27,385 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2978
[INFO] 2021-07-12 19:31:27,385 [run_pretraining.py:  558]:	worker_index: 7, step: 2978, cost: 7.184359, mlm loss: 7.184359, speed: 0.948916 steps/s, speed: 7.591329 samples/s, speed: 3886.760296 tokens/s, learning rate: 2.977e-05, loss_scalings: 2814.750488, pp_loss: 6.691428
[INFO] 2021-07-12 19:31:27,386 [run_pretraining.py:  512]:	********exe.run_2978******* 
[INFO] 2021-07-12 19:31:28,429 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:28,429 [run_pretraining.py:  534]:	loss/total_loss, 5.558394432067871, 2979
[INFO] 2021-07-12 19:31:28,430 [run_pretraining.py:  535]:	loss/mlm_loss, 5.558394432067871, 2979
[INFO] 2021-07-12 19:31:28,430 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9779999749734998e-05, 2979
[INFO] 2021-07-12 19:31:28,430 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2979
[INFO] 2021-07-12 19:31:28,430 [run_pretraining.py:  558]:	worker_index: 7, step: 2979, cost: 5.558394, mlm loss: 5.558394, speed: 0.958139 steps/s, speed: 7.665115 samples/s, speed: 3924.538899 tokens/s, learning rate: 2.978e-05, loss_scalings: 2814.750488, pp_loss: 6.582251
[INFO] 2021-07-12 19:31:28,430 [run_pretraining.py:  512]:	********exe.run_2979******* 
[INFO] 2021-07-12 19:31:29,488 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:29,489 [run_pretraining.py:  534]:	loss/total_loss, 6.603177547454834, 2980
[INFO] 2021-07-12 19:31:29,489 [run_pretraining.py:  535]:	loss/mlm_loss, 6.603177547454834, 2980
[INFO] 2021-07-12 19:31:29,489 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.978999873448629e-05, 2980
[INFO] 2021-07-12 19:31:29,489 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2980
[INFO] 2021-07-12 19:31:29,489 [run_pretraining.py:  558]:	worker_index: 7, step: 2980, cost: 6.603178, mlm loss: 6.603178, speed: 0.944427 steps/s, speed: 7.555416 samples/s, speed: 3868.372813 tokens/s, learning rate: 2.979e-05, loss_scalings: 2814.750488, pp_loss: 7.139975
[INFO] 2021-07-12 19:31:29,489 [run_pretraining.py:  512]:	********exe.run_2980******* 
[INFO] 2021-07-12 19:31:30,542 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:30,543 [run_pretraining.py:  534]:	loss/total_loss, 7.536343097686768, 2981
[INFO] 2021-07-12 19:31:30,543 [run_pretraining.py:  535]:	loss/mlm_loss, 7.536343097686768, 2981
[INFO] 2021-07-12 19:31:30,543 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9799999538226984e-05, 2981
[INFO] 2021-07-12 19:31:30,543 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2981
[INFO] 2021-07-12 19:31:30,543 [run_pretraining.py:  558]:	worker_index: 7, step: 2981, cost: 7.536343, mlm loss: 7.536343, speed: 0.949576 steps/s, speed: 7.596608 samples/s, speed: 3889.463500 tokens/s, learning rate: 2.980e-05, loss_scalings: 2814.750488, pp_loss: 7.038503
[INFO] 2021-07-12 19:31:30,543 [run_pretraining.py:  512]:	********exe.run_2981******* 
[INFO] 2021-07-12 19:31:31,608 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:31,609 [run_pretraining.py:  534]:	loss/total_loss, 7.0010576248168945, 2982
[INFO] 2021-07-12 19:31:31,609 [run_pretraining.py:  535]:	loss/mlm_loss, 7.0010576248168945, 2982
[INFO] 2021-07-12 19:31:31,609 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9809998522978276e-05, 2982
[INFO] 2021-07-12 19:31:31,609 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2982
[INFO] 2021-07-12 19:31:31,609 [run_pretraining.py:  558]:	worker_index: 7, step: 2982, cost: 7.001058, mlm loss: 7.001058, speed: 0.938471 steps/s, speed: 7.507765 samples/s, speed: 3843.975727 tokens/s, learning rate: 2.981e-05, loss_scalings: 2814.750488, pp_loss: 7.002170
[INFO] 2021-07-12 19:31:31,609 [run_pretraining.py:  512]:	********exe.run_2982******* 
[INFO] 2021-07-12 19:31:32,663 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:32,664 [run_pretraining.py:  534]:	loss/total_loss, 7.050415992736816, 2983
[INFO] 2021-07-12 19:31:32,664 [run_pretraining.py:  535]:	loss/mlm_loss, 7.050415992736816, 2983
[INFO] 2021-07-12 19:31:32,664 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9820001145708375e-05, 2983
[INFO] 2021-07-12 19:31:32,664 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2983
[INFO] 2021-07-12 19:31:32,664 [run_pretraining.py:  558]:	worker_index: 7, step: 2983, cost: 7.050416, mlm loss: 7.050416, speed: 0.948342 steps/s, speed: 7.586739 samples/s, speed: 3884.410369 tokens/s, learning rate: 2.982e-05, loss_scalings: 2814.750488, pp_loss: 7.065600
[INFO] 2021-07-12 19:31:32,664 [run_pretraining.py:  512]:	********exe.run_2983******* 
[INFO] 2021-07-12 19:31:33,725 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:33,725 [run_pretraining.py:  534]:	loss/total_loss, 7.032924175262451, 2984
[INFO] 2021-07-12 19:31:33,725 [run_pretraining.py:  535]:	loss/mlm_loss, 7.032924175262451, 2984
[INFO] 2021-07-12 19:31:33,725 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9829998311470263e-05, 2984
[INFO] 2021-07-12 19:31:33,725 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2984
[INFO] 2021-07-12 19:31:33,725 [run_pretraining.py:  558]:	worker_index: 7, step: 2984, cost: 7.032924, mlm loss: 7.032924, speed: 0.942958 steps/s, speed: 7.543665 samples/s, speed: 3862.356348 tokens/s, learning rate: 2.983e-05, loss_scalings: 2814.750488, pp_loss: 7.146091
[INFO] 2021-07-12 19:31:33,726 [run_pretraining.py:  512]:	********exe.run_2984******* 
[INFO] 2021-07-12 19:31:34,783 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:34,783 [run_pretraining.py:  534]:	loss/total_loss, 7.499045372009277, 2985
[INFO] 2021-07-12 19:31:34,783 [run_pretraining.py:  535]:	loss/mlm_loss, 7.499045372009277, 2985
[INFO] 2021-07-12 19:31:34,783 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.984000093420036e-05, 2985
[INFO] 2021-07-12 19:31:34,784 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2985
[INFO] 2021-07-12 19:31:34,784 [run_pretraining.py:  558]:	worker_index: 7, step: 2985, cost: 7.499045, mlm loss: 7.499045, speed: 0.945683 steps/s, speed: 7.565465 samples/s, speed: 3873.517897 tokens/s, learning rate: 2.984e-05, loss_scalings: 2814.750488, pp_loss: 7.513102
[INFO] 2021-07-12 19:31:34,784 [run_pretraining.py:  512]:	********exe.run_2985******* 
[INFO] 2021-07-12 19:31:35,936 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:35,936 [run_pretraining.py:  534]:	loss/total_loss, 7.154618263244629, 2986
[INFO] 2021-07-12 19:31:35,937 [run_pretraining.py:  535]:	loss/mlm_loss, 7.154618263244629, 2986
[INFO] 2021-07-12 19:31:35,937 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9849999918951653e-05, 2986
[INFO] 2021-07-12 19:31:35,937 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2986
[INFO] 2021-07-12 19:31:35,937 [run_pretraining.py:  558]:	worker_index: 7, step: 2986, cost: 7.154618, mlm loss: 7.154618, speed: 0.867649 steps/s, speed: 6.941192 samples/s, speed: 3553.890502 tokens/s, learning rate: 2.985e-05, loss_scalings: 2814.750488, pp_loss: 7.049767
[INFO] 2021-07-12 19:31:35,937 [run_pretraining.py:  512]:	********exe.run_2986******* 
[INFO] 2021-07-12 19:31:37,059 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:37,060 [run_pretraining.py:  534]:	loss/total_loss, 6.697552680969238, 2987
[INFO] 2021-07-12 19:31:37,060 [run_pretraining.py:  535]:	loss/mlm_loss, 6.697552680969238, 2987
[INFO] 2021-07-12 19:31:37,060 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9859998903702945e-05, 2987
[INFO] 2021-07-12 19:31:37,060 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2987
[INFO] 2021-07-12 19:31:37,060 [run_pretraining.py:  558]:	worker_index: 7, step: 2987, cost: 6.697553, mlm loss: 6.697553, speed: 0.890521 steps/s, speed: 7.124168 samples/s, speed: 3647.573980 tokens/s, learning rate: 2.986e-05, loss_scalings: 2814.750488, pp_loss: 7.222275
[INFO] 2021-07-12 19:31:37,060 [run_pretraining.py:  512]:	********exe.run_2987******* 
[INFO] 2021-07-12 19:31:38,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:38,147 [run_pretraining.py:  534]:	loss/total_loss, 7.625364780426025, 2988
[INFO] 2021-07-12 19:31:38,147 [run_pretraining.py:  535]:	loss/mlm_loss, 7.625364780426025, 2988
[INFO] 2021-07-12 19:31:38,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.986999970744364e-05, 2988
[INFO] 2021-07-12 19:31:38,147 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2988
[INFO] 2021-07-12 19:31:38,148 [run_pretraining.py:  558]:	worker_index: 7, step: 2988, cost: 7.625365, mlm loss: 7.625365, speed: 0.920433 steps/s, speed: 7.363465 samples/s, speed: 3770.093883 tokens/s, learning rate: 2.987e-05, loss_scalings: 2814.750488, pp_loss: 7.005195
[INFO] 2021-07-12 19:31:38,148 [run_pretraining.py:  512]:	********exe.run_2988******* 
[INFO] 2021-07-12 19:31:39,177 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:39,178 [run_pretraining.py:  534]:	loss/total_loss, 7.060837745666504, 2989
[INFO] 2021-07-12 19:31:39,178 [run_pretraining.py:  535]:	loss/mlm_loss, 7.060837745666504, 2989
[INFO] 2021-07-12 19:31:39,178 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.987999869219493e-05, 2989
[INFO] 2021-07-12 19:31:39,178 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2989
[INFO] 2021-07-12 19:31:39,178 [run_pretraining.py:  558]:	worker_index: 7, step: 2989, cost: 7.060838, mlm loss: 7.060838, speed: 0.970714 steps/s, speed: 7.765711 samples/s, speed: 3976.043849 tokens/s, learning rate: 2.988e-05, loss_scalings: 2814.750488, pp_loss: 7.205036
[INFO] 2021-07-12 19:31:39,178 [run_pretraining.py:  512]:	********exe.run_2989******* 
[INFO] 2021-07-12 19:31:40,084 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:40,085 [run_pretraining.py:  534]:	loss/total_loss, 7.9398956298828125, 2990
[INFO] 2021-07-12 19:31:40,085 [run_pretraining.py:  535]:	loss/mlm_loss, 7.9398956298828125, 2990
[INFO] 2021-07-12 19:31:40,085 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9889999495935626e-05, 2990
[INFO] 2021-07-12 19:31:40,085 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2990
[INFO] 2021-07-12 19:31:40,085 [run_pretraining.py:  558]:	worker_index: 7, step: 2990, cost: 7.939896, mlm loss: 7.939896, speed: 1.103504 steps/s, speed: 8.828030 samples/s, speed: 4519.951260 tokens/s, learning rate: 2.989e-05, loss_scalings: 2814.750488, pp_loss: 7.240184
[INFO] 2021-07-12 19:31:40,085 [run_pretraining.py:  512]:	********exe.run_2990******* 
[INFO] 2021-07-12 19:31:40,987 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:40,988 [run_pretraining.py:  534]:	loss/total_loss, 6.5540876388549805, 2991
[INFO] 2021-07-12 19:31:40,988 [run_pretraining.py:  535]:	loss/mlm_loss, 6.5540876388549805, 2991
[INFO] 2021-07-12 19:31:40,988 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9899998480686918e-05, 2991
[INFO] 2021-07-12 19:31:40,988 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2991
[INFO] 2021-07-12 19:31:40,988 [run_pretraining.py:  558]:	worker_index: 7, step: 2991, cost: 6.554088, mlm loss: 6.554088, speed: 1.108280 steps/s, speed: 8.866244 samples/s, speed: 4539.516737 tokens/s, learning rate: 2.990e-05, loss_scalings: 2814.750488, pp_loss: 6.906311
[INFO] 2021-07-12 19:31:40,988 [run_pretraining.py:  512]:	********exe.run_2991******* 
[INFO] 2021-07-12 19:31:41,896 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:41,897 [run_pretraining.py:  534]:	loss/total_loss, 7.377619743347168, 2992
[INFO] 2021-07-12 19:31:41,897 [run_pretraining.py:  535]:	loss/mlm_loss, 7.377619743347168, 2992
[INFO] 2021-07-12 19:31:41,897 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9910001103417017e-05, 2992
[INFO] 2021-07-12 19:31:41,897 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2992
[INFO] 2021-07-12 19:31:41,897 [run_pretraining.py:  558]:	worker_index: 7, step: 2992, cost: 7.377620, mlm loss: 7.377620, speed: 1.101057 steps/s, speed: 8.808456 samples/s, speed: 4509.929713 tokens/s, learning rate: 2.991e-05, loss_scalings: 2814.750488, pp_loss: 7.248303
[INFO] 2021-07-12 19:31:41,897 [run_pretraining.py:  512]:	********exe.run_2992******* 
[INFO] 2021-07-12 19:31:42,797 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:42,798 [run_pretraining.py:  534]:	loss/total_loss, 6.693830490112305, 2993
[INFO] 2021-07-12 19:31:42,798 [run_pretraining.py:  535]:	loss/mlm_loss, 6.693830490112305, 2993
[INFO] 2021-07-12 19:31:42,798 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9919998269178905e-05, 2993
[INFO] 2021-07-12 19:31:42,798 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2993
[INFO] 2021-07-12 19:31:42,798 [run_pretraining.py:  558]:	worker_index: 7, step: 2993, cost: 6.693830, mlm loss: 6.693830, speed: 1.110280 steps/s, speed: 8.882241 samples/s, speed: 4547.707264 tokens/s, learning rate: 2.992e-05, loss_scalings: 2814.750488, pp_loss: 7.150052
[INFO] 2021-07-12 19:31:42,798 [run_pretraining.py:  512]:	********exe.run_2993******* 
[INFO] 2021-07-12 19:31:43,707 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:43,708 [run_pretraining.py:  534]:	loss/total_loss, 7.166413307189941, 2994
[INFO] 2021-07-12 19:31:43,708 [run_pretraining.py:  535]:	loss/mlm_loss, 7.166413307189941, 2994
[INFO] 2021-07-12 19:31:43,708 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9929997253930196e-05, 2994
[INFO] 2021-07-12 19:31:43,708 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2994
[INFO] 2021-07-12 19:31:43,708 [run_pretraining.py:  558]:	worker_index: 7, step: 2994, cost: 7.166413, mlm loss: 7.166413, speed: 1.099762 steps/s, speed: 8.798096 samples/s, speed: 4504.624928 tokens/s, learning rate: 2.993e-05, loss_scalings: 2814.750488, pp_loss: 7.020625
[INFO] 2021-07-12 19:31:43,708 [run_pretraining.py:  512]:	********exe.run_2994******* 
[INFO] 2021-07-12 19:31:44,618 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:44,619 [run_pretraining.py:  534]:	loss/total_loss, 6.871789455413818, 2995
[INFO] 2021-07-12 19:31:44,619 [run_pretraining.py:  535]:	loss/mlm_loss, 6.871789455413818, 2995
[INFO] 2021-07-12 19:31:44,619 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9939999876660295e-05, 2995
[INFO] 2021-07-12 19:31:44,619 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2995
[INFO] 2021-07-12 19:31:44,619 [run_pretraining.py:  558]:	worker_index: 7, step: 2995, cost: 6.871789, mlm loss: 6.871789, speed: 1.098567 steps/s, speed: 8.788535 samples/s, speed: 4499.729748 tokens/s, learning rate: 2.994e-05, loss_scalings: 2814.750488, pp_loss: 7.108453
[INFO] 2021-07-12 19:31:44,619 [run_pretraining.py:  512]:	********exe.run_2995******* 
[INFO] 2021-07-12 19:31:45,521 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:45,522 [run_pretraining.py:  534]:	loss/total_loss, 6.905858993530273, 2996
[INFO] 2021-07-12 19:31:45,522 [run_pretraining.py:  535]:	loss/mlm_loss, 6.905858993530273, 2996
[INFO] 2021-07-12 19:31:45,522 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9949998861411586e-05, 2996
[INFO] 2021-07-12 19:31:45,522 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2996
[INFO] 2021-07-12 19:31:45,522 [run_pretraining.py:  558]:	worker_index: 7, step: 2996, cost: 6.905859, mlm loss: 6.905859, speed: 1.107992 steps/s, speed: 8.863939 samples/s, speed: 4538.336738 tokens/s, learning rate: 2.995e-05, loss_scalings: 2814.750488, pp_loss: 6.971364
[INFO] 2021-07-12 19:31:45,522 [run_pretraining.py:  512]:	********exe.run_2996******* 
[INFO] 2021-07-12 19:31:46,422 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:46,423 [run_pretraining.py:  534]:	loss/total_loss, 7.475874900817871, 2997
[INFO] 2021-07-12 19:31:46,423 [run_pretraining.py:  535]:	loss/mlm_loss, 7.475874900817871, 2997
[INFO] 2021-07-12 19:31:46,423 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.995999966515228e-05, 2997
[INFO] 2021-07-12 19:31:46,423 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2997
[INFO] 2021-07-12 19:31:46,423 [run_pretraining.py:  558]:	worker_index: 7, step: 2997, cost: 7.475875, mlm loss: 7.475875, speed: 1.110929 steps/s, speed: 8.887431 samples/s, speed: 4550.364465 tokens/s, learning rate: 2.996e-05, loss_scalings: 2814.750488, pp_loss: 7.168030
[INFO] 2021-07-12 19:31:46,423 [run_pretraining.py:  512]:	********exe.run_2997******* 
[INFO] 2021-07-12 19:31:47,324 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:47,325 [run_pretraining.py:  534]:	loss/total_loss, 7.478821277618408, 2998
[INFO] 2021-07-12 19:31:47,325 [run_pretraining.py:  535]:	loss/mlm_loss, 7.478821277618408, 2998
[INFO] 2021-07-12 19:31:47,325 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9969998649903573e-05, 2998
[INFO] 2021-07-12 19:31:47,325 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2998
[INFO] 2021-07-12 19:31:47,325 [run_pretraining.py:  558]:	worker_index: 7, step: 2998, cost: 7.478821, mlm loss: 7.478821, speed: 1.109214 steps/s, speed: 8.873712 samples/s, speed: 4543.340355 tokens/s, learning rate: 2.997e-05, loss_scalings: 2814.750488, pp_loss: 7.594429
[INFO] 2021-07-12 19:31:47,325 [run_pretraining.py:  512]:	********exe.run_2998******* 
[INFO] 2021-07-12 19:31:48,229 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:48,230 [run_pretraining.py:  534]:	loss/total_loss, 6.550876617431641, 2999
[INFO] 2021-07-12 19:31:48,230 [run_pretraining.py:  535]:	loss/mlm_loss, 6.550876617431641, 2999
[INFO] 2021-07-12 19:31:48,230 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.9979999453644268e-05, 2999
[INFO] 2021-07-12 19:31:48,230 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 2999
[INFO] 2021-07-12 19:31:48,230 [run_pretraining.py:  558]:	worker_index: 7, step: 2999, cost: 6.550877, mlm loss: 6.550877, speed: 1.106132 steps/s, speed: 8.849058 samples/s, speed: 4530.717519 tokens/s, learning rate: 2.998e-05, loss_scalings: 2814.750488, pp_loss: 6.854079
[INFO] 2021-07-12 19:31:48,230 [run_pretraining.py:  512]:	********exe.run_2999******* 
[INFO] 2021-07-12 19:31:49,147 [run_pretraining.py:  514]:	*******exe .run .end ******
[INFO] 2021-07-12 19:31:49,147 [run_pretraining.py:  534]:	loss/total_loss, 7.170666694641113, 3000
[INFO] 2021-07-12 19:31:49,147 [run_pretraining.py:  535]:	loss/mlm_loss, 7.170666694641113, 3000
[INFO] 2021-07-12 19:31:49,147 [run_pretraining.py:  536]:	lr/scheduled_lr, 2.998999843839556e-05, 3000
[INFO] 2021-07-12 19:31:49,147 [run_pretraining.py:  539]:	lr/loss_scaling, 2814.75048828125, 3000
[INFO] 2021-07-12 19:31:49,147 [run_pretraining.py:  558]:	worker_index: 7, step: 3000, cost: 7.170667, mlm loss: 7.170667, speed: 1.090783 steps/s, speed: 8.726264 samples/s, speed: 4467.847296 tokens/s, learning rate: 2.999e-05, loss_scalings: 2814.750488, pp_loss: 7.221375
[DEBUG] 2021-07-12 19:31:50,235 [run_pretraining.py:  575]:	saving final models to output/step3000-3p-bs8-npu_7/final_step_3000
[DEBUG] 2021-07-12 19:31:50,235 [run_pretraining.py:  576]:	end of training, total steps: 3000
I0712 19:31:50.235690 48466 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:50.235718 48466 blocking_queue.h:132] close queue
I0712 19:31:50.236291 51938 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:50.236338 51938 blocking_queue.h:132] close queue
I0712 19:31:57.408577 48466 reader.h:164] ~ReaderHolder
I0712 19:31:57.408656 48466 buffered_reader.cc:22] ~BufferedReader
I0712 19:31:57.408668 48466 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:57.408674 48466 blocking_queue.h:132] close queue
I0712 19:31:57.408859 48466 reader.cc:76] ~DecoratedReader
I0712 19:31:57.408869 48466 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:57.408874 48466 blocking_queue.h:132] close queue
I0712 19:31:57.408881 48466 lod_tensor_blocking_queue.h:59] LoDTensorBlockingQueue close
I0712 19:31:57.408910 48466 blocking_queue.h:132] close queue
I0712 19:31:57.409956 48466 reader.h:164] ~ReaderHolder
